{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Get-Pretrained-Params\" data-toc-modified-id=\"Get-Pretrained-Params-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Get Pretrained Params</a></span></li><li><span><a href=\"#Transfer-Weights\" data-toc-modified-id=\"Transfer-Weights-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Transfer Weights</a></span></li><li><span><a href=\"#Prune-w/-SBP\" data-toc-modified-id=\"Prune-w/-SBP-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Prune w/ SBP</a></span></li><li><span><a href=\"#Resume-Training\" data-toc-modified-id=\"Resume-Training-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Resume Training</a></span></li><li><span><a href=\"#Get-Mask-&amp;-Prune-Network\" data-toc-modified-id=\"Get-Mask-&amp;-Prune-Network-0.5\"><span class=\"toc-item-num\">0.5&nbsp;&nbsp;</span>Get Mask &amp; Prune Network</a></span></li><li><span><a href=\"#PTFLOPS\" data-toc-modified-id=\"PTFLOPS-0.6\"><span class=\"toc-item-num\">0.6&nbsp;&nbsp;</span>PTFLOPS</a></span></li><li><span><a href=\"#Flop-weighted-importance\" data-toc-modified-id=\"Flop-weighted-importance-0.7\"><span class=\"toc-item-num\">0.7&nbsp;&nbsp;</span>Flop weighted importance</a></span></li><li><span><a href=\"#Layer-index\" data-toc-modified-id=\"Layer-index-0.8\"><span class=\"toc-item-num\">0.8&nbsp;&nbsp;</span>Layer index</a></span></li><li><span><a href=\"#Correlated-Net\" data-toc-modified-id=\"Correlated-Net-0.9\"><span class=\"toc-item-num\">0.9&nbsp;&nbsp;</span>Correlated Net</a></span></li><li><span><a href=\"#Decorrelated-net\" data-toc-modified-id=\"Decorrelated-net-0.10\"><span class=\"toc-item-num\">0.10&nbsp;&nbsp;</span>Decorrelated net</a></span></li></ul></li><li><span><a href=\"#Subplots\" data-toc-modified-id=\"Subplots-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Subplots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Net-Slim-Train\" data-toc-modified-id=\"Net-Slim-Train-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Net-Slim Train</a></span></li><li><span><a href=\"#L2-based-pruning-Train\" data-toc-modified-id=\"L2-based-pruning-Train-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>L2 based pruning Train</a></span><ul class=\"toc-item\"><li><span><a href=\"#Importance-plots-Netslim-Train\" data-toc-modified-id=\"Importance-plots-Netslim-Train-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Importance plots Netslim Train</a></span></li><li><span><a href=\"#Importance-plots-L2-train\" data-toc-modified-id=\"Importance-plots-L2-train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Importance plots L2 train</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-/\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SBP_alexnet import SBPConv_AlexNet\n",
    "import SBP_utils_gpu as SBP_utils\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomRotation(45),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "     ])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./../data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg, classes=100):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, cfg[0], kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[0]),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(cfg[0], cfg[1], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[1]),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[2]),\n",
    "            \n",
    "            nn.Conv2d(cfg[2], cfg[3], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[3]),\n",
    "            \n",
    "            nn.Conv2d(cfg[3], cfg[4], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[4]),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(cfg[4] * 1 * 1, cfg[5]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(cfg[5], cfg[6]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(cfg[6], classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_test(epoch,net, criterion = nn.CrossEntropyLoss()):\n",
    "    global best_base_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_base_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/alex_ckpt.pth')\n",
    "        best_base_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def SBP_net_train(epoch,net,optimizer,criterion = nn.CrossEntropyLoss(),lr_adjust=None, scheduler=None):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs,kl = net(inputs)\n",
    "        \n",
    "        #have to add the KL divergence while training for the SBP layers\n",
    "        loss = criterion(outputs, targets) + kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    if lr_adjust:\n",
    "        lr_adjust(optimizer,epoch)\n",
    "    if scheduler:\n",
    "        scheduler.step()\n",
    "    return \n",
    "def SBP_net_test(epoch,net,criterion= nn.CrossEntropyLoss()):\n",
    "    global best_sbp_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item() \n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_sbp_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/sbp_ckpt.pth')\n",
    "        best_spb_acc = acc\n",
    "         \n",
    "    net.get_sparsity()\n",
    "    return acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "__all__ = ['accuracy']\n",
    "\n",
    "def kaccuracy(output, target, topk=(5,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def top5cal(net):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            acc1, acc5 = kaccuracy(outputs, targets, topk=(1, 5))\n",
    "            top1 += (acc1.item()*inputs.shape[0])\n",
    "            top5 += (acc5.item()*inputs.shape[0])\n",
    "    top1 /= 10000\n",
    "    top5 /= 10000\n",
    "    \n",
    "    print(\"top5\", top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pretrained Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = [64, 192, 384, 256, 256, 4096, 4096]\n",
    "best_sbp_acc = best_base_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = AlexNet(cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dict = torch.load('./pretrained_alex.pth')\n",
    "best_net.load_state_dict(net_dict['net'])\n",
    "best_acc = net_dict['best_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 7ms | Tot: 794ms | Loss: 1.950 | Acc: 50.960% (5096/1000 79/79 43/79 ........]  Step: 12ms | Tot: 459ms | Loss: 1.948 | Acc: 50.538% (2911/576 45/7 56/79 \n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "## check pretrained accuracy 51%\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "net_test(1,best_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_base_acc:  50.96\n"
     ]
    }
   ],
   "source": [
    "print('best_base_acc: ',best_base_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sbp_acc = best_base_acc = 0 #reset best accuracy to save after running SBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_weights = cfg\n",
    "all_ones = [1] * 10\n",
    "sbp_net = SBPConv_AlexNet(cfg,kl_weights=all_ones).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#block 1\n",
    "\n",
    "def transfer_weights(sbp_net):\n",
    "    sbp_net.block1.conv1.weight = best_net.features[0].weight\n",
    "    sbp_net.block1.conv1.bias = best_net.features[0].bias\n",
    "    sbp_net.block1.bn1.weight = best_net.features[2].weight\n",
    "    sbp_net.block1.bn1.bias = best_net.features[2].bias\n",
    "\n",
    "    #block 2\n",
    "    sbp_net.block2.conv1.weight = best_net.features[4].weight\n",
    "    sbp_net.block2.conv1.bias = best_net.features[4].bias\n",
    "    sbp_net.block2.bn1.weight = best_net.features[6].weight\n",
    "    sbp_net.block2.bn1.bias = best_net.features[6].bias\n",
    "\n",
    "    #block 3\n",
    "    sbp_net.block3.conv1.weight = best_net.features[8].weight\n",
    "    sbp_net.block3.conv1.bias = best_net.features[8].bias\n",
    "    sbp_net.block3.bn1.weight = best_net.features[10].weight\n",
    "    sbp_net.block3.bn1.bias = best_net.features[10].bias\n",
    "\n",
    "    #block 4\n",
    "    sbp_net.block4.conv1.weight = best_net.features[11].weight\n",
    "    sbp_net.block4.conv1.bias = best_net.features[11].bias\n",
    "    sbp_net.block4.bn1.weight = best_net.features[13].weight\n",
    "    sbp_net.block4.bn1.bias = best_net.features[13].bias\n",
    "\n",
    "\n",
    "    #block 5\n",
    "    sbp_net.block5.conv1.weight = best_net.features[14].weight\n",
    "    sbp_net.block5.conv1.bias = best_net.features[14].bias\n",
    "    sbp_net.block5.bn1.weight = best_net.features[16].weight\n",
    "    sbp_net.block5.bn1.bias = best_net.features[16].bias\n",
    "\n",
    "    #note! Im not using SBP layers in the classifier right now. \n",
    "    #Otherwise, would need to transfer code here as well!\n",
    "    sbp_net.lsbp1.weight = best_net.classifier[1].weight\n",
    "    sbp_net.lsbp1.bias = best_net.classifier[1].bias\n",
    "\n",
    "    sbp_net.lsbp2.weight = best_net.classifier[4].weight\n",
    "    sbp_net.lsbp2.bias = best_net.classifier[4].bias\n",
    "    \n",
    "    return sbp_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Weights After Transferring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 45ms | Tot: 3s815ms | Loss: 4.613 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(246.9508, device='cuda:0'), tensor(246.9508, device='cuda:0'), tensor(246.9508, device='cuda:0'), tensor(246.9508, device='cuda:0'), tensor(246.9508, device='cuda:0'), tensor(246.9508, device='cuda:0'), tensor(246.9508, device='cuda:0')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#its not that terrifying that the accuracy is trash \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "SBP_net_test(1,sbp_net,criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune w/ SBP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First attempt w/ lr. This is no longer being used. Here for completeness.\n",
    "\n",
    "sbp_learningrate = 1e-5\n",
    "finetune_epoch = 300 ## that seems excessive\n",
    "\n",
    "kl_weights = cfg\n",
    "all_ones = [1] * 10\n",
    "sbp_net = SBPConv_AlexNet(cfg,kl_weights=cfg).to(device)\n",
    "\n",
    "optimizer = optim.Adam(sbp_net.parameters(), lr=sbp_learningrate, betas=[0.95,0.999])\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size= 250,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 69ms | Tot: 24s49ms | Loss: 66854.630 | Acc: 18.832% (9416/5000 391/391  1 69/391 .......]  Step: 68ms | Tot: 4s938ms | Loss: 67715.683 | Acc: 4.124% (417/1011 79/391 ....]  Step: 64ms | Tot: 5s71ms | Loss: 67710.069 | Acc: 4.167% (432/1036 81/391 =====>...................]  Step: 58ms | Tot: 5s732ms | Loss: 67682.008 | Acc: 4.851% (565/1164 91/391 ===============>.........]  Step: 61ms | Tot: 14s609ms | Loss: 67272.197 | Acc: 12.726% (3877/3046 238/391 379/391 380/39 389/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s523ms | Loss: 3.620 | Acc: 37.410% (3741/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(207.3631, device='cuda:0'), tensor(207.3631, device='cuda:0'), tensor(207.3631, device='cuda:0'), tensor(207.3631, device='cuda:0'), tensor(207.3631, device='cuda:0'), tensor(207.9739, device='cuda:0'), tensor(207.9592, device='cuda:0')]\n",
      "\n",
      "Epoch: 1\n",
      " [========================>]  Step: 70ms | Tot: 24s731ms | Loss: 64879.343 | Acc: 45.196% (22598/5000 391/391 ...........]  Step: 50ms | Tot: 598ms | Loss: 65773.331 | Acc: 34.896% (536/153 12/39 114/391 123/39 125/391 ..]  Step: 66ms | Tot: 11s458ms | Loss: 65331.458 | Acc: 41.034% (10032/2444 191/39 228/39 232/391 =======>..........]  Step: 70ms | Tot: 14s138ms | Loss: 65232.615 | Acc: 42.268% (12606/2982 233/39 234/391 .........]  Step: 68ms | Tot: 14s653ms | Loss: 65214.015 | Acc: 42.440% (13092/3084 241/391 275/39 276/391 ==>.......]  Step: 68ms | Tot: 17s155ms | Loss: 65124.397 | Acc: 43.345% (15535/3584 280/39 283/391 ==========>......]  Step: 71ms | Tot: 17s428ms | Loss: 65115.307 | Acc: 43.395% (15775/3635 284/391 ===========>......]  Step: 67ms | Tot: 17s558ms | Loss: 65110.768 | Acc: 43.441% (15903/3660 286/391 ============>......]  Step: 70ms | Tot: 18s33ms | Loss: 65094.922 | Acc: 43.593% (16349/3750 293/391 ===========>......]  Step: 67ms | Tot: 18s374ms | Loss: 65083.639 | Acc: 43.684% (16663/3814 298/39 333/39 335/39 343/39 346/391 =================>.]  Step: 61ms | Tot: 22s742ms | Loss: 64941.902 | Acc: 44.721% (20722/4633 362/39 377/391 ======================>]  Step: 64ms | Tot: 24s246ms | Loss: 64894.347 | Acc: 45.103% (22169/4915 384/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s521ms | Loss: 2.459 | Acc: 46.580% (4658/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(181.1531, device='cuda:0'), tensor(181.1544, device='cuda:0'), tensor(181.1531, device='cuda:0'), tensor(181.1531, device='cuda:0'), tensor(181.1531, device='cuda:0'), tensor(180.7624, device='cuda:0'), tensor(180.7803, device='cuda:0')]\n",
      "\n",
      "Epoch: 2\n",
      " [========================>]  Step: 63ms | Tot: 25s478ms | Loss: 63403.365 | Acc: 53.240% (26620/5000 391/391 /39 15/391 29/39 32/391 .................]  Step: 64ms | Tot: 2s536ms | Loss: 63968.371 | Acc: 50.684% (2595/512 40/391 ....................]  Step: 68ms | Tot: 2s735ms | Loss: 63962.860 | Acc: 50.727% (2792/550 43/391 44/39 57/391 66/39 87/39 88/391 94/39 97/391 102/391 129/391 ====>................]  Step: 72ms | Tot: 9s5ms | Loss: 63792.774 | Acc: 52.018% (9255/1779 139/391 .............]  Step: 69ms | Tot: 10s64ms | Loss: 63765.618 | Acc: 52.046% (10326/1984 155/391 =======>...............]  Step: 71ms | Tot: 10s195ms | Loss: 63762.247 | Acc: 52.070% (10464/2009 157/391 ===========>.............]  Step: 70ms | Tot: 11s375ms | Loss: 63732.148 | Acc: 52.121% (11675/2240 175/39 192/391 ...]  Step: 70ms | Tot: 12s698ms | Loss: 63699.206 | Acc: 52.208% (13031/2496 195/39 204/391 ...]  Step: 69ms | Tot: 13s495ms | Loss: 63679.688 | Acc: 52.249% (13844/2649 207/391 ===>...........]  Step: 70ms | Tot: 14s291ms | Loss: 63660.356 | Acc: 52.358% (14677/2803 219/391 ..........]  Step: 70ms | Tot: 14s554ms | Loss: 63653.953 | Acc: 52.417% (14962/2854 223/39 244/39 247/391 .......]  Step: 69ms | Tot: 16s662ms | Loss: 63603.483 | Acc: 52.693% (17199/3264 255/391 ==============>........]  Step: 72ms | Tot: 16s796ms | Loss: 63600.373 | Acc: 52.696% (17335/3289 257/391 ===========>........]  Step: 63ms | Tot: 17s388ms | Loss: 63586.439 | Acc: 52.729% (17953/3404 266/39 268/391 =======>.......]  Step: 70ms | Tot: 17s721ms | Loss: 63578.741 | Acc: 52.776% (18307/3468 271/39 275/391 ]  Step: 68ms | Tot: 19s963ms | Loss: 63527.241 | Acc: 52.928% (20663/3904 305/391 313/391 ================>....]  Step: 70ms | Tot: 20s618ms | Loss: 63512.370 | Acc: 52.939% (21345/4032 315/391 ===========>....]  Step: 61ms | Tot: 21s84ms | Loss: 63502.034 | Acc: 52.999% (21844/4121 322/391 ===>....]  Step: 69ms | Tot: 21s285ms | Loss: 63497.623 | Acc: 53.026% (22059/4160 325/391 337/391 =====>.]  Step: 70ms | Tot: 23s645ms | Loss: 63445.555 | Acc: 53.194% (24580/4620 361/391 371/391 ======>]  Step: 74ms | Tot: 24s553ms | Loss: 63422.919 | Acc: 53.282% (25712/4825 377/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s521ms | Loss: 2.066 | Acc: 48.870% (4887/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(164.1757, device='cuda:0'), tensor(164.1472, device='cuda:0'), tensor(164.1658, device='cuda:0'), tensor(164.1537, device='cuda:0'), tensor(164.1472, device='cuda:0'), tensor(165.5558, device='cuda:0'), tensor(165.5764, device='cuda:0')]\n",
      "\n",
      "Epoch: 3\n",
      " [========================>]  Step: 64ms | Tot: 21s682ms | Loss: 62483.495 | Acc: 55.052% (27526/5000 391/391 ............]  Step: 49ms | Tot: 50ms | Loss: 62858.203 | Acc: 56.641% (145/25 2/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s611ms | Loss: 1.971 | Acc: 49.290% (4929/1000 79/79 ========>..............]  Step: 65ms | Tot: 1s564ms | Loss: 1.958 | Acc: 48.594% (2177/448 35/79 ...........]  Step: 45ms | Tot: 1s655ms | Loss: 1.961 | Acc: 48.775% (2310/473 37/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(157.9760, device='cuda:0'), tensor(158.0722, device='cuda:0'), tensor(158.0343, device='cuda:0'), tensor(158.0688, device='cuda:0'), tensor(158.0915, device='cuda:0'), tensor(157.2785, device='cuda:0'), tensor(157.3023, device='cuda:0')]\n",
      "\n",
      "Epoch: 4\n",
      " [========================>]  Step: 62ms | Tot: 25s244ms | Loss: 61960.758 | Acc: 56.314% (28157/5000 391/391 91 .]  Step: 64ms | Tot: 4s262ms | Loss: 62129.140 | Acc: 55.265% (4881/883 69/391 ...............]  Step: 62ms | Tot: 5s98ms | Loss: 62121.303 | Acc: 55.107% (5784/1049 82/39 88/391  101/391 ..............]  Step: 63ms | Tot: 7s107ms | Loss: 62103.013 | Acc: 55.275% (7995/1446 113/391 116/39 119/39 121/391 ..............]  Step: 67ms | Tot: 8s349ms | Loss: 62092.073 | Acc: 55.350% (9352/1689 132/391 ...]  Step: 64ms | Tot: 9s327ms | Loss: 62083.582 | Acc: 55.447% (10433/1881 147/391 151/39 157/391 ======>.............]  Step: 66ms | Tot: 11s465ms | Loss: 62065.304 | Acc: 55.694% (12832/2304 180/39 181/391 182/391 .........]  Step: 69ms | Tot: 11s796ms | Loss: 62062.584 | Acc: 55.667% (13182/2368 185/39 186/391 =======>............]  Step: 69ms | Tot: 12s58ms | Loss: 62060.419 | Acc: 55.642% (13461/2419 189/391 ====>............]  Step: 63ms | Tot: 12s122ms | Loss: 62059.879 | Acc: 55.617% (13526/2432 190/39 195/391 197/391 ............]  Step: 67ms | Tot: 12s653ms | Loss: 62055.574 | Acc: 55.607% (14093/25 198/391  199/39 207/391 =====>...........]  Step: 64ms | Tot: 13s505ms | Loss: 62048.644 | Acc: 55.728% (15051/2700 211/391 235/39 238/39 239/39 246/391 =========>........]  Step: 69ms | Tot: 16s913ms | Loss: 62021.749 | Acc: 55.902% (18819/3366 263/39 264/391 265/391 269/39 275/391 =================>.......]  Step: 66ms | Tot: 17s762ms | Loss: 62015.225 | Acc: 55.964% (19771/3532 276/391 278/391 279/391 287/391  300/39 302/391 304/391 ==========>.....]  Step: 66ms | Tot: 20s115ms | Loss: 61997.559 | Acc: 56.065% (22390/3993 312/391 314/391 320/39 332/391 ==============>...]  Step: 69ms | Tot: 21s494ms | Loss: 61987.517 | Acc: 56.208% (23958/4262 333/391 =====================>...]  Step: 62ms | Tot: 21s557ms | Loss: 61987.044 | Acc: 56.220% (24035/4275 334/391 338/391 ===========>...]  Step: 66ms | Tot: 22s213ms | Loss: 61982.335 | Acc: 56.171% (24733/4403 344/39 346/39 351/391 353/39 367/39 377/391 387/39 389/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s524ms | Loss: 1.948 | Acc: 49.760% (4976/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(151.9781, device='cuda:0'), tensor(151.9720, device='cuda:0'), tensor(151.9770, device='cuda:0'), tensor(151.9781, device='cuda:0'), tensor(151.9781, device='cuda:0'), tensor(150.9995, device='cuda:0'), tensor(151.0058, device='cuda:0')]\n",
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 60ms | Tot: 23s756ms | Loss: 61660.916 | Acc: 57.142% (28571/5000 391/391  Step: 66ms | Tot: 1s271ms | Loss: 61777.260 | Acc: 55.841% (1501/268 21/39 43/39 44/391 45/391 ==>......................]  Step: 67ms | Tot: 2s873ms | Loss: 61768.272 | Acc: 55.859% (3289/588 46/391 51/391 58/39 61/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s511ms | Loss: 1.946 | Acc: 49.960% (4996/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(149.0000, device='cuda:0'), tensor(149.0020, device='cuda:0'), tensor(148.9927, device='cuda:0'), tensor(149.0003, device='cuda:0'), tensor(149.0062, device='cuda:0'), tensor(148.6904, device='cuda:0'), tensor(148.6919, device='cuda:0')]\n",
      "\n",
      "Epoch: 6\n",
      " [========================>]  Step: 61ms | Tot: 25s257ms | Loss: 61476.320 | Acc: 57.572% (28786/5000 391/391 : 68ms | Tot: 265ms | Loss: 61554.082 | Acc: 54.688% (350/64 5/391  6/39 9/391 ....]  Step: 65ms | Tot: 591ms | Loss: 61552.936 | Acc: 55.781% (714/128 10/391 13/39 27/391 =>.......................]  Step: 64ms | Tot: 1s831ms | Loss: 61548.622 | Acc: 56.519% (2098/371 29/391 37/391 41/39 43/39 47/39 65/39 81/39 95/39 122/39 123/391 132/39 134/39 156/391 ............]  Step: 67ms | Tot: 10s210ms | Loss: 61520.810 | Acc: 57.189% (11566/2022 158/39 171/391 173/39 177/39 185/39 193/391 ..........]  Step: 68ms | Tot: 12s610ms | Loss: 61513.291 | Acc: 57.131% (14260/2496 195/39 197/391 198/391 200/391 201/391 207/39 209/39 215/391 ======>...........]  Step: 73ms | Tot: 14s124ms | Loss: 61508.704 | Acc: 57.175% (15954/2790 218/391 219/391 ===>..........]  Step: 70ms | Tot: 14s383ms | Loss: 61507.912 | Acc: 57.271% (16274/28 222/391 ======>..........]  Step: 69ms | Tot: 14s645ms | Loss: 61507.125 | Acc: 57.249% (16561/2892 226/391 ==============>..........]  Step: 69ms | Tot: 14s776ms | Loss: 61506.734 | Acc: 57.203% (16694/2918 228/391 ......]  Step: 69ms | Tot: 16s351ms | Loss: 61502.051 | Acc: 57.313% (18487/3225 252/39 258/39 262/391 >........]  Step: 69ms | Tot: 17s136ms | Loss: 61499.739 | Acc: 57.360% (19383/3379 264/391 ......]  Step: 68ms | Tot: 17s267ms | Loss: 61499.357 | Acc: 57.343% (19524/3404 266/391 301/391 ============>....]  Step: 71ms | Tot: 20s926ms | Loss: 61488.628 | Acc: 57.498% (23772/4134 323/391 ============>....]  Step: 69ms | Tot: 21s187ms | Loss: 61487.889 | Acc: 57.526% (24078/4185 327/391 ===============>....]  Step: 68ms | Tot: 21s316ms | Loss: 61487.521 | Acc: 57.528% (24226/4211 329/391 ===========>...]  Step: 70ms | Tot: 21s447ms | Loss: 61487.152 | Acc: 57.546% (24381/4236 331/391 348/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s556ms | Loss: 1.951 | Acc: 50.030% (5003/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(146.6345, device='cuda:0'), tensor(146.6403, device='cuda:0'), tensor(146.6255, device='cuda:0'), tensor(146.6537, device='cuda:0'), tensor(146.6520, device='cuda:0'), tensor(146.6573, device='cuda:0'), tensor(146.6468, device='cuda:0')]\n",
      "\n",
      "Epoch: 7\n",
      " [========================>]  Step: 48ms | Tot: 23s369ms | Loss: 61351.939 | Acc: 57.654% (28827/5000 391/391 /391 ................]  Step: 71ms | Tot: 8s107ms | Loss: 61386.870 | Acc: 57.078% (9790/1715 134/39 140/391 =====>...............]  Step: 70ms | Tot: 8s762ms | Loss: 61385.425 | Acc: 57.134% (10531/1843 144/391 =========>...............]  Step: 70ms | Tot: 9s288ms | Loss: 61384.271 | Acc: 57.257% (11140/1945 152/391 154/391  158/391 ===========>.............]  Step: 72ms | Tot: 10s682ms | Loss: 61381.131 | Acc: 57.188% (12737/2227 174/39 180/391 ===========>.............]  Step: 71ms | Tot: 11s598ms | Loss: 61379.149 | Acc: 57.310% (13791/2406 188/39 209/391 ==============>..........]  Step: 51ms | Tot: 14s288ms | Loss: 61372.742 | Acc: 57.322% (17169/2995 234/39 269/39 298/391 ========>.....]  Step: 47ms | Tot: 18s272ms | Loss: 61363.801 | Acc: 57.586% (22113/3840 300/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s440ms | Loss: 1.955 | Acc: 49.970% (4997/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(145.2052, device='cuda:0'), tensor(145.2205, device='cuda:0'), tensor(145.2202, device='cuda:0'), tensor(145.2542, device='cuda:0'), tensor(145.2223, device='cuda:0'), tensor(145.3037, device='cuda:0'), tensor(145.3162, device='cuda:0')]\n",
      "\n",
      "Epoch: 8\n",
      " [========================>]  Step: 56ms | Tot: 22s793ms | Loss: 61260.093 | Acc: 58.338% (29169/5000 391/391 96/39 298/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s557ms | Loss: 1.964 | Acc: 49.900% (4990/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(145.6074, device='cuda:0'), tensor(145.5469, device='cuda:0'), tensor(145.5626, device='cuda:0'), tensor(145.4458, device='cuda:0'), tensor(145.5694, device='cuda:0'), tensor(144.2107, device='cuda:0'), tensor(144.2222, device='cuda:0')]\n",
      "\n",
      "Epoch: 9\n",
      " [========================>]  Step: 71ms | Tot: 24s680ms | Loss: 61186.833 | Acc: 58.364% (29182/50000390/391 3/39 42/391 62/391 230/391 235/391 ===========>........]  Step: 68ms | Tot: 16s13ms | Loss: 61198.187 | Acc: 58.267% (19093/3276 256/391 ..]  Step: 64ms | Tot: 16s861ms | Loss: 61197.071 | Acc: 58.254% (20058/3443 269/39 278/39 279/391 .]  Step: 67ms | Tot: 17s890ms | Loss: 61195.700 | Acc: 58.262% (21254/3648 285/39 289/391 291/39 294/391 =======>......]  Step: 68ms | Tot: 18s547ms | Loss: 61194.848 | Acc: 58.305% (22016/3776 295/39 297/391 316/391 ===========>....]  Step: 63ms | Tot: 20s412ms | Loss: 61192.398 | Acc: 58.377% (24210/4147 324/39 329/391 336/391 339/391 341/391  343/391 ]  Step: 64ms | Tot: 22s220ms | Loss: 61190.055 | Acc: 58.441% (26331/4505 352/391 361/391 ==================>.]  Step: 69ms | Tot: 23s548ms | Loss: 61188.314 | Acc: 58.430% (27897/4774 373/391 =======================>.]  Step: 65ms | Tot: 23s679ms | Loss: 61188.149 | Acc: 58.446% (28054/4800 375/391 391/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s433ms | Loss: 1.966 | Acc: 50.020% (5002/1000 79/79 ................]  Step: 42ms | Tot: 202ms | Loss: 2.125 | Acc: 46.875% (300/64 5/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(144.5139, device='cuda:0'), tensor(144.5075, device='cuda:0'), tensor(144.3549, device='cuda:0'), tensor(144.2810, device='cuda:0'), tensor(144.6321, device='cuda:0'), tensor(143.2076, device='cuda:0'), tensor(143.2185, device='cuda:0')]\n",
      "\n",
      "Epoch: 10\n",
      " [========================>]  Step: 64ms | Tot: 20s150ms | Loss: 61125.812 | Acc: 58.666% (29333/5000 391/391 55/391 ================>........]  Step: 56ms | Tot: 12s822ms | Loss: 61135.529 | Acc: 58.636% (19214/3276 256/39 259/391 ============>...]  Step: 45ms | Tot: 17s46ms | Loss: 61129.957 | Acc: 58.605% (24980/4262 333/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s548ms | Loss: 1.971 | Acc: 50.040% (5004/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(144.0903, device='cuda:0'), tensor(144.0573, device='cuda:0'), tensor(143.9492, device='cuda:0'), tensor(143.8068, device='cuda:0'), tensor(144.1480, device='cuda:0'), tensor(143.0309, device='cuda:0'), tensor(143.0141, device='cuda:0')]\n",
      "\n",
      "Epoch: 11\n",
      " [========================>]  Step: 54ms | Tot: 22s204ms | Loss: 61072.085 | Acc: 58.926% (29463/5000 391/391 39 84/391 ]  Step: 54ms | Tot: 5s362ms | Loss: 61091.608 | Acc: 57.969% (7049/1216 95/391 96/391 ======>..................]  Step: 53ms | Tot: 5s464ms | Loss: 61091.471 | Acc: 57.957% (7196/1241 97/391 ======>..................]  Step: 49ms | Tot: 5s561ms | Loss: 61091.340 | Acc: 57.939% (7342/1267 99/391 ======>..................]  Step: 49ms | Tot: 5s611ms | Loss: 61091.272 | Acc: 57.984% (7422/1280 100/39 101/391 ======>..................]  Step: 52ms | Tot: 5s713ms | Loss: 61091.136 | Acc: 58.042% (7578/1305 102/39 158/391 383/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s530ms | Loss: 1.974 | Acc: 50.110% (5011/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(142.1577, device='cuda:0'), tensor(142.1582, device='cuda:0'), tensor(142.4304, device='cuda:0'), tensor(142.5729, device='cuda:0'), tensor(142.0845, device='cuda:0'), tensor(143.2438, device='cuda:0'), tensor(143.3223, device='cuda:0')]\n",
      "\n",
      "Epoch: 12\n",
      " [========================>]  Step: 67ms | Tot: 21s569ms | Loss: 61022.855 | Acc: 59.224% (29612/5000 391/391  31/391 136/39 148/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s531ms | Loss: 1.976 | Acc: 50.290% (5029/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(138.5478, device='cuda:0'), tensor(138.6043, device='cuda:0'), tensor(138.8086, device='cuda:0'), tensor(138.8451, device='cuda:0'), tensor(138.4857, device='cuda:0'), tensor(140.2587, device='cuda:0'), tensor(140.2620, device='cuda:0')]\n",
      "\n",
      "Epoch: 13\n",
      " [========================>]  Step: 56ms | Tot: 23s314ms | Loss: 60976.626 | Acc: 59.226% (29613/5000 391/391 91 \n",
      " [========================>]  Step: 49ms | Tot: 3s548ms | Loss: 1.977 | Acc: 50.110% (5011/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(139.2267, device='cuda:0'), tensor(139.1635, device='cuda:0'), tensor(139.2640, device='cuda:0'), tensor(139.2632, device='cuda:0'), tensor(139.1469, device='cuda:0'), tensor(140.0314, device='cuda:0'), tensor(139.9785, device='cuda:0')]\n",
      "\n",
      "Epoch: 14\n",
      " [========================>]  Step: 67ms | Tot: 23s849ms | Loss: 60932.538 | Acc: 59.386% (29693/5000 391/391 192/391 .]  Step: 64ms | Tot: 16s374ms | Loss: 60939.282 | Acc: 59.223% (20316/3430 268/391 315/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s572ms | Loss: 1.985 | Acc: 50.210% (5021/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(139.9142, device='cuda:0'), tensor(140.1258, device='cuda:0'), tensor(139.7344, device='cuda:0'), tensor(139.6156, device='cuda:0'), tensor(140.1911, device='cuda:0'), tensor(138.8182, device='cuda:0'), tensor(138.8075, device='cuda:0')]\n",
      "\n",
      "Epoch: 15\n",
      " [========================>]  Step: 61ms | Tot: 23s15ms | Loss: 60891.118 | Acc: 59.542% (29771/5000 391/391  9 35/391 ...................]  Step: 68ms | Tot: 2s958ms | Loss: 60908.928 | Acc: 58.268% (3580/614 48/391 ...]  Step: 63ms | Tot: 3s21ms | Loss: 60908.876 | Acc: 58.307% (3657/627 49/39 57/391 ]  Step: 64ms | Tot: 3s606ms | Loss: 60908.409 | Acc: 58.270% (4326/742 58/391 .......]  Step: 52ms | Tot: 13s697ms | Loss: 60899.693 | Acc: 59.444% (17120/2880 225/391 ......]  Step: 51ms | Tot: 14s292ms | Loss: 60899.073 | Acc: 59.438% (18031/3033 237/391 =====>.........]  Step: 53ms | Tot: 14s659ms | Loss: 60898.711 | Acc: 59.413% (18556/3123 244/391 ===========>.........]  Step: 47ms | Tot: 14s707ms | Loss: 60898.659 | Acc: 59.401% (18628/3136 245/39 247/39 260/391 =================>.......]  Step: 47ms | Tot: 15s914ms | Loss: 60897.414 | Acc: 59.526% (20496/3443 269/39 271/391 ============>......]  Step: 54ms | Tot: 16s687ms | Loss: 60896.639 | Acc: 59.438% (21607/3635 284/391 295/391 =====>.....]  Step: 46ms | Tot: 17s762ms | Loss: 60895.557 | Acc: 59.352% (23171/3904 305/391 >.....]  Step: 47ms | Tot: 18s68ms | Loss: 60895.246 | Acc: 59.355% (23628/3980 311/391 312/391 .]  Step: 48ms | Tot: 18s168ms | Loss: 60895.143 | Acc: 59.350% (23778/4006 313/39 342/39 343/39 344/391 ===============>..]  Step: 64ms | Tot: 20s249ms | Loss: 60893.335 | Acc: 59.440% (26477/4454 348/391 ========>..]  Step: 68ms | Tot: 20s520ms | Loss: 60893.127 | Acc: 59.473% (26796/4505 352/391 ======================>..]  Step: 69ms | Tot: 20s721ms | Loss: 60892.973 | Acc: 59.485% (27030/45 355/391  362/391   Step: 66ms | Tot: 21s306ms | Loss: 60892.510 | Acc: 59.442% (27695/4659 364/391 366/39 368/391 370/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s534ms | Loss: 1.981 | Acc: 50.080% (5008/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(141.1015, device='cuda:0'), tensor(141.2100, device='cuda:0'), tensor(140.8951, device='cuda:0'), tensor(140.7042, device='cuda:0'), tensor(141.2896, device='cuda:0'), tensor(140.3048, device='cuda:0'), tensor(140.3408, device='cuda:0')]\n",
      "\n",
      "Epoch: 16\n",
      " [========================>]  Step: 61ms | Tot: 24s39ms | Loss: 60851.195 | Acc: 59.744% (29872/5000 391/391  2/39 58/391 ..................]  Step: 68ms | Tot: 3s743ms | Loss: 60867.987 | Acc: 58.372% (4483/768 60/39 366/391 =====================>]  Step: 64ms | Tot: 23s658ms | Loss: 60851.498 | Acc: 59.732% (29436/4928 385/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s535ms | Loss: 1.988 | Acc: 50.220% (5022/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(137.2647, device='cuda:0'), tensor(137.9667, device='cuda:0'), tensor(137.6071, device='cuda:0'), tensor(137.1820, device='cuda:0'), tensor(137.9131, device='cuda:0'), tensor(137.3633, device='cuda:0'), tensor(137.4085, device='cuda:0')]\n",
      "\n",
      "Epoch: 17\n",
      " [========================>]  Step: 63ms | Tot: 23s718ms | Loss: 60812.054 | Acc: 59.742% (29871/5000 391/391 1 68/39 70/391 ....]  Step: 69ms | Tot: 9s440ms | Loss: 60823.839 | Acc: 59.172% (11664/1971 154/39 156/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s536ms | Loss: 1.984 | Acc: 50.300% (5030/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(140.3810, device='cuda:0'), tensor(139.3957, device='cuda:0'), tensor(139.7229, device='cuda:0'), tensor(140.0534, device='cuda:0'), tensor(139.5219, device='cuda:0'), tensor(139.7033, device='cuda:0'), tensor(139.7086, device='cuda:0')]\n",
      "\n",
      "Epoch: 18\n",
      " [========================>]  Step: 69ms | Tot: 24s472ms | Loss: 60773.493 | Acc: 60.018% (30009/5000 391/391 .............]  Step: 70ms | Tot: 3s323ms | Loss: 60790.067 | Acc: 58.608% (4051/691 54/391 ...........]  Step: 68ms | Tot: 3s392ms | Loss: 60790.018 | Acc: 58.622% (4127/704 55/391 ..............]  Step: 62ms | Tot: 3s454ms | Loss: 60789.965 | Acc: 58.761% (4212/716 56/391  60/391 62/391 63/391 ............]  Step: 68ms | Tot: 4s49ms | Loss: 60789.515 | Acc: 59.243% (4929/832 65/39 67/391 68/39 70/391 74/39 76/391 80/391 82/39 89/39 99/391 .......]  Step: 67ms | Tot: 6s319ms | Loss: 60787.778 | Acc: 59.516% (7618/1280 100/391 140/39 203/391 =>.]  Step: 68ms | Tot: 22s967ms | Loss: 60774.620 | Acc: 59.955% (28241/4710 368/39 369/39 375/391 =====================>]  Step: 65ms | Tot: 23s758ms | Loss: 60774.031 | Acc: 60.033% (29200/4864 380/39 389/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s533ms | Loss: 1.987 | Acc: 50.430% (5043/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(137.7856, device='cuda:0'), tensor(138.4570, device='cuda:0'), tensor(138.3470, device='cuda:0'), tensor(138.3817, device='cuda:0'), tensor(138.3453, device='cuda:0'), tensor(138.5377, device='cuda:0'), tensor(138.6176, device='cuda:0')]\n",
      "\n",
      "Epoch: 19\n",
      " [========================>]  Step: 64ms | Tot: 24s95ms | Loss: 60735.373 | Acc: 60.244% (30122/5000 391/391  73/391 287/39 347/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s527ms | Loss: 1.990 | Acc: 50.190% (5019/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(135.2585, device='cuda:0'), tensor(134.9056, device='cuda:0'), tensor(135.6157, device='cuda:0'), tensor(135.8593, device='cuda:0'), tensor(134.8743, device='cuda:0'), tensor(137.1266, device='cuda:0'), tensor(137.1691, device='cuda:0')]\n",
      "\n",
      "Epoch: 20\n",
      " [========================>]  Step: 61ms | Tot: 24s91ms | Loss: 60697.578 | Acc: 60.006% (30003/5000 391/391  30/391 ........]  Step: 64ms | Tot: 3s824ms | Loss: 60713.476 | Acc: 58.795% (4666/793 62/391 71/39 76/39 80/391 =>......]  Step: 67ms | Tot: 18s422ms | Loss: 60702.058 | Acc: 59.975% (22877/3814 298/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s558ms | Loss: 1.989 | Acc: 50.270% (5027/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(137.2185, device='cuda:0'), tensor(137.3282, device='cuda:0'), tensor(137.0058, device='cuda:0'), tensor(136.7669, device='cuda:0'), tensor(137.3340, device='cuda:0'), tensor(135.7742, device='cuda:0'), tensor(135.6929, device='cuda:0')]\n",
      "\n",
      "Epoch: 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 67ms | Tot: 25s59ms | Loss: 60660.040 | Acc: 60.402% (30201/50000 390/391 91 50/39 52/391 ...............]  Step: 63ms | Tot: 3s309ms | Loss: 60676.218 | Acc: 59.259% (4096/691 54/391 ...............]  Step: 65ms | Tot: 3s964ms | Loss: 60675.729 | Acc: 59.607% (4883/819 64/39 119/391 .........]  Step: 68ms | Tot: 8s470ms | Loss: 60672.212 | Acc: 60.179% (10553/1753 137/391 ........]  Step: 63ms | Tot: 8s533ms | Loss: 60672.165 | Acc: 60.190% (10632/1766 138/391 154/391 >...............]  Step: 64ms | Tot: 9s743ms | Loss: 60671.254 | Acc: 60.047% (12067/20 157/391 ....]  Step: 67ms | Tot: 10s703ms | Loss: 60670.536 | Acc: 60.043% (13219/2201 172/391 174/39 180/391 =====>.............]  Step: 68ms | Tot: 11s722ms | Loss: 60669.814 | Acc: 60.119% (14390/2393 187/391 .....]  Step: 67ms | Tot: 11s789ms | Loss: 60669.766 | Acc: 60.140% (14472/2406 188/39 189/39 191/39 194/39 203/391 ....]  Step: 64ms | Tot: 12s845ms | Loss: 60669.004 | Acc: 59.995% (15666/2611 204/39 208/391 =========>...........]  Step: 66ms | Tot: 13s370ms | Loss: 60668.617 | Acc: 60.149% (16322/2713 212/391 ======>...........]  Step: 64ms | Tot: 13s774ms | Loss: 60668.329 | Acc: 60.124% (16777/2790 218/39 224/39 230/391 232/391  242/39 248/391  254/39 256/391 ===========>........]  Step: 68ms | Tot: 16s389ms | Loss: 60666.410 | Acc: 60.289% (19910/3302 258/39 278/391 ======>......]  Step: 65ms | Tot: 18s217ms | Loss: 60665.115 | Acc: 60.252% (21980/3648 285/391 =============>......]  Step: 69ms | Tot: 18s286ms | Loss: 60665.068 | Acc: 60.249% (22056/3660 286/39 287/391 ==================>......]  Step: 71ms | Tot: 18s419ms | Loss: 60664.972 | Acc: 60.289% (22225/3686 288/391 ============>......]  Step: 67ms | Tot: 18s486ms | Loss: 60664.925 | Acc: 60.289% (22302/3699 289/39 290/391 ...]  Step: 65ms | Tot: 19s702ms | Loss: 60664.013 | Acc: 60.324% (23782/3942 308/39 314/391 ===>....]  Step: 66ms | Tot: 20s954ms | Loss: 60663.101 | Acc: 60.417% (25288/4185 327/391 ==============>...]  Step: 66ms | Tot: 21s294ms | Loss: 60662.862 | Acc: 60.434% (25682/4249 332/391 =====================>...]  Step: 65ms | Tot: 21s559ms | Loss: 60662.672 | Acc: 60.391% (25973/4300 336/391 350/391 ============>..]  Step: 67ms | Tot: 22s646ms | Loss: 60661.857 | Acc: 60.435% (27307/45 353/391 ==>]  Step: 65ms | Tot: 24s929ms | Loss: 60660.136 | Acc: 60.399% (30074/4979 389/391 391/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s568ms | Loss: 1.991 | Acc: 50.230% (5023/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(135.2156, device='cuda:0'), tensor(135.2143, device='cuda:0'), tensor(135.0398, device='cuda:0'), tensor(135.0377, device='cuda:0'), tensor(135.1791, device='cuda:0'), tensor(134.5666, device='cuda:0'), tensor(134.3785, device='cuda:0')]\n",
      "\n",
      "Epoch: 22\n",
      " [========================>]  Step: 66ms | Tot: 22s993ms | Loss: 60622.693 | Acc: 60.734% (30367/5000 391/391 /391 14/391 ..............]  Step: 69ms | Tot: 1s251ms | Loss: 60640.370 | Acc: 61.250% (1568/256 20/391 .......]  Step: 69ms | Tot: 1s383ms | Loss: 60640.265 | Acc: 61.364% (1728/281 22/391 ..]  Step: 70ms | Tot: 1s515ms | Loss: 60640.182 | Acc: 61.133% (1878/307 24/391 .............]  Step: 69ms | Tot: 1s585ms | Loss: 60640.128 | Acc: 61.406% (1965/320 25/39 71/39 72/391 ....................]  Step: 71ms | Tot: 4s602ms | Loss: 60637.767 | Acc: 60.562% (5814/960 75/391 ................]  Step: 68ms | Tot: 4s803ms | Loss: 60637.632 | Acc: 60.347% (6025/998 78/39 79/391 >...................]  Step: 69ms | Tot: 4s934ms | Loss: 60637.532 | Acc: 60.449% (6190/1024 80/391 87/391 .....]  Step: 66ms | Tot: 6s4ms | Loss: 60636.760 | Acc: 60.604% (7447/1228 96/391 98/391 ......]  Step: 69ms | Tot: 6s338ms | Loss: 60636.521 | Acc: 60.651% (7841/1292 101/391   Step: 68ms | Tot: 6s538ms | Loss: 60636.375 | Acc: 60.720% (8083/1331 104/391 ......]  Step: 67ms | Tot: 7s430ms | Loss: 60635.752 | Acc: 60.757% (9099/1497 117/39 119/391 138/391 139/ 141/391 142/39 148/391 =====>...............]  Step: 71ms | Tot: 10s56ms | Loss: 60633.844 | Acc: 60.763% (12211/2009 157/391 .......]  Step: 73ms | Tot: 10s879ms | Loss: 60633.271 | Acc: 60.753% (13142/2163 169/39 177/391 .............]  Step: 69ms | Tot: 11s526ms | Loss: 60632.795 | Acc: 60.732% (13915/2291 179/391 189/391 ======>.........]  Step: 47ms | Tot: 15s388ms | Loss: 60629.457 | Acc: 60.721% (19353/3187 249/391 253/391 =====>.....]  Step: 49ms | Tot: 18s282ms | Loss: 60626.834 | Acc: 60.819% (23666/3891 304/391 ==============>.....]  Step: 49ms | Tot: 18s685ms | Loss: 60626.451 | Acc: 60.855% (24303/3993 312/39 313/391 ====================>...]  Step: 51ms | Tot: 20s204ms | Loss: 60625.164 | Acc: 60.829% (26395/4339 339/39 343/391 =====>..]  Step: 49ms | Tot: 20s554ms | Loss: 60624.830 | Acc: 60.847% (26948/4428 346/39 347/391 ]  Step: 49ms | Tot: 20s857ms | Loss: 60624.544 | Acc: 60.860% (27421/4505 352/391 ================>..]  Step: 53ms | Tot: 21s105ms | Loss: 60624.307 | Acc: 60.850% (27806/4569 357/391 ==============>..]  Step: 49ms | Tot: 21s252ms | Loss: 60624.165 | Acc: 60.836% (28033/4608 360/391 =====>.]  Step: 53ms | Tot: 21s305ms | Loss: 60624.118 | Acc: 60.825% (28106/46 361/391 362/391 =>.]  Step: 52ms | Tot: 21s504ms | Loss: 60623.927 | Acc: 60.822% (28416/4672 365/39 366/ 370/39 376/391 377/391 ==========>]  Step: 66ms | Tot: 22s795ms | Loss: 60622.836 | Acc: 60.740% (30166/4966 388/391 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s588ms | Loss: 1.994 | Acc: 50.430% (5043/1000 79/79 7/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(132.5202, device='cuda:0'), tensor(131.8779, device='cuda:0'), tensor(132.6906, device='cuda:0'), tensor(133.2493, device='cuda:0'), tensor(131.7125, device='cuda:0'), tensor(133.3901, device='cuda:0'), tensor(133.2096, device='cuda:0')]\n",
      "\n",
      "Epoch: 23\n",
      " [========================>]  Step: 53ms | Tot: 22s290ms | Loss: 60585.511 | Acc: 60.564% (30282/5000 391/391 p: 62ms | Tot: 853ms | Loss: 60602.948 | Acc: 60.091% (1846/307 24/391 \n",
      " [========================>]  Step: 41ms | Tot: 3s287ms | Loss: 1.994 | Acc: 50.320% (5032/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(134.3783, device='cuda:0'), tensor(133.8230, device='cuda:0'), tensor(133.9697, device='cuda:0'), tensor(134.0416, device='cuda:0'), tensor(134.0424, device='cuda:0'), tensor(133.8369, device='cuda:0'), tensor(133.5646, device='cuda:0')]\n",
      "\n",
      "Epoch: 24\n",
      " [========================>]  Step: 68ms | Tot: 25s43ms | Loss: 60548.540 | Acc: 60.833% (30290/4979 389/391    Step: 68ms | Tot: 646ms | Loss: 60566.479 | Acc: 59.659% (840/140 11/391 32/39 33/391 63/391 .]  Step: 63ms | Tot: 4s119ms | Loss: 60563.924 | Acc: 59.663% (4964/832 65/39 68/39 79/391 ....]  Step: 65ms | Tot: 5s156ms | Loss: 60563.154 | Acc: 59.838% (6204/1036 81/391 103/39 105/391 140/39 141/391 142/391 146/391 167/391 168/39 179/39 183/391 185/391 ===>............]  Step: 67ms | Tot: 12s319ms | Loss: 60557.881 | Acc: 60.238% (14804/2457 192/391 ======>............]  Step: 69ms | Tot: 12s581ms | Loss: 60557.692 | Acc: 60.192% (15101/2508 196/39 197/39 198/39 208/391 ===============>.........]  Step: 68ms | Tot: 15s841ms | Loss: 60555.316 | Acc: 60.556% (19068/3148 246/391 ======>........]  Step: 71ms | Tot: 16s498ms | Loss: 60554.840 | Acc: 60.608% (19860/3276 256/39 267/391 270/391 =========>.......]  Step: 64ms | Tot: 18s14ms | Loss: 60553.749 | Acc: 60.638% (21655/3571 279/39 321/39 353/39 355/391 367/39 369/39 388/391 ===========>]  Step: 69ms | Tot: 25s112ms | Loss: 60548.492 | Acc: 60.841% (30372/4992 390/391 ==================>]  Step: 61ms | Tot: 25s174ms | Loss: 60548.444 | Acc: 60.840% (30420/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s550ms | Loss: 1.995 | Acc: 50.440% (5044/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(133.6478, device='cuda:0'), tensor(133.0002, device='cuda:0'), tensor(133.3140, device='cuda:0'), tensor(133.4440, device='cuda:0'), tensor(133.5357, device='cuda:0'), tensor(133.7623, device='cuda:0'), tensor(133.8098, device='cuda:0')]\n",
      "\n",
      "Epoch: 25\n",
      " [========================>]  Step: 60ms | Tot: 24s569ms | Loss: 60511.474 | Acc: 60.680% (30340/5000 391/391  32/391 34/391 42/391 ....]  Step: 64ms | Tot: 2s739ms | Loss: 60527.901 | Acc: 59.109% (3329/563 44/391 45/39 46/391 47/39 62/391 ...............]  Step: 65ms | Tot: 4s281ms | Loss: 60526.741 | Acc: 60.191% (5239/870 68/391  75/391 88/391 ..............]  Step: 69ms | Tot: 5s765ms | Loss: 60525.648 | Acc: 60.216% (7014/1164 91/391 93/39 119/391 ...............]  Step: 67ms | Tot: 7s843ms | Loss: 60524.131 | Acc: 60.391% (9508/1574 123/391 ==>................]  Step: 69ms | Tot: 8s297ms | Loss: 60523.802 | Acc: 60.306% (10035/1664 130/391 ........]  Step: 63ms | Tot: 8s498ms | Loss: 60523.661 | Acc: 60.327% (10270/1702 133/391 139/391 .........]  Step: 65ms | Tot: 9s20ms | Loss: 60523.284 | Acc: 60.328% (10888/1804 141/391   Step: 67ms | Tot: 16s317ms | Loss: 60517.618 | Acc: 60.599% (20245/3340 261/39 278/39 280/391 =========>.....]  Step: 63ms | Tot: 19s243ms | Loss: 60515.446 | Acc: 60.640% (23829/3929 307/39 322/391 341/391 356/391 370/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s525ms | Loss: 1.998 | Acc: 50.230% (5023/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(134.6408, device='cuda:0'), tensor(133.1183, device='cuda:0'), tensor(133.7505, device='cuda:0'), tensor(133.9559, device='cuda:0'), tensor(134.0916, device='cuda:0'), tensor(132.8926, device='cuda:0'), tensor(132.5191, device='cuda:0')]\n",
      "\n",
      "Epoch: 26\n",
      " [========================>]  Step: 60ms | Tot: 24s671ms | Loss: 60474.576 | Acc: 61.162% (30581/5000 391/391 .....................]  Step: 69ms | Tot: 2s341ms | Loss: 60491.219 | Acc: 59.315% (2961/499 39/391 .....................]  Step: 69ms | Tot: 2s674ms | Loss: 60490.988 | Acc: 59.144% (3331/563 44/391 47/391 ..........]  Step: 66ms | Tot: 2s937ms | Loss: 60490.797 | Acc: 59.538% (3658/614 48/391 ......]  Step: 64ms | Tot: 3s834ms | Loss: 60490.136 | Acc: 59.677% (4736/793 62/391 82/391 ..]  Step: 67ms | Tot: 5s257ms | Loss: 60489.077 | Acc: 60.203% (6473/1075 84/39 92/39 96/39 107/391 109/391 ............]  Step: 65ms | Tot: 7s142ms | Loss: 60487.703 | Acc: 60.357% (8730/1446 113/39 198/391 ======>............]  Step: 70ms | Tot: 12s844ms | Loss: 60483.456 | Acc: 60.541% (15731/2598 203/391 ===========>........]  Step: 69ms | Tot: 16s376ms | Loss: 60480.805 | Acc: 60.974% (20214/3315 259/39 367/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s516ms | Loss: 2.000 | Acc: 50.520% (5052/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(130.5380, device='cuda:0'), tensor(130.9727, device='cuda:0'), tensor(130.9623, device='cuda:0'), tensor(130.9455, device='cuda:0'), tensor(130.6036, device='cuda:0'), tensor(131.2930, device='cuda:0'), tensor(131.6300, device='cuda:0')]\n",
      "\n",
      "Epoch: 27\n",
      " [========================>]  Step: 68ms | Tot: 24s141ms | Loss: 60437.740 | Acc: 61.136% (30568/5000 391/391 17/391 18/391 75/391 ..................]  Step: 70ms | Tot: 4s901ms | Loss: 60452.446 | Acc: 60.542% (6122/1011 79/391 80/391  127/39 172/39 176/39 235/39 274/391 293/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s859ms | Loss: 2.006 | Acc: 50.460% (5046/1000 79/79 7 31/79 >............]  Step: 55ms | Tot: 1s988ms | Loss: 2.008 | Acc: 50.343% (2642/524 41/7 42/79 43/7 47/79 50/7 54/79 ....]  Step: 56ms | Tot: 2s685ms | Loss: 2.007 | Acc: 50.455% (3552/704 55/79 56/7 58/7 61/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(134.9752, device='cuda:0'), tensor(135.1893, device='cuda:0'), tensor(135.2438, device='cuda:0'), tensor(135.0216, device='cuda:0'), tensor(135.0334, device='cuda:0'), tensor(135.2520, device='cuda:0'), tensor(135.5898, device='cuda:0')]\n",
      "\n",
      "Epoch: 28\n",
      " [========================>]  Step: 60ms | Tot: 23s213ms | Loss: 60400.953 | Acc: 61.204% (30602/5000 391/391 ...........]  Step: 34ms | Tot: 8s272ms | Loss: 60412.769 | Acc: 60.932% (10919/1792 140/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s527ms | Loss: 2.002 | Acc: 50.410% (5041/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(134.1359, device='cuda:0'), tensor(134.6742, device='cuda:0'), tensor(134.3387, device='cuda:0'), tensor(134.2397, device='cuda:0'), tensor(134.0921, device='cuda:0'), tensor(134.6227, device='cuda:0'), tensor(134.7842, device='cuda:0')]\n",
      "\n",
      "Epoch: 29\n",
      " [========================>]  Step: 61ms | Tot: 22s150ms | Loss: 60364.196 | Acc: 61.458% (30729/5000 391/391  7/39 28/39 74/39 77/39 82/391 84/39 86/391 88/39 95/391 104/391 115/39 129/391 130/391 131/39 133/39 136/391 ========>................]  Step: 47ms | Tot: 8s247ms | Loss: 60375.956 | Acc: 60.982% (11006/1804 141/391   Step: 52ms | Tot: 8s299ms | Loss: 60375.910 | Acc: 60.954% (11079/1817 142/39 144/39 145/391 ....]  Step: 56ms | Tot: 8s501ms | Loss: 60375.723 | Acc: 60.932% (11387/1868 146/39 148/391 ....]  Step: 47ms | Tot: 9s286ms | Loss: 60375.015 | Acc: 61.059% (12583/2060 161/39 162/391 164/391 .]  Step: 54ms | Tot: 12s586ms | Loss: 60371.863 | Acc: 61.177% (17854/2918 228/391 .....]  Step: 48ms | Tot: 12s634ms | Loss: 60371.815 | Acc: 61.187% (17935/2931 229/391 ========>........]  Step: 54ms | Tot: 14s170ms | Loss: 60370.452 | Acc: 61.234% (20222/3302 258/39 259/391 ========>........]  Step: 52ms | Tot: 14s269ms | Loss: 60370.358 | Acc: 61.241% (20381/3328 260/391  261/391 284/39 291/39 295/39 321/39 322/391 ===============>...]  Step: 68ms | Tot: 18s442ms | Loss: 60366.926 | Acc: 61.418% (26179/4262 333/391 ========>...]  Step: 63ms | Tot: 18s506ms | Loss: 60366.878 | Acc: 61.429% (26262/4275 334/391 =>...]  Step: 68ms | Tot: 18s767ms | Loss: 60366.690 | Acc: 61.386% (26558/4326 338/391 365/391 371/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s424ms | Loss: 2.002 | Acc: 50.340% (5034/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(128.8537, device='cuda:0'), tensor(129.2076, device='cuda:0'), tensor(129.1854, device='cuda:0'), tensor(129.0138, device='cuda:0'), tensor(128.7759, device='cuda:0'), tensor(130.5425, device='cuda:0'), tensor(130.6116, device='cuda:0')]\n",
      "\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 60ms | Tot: 25s254ms | Loss: 60327.485 | Acc: 61.442% (30721/5000 391/391 65/391 .........]  Step: 66ms | Tot: 4s331ms | Loss: 60342.637 | Acc: 60.485% (5342/883 69/39 73/391 .................]  Step: 69ms | Tot: 4s663ms | Loss: 60342.397 | Acc: 60.631% (5743/947 74/391 81/39 82/39 91/39 95/391 98/391 .]  Step: 64ms | Tot: 6s885ms | Loss: 60340.782 | Acc: 60.894% (8418/1382 108/391 112/39 116/391 ............]  Step: 65ms | Tot: 8s438ms | Loss: 60339.653 | Acc: 60.991% (10305/1689 132/39 145/391 ..........]  Step: 69ms | Tot: 10s354ms | Loss: 60338.244 | Acc: 60.986% (12646/2073 162/391 ]  Step: 69ms | Tot: 10s879ms | Loss: 60337.865 | Acc: 61.167% (13310/2176 170/39 174/391 176/391 ===========>.............]  Step: 70ms | Tot: 12s59ms | Loss: 60337.021 | Acc: 61.041% (14689/2406 188/391 .......]  Step: 71ms | Tot: 12s452ms | Loss: 60336.741 | Acc: 60.978% (15142/2483 194/391 ............]  Step: 71ms | Tot: 12s845ms | Loss: 60336.459 | Acc: 60.973% (15609/2560 200/391 ..........]  Step: 70ms | Tot: 12s976ms | Loss: 60336.365 | Acc: 60.972% (15765/2585 202/391 ========>..........]  Step: 69ms | Tot: 14s822ms | Loss: 60335.050 | Acc: 61.022% (17965/2944 230/39 232/391 ===>.........]  Step: 74ms | Tot: 15s215ms | Loss: 60334.767 | Acc: 61.083% (18452/3020 236/391 244/391 ..]  Step: 70ms | Tot: 16s397ms | Loss: 60333.921 | Acc: 61.184% (19892/3251 254/391 ===========>........]  Step: 70ms | Tot: 16s659ms | Loss: 60333.734 | Acc: 61.162% (20198/3302 258/391 ..]  Step: 70ms | Tot: 16s921ms | Loss: 60333.545 | Acc: 61.176% (20516/3353 262/391 ===========>.......]  Step: 69ms | Tot: 17s709ms | Loss: 60332.981 | Acc: 61.220% (21471/3507 274/391 =================>.......]  Step: 71ms | Tot: 17s841ms | Loss: 60332.887 | Acc: 61.221% (21628/3532 276/39 278/39 284/391 ==========>......]  Step: 70ms | Tot: 19s20ms | Loss: 60332.041 | Acc: 61.312% (23073/3763 294/391 =======>......]  Step: 68ms | Tot: 19s281ms | Loss: 60331.853 | Acc: 61.315% (23388/3814 298/391 ....]  Step: 65ms | Tot: 21s9ms | Loss: 60330.583 | Acc: 61.387% (25537/4160 325/39 338/391 =====>...]  Step: 66ms | Tot: 22s299ms | Loss: 60329.644 | Acc: 61.429% (27127/4416 345/391 ================>..]  Step: 68ms | Tot: 22s691ms | Loss: 60329.361 | Acc: 61.458% (27612/4492 351/391 .]  Step: 69ms | Tot: 23s468ms | Loss: 60328.799 | Acc: 61.426% (28541/4646 363/39 370/391 382/39 384/39 387/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s597ms | Loss: 2.005 | Acc: 50.380% (5038/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(132.5656, device='cuda:0'), tensor(132.4066, device='cuda:0'), tensor(132.1649, device='cuda:0'), tensor(131.9333, device='cuda:0'), tensor(132.6419, device='cuda:0'), tensor(130.8342, device='cuda:0'), tensor(130.6447, device='cuda:0')]\n",
      "\n",
      "Epoch: 31\n",
      " [========================>]  Step: 56ms | Tot: 23s594ms | Loss: 60290.784 | Acc: 61.632% (30816/5000 391/391 32/39 56/391 57/391   Step: 69ms | Tot: 3s778ms | Loss: 60306.305 | Acc: 61.450% (4798/780 61/391 62/391 .......]  Step: 64ms | Tot: 3s909ms | Loss: 60306.204 | Acc: 61.458% (4956/806 63/391 .........]  Step: 63ms | Tot: 4s363ms | Loss: 60305.870 | Acc: 61.551% (5515/896 70/391 =>..................]  Step: 68ms | Tot: 6s664ms | Loss: 60304.164 | Acc: 61.483% (8342/1356 106/391 .......]  Step: 63ms | Tot: 6s727ms | Loss: 60304.118 | Acc: 61.419% (8412/1369 107/391 118/391 ....]  Step: 69ms | Tot: 7s566ms | Loss: 60303.509 | Acc: 61.393% (9430/1536 120/391 122/391   Step: 69ms | Tot: 8s775ms | Loss: 60302.618 | Acc: 61.275% (10902/1779 139/39 140/391 200/39 210/39 211/39 228/391 231/39 264/39 265/39 359/391 \n",
      " [========================>]  Step: 61ms | Tot: 3s474ms | Loss: 2.011 | Acc: 50.400% (5040/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(127.8364, device='cuda:0'), tensor(127.6127, device='cuda:0'), tensor(127.9818, device='cuda:0'), tensor(128.0538, device='cuda:0'), tensor(127.3882, device='cuda:0'), tensor(128.0643, device='cuda:0'), tensor(128.0743, device='cuda:0')]\n",
      "\n",
      "Epoch: 32\n",
      " [========================>]  Step: 54ms | Tot: 19s901ms | Loss: 60254.109 | Acc: 61.880% (30940/5000 391/391 1  23/39 25/391 26/391 27/39 28/391 32/39 39/391 .....................]  Step: 47ms | Tot: 2s132ms | Loss: 60270.482 | Acc: 60.065% (3306/550 43/391 .................]  Step: 52ms | Tot: 2s740ms | Loss: 60269.916 | Acc: 60.455% (4256/704 55/39 58/391 72/39 74/391 ..................]  Step: 53ms | Tot: 3s750ms | Loss: 60268.958 | Acc: 60.812% (5838/960 75/39 78/39 93/391 ]  Step: 50ms | Tot: 4s794ms | Loss: 60267.964 | Acc: 61.149% (7514/1228 96/391 ....]  Step: 52ms | Tot: 4s847ms | Loss: 60267.916 | Acc: 61.219% (7601/12 97/391 ...........]  Step: 47ms | Tot: 5s48ms | Loss: 60267.725 | Acc: 61.278% (7922/1292 101/39 102/391 ======>..................]  Step: 46ms | Tot: 5s301ms | Loss: 60267.486 | Acc: 61.358% (8325/13 106/391  108/39 110/391 112/391 =======>.................]  Step: 52ms | Tot: 5s856ms | Loss: 60266.968 | Acc: 61.365% (9190/1497 117/391 ]  Step: 49ms | Tot: 6s56ms | Loss: 60266.780 | Acc: 61.370% (9505/15 121/391 122/391 ========>................]  Step: 49ms | Tot: 6s780ms | Loss: 60266.120 | Acc: 61.435% (10616/1728 135/39 159/391 ==>..............]  Step: 50ms | Tot: 8s183ms | Loss: 60264.857 | Acc: 61.463% (12745/2073 162/391 =====>..............]  Step: 53ms | Tot: 8s236ms | Loss: 60264.809 | Acc: 61.522% (12836/2086 163/391 ===========>.............]  Step: 53ms | Tot: 8s823ms | Loss: 60264.293 | Acc: 61.503% (13698/2227 174/391 ======>.............]  Step: 45ms | Tot: 9s71ms | Loss: 60264.060 | Acc: 61.444% (14078/2291 179/39 180/391 ...........]  Step: 45ms | Tot: 9s272ms | Loss: 60263.870 | Acc: 61.488% (14403/2342 183/391 202/391 .......]  Step: 53ms | Tot: 10s397ms | Loss: 60262.795 | Acc: 61.400% (16190/2636 206/391 =============>...........]  Step: 51ms | Tot: 10s961ms | Loss: 60262.276 | Acc: 61.517% (17087/2777 217/391 ..]  Step: 49ms | Tot: 11s114ms | Loss: 60262.136 | Acc: 61.534% (17328/2816 220/391 ]  Step: 48ms | Tot: 12s102ms | Loss: 60261.243 | Acc: 61.647% (18859/3059 239/391 ..]  Step: 50ms | Tot: 12s455ms | Loss: 60260.915 | Acc: 61.674% (19420/3148 246/391 247/391 ==========>.........]  Step: 54ms | Tot: 12s557ms | Loss: 60260.819 | Acc: 61.744% (19600/3174 248/391 .....]  Step: 46ms | Tot: 12s655ms | Loss: 60260.724 | Acc: 61.756% (19762/3200 250/391 ....]  Step: 53ms | Tot: 12s757ms | Loss: 60260.629 | Acc: 61.799% (19934/3225 252/391 =============>.......]  Step: 51ms | Tot: 14s97ms | Loss: 60259.410 | Acc: 61.814% (21996/3558 278/391 =============>.......]  Step: 48ms | Tot: 14s199ms | Loss: 60259.317 | Acc: 61.789% (22145/3584 280/39 282/391 283/39 285/391 ===============>......]  Step: 52ms | Tot: 14s702ms | Loss: 60258.847 | Acc: 61.810% (22944/3712 290/39 292/39 294/391 ======>.....]  Step: 54ms | Tot: 15s734ms | Loss: 60257.909 | Acc: 61.870% (24550/3968 310/391 ===========>....]  Step: 47ms | Tot: 15s934ms | Loss: 60257.721 | Acc: 61.836% (24853/4019 314/391 ============>...]  Step: 48ms | Tot: 16s959ms | Loss: 60256.783 | Acc: 61.843% (26439/4275 334/391 =================>...]  Step: 52ms | Tot: 17s215ms | Loss: 60256.549 | Acc: 61.818% (26824/4339 339/39 347/391 ===================>..]  Step: 46ms | Tot: 17s838ms | Loss: 60255.985 | Acc: 61.857% (27791/4492 351/391 352/391 ]  Step: 51ms | Tot: 18s737ms | Loss: 60255.188 | Acc: 61.884% (29150/4710 368/391 373/391 381/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s620ms | Loss: 2.010 | Acc: 50.390% (5039/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(128.3497, device='cuda:0'), tensor(128.5489, device='cuda:0'), tensor(128.4160, device='cuda:0'), tensor(127.9779, device='cuda:0'), tensor(128.7033, device='cuda:0'), tensor(127.6083, device='cuda:0'), tensor(127.4878, device='cuda:0')]\n",
      "\n",
      "Epoch: 33\n",
      " [========================>]  Step: 68ms | Tot: 25s223ms | Loss: 60217.448 | Acc: 61.950% (30975/5000 391/391 p: 49ms | Tot: 258ms | Loss: 60235.512 | Acc: 60.807% (467/76 6/391 64/391 ===>....................]  Step: 60ms | Tot: 3s912ms | Loss: 60232.632 | Acc: 60.547% (5270/870 68/391 ...................]  Step: 67ms | Tot: 4s869ms | Loss: 60231.963 | Acc: 60.966% (6399/1049 82/391 ===>...................]  Step: 60ms | Tot: 5s144ms | Loss: 60231.771 | Acc: 61.101% (6726/1100 86/391 87/39 97/391 ======>..................]  Step: 67ms | Tot: 6s566ms | Loss: 60230.776 | Acc: 61.266% (8391/1369 107/39 115/391 ==>................]  Step: 65ms | Tot: 7s931ms | Loss: 60229.834 | Acc: 61.479% (9994/1625 127/391 ......]  Step: 67ms | Tot: 7s999ms | Loss: 60229.789 | Acc: 61.438% (10066/1638 128/391 =>...............]  Step: 63ms | Tot: 9s810ms | Loss: 60228.526 | Acc: 61.361% (12174/1984 155/391 =======>.............]  Step: 66ms | Tot: 11s138ms | Loss: 60227.631 | Acc: 61.427% (13681/2227 174/391 ==========>............]  Step: 67ms | Tot: 12s575ms | Loss: 60226.648 | Acc: 61.394% (15324/2496 195/391 =============>...........]  Step: 67ms | Tot: 13s230ms | Loss: 60226.179 | Acc: 61.380% (16106/2624 205/391 207/391 =========>...........]  Step: 62ms | Tot: 13s897ms | Loss: 60225.708 | Acc: 61.461% (16914/2752 215/391 ..]  Step: 66ms | Tot: 14s773ms | Loss: 60225.096 | Acc: 61.592% (17975/2918 228/391 230/391 ]  Step: 69ms | Tot: 15s175ms | Loss: 60224.813 | Acc: 61.639% (18462/2995 234/391 =======>..........]  Step: 63ms | Tot: 15s239ms | Loss: 60224.766 | Acc: 61.606% (18531/3008 235/39 236/391 .....]  Step: 67ms | Tot: 15s631ms | Loss: 60224.485 | Acc: 61.615% (19007/3084 241/39 245/391 259/39 277/391 284/391 ...]  Step: 67ms | Tot: 18s443ms | Loss: 60222.420 | Acc: 61.664% (22495/3648 285/391 294/391 ===>....]  Step: 66ms | Tot: 20s745ms | Loss: 60220.732 | Acc: 61.799% (25392/4108 321/391 ....]  Step: 67ms | Tot: 21s137ms | Loss: 60220.449 | Acc: 61.824% (25877/4185 327/391  328/391 ]  Step: 68ms | Tot: 21s269ms | Loss: 60220.355 | Acc: 61.856% (26049/4211 329/391 358/39 366/391 371/391 381/391 ===============>]  Step: 65ms | Tot: 24s630ms | Loss: 60217.869 | Acc: 61.995% (30313/4889 382/391  386/39 387/39 388/391 390/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s548ms | Loss: 2.008 | Acc: 50.650% (5065/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(128.1081, device='cuda:0'), tensor(128.2207, device='cuda:0'), tensor(127.7051, device='cuda:0'), tensor(127.4913, device='cuda:0'), tensor(128.2234, device='cuda:0'), tensor(127.0343, device='cuda:0'), tensor(127.0379, device='cuda:0')]\n",
      "\n",
      "Epoch: 34\n",
      " [========================>]  Step: 59ms | Tot: 23s216ms | Loss: 60180.801 | Acc: 62.038% (31019/5000 391/391 ........]  Step: 61ms | Tot: 893ms | Loss: 60198.472 | Acc: 60.104% (1154/192 15/39 42/39 50/391 52/391 60/391 62/39 108/391 ................]  Step: 66ms | Tot: 6s844ms | Loss: 60193.979 | Acc: 61.364% (8640/1408 110/391 ===============>.......]  Step: 69ms | Tot: 16s565ms | Loss: 60185.915 | Acc: 61.816% (22313/3609 282/391 =>......]  Step: 67ms | Tot: 17s36ms | Loss: 60185.588 | Acc: 61.816% (22867/3699 289/391 =>......]  Step: 61ms | Tot: 17s98ms | Loss: 60185.541 | Acc: 61.837% (22954/3712 290/39 294/391 299/39 301/391 323/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s531ms | Loss: 2.013 | Acc: 50.470% (5047/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(129.9123, device='cuda:0'), tensor(129.8851, device='cuda:0'), tensor(129.4747, device='cuda:0'), tensor(129.3299, device='cuda:0'), tensor(130.0759, device='cuda:0'), tensor(128.8911, device='cuda:0'), tensor(129.0080, device='cuda:0')]\n",
      "\n",
      "Epoch: 35\n",
      " [========================>]  Step: 60ms | Tot: 24s582ms | Loss: 60144.168 | Acc: 62.282% (31141/5000 391/391 ................]  Step: 71ms | Tot: 2s208ms | Loss: 60160.675 | Acc: 61.819% (3086/499 39/39 47/391 63/391 91/39 93/391 97/391 ======>..................]  Step: 70ms | Tot: 6s459ms | Loss: 60157.477 | Acc: 62.084% (8503/1369 107/391 >.................]  Step: 71ms | Tot: 7s639ms | Loss: 60156.633 | Acc: 62.150% (9944/1600 125/391 127/391 135/39 139/391 ..]  Step: 68ms | Tot: 8s788ms | Loss: 60155.790 | Acc: 62.139% (11374/1830 143/39 147/391 .....]  Step: 72ms | Tot: 9s686ms | Loss: 60155.133 | Acc: 62.251% (12510/2009 157/39 163/391 169/391 177/391 .....]  Step: 69ms | Tot: 11s858ms | Loss: 60153.541 | Acc: 62.255% (15220/2444 191/391 .....]  Step: 67ms | Tot: 12s793ms | Loss: 60152.792 | Acc: 62.187% (16477/2649 207/391 209/391 >..........]  Step: 69ms | Tot: 13s956ms | Loss: 60151.947 | Acc: 62.247% (17927/2880 225/391 227/391 ......]  Step: 73ms | Tot: 14s218ms | Loss: 60151.762 | Acc: 62.176% (18225/2931 229/39 239/39 247/391 251/391   Step: 72ms | Tot: 15s865ms | Loss: 60150.542 | Acc: 62.264% (20323/3264 255/391 259/391 261/391 =============>.......]  Step: 74ms | Tot: 16s760ms | Loss: 60149.886 | Acc: 62.317% (21457/3443 269/391 281/391 ...]  Step: 69ms | Tot: 17s933ms | Loss: 60149.042 | Acc: 62.263% (22873/3673 287/39 291/391 =================>.....]  Step: 68ms | Tot: 18s720ms | Loss: 60148.478 | Acc: 62.312% (23848/3827 299/39 301/39 313/391 ..]  Step: 70ms | Tot: 20s757ms | Loss: 60146.979 | Acc: 62.302% (26396/4236 331/39 335/39 337/391 =========>...]  Step: 69ms | Tot: 21s403ms | Loss: 60146.511 | Acc: 62.280% (27184/4364 341/39 349/391 355/391 371/39 373/39 381/391 ==================>]  Step: 70ms | Tot: 24s88ms | Loss: 60144.542 | Acc: 62.298% (30541/4902 383/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s534ms | Loss: 2.013 | Acc: 50.580% (5058/1000 79/79  \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(125.8909, device='cuda:0'), tensor(126.3711, device='cuda:0'), tensor(126.2594, device='cuda:0'), tensor(125.9334, device='cuda:0'), tensor(126.0850, device='cuda:0'), tensor(126.4102, device='cuda:0'), tensor(126.3991, device='cuda:0')]\n",
      "\n",
      "Epoch: 36\n",
      " [========================>]  Step: 52ms | Tot: 20s849ms | Loss: 60107.542 | Acc: 62.316% (31158/5000 391/391 91 ............]  Step: 54ms | Tot: 5s661ms | Loss: 60121.314 | Acc: 62.113% (7712/1241 97/391 ................]  Step: 50ms | Tot: 5s862ms | Loss: 60121.128 | Acc: 62.020% (8018/1292 101/391 ..]  Step: 52ms | Tot: 6s625ms | Loss: 60120.423 | Acc: 61.860% (9185/1484 116/391 ...]  Step: 50ms | Tot: 6s877ms | Loss: 60120.188 | Acc: 61.977% (9599/1548 121/391 133/391 134/39 211/39 213/3 215/391 ==>...........]  Step: 54ms | Tot: 10s877ms | Loss: 60115.695 | Acc: 62.086% (17245/2777 217/391 219/3 221/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s526ms | Loss: 2.013 | Acc: 50.590% (5059/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(125.8278, device='cuda:0'), tensor(125.7126, device='cuda:0'), tensor(125.7741, device='cuda:0'), tensor(125.6540, device='cuda:0'), tensor(125.9305, device='cuda:0'), tensor(125.6530, device='cuda:0'), tensor(125.6684, device='cuda:0')]\n",
      "\n",
      "Epoch: 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 49ms | Tot: 19s388ms | Loss: 60070.976 | Acc: 62.093% (30997/4992 390/391 /39 11/391 .......]  Step: 48ms | Tot: 848ms | Loss: 60088.456 | Acc: 60.200% (1387/230 18/39 24/391 ...]  Step: 51ms | Tot: 1s192ms | Loss: 60088.108 | Acc: 60.688% (1942/320 25/391 28/391 .............]  Step: 53ms | Tot: 1s393ms | Loss: 60087.916 | Acc: 60.749% (2255/371 29/39 32/391 36/391 ]  Step: 53ms | Tot: 1s788ms | Loss: 60087.558 | Acc: 60.790% (2879/473 37/391 .................]  Step: 47ms | Tot: 1s935ms | Loss: 60087.413 | Acc: 60.996% (3123/512 40/39 41/391 ..]  Step: 51ms | Tot: 2s231ms | Loss: 60087.126 | Acc: 61.294% (3609/588 46/391 .............]  Step: 49ms | Tot: 2s329ms | Loss: 60087.023 | Acc: 61.540% (3781/614 48/391 ..............]  Step: 50ms | Tot: 2s432ms | Loss: 60086.930 | Acc: 61.594% (3942/640 50/391 ===>.....................]  Step: 45ms | Tot: 2s582ms | Loss: 60086.787 | Acc: 61.557% (4176/678 53/39 54/391 55/391 60/39 76/391 .................]  Step: 52ms | Tot: 3s898ms | Loss: 60085.506 | Acc: 61.729% (6321/1024 80/39 82/39 83/391 .....]  Step: 51ms | Tot: 4s96ms | Loss: 60085.320 | Acc: 61.775% (6642/10 84/391  102/391 ======>..................]  Step: 46ms | Tot: 5s177ms | Loss: 60084.278 | Acc: 62.102% (8426/1356 106/391 ====>.................]  Step: 46ms | Tot: 6s124ms | Loss: 60083.390 | Acc: 62.056% (9929/1600 125/391 .................]  Step: 49ms | Tot: 6s174ms | Loss: 60083.343 | Acc: 62.041% (10006/1612 126/391 ========>................]  Step: 51ms | Tot: 6s225ms | Loss: 60083.295 | Acc: 62.063% (10089/1625 127/391 132/39 142/391 ....]  Step: 48ms | Tot: 8s131ms | Loss: 60081.466 | Acc: 62.199% (13216/2124 166/39 168/391 ........]  Step: 49ms | Tot: 8s434ms | Loss: 60081.186 | Acc: 62.150% (13683/2201 172/391 =========>.............]  Step: 49ms | Tot: 8s636ms | Loss: 60081.000 | Acc: 62.078% (13985/2252 176/391 .]  Step: 49ms | Tot: 8s738ms | Loss: 60080.906 | Acc: 62.096% (14148/2278 178/391 190/39 202/391 204/39 205/391 ==>...........]  Step: 51ms | Tot: 10s181ms | Loss: 60079.595 | Acc: 62.079% (16369/2636 206/391 ........]  Step: 47ms | Tot: 10s228ms | Loss: 60079.549 | Acc: 62.074% (16447/2649 207/39 208/391 .....]  Step: 52ms | Tot: 10s332ms | Loss: 60079.455 | Acc: 62.111% (16616/2675 209/391 ........]  Step: 48ms | Tot: 10s480ms | Loss: 60079.313 | Acc: 62.128% (16859/27 212/391 =>...........]  Step: 52ms | Tot: 10s532ms | Loss: 60079.267 | Acc: 62.104% (16932/2726 213/391 ==========>...........]  Step: 51ms | Tot: 10s583ms | Loss: 60079.222 | Acc: 62.106% (17012/2739 214/391 ===========>...........]  Step: 49ms | Tot: 10s681ms | Loss: 60079.129 | Acc: 62.099% (17169/2764 216/39 217/391 ==========>..........]  Step: 49ms | Tot: 10s883ms | Loss: 60078.940 | Acc: 62.152% (17502/2816 220/391 ============>..........]  Step: 52ms | Tot: 10s986ms | Loss: 60078.846 | Acc: 62.166% (17665/2841 222/391 ==============>..........]  Step: 49ms | Tot: 11s186ms | Loss: 60078.661 | Acc: 62.116% (17969/2892 226/391 ==============>..........]  Step: 49ms | Tot: 11s288ms | Loss: 60078.569 | Acc: 62.041% (18106/2918 228/391 ============>..........]  Step: 51ms | Tot: 11s389ms | Loss: 60078.474 | Acc: 62.082% (18277/2944 230/391 ........]  Step: 47ms | Tot: 12s43ms | Loss: 60077.864 | Acc: 62.130% (19325/3110 243/39 251/39 260/39 261/39 278/391 ==================>......]  Step: 49ms | Tot: 14s653ms | Loss: 60075.379 | Acc: 62.138% (23543/3788 296/391 297/39 298/391 ===================>.....]  Step: 50ms | Tot: 14s908ms | Loss: 60075.144 | Acc: 62.181% (23957/3852 301/391 ===========>.....]  Step: 49ms | Tot: 14s958ms | Loss: 60075.098 | Acc: 62.138% (24020/3865 302/39 303/391 317/391 ========>....]  Step: 51ms | Tot: 15s733ms | Loss: 60074.349 | Acc: 62.095% (25275/4070 318/391 >....]  Step: 48ms | Tot: 16s297ms | Loss: 60073.833 | Acc: 62.168% (26180/4211 329/391 330/391 =====================>...]  Step: 47ms | Tot: 16s903ms | Loss: 60073.273 | Acc: 62.111% (27110/4364 341/391 342/391 .]  Step: 52ms | Tot: 17s4ms | Loss: 60073.178 | Acc: 62.145% (27284/4390 343/391 ==>...]  Step: 51ms | Tot: 17s105ms | Loss: 60073.084 | Acc: 62.147% (27444/4416 345/391 ====================>..]  Step: 47ms | Tot: 17s408ms | Loss: 60072.802 | Acc: 62.197% (27944/4492 351/391 ====================>..]  Step: 50ms | Tot: 17s458ms | Loss: 60072.755 | Acc: 62.196% (28023/4505 352/391 ====================>..]  Step: 49ms | Tot: 17s560ms | Loss: 60072.662 | Acc: 62.189% (28179/4531 354/391 ====>..]  Step: 48ms | Tot: 17s760ms | Loss: 60072.475 | Acc: 62.166% (28487/45 358/391 >.]  Step: 45ms | Tot: 18s235ms | Loss: 60072.052 | Acc: 62.151% (29196/4697 367/391 ============>.]  Step: 48ms | Tot: 18s388ms | Loss: 60071.912 | Acc: 62.141% (29430/4736 370/391 .]  Step: 47ms | Tot: 18s436ms | Loss: 60071.865 | Acc: 62.163% (29520/4748 371/391 ====>.]  Step: 51ms | Tot: 18s487ms | Loss: 60071.818 | Acc: 62.156% (29596/4761 372/391 373/39 381/391 =====>]  Step: 48ms | Tot: 19s146ms | Loss: 60071.210 | Acc: 62.104% (30605/4928 385/391 386/391   Step: 49ms | Tot: 19s242ms | Loss: 60071.116 | Acc: 62.086% (30755/4953 387/391 ========================>]  Step: 56ms | Tot: 19s444ms | Loss: 60070.928 | Acc: 62.112% (31056/5000 391/391 \n",
      " [========================>]  Step: 46ms | Tot: 3s548ms | Loss: 2.014 | Acc: 50.430% (5043/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(126.9304, device='cuda:0'), tensor(126.5320, device='cuda:0'), tensor(126.7699, device='cuda:0'), tensor(127.0817, device='cuda:0'), tensor(126.3421, device='cuda:0'), tensor(127.3886, device='cuda:0'), tensor(127.3848, device='cuda:0')]\n",
      "\n",
      "Epoch: 38\n",
      " [========================>]  Step: 56ms | Tot: 24s898ms | Loss: 60034.301 | Acc: 62.434% (31217/5000 391/391 91 >.......................]  Step: 71ms | Tot: 1s887ms | Loss: 60051.258 | Acc: 61.422% (2280/371 29/391 .........]  Step: 69ms | Tot: 2s369ms | Loss: 60050.955 | Acc: 61.176% (2819/460 36/391 ==>......................]  Step: 69ms | Tot: 2s439ms | Loss: 60050.910 | Acc: 61.085% (2893/473 37/39 50/391 ===>.....................]  Step: 69ms | Tot: 3s570ms | Loss: 60050.118 | Acc: 61.429% (4246/691 54/39 58/391 ..........]  Step: 69ms | Tot: 4s671ms | Loss: 60049.354 | Acc: 61.830% (5540/896 70/391 ..]  Step: 68ms | Tot: 5s64ms | Loss: 60049.073 | Acc: 61.832% (6015/972 76/39 91/391 =====>...................]  Step: 64ms | Tot: 6s136ms | Loss: 60048.318 | Acc: 61.931% (7293/1177 92/391 ======>..................]  Step: 68ms | Tot: 6s680ms | Loss: 60047.939 | Acc: 61.961% (7931/1280 100/391 ........]  Step: 58ms | Tot: 6s880ms | Loss: 60047.796 | Acc: 62.037% (8179/1318 103/39 111/391 ===>.................]  Step: 65ms | Tot: 8s438ms | Loss: 60046.716 | Acc: 62.178% (10028/1612 126/39 129/391 ========>................]  Step: 68ms | Tot: 9s305ms | Loss: 60046.106 | Acc: 62.286% (11082/1779 139/39 142/ 145/391 ========>..............]  Step: 60ms | Tot: 10s991ms | Loss: 60044.935 | Acc: 62.124% (13041/2099 164/391 ========>..............]  Step: 66ms | Tot: 11s335ms | Loss: 60044.700 | Acc: 62.190% (13453/2163 169/39 234/391 ======>.........]  Step: 65ms | Tot: 15s575ms | Loss: 60041.563 | Acc: 62.238% (18801/3020 236/391 380/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s527ms | Loss: 2.019 | Acc: 50.590% (5059/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(126.4336, device='cuda:0'), tensor(126.6670, device='cuda:0'), tensor(126.6535, device='cuda:0'), tensor(126.6290, device='cuda:0'), tensor(126.7180, device='cuda:0'), tensor(126.8485, device='cuda:0'), tensor(126.8391, device='cuda:0')]\n",
      "\n",
      "Epoch: 39\n",
      " [========================>]  Step: 68ms | Tot: 23s995ms | Loss: 59997.741 | Acc: 62.510% (31205/4992 390/391 ........]  Step: 63ms | Tot: 3s382ms | Loss: 60013.400 | Acc: 61.733% (4425/716 56/391 228/391 245/39 333/391 ================>...]  Step: 68ms | Tot: 20s879ms | Loss: 59999.987 | Acc: 62.548% (27381/4377 342/391 =====================>...]  Step: 66ms | Tot: 21s10ms | Loss: 59999.893 | Acc: 62.559% (27546/4403 344/391 349/391 357/391 >.]  Step: 65ms | Tot: 22s233ms | Loss: 59999.004 | Acc: 62.517% (29048/4646 363/391 367/39 374/39 376/391 ========================>]  Step: 63ms | Tot: 24s58ms | Loss: 59997.693 | Acc: 62.520% (31260/5000 391/391 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 43ms | Tot: 3s749ms | Loss: 2.026 | Acc: 50.530% (5053/1000 79/79 .......]  Step: 45ms | Tot: 2s68ms | Loss: 2.026 | Acc: 50.260% (2895/576 45/79 .....]  Step: 45ms | Tot: 2s269ms | Loss: 2.030 | Acc: 50.223% (3150/627 49/79 ==========>.........]  Step: 54ms | Tot: 2s323ms | Loss: 2.025 | Acc: 50.328% (3221/640 50/79 =============>.........]  Step: 45ms | Tot: 2s369ms | Loss: 2.029 | Acc: 50.398% (3290/652 51/79 ======>........]  Step: 45ms | Tot: 2s469ms | Loss: 2.024 | Acc: 50.516% (3427/678 53/79 66/79 =================>...]  Step: 55ms | Tot: 3s326ms | Loss: 2.025 | Acc: 50.513% (4526/896 70/7 75/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(126.3112, device='cuda:0'), tensor(126.0520, device='cuda:0'), tensor(126.2500, device='cuda:0'), tensor(126.3692, device='cuda:0'), tensor(126.2307, device='cuda:0'), tensor(126.3785, device='cuda:0'), tensor(126.3878, device='cuda:0')]\n",
      "\n",
      "Epoch: 40\n",
      " [========================>]  Step: 67ms | Tot: 24s10ms | Loss: 59961.133 | Acc: 62.586% (31243/4992 390/391  1/391 .....]  Step: 73ms | Tot: 9s105ms | Loss: 59972.150 | Acc: 61.941% (12289/1984 155/391 ......]  Step: 72ms | Tot: 9s712ms | Loss: 59971.680 | Acc: 62.041% (13103/2112 165/391 177/39 179/391 .........]  Step: 70ms | Tot: 10s852ms | Loss: 59970.835 | Acc: 62.086% (14543/2342 183/391 .]  Step: 73ms | Tot: 10s981ms | Loss: 59970.741 | Acc: 62.095% (14704/2368 185/391 189/391 209/391 ===>...........]  Step: 76ms | Tot: 12s758ms | Loss: 59969.425 | Acc: 62.291% (16983/2726 213/391 ...]  Step: 73ms | Tot: 13s150ms | Loss: 59969.144 | Acc: 62.286% (17460/2803 219/39 221/391 239/39 247/39 255/39 257/39 259/39 263/39 269/391 =========>.......]  Step: 69ms | Tot: 16s425ms | Loss: 59966.703 | Acc: 62.494% (21678/3468 271/391 275/391 ========>......]  Step: 73ms | Tot: 17s609ms | Loss: 59965.860 | Acc: 62.538% (23134/3699 289/391 ====>......]  Step: 75ms | Tot: 18s3ms | Loss: 59965.579 | Acc: 62.569% (23626/3776 295/391 ==>.....]  Step: 75ms | Tot: 18s910ms | Loss: 59964.925 | Acc: 62.556% (24742/3955 309/39 315/391 ============>....]  Step: 71ms | Tot: 19s404ms | Loss: 59964.550 | Acc: 62.537% (25375/4057 317/391 ====>....]  Step: 65ms | Tot: 19s534ms | Loss: 59964.456 | Acc: 62.559% (25544/4083 319/391 ==================>]  Step: 62ms | Tot: 24s73ms | Loss: 59961.085 | Acc: 62.592% (31296/5000 391/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s515ms | Loss: 2.025 | Acc: 50.550% (5055/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(125.7079, device='cuda:0'), tensor(125.5470, device='cuda:0'), tensor(125.7993, device='cuda:0'), tensor(125.8800, device='cuda:0'), tensor(125.8184, device='cuda:0'), tensor(125.9055, device='cuda:0'), tensor(125.8959, device='cuda:0')]\n",
      "\n",
      "Epoch: 41\n",
      " [========================>]  Step: 60ms | Tot: 23s357ms | Loss: 59924.485 | Acc: 62.654% (31327/5000 391/391 2/391 109/391 =>.................]  Step: 68ms | Tot: 6s211ms | Loss: 59937.592 | Acc: 62.162% (8832/1420 111/391 162/391 164/39 166/39 169/391 174/39 249/39 267/39 284/391   Step: 65ms | Tot: 16s596ms | Loss: 59929.449 | Acc: 62.503% (22801/3648 285/391 =============>......]  Step: 67ms | Tot: 16s663ms | Loss: 59929.402 | Acc: 62.497% (22879/3660 286/39 341/39 346/39 375/391 380/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s530ms | Loss: 2.019 | Acc: 50.550% (5055/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(125.3650, device='cuda:0'), tensor(125.3574, device='cuda:0'), tensor(125.2772, device='cuda:0'), tensor(125.2268, device='cuda:0'), tensor(125.4461, device='cuda:0'), tensor(125.3610, device='cuda:0'), tensor(125.3766, device='cuda:0')]\n",
      "\n",
      "Epoch: 42\n",
      " [========================>]  Step: 60ms | Tot: 23s551ms | Loss: 59887.882 | Acc: 63.070% (31535/5000 391/391 ...........]  Step: 68ms | Tot: 808ms | Loss: 59905.534 | Acc: 62.723% (1124/179 14/391 ..]  Step: 63ms | Tot: 941ms | Loss: 59905.444 | Acc: 62.988% (1290/204 16/39 143/391 209/391 211/391 ....]  Step: 62ms | Tot: 13s320ms | Loss: 59896.084 | Acc: 62.695% (17334/2764 216/391 ==========>..........]  Step: 69ms | Tot: 13s733ms | Loss: 59895.800 | Acc: 62.774% (17838/2841 222/39 238/391 255/391 257/391 =======>]  Step: 47ms | Tot: 22s837ms | Loss: 59888.489 | Acc: 63.106% (30533/4838 378/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s620ms | Loss: 2.020 | Acc: 50.680% (5068/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(126.9880, device='cuda:0'), tensor(126.8757, device='cuda:0'), tensor(127.0980, device='cuda:0'), tensor(126.9589, device='cuda:0'), tensor(126.8638, device='cuda:0'), tensor(127.3261, device='cuda:0'), tensor(127.4521, device='cuda:0')]\n",
      "\n",
      "Epoch: 43\n",
      " [========================>]  Step: 60ms | Tot: 23s506ms | Loss: 59851.287 | Acc: 62.752% (31376/5000 391/391 /391 123/391 167/391 169/391 172/391 ======>.............]  Step: 70ms | Tot: 9s766ms | Loss: 59861.316 | Acc: 62.421% (14142/2265 177/391 179/391 199/39 201/391 205/391 233/391 234/39 243/391 244/39 271/391 278/39 280/391 282/391 283/391 =============>......]  Step: 63ms | Tot: 16s715ms | Loss: 59856.253 | Acc: 62.634% (22849/3648 285/391 287/391 ....]  Step: 67ms | Tot: 16s916ms | Loss: 59856.112 | Acc: 62.652% (23096/3686 288/391 313/391 ===============>....]  Step: 68ms | Tot: 18s642ms | Loss: 59854.845 | Acc: 62.760% (25305/4032 315/39 317/391 333/39 353/391 355/391 ==========>..]  Step: 65ms | Tot: 21s428ms | Loss: 59852.830 | Acc: 62.825% (28789/4582 358/39 364/391 =>.]  Step: 67ms | Tot: 21s884ms | Loss: 59852.502 | Acc: 62.793% (29337/4672 365/391 367/391 ==============>.]  Step: 69ms | Tot: 22s83ms | Loss: 59852.361 | Acc: 62.814% (29588/4710 368/391 369/39 377/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s542ms | Loss: 2.028 | Acc: 50.940% (5094/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(124.5149, device='cuda:0'), tensor(123.8909, device='cuda:0'), tensor(124.3620, device='cuda:0'), tensor(124.6346, device='cuda:0'), tensor(124.6380, device='cuda:0'), tensor(124.3062, device='cuda:0'), tensor(124.3699, device='cuda:0')]\n",
      "\n",
      "Epoch: 44\n",
      " [========================>]  Step: 58ms | Tot: 24s961ms | Loss: 59814.690 | Acc: 63.132% (31566/5000 391/391 0/39 25/391 ..........]  Step: 71ms | Tot: 1s960ms | Loss: 59831.539 | Acc: 63.332% (2513/396 31/391 >......................]  Step: 72ms | Tot: 2s353ms | Loss: 59831.285 | Acc: 62.310% (2951/473 37/391 45/391   Step: 70ms | Tot: 2s999ms | Loss: 59830.822 | Acc: 62.151% (3739/601 47/391 55/391 57/391 ............]  Step: 74ms | Tot: 4s277ms | Loss: 59829.878 | Acc: 62.383% (5350/857 67/39 69/391 ............]  Step: 75ms | Tot: 4s904ms | Loss: 59829.412 | Acc: 62.185% (6129/985 77/391 .....]  Step: 75ms | Tot: 5s799ms | Loss: 59828.748 | Acc: 62.423% (7271/1164 91/391 113/39 115/391 117/391 ====>................]  Step: 71ms | Tot: 8s395ms | Loss: 59826.772 | Acc: 62.606% (10658/1702 133/391 ....]  Step: 72ms | Tot: 8s523ms | Loss: 59826.678 | Acc: 62.610% (10819/1728 135/39 137/391 ==>..............]  Step: 72ms | Tot: 10s137ms | Loss: 59825.465 | Acc: 62.597% (12900/2060 161/391 201/391 ==>............]  Step: 70ms | Tot: 12s822ms | Loss: 59823.502 | Acc: 62.631% (16274/2598 203/391 .....]  Step: 69ms | Tot: 13s216ms | Loss: 59823.220 | Acc: 62.717% (16778/2675 209/391 =>...........]  Step: 69ms | Tot: 13s347ms | Loss: 59823.125 | Acc: 62.778% (16955/2700 211/391 ]  Step: 70ms | Tot: 13s609ms | Loss: 59822.937 | Acc: 62.783% (17278/2752 215/39 229/391 ====>.........]  Step: 70ms | Tot: 15s666ms | Loss: 59821.435 | Acc: 62.876% (19879/3161 247/391 .......]  Step: 71ms | Tot: 15s798ms | Loss: 59821.340 | Acc: 62.949% (20063/3187 249/391 =====>........]  Step: 70ms | Tot: 16s181ms | Loss: 59821.059 | Acc: 62.999% (20563/3264 255/391 ==========>........]  Step: 71ms | Tot: 16s313ms | Loss: 59820.966 | Acc: 62.992% (20722/3289 257/391 ====>.......]  Step: 75ms | Tot: 17s98ms | Loss: 59820.405 | Acc: 63.026% (21701/3443 269/39 295/39 299/391 ===========>.....]  Step: 75ms | Tot: 19s165ms | Loss: 59818.909 | Acc: 63.006% (24275/3852 301/391 .]  Step: 65ms | Tot: 19s422ms | Loss: 59818.723 | Acc: 62.979% (24587/3904 305/39 307/391 =======>....]  Step: 69ms | Tot: 20s214ms | Loss: 59818.160 | Acc: 63.013% (25568/4057 317/391 ==========>....]  Step: 68ms | Tot: 20s344ms | Loss: 59818.067 | Acc: 63.002% (25725/4083 319/391 321/391 ..]  Step: 67ms | Tot: 21s393ms | Loss: 59817.316 | Acc: 63.048% (27035/4288 335/391 341/391 ==>...]  Step: 68ms | Tot: 21s889ms | Loss: 59816.940 | Acc: 63.088% (27698/4390 343/391 .]  Step: 69ms | Tot: 22s19ms | Loss: 59816.846 | Acc: 63.091% (27861/4416 345/391 ====>..]  Step: 71ms | Tot: 22s402ms | Loss: 59816.564 | Acc: 63.145% (28370/4492 351/39 355/391 ==============>..]  Step: 67ms | Tot: 22s793ms | Loss: 59816.284 | Acc: 63.126% (28846/4569 357/39 363/391 ========>.]  Step: 70ms | Tot: 23s561ms | Loss: 59815.722 | Acc: 63.101% (29804/4723 369/39 371/39 379/39 383/391 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s438ms | Loss: 2.036 | Acc: 50.670% (5067/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(123.7128, device='cuda:0'), tensor(123.9572, device='cuda:0'), tensor(123.8389, device='cuda:0'), tensor(123.6442, device='cuda:0'), tensor(123.9339, device='cuda:0'), tensor(123.8033, device='cuda:0'), tensor(123.8087, device='cuda:0')]\n",
      "\n",
      "Epoch: 45\n",
      " [========================>]  Step: 68ms | Tot: 24s410ms | Loss: 59778.089 | Acc: 63.332% (31666/5000 391/391 ]  Step: 68ms | Tot: 2s680ms | Loss: 59794.324 | Acc: 62.483% (3599/576 45/391 .................]  Step: 70ms | Tot: 3s195ms | Loss: 59793.947 | Acc: 62.471% (4238/678 53/391 .................]  Step: 71ms | Tot: 5s425ms | Loss: 59792.246 | Acc: 62.816% (7156/1139 89/391 ............]  Step: 70ms | Tot: 5s819ms | Loss: 59791.962 | Acc: 62.903% (7649/1216 95/391 ............]  Step: 69ms | Tot: 6s80ms | Loss: 59791.779 | Acc: 62.808% (7959/1267 99/39 101/391 240/391 =====>....]  Step: 65ms | Tot: 19s668ms | Loss: 59781.467 | Acc: 63.230% (25818/4083 319/391 323/391 324/391 332/39 338/391 ==============>...]  Step: 62ms | Tot: 20s979ms | Loss: 59780.527 | Acc: 63.337% (27483/4339 339/391 =========>..]  Step: 65ms | Tot: 21s636ms | Loss: 59780.057 | Acc: 63.386% (28316/4467 349/391 =================>..]  Step: 70ms | Tot: 21s907ms | Loss: 59779.870 | Acc: 63.394% (28644/4518 353/39 355/391   Step: 68ms | Tot: 22s300ms | Loss: 59779.590 | Acc: 63.370% (29120/4595 359/391 =============>.]  Step: 66ms | Tot: 22s625ms | Loss: 59779.355 | Acc: 63.328% (29506/4659 364/39 385/391 386/391 389/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s525ms | Loss: 2.035 | Acc: 50.610% (5061/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(123.6819, device='cuda:0'), tensor(124.2642, device='cuda:0'), tensor(123.6661, device='cuda:0'), tensor(123.2886, device='cuda:0'), tensor(124.1003, device='cuda:0'), tensor(123.3374, device='cuda:0'), tensor(123.3709, device='cuda:0')]\n",
      "\n",
      "Epoch: 46\n",
      " [========================>]  Step: 61ms | Tot: 23s226ms | Loss: 59741.500 | Acc: 63.146% (31573/5000 391/391 .......]  Step: 44ms | Tot: 6s183ms | Loss: 59754.845 | Acc: 62.463% (8475/1356 106/391 389/391 =====>]  Step: 65ms | Tot: 23s165ms | Loss: 59741.547 | Acc: 63.133% (31516/4992 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s676ms | Loss: 2.037 | Acc: 50.390% (5039/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(120.2970, device='cuda:0'), tensor(120.1307, device='cuda:0'), tensor(120.3646, device='cuda:0'), tensor(120.6555, device='cuda:0'), tensor(119.9251, device='cuda:0'), tensor(120.6693, device='cuda:0'), tensor(120.6466, device='cuda:0')]\n",
      "\n",
      "Epoch: 47\n",
      " [========================>]  Step: 58ms | Tot: 24s394ms | Loss: 59704.908 | Acc: 63.244% (31622/5000 391/391 91 48/391 90/391 166/391 ===========>.............]  Step: 66ms | Tot: 11s535ms | Loss: 59714.560 | Acc: 62.732% (14855/2368 185/391 190/39 197/39 214/391 218/391 ..]  Step: 68ms | Tot: 13s714ms | Loss: 59712.968 | Acc: 62.800% (17604/2803 219/39 220/391 ==============>..........]  Step: 62ms | Tot: 14s240ms | Loss: 59712.594 | Acc: 62.820% (18253/2905 227/391  235/391 237/39 238/39 240/391 =========>.........]  Step: 65ms | Tot: 15s483ms | Loss: 59711.705 | Acc: 62.795% (19773/3148 246/391  247/391 248/391 260/391 281/39 283/39 288/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s407ms | Loss: 2.035 | Acc: 50.460% (5046/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(124.6712, device='cuda:0'), tensor(124.9330, device='cuda:0'), tensor(124.7037, device='cuda:0'), tensor(124.6719, device='cuda:0'), tensor(124.7396, device='cuda:0'), tensor(124.7500, device='cuda:0'), tensor(124.7104, device='cuda:0')]\n",
      "\n",
      "Epoch: 48\n",
      " [========================>]  Step: 67ms | Tot: 22s813ms | Loss: 59668.307 | Acc: 63.634% (31817/5000 391/391 91 49/391 117/391 124/391 129/391 ............]  Step: 47ms | Tot: 7s574ms | Loss: 59680.442 | Acc: 62.849% (10619/1689 132/39 133/391 ===>...........]  Step: 67ms | Tot: 12s219ms | Loss: 59676.837 | Acc: 63.139% (16891/2675 209/39 211/391 .........]  Step: 48ms | Tot: 13s661ms | Loss: 59675.710 | Acc: 63.197% (18848/2982 233/391 234/391 ........]  Step: 50ms | Tot: 13s766ms | Loss: 59675.617 | Acc: 63.191% (19008/3008 235/391 266/39 295/391 >....]  Step: 50ms | Tot: 19s363ms | Loss: 59671.212 | Acc: 63.573% (26772/4211 329/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s544ms | Loss: 2.038 | Acc: 50.830% (5083/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(124.5729, device='cuda:0'), tensor(124.9542, device='cuda:0'), tensor(124.3419, device='cuda:0'), tensor(124.3079, device='cuda:0'), tensor(124.8967, device='cuda:0'), tensor(124.2738, device='cuda:0'), tensor(124.2071, device='cuda:0')]\n",
      "\n",
      "Epoch: 49\n",
      " [========================>]  Step: 60ms | Tot: 20s975ms | Loss: 59631.713 | Acc: 63.946% (31973/5000 391/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s511ms | Loss: 2.044 | Acc: 50.540% (5054/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(119.2460, device='cuda:0'), tensor(119.0401, device='cuda:0'), tensor(119.1084, device='cuda:0'), tensor(119.1579, device='cuda:0'), tensor(119.2165, device='cuda:0'), tensor(119.2957, device='cuda:0'), tensor(119.2786, device='cuda:0')]\n",
      "\n",
      "Epoch: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 59ms | Tot: 24s177ms | Loss: 59595.121 | Acc: 63.956% (31978/5000 391/391 2/391 ........]  Step: 62ms | Tot: 9s772ms | Loss: 59605.985 | Acc: 63.576% (12939/2035 159/39 185/391 212/391 =======>......]  Step: 70ms | Tot: 18s54ms | Loss: 59599.755 | Acc: 63.907% (23886/3737 292/391   Step: 69ms | Tot: 18s316ms | Loss: 59599.566 | Acc: 63.975% (24239/3788 296/391 \n",
      " [========================>]  Step: 60ms | Tot: 3s474ms | Loss: 2.047 | Acc: 50.610% (5061/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(121.0106, device='cuda:0'), tensor(120.8518, device='cuda:0'), tensor(120.8799, device='cuda:0'), tensor(120.8073, device='cuda:0'), tensor(120.8225, device='cuda:0'), tensor(120.8744, device='cuda:0'), tensor(120.8779, device='cuda:0')]\n",
      "\n",
      "Epoch: 51\n",
      " [========================>]  Step: 62ms | Tot: 24s165ms | Loss: 59558.532 | Acc: 63.850% (31925/5000 391/391 ................]  Step: 70ms | Tot: 1s511ms | Loss: 59575.689 | Acc: 63.094% (2019/320 25/391 .................]  Step: 69ms | Tot: 2s428ms | Loss: 59575.060 | Acc: 62.079% (3099/499 39/39 41/391 ........]  Step: 71ms | Tot: 3s337ms | Loss: 59574.396 | Acc: 62.426% (4235/678 53/391 136/391 266/39 268/391 270/391 302/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s803ms | Loss: 2.046 | Acc: 50.300% (5030/1000 79/79 /7 32/79 35/7 39/79  43/7 44/79 45/79 ====>..........]  Step: 45ms | Tot: 2s232ms | Loss: 2.046 | Acc: 49.884% (3001/601 47/79 50/79 =============>.........]  Step: 45ms | Tot: 2s432ms | Loss: 2.049 | Acc: 50.031% (3266/652 51/79 68/7 73/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(120.4518, device='cuda:0'), tensor(120.2635, device='cuda:0'), tensor(120.4918, device='cuda:0'), tensor(120.5464, device='cuda:0'), tensor(120.6669, device='cuda:0'), tensor(120.5145, device='cuda:0'), tensor(120.4946, device='cuda:0')]\n",
      "\n",
      "Epoch: 52\n",
      " [========================>]  Step: 70ms | Tot: 24s33ms | Loss: 59521.937 | Acc: 64.120% (32060/5000 391/391  42/391 ....]  Step: 65ms | Tot: 17s97ms | Loss: 59526.900 | Acc: 63.991% (23344/3648 285/39 287/391  289/391 .]  Step: 69ms | Tot: 18s7ms | Loss: 59526.246 | Acc: 64.023% (24503/3827 299/391 ===============>.....]  Step: 65ms | Tot: 18s206ms | Loss: 59526.104 | Acc: 64.057% (24762/3865 302/391 ...]  Step: 67ms | Tot: 18s530ms | Loss: 59525.871 | Acc: 64.042% (25166/3929 307/39 309/391 313/39 318/39 325/391 ..]  Step: 65ms | Tot: 19s773ms | Loss: 59524.980 | Acc: 64.074% (26737/4172 326/391 =====>...]  Step: 68ms | Tot: 20s620ms | Loss: 59524.372 | Acc: 64.136% (27830/4339 339/391 ==============>...]  Step: 66ms | Tot: 20s821ms | Loss: 59524.231 | Acc: 64.136% (28076/4377 342/39 346/39 348/ 351/391 ================>..]  Step: 69ms | Tot: 21s871ms | Loss: 59523.482 | Acc: 64.108% (29377/4582 358/391 369/39 370/391 372/39 373/391   Step: 65ms | Tot: 22s913ms | Loss: 59522.733 | Acc: 64.115% (30693/4787 374/39 379/39 380/39 382/39 384/391 386/391 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s576ms | Loss: 2.046 | Acc: 50.540% (5054/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(120.1386, device='cuda:0'), tensor(119.7568, device='cuda:0'), tensor(119.8390, device='cuda:0'), tensor(120.0591, device='cuda:0'), tensor(119.8318, device='cuda:0'), tensor(119.9685, device='cuda:0'), tensor(119.9897, device='cuda:0')]\n",
      "\n",
      "Epoch: 53\n",
      " [========================>]  Step: 48ms | Tot: 20s752ms | Loss: 59485.350 | Acc: 64.444% (32222/5000 391/391 391 .....]  Step: 51ms | Tot: 6s592ms | Loss: 59497.672 | Acc: 63.721% (10440/1638 128/391 ...............]  Step: 46ms | Tot: 7s588ms | Loss: 59496.782 | Acc: 63.818% (12008/1881 147/39 148/391 .........]  Step: 55ms | Tot: 7s693ms | Loss: 59496.687 | Acc: 63.858% (12179/1907 149/391 ==========>..............]  Step: 50ms | Tot: 8s212ms | Loss: 59496.218 | Acc: 63.959% (13017/2035 159/39 160/391 ======>..............]  Step: 49ms | Tot: 8s575ms | Loss: 59495.887 | Acc: 64.025% (13604/2124 166/39 179/391  194/391 =>............]  Step: 50ms | Tot: 10s101ms | Loss: 59494.441 | Acc: 63.880% (16108/2521 197/39 198/39 203/391 ..]  Step: 48ms | Tot: 10s453ms | Loss: 59494.113 | Acc: 63.963% (16702/2611 204/391 ......]  Step: 47ms | Tot: 10s607ms | Loss: 59493.972 | Acc: 64.055% (16972/2649 207/391 =============>...........]  Step: 51ms | Tot: 10s908ms | Loss: 59493.689 | Acc: 64.154% (17491/2726 213/39 214/391 ..........]  Step: 47ms | Tot: 11s160ms | Loss: 59493.455 | Acc: 64.120% (17892/2790 218/391 ==>........]  Step: 50ms | Tot: 13s667ms | Loss: 59491.345 | Acc: 64.303% (21647/3366 263/391 ====>........]  Step: 50ms | Tot: 13s717ms | Loss: 59491.299 | Acc: 64.252% (21712/3379 264/39 274/391 =================>.......]  Step: 49ms | Tot: 14s281ms | Loss: 59490.784 | Acc: 64.281% (22627/3520 275/39 381/391 ========================>]  Step: 46ms | Tot: 20s336ms | Loss: 59485.724 | Acc: 64.440% (31591/4902 383/39 384/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s552ms | Loss: 2.051 | Acc: 50.420% (5042/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(121.4385, device='cuda:0'), tensor(121.7024, device='cuda:0'), tensor(121.7100, device='cuda:0'), tensor(121.6675, device='cuda:0'), tensor(121.3913, device='cuda:0'), tensor(121.7373, device='cuda:0'), tensor(121.6868, device='cuda:0')]\n",
      "\n",
      "Epoch: 54\n",
      " [========================>]  Step: 70ms | Tot: 21s440ms | Loss: 59448.766 | Acc: 64.182% (32091/5000 391/391 ........]  Step: 70ms | Tot: 605ms | Loss: 59466.596 | Acc: 62.578% (801/128 10/391 ...]  Step: 60ms | Tot: 935ms | Loss: 59466.375 | Acc: 62.708% (1204/192 15/391 .................]  Step: 66ms | Tot: 1s382ms | Loss: 59466.034 | Acc: 63.459% (1787/281 22/391 .......................]  Step: 60ms | Tot: 1s582ms | Loss: 59465.889 | Acc: 63.781% (2041/3 25/391 ...................]  Step: 65ms | Tot: 3s427ms | Loss: 59464.565 | Acc: 63.093% (4361/691 54/391 ............]  Step: 68ms | Tot: 3s496ms | Loss: 59464.518 | Acc: 63.082% (4441/704 55/391 ....................]  Step: 68ms | Tot: 4s203ms | Loss: 59463.993 | Acc: 63.329% (5350/844 66/391 72/391 ===>..................]  Step: 45ms | Tot: 6s227ms | Loss: 59462.296 | Acc: 63.664% (8312/1305 102/39 104/39 115/391 =======>.................]  Step: 50ms | Tot: 7s427ms | Loss: 59461.217 | Acc: 63.825% (10212/1600 125/391 >.................]  Step: 52ms | Tot: 7s480ms | Loss: 59461.172 | Acc: 63.845% (10297/1612 126/391 ========>................]  Step: 51ms | Tot: 7s996ms | Loss: 59460.703 | Acc: 63.821% (11110/1740 136/39 147/391 ==>...............]  Step: 51ms | Tot: 8s784ms | Loss: 59459.956 | Acc: 63.759% (12405/1945 152/39 167/391 ======>..............]  Step: 49ms | Tot: 9s624ms | Loss: 59459.205 | Acc: 63.751% (13709/2150 168/391 197/39 198/391 ==>...........]  Step: 50ms | Tot: 12s296ms | Loss: 59456.867 | Acc: 63.901% (17831/2790 218/39 219/391 228/391 270/39 282/391 ==================>......]  Step: 57ms | Tot: 15s995ms | Loss: 59453.633 | Acc: 64.098% (23547/3673 287/39 295/391 .]  Step: 53ms | Tot: 16s561ms | Loss: 59453.118 | Acc: 64.136% (24464/3814 298/391 ====================>....]  Step: 52ms | Tot: 17s400ms | Loss: 59452.369 | Acc: 64.122% (25772/4019 314/391 ================>....]  Step: 52ms | Tot: 17s600ms | Loss: 59452.182 | Acc: 64.148% (26111/4070 318/391 ...]  Step: 58ms | Tot: 18s345ms | Loss: 59451.478 | Acc: 64.231% (27378/4262 333/391 =====================>...]  Step: 49ms | Tot: 18s548ms | Loss: 59451.292 | Acc: 64.211% (27698/4313 337/391 =====>...]  Step: 48ms | Tot: 18s597ms | Loss: 59451.244 | Acc: 64.224% (27786/4326 338/39 344/391 ==============>.]  Step: 53ms | Tot: 20s464ms | Loss: 59449.607 | Acc: 64.199% (30651/4774 373/39 383/391 384/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s478ms | Loss: 2.046 | Acc: 50.550% (5055/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(119.0945, device='cuda:0'), tensor(118.9803, device='cuda:0'), tensor(119.0292, device='cuda:0'), tensor(119.1129, device='cuda:0'), tensor(119.1486, device='cuda:0'), tensor(119.0856, device='cuda:0'), tensor(119.0815, device='cuda:0')]\n",
      "\n",
      "Epoch: 55\n",
      " [========================>]  Step: 57ms | Tot: 23s831ms | Loss: 59412.172 | Acc: 64.634% (32317/5000 391/391 ...........]  Step: 65ms | Tot: 334ms | Loss: 59430.222 | Acc: 63.542% (488/76 6/391 17/391 28/391 .......]  Step: 65ms | Tot: 1s810ms | Loss: 59429.124 | Acc: 64.628% (2399/371 29/391 50/39 60/391 ...........]  Step: 67ms | Tot: 3s794ms | Loss: 59427.635 | Acc: 64.088% (5004/780 61/39 67/39 89/391 >..................]  Step: 68ms | Tot: 6s104ms | Loss: 59425.848 | Acc: 64.512% (8175/1267 99/391 .]  Step: 69ms | Tot: 6s173ms | Loss: 59425.801 | Acc: 64.508% (8257/1280 100/391 101/39 109/39 138/391 .]  Step: 70ms | Tot: 10s540ms | Loss: 59422.242 | Acc: 64.422% (14513/2252 176/39 188/39 194/391 ]  Step: 69ms | Tot: 12s44ms | Loss: 59421.120 | Acc: 64.379% (16481/2560 200/391 ..]  Step: 69ms | Tot: 12s558ms | Loss: 59420.746 | Acc: 64.423% (17152/2662 208/391 ==========>...........]  Step: 70ms | Tot: 12s822ms | Loss: 59420.556 | Acc: 64.508% (17505/2713 212/391 =====>...........]  Step: 72ms | Tot: 12s953ms | Loss: 59420.463 | Acc: 64.475% (17661/2739 214/391 ============>..........]  Step: 66ms | Tot: 13s345ms | Loss: 59420.182 | Acc: 64.478% (18157/2816 220/391 =>.........]  Step: 67ms | Tot: 14s333ms | Loss: 59419.431 | Acc: 64.602% (19515/3020 236/39 238/391 242/391 =============>.........]  Step: 75ms | Tot: 15s234ms | Loss: 59418.776 | Acc: 64.584% (20667/3200 250/391 ...]  Step: 70ms | Tot: 15s360ms | Loss: 59418.682 | Acc: 64.596% (20836/3225 252/39 254/39 296/39 298/391 ====>.....]  Step: 72ms | Tot: 18s238ms | Loss: 59416.434 | Acc: 64.625% (24816/3840 300/39 308/391 ==>....]  Step: 69ms | Tot: 19s521ms | Loss: 59415.498 | Acc: 64.590% (26456/4096 320/39 322/39 324/391 =============>.]  Step: 71ms | Tot: 22s102ms | Loss: 59413.529 | Acc: 64.654% (29958/4633 362/39 364/39 370/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s528ms | Loss: 2.057 | Acc: 50.380% (5038/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(116.4460, device='cuda:0'), tensor(116.5243, device='cuda:0'), tensor(116.5197, device='cuda:0'), tensor(116.5812, device='cuda:0'), tensor(116.3588, device='cuda:0'), tensor(116.5278, device='cuda:0'), tensor(116.5278, device='cuda:0')]\n",
      "\n",
      "Epoch: 56\n",
      " [========================>]  Step: 61ms | Tot: 22s556ms | Loss: 59375.579 | Acc: 64.516% (32258/5000 391/391  25/391 ...]  Step: 52ms | Tot: 1s878ms | Loss: 59392.153 | Acc: 62.808% (3055/486 38/39 42/39 56/391 ===>.....................]  Step: 51ms | Tot: 3s139ms | Loss: 59390.962 | Acc: 63.467% (5118/806 63/391 =====>...................]  Step: 49ms | Tot: 4s430ms | Loss: 59389.775 | Acc: 63.991% (7208/1126 88/391 =====>...................]  Step: 48ms | Tot: 4s630ms | Loss: 59389.583 | Acc: 64.181% (7558/1177 92/391 ................]  Step: 51ms | Tot: 4s682ms | Loss: 59389.536 | Acc: 64.180% (7640/1190 93/391 =====>...................]  Step: 50ms | Tot: 4s732ms | Loss: 59389.487 | Acc: 64.237% (7729/1203 94/391 .......]  Step: 47ms | Tot: 4s883ms | Loss: 59389.344 | Acc: 64.248% (7977/1241 97/39 98/391 ...............]  Step: 38ms | Tot: 5s257ms | Loss: 59389.012 | Acc: 64.325% (8563/1331 104/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s857ms | Loss: 2.069 | Acc: 50.400% (5040/1000 79/79 79 19/7 21/79 23/79 27/7 29/7 30/7 32/79 35/79 =========>.............]  Step: 45ms | Tot: 1s734ms | Loss: 2.060 | Acc: 50.087% (2308/460 36/79 38/79 40/79 =========>...........]  Step: 55ms | Tot: 2s89ms | Loss: 2.073 | Acc: 49.909% (2747/550 43/79  51/79 ]  Step: 55ms | Tot: 2s588ms | Loss: 2.068 | Acc: 50.280% (3411/678 53/79 ====>.......]  Step: 55ms | Tot: 2s688ms | Loss: 2.072 | Acc: 50.213% (3535/704 55/79 ===============>......]  Step: 56ms | Tot: 2s889ms | Loss: 2.071 | Acc: 50.212% (3792/755 59/79 ....]  Step: 55ms | Tot: 2s989ms | Loss: 2.076 | Acc: 50.077% (3910/780 61/79   Step: 44ms | Tot: 3s34ms | Loss: 2.075 | Acc: 50.050% (3972/793 62/7 67/79 ========>...]  Step: 45ms | Tot: 3s334ms | Loss: 2.067 | Acc: 50.391% (4386/870 68/79 ]  Step: 54ms | Tot: 3s389ms | Loss: 2.067 | Acc: 50.476% (4458/883 69/79 71/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(118.0036, device='cuda:0'), tensor(117.8371, device='cuda:0'), tensor(118.0524, device='cuda:0'), tensor(118.2065, device='cuda:0'), tensor(117.6864, device='cuda:0'), tensor(118.1267, device='cuda:0'), tensor(118.1582, device='cuda:0')]\n",
      "\n",
      "Epoch: 57\n",
      " [========================>]  Step: 56ms | Tot: 21s787ms | Loss: 59338.992 | Acc: 64.888% (32444/5000 391/391 1 ...............]  Step: 50ms | Tot: 1s971ms | Loss: 59355.556 | Acc: 62.993% (3064/486 38/391 ==>......................]  Step: 47ms | Tot: 2s172ms | Loss: 59355.370 | Acc: 63.170% (3396/537 42/39 83/39 246/391  303/391 325/39 327/391 ===============>...]  Step: 50ms | Tot: 19s252ms | Loss: 59341.238 | Acc: 64.903% (28495/4390 343/391 345/391 ==>.]  Step: 45ms | Tot: 20s842ms | Loss: 59339.835 | Acc: 64.904% (30988/4774 373/391 =======================>.]  Step: 45ms | Tot: 20s941ms | Loss: 59339.741 | Acc: 64.925% (31164/4800 375/39 390/391 \n",
      " [===>.....................]  Step: 45ms | Tot: 453ms | Loss: 2.161 | Acc: 50.000% (704/140 11/79 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4896db60c432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mSBP_net_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msbp_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mSBP_net_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msbp_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-a1064e237ff8>\u001b[0m in \u001b[0;36mSBP_net_test\u001b[0;34m(epoch, net, criterion)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mClient\u001b[0;34m(address, family, authkey)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSocketClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mauthkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mSocketClient\u001b[0;34m(address)\u001b[0m\n\u001b[1;32m    617\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetblocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 619\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mConnection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(0,300):\n",
    "    SBP_net_train(epoch,sbp_net,optimizer=optimizer,criterion=nn.CrossEntropyLoss())\n",
    "    SBP_net_test(epoch,sbp_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equal_optimizer.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Equal KL Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 71ms | Tot: 22s651ms | Loss: 54.625 | Acc: 2.440% (1220/5000 391/391 43/391 .........]  Step: 67ms | Tot: 3s427ms | Loss: 55.425 | Acc: 1.353% (97/716 56/391 ]  Step: 59ms | Tot: 3s872ms | Loss: 55.405 | Acc: 1.438% (116/806 63/391 ............]  Step: 62ms | Tot: 8s709ms | Loss: 55.157 | Acc: 1.539% (329/2137 167/39 332/391 349/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s590ms | Loss: 4.332 | Acc: 6.030% (603/1000 79/79 9 ====>..................]  Step: 46ms | Tot: 992ms | Loss: 4.325 | Acc: 6.001% (169/281 22/7 23/79 24/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(207.3795, device='cuda:0'), tensor(207.5979, device='cuda:0'), tensor(207.8234, device='cuda:0'), tensor(207.5694, device='cuda:0'), tensor(207.5939, device='cuda:0'), tensor(208.0278, device='cuda:0'), tensor(208.0318, device='cuda:0')]\n",
      "\n",
      "Epoch: 1\n",
      " [========================>]  Step: 54ms | Tot: 24s735ms | Loss: 52.857 | Acc: 5.188% (2594/5000 391/391 /391 .........]  Step: 68ms | Tot: 3s534ms | Loss: 53.553 | Acc: 4.263% (311/729 57/391 ..........]  Step: 68ms | Tot: 3s603ms | Loss: 53.551 | Acc: 4.270% (317/742 58/39 59/391 77/391 ..................]  Step: 66ms | Tot: 5s57ms | Loss: 53.500 | Acc: 4.273% (443/1036 81/39 83/39 96/391 .........]  Step: 65ms | Tot: 6s976ms | Loss: 53.433 | Acc: 4.329% (615/1420 111/391 119/391 ..........]  Step: 68ms | Tot: 7s952ms | Loss: 53.402 | Acc: 4.340% (700/1612 126/391 .........]  Step: 67ms | Tot: 9s42ms | Loss: 53.362 | Acc: 4.524% (828/1830 143/391 ....]  Step: 68ms | Tot: 9s111ms | Loss: 53.360 | Acc: 4.525% (834/1843 144/39 145/39 152/391 164/391 169/391 ..]  Step: 70ms | Tot: 11s946ms | Loss: 53.263 | Acc: 4.609% (1115/2419 189/391 190/391 ============>............]  Step: 68ms | Tot: 12s78ms | Loss: 53.259 | Acc: 4.589% (1122/2444 191/391 =>............]  Step: 69ms | Tot: 12s147ms | Loss: 53.257 | Acc: 4.574% (1124/2457 192/391 ======>............]  Step: 68ms | Tot: 12s410ms | Loss: 53.248 | Acc: 4.580% (1149/2508 196/391 ..........]  Step: 61ms | Tot: 12s472ms | Loss: 53.245 | Acc: 4.592% (1158/2521 197/391 =====>............]  Step: 69ms | Tot: 12s673ms | Loss: 53.238 | Acc: 4.594% (1176/2560 200/391 .]  Step: 68ms | Tot: 12s804ms | Loss: 53.234 | Acc: 4.591% (1187/2585 202/391 ..]  Step: 71ms | Tot: 12s937ms | Loss: 53.230 | Acc: 4.584% (1197/2611 204/391 ======>...........]  Step: 68ms | Tot: 13s6ms | Loss: 53.228 | Acc: 4.585% (1203/2624 205/39 207/391 ====>...........]  Step: 71ms | Tot: 13s390ms | Loss: 53.214 | Acc: 4.650% (1256/2700 211/391 ====>...........]  Step: 60ms | Tot: 13s589ms | Loss: 53.208 | Acc: 4.680% (1282/2739 214/391 238/391 263/39 270/391 ..]  Step: 63ms | Tot: 17s201ms | Loss: 53.086 | Acc: 4.906% (1708/3481 272/391  300/391 302/39 303/391 =====>.....]  Step: 67ms | Tot: 19s436ms | Loss: 53.016 | Acc: 5.021% (1973/3929 307/391 ==>....]  Step: 68ms | Tot: 19s891ms | Loss: 53.003 | Acc: 5.036% (2024/4019 314/391 338/391 339/391 ==>...]  Step: 69ms | Tot: 21s686ms | Loss: 52.948 | Acc: 5.096% (2231/43 342/391 >.]  Step: 67ms | Tot: 23s8ms | Loss: 52.909 | Acc: 5.111% (2375/4646 363/39 368/391 370/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s561ms | Loss: 4.055 | Acc: 8.910% (891/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(181.1606, device='cuda:0'), tensor(181.1507, device='cuda:0'), tensor(180.9419, device='cuda:0'), tensor(181.1448, device='cuda:0'), tensor(181.1411, device='cuda:0'), tensor(181.5152, device='cuda:0'), tensor(181.5367, device='cuda:0')]\n",
      "\n",
      "Epoch: 2\n",
      " [========================>]  Step: 54ms | Tot: 24s349ms | Loss: 51.549 | Acc: 7.712% (3856/5000 391/391 .]  Step: 68ms | Tot: 266ms | Loss: 52.106 | Acc: 5.938% (38/64 5/391 .......]  Step: 67ms | Tot: 528ms | Loss: 52.078 | Acc: 6.858% (79/115 9/39 10/391 ..............]  Step: 69ms | Tot: 793ms | Loss: 52.091 | Acc: 6.791% (113/1 13/391 19/39 21/391 24/391  62/39 105/39 120/391 ....]  Step: 66ms | Tot: 9s60ms | Loss: 51.879 | Acc: 7.366% (1386/1881 147/39 152/39 161/391 ..........]  Step: 69ms | Tot: 10s281ms | Loss: 51.848 | Acc: 7.469% (1587/2124 166/391 ............]  Step: 69ms | Tot: 10s483ms | Loss: 51.846 | Acc: 7.424% (1606/2163 169/39 171/391 ........]  Step: 70ms | Tot: 11s833ms | Loss: 51.817 | Acc: 7.368% (1792/2432 190/39 211/39 213/39 293/391 ===============>..]  Step: 75ms | Tot: 21s780ms | Loss: 51.596 | Acc: 7.650% (3437/4492 351/391 357/391 359/391 ===============>.]  Step: 70ms | Tot: 22s563ms | Loss: 51.582 | Acc: 7.698% (3577/4646 363/391 ========>.]  Step: 74ms | Tot: 22s828ms | Loss: 51.578 | Acc: 7.700% (3617/4697 367/391 381/39 385/39 388/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s559ms | Loss: 3.885 | Acc: 11.030% (1103/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(164.5153, device='cuda:0'), tensor(165.5872, device='cuda:0'), tensor(165.3192, device='cuda:0'), tensor(165.6361, device='cuda:0'), tensor(165.7697, device='cuda:0'), tensor(165.6310, device='cuda:0'), tensor(165.6275, device='cuda:0')]\n",
      "\n",
      "Epoch: 3\n",
      " [========================>]  Step: 56ms | Tot: 22s537ms | Loss: 50.729 | Acc: 9.648% (4824/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s400ms | Loss: 3.762 | Acc: 12.590% (1259/1000 79/79 /79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(157.7774, device='cuda:0'), tensor(157.4804, device='cuda:0'), tensor(157.5941, device='cuda:0'), tensor(157.5409, device='cuda:0'), tensor(157.4873, device='cuda:0'), tensor(156.8550, device='cuda:0'), tensor(156.8557, device='cuda:0')]\n",
      "\n",
      "Epoch: 4\n",
      " [========================>]  Step: 64ms | Tot: 24s885ms | Loss: 50.243 | Acc: 10.904% (5452/5000 391/391 ]  Step: 70ms | Tot: 531ms | Loss: 50.424 | Acc: 10.590% (122/115 9/391 ..................]  Step: 60ms | Tot: 661ms | Loss: 50.428 | Acc: 10.440% (147/140 11/391 12/39 14/391   Step: 64ms | Tot: 1s64ms | Loss: 50.447 | Acc: 10.018% (218/217 17/391 ..................]  Step: 61ms | Tot: 1s467ms | Loss: 50.427 | Acc: 9.952% (293/294 23/39 27/391 =>.......................]  Step: 65ms | Tot: 1s931ms | Loss: 50.426 | Acc: 9.792% (376/384 30/39 31/391 33/391 35/391 .................]  Step: 70ms | Tot: 3s777ms | Loss: 50.407 | Acc: 10.112% (919/908 71/391 76/39 85/39 88/391 ...................]  Step: 64ms | Tot: 5s47ms | Loss: 50.388 | Acc: 10.503% (1210/1152 90/391 98/391 ..............]  Step: 71ms | Tot: 5s787ms | Loss: 50.385 | Acc: 10.589% (1369/1292 101/391 ...............]  Step: 60ms | Tot: 7s45ms | Loss: 50.375 | Acc: 10.690% (1642/1536 120/39 128/39 131/391 136/391 ...]  Step: 62ms | Tot: 8s520ms | Loss: 50.363 | Acc: 10.668% (1939/1817 142/39 148/391 .........]  Step: 63ms | Tot: 9s466ms | Loss: 50.357 | Acc: 10.637% (2124/1996 156/391 >..............]  Step: 61ms | Tot: 9s739ms | Loss: 50.354 | Acc: 10.635% (2178/2048 160/391 168/391 .........]  Step: 71ms | Tot: 10s478ms | Loss: 50.349 | Acc: 10.659% (2333/2188 171/391 ===>.............]  Step: 62ms | Tot: 10s678ms | Loss: 50.347 | Acc: 10.686% (2380/2227 174/391 ==========>.............]  Step: 60ms | Tot: 11s222ms | Loss: 50.344 | Acc: 10.654% (2482/2329 182/391 ......]  Step: 69ms | Tot: 11s484ms | Loss: 50.343 | Acc: 10.681% (2543/2380 186/39 187/39 190/39 193/391 ===>............]  Step: 62ms | Tot: 12s11ms | Loss: 50.340 | Acc: 10.652% (2645/2483 194/391 ====>............]  Step: 67ms | Tot: 12s210ms | Loss: 50.338 | Acc: 10.640% (2683/25 197/391 213/391 =>...........]  Step: 69ms | Tot: 13s509ms | Loss: 50.323 | Acc: 10.786% (2996/2777 217/39 218/391 243/391 ...]  Step: 68ms | Tot: 15s446ms | Loss: 50.307 | Acc: 10.757% (3401/3161 247/39 248/391 251/391 =====>........]  Step: 63ms | Tot: 15s914ms | Loss: 50.304 | Acc: 10.805% (3513/3251 254/391 ================>........]  Step: 64ms | Tot: 16s185ms | Loss: 50.301 | Acc: 10.832% (3577/3302 258/39 259/39 263/39 264/391 ==========>.......]  Step: 68ms | Tot: 16s839ms | Loss: 50.297 | Acc: 10.833% (3716/3430 268/391 ===>.......]  Step: 68ms | Tot: 17s172ms | Loss: 50.294 | Acc: 10.857% (3794/3494 273/391 ===============>......]  Step: 67ms | Tot: 18s332ms | Loss: 50.284 | Acc: 10.919% (4067/3724 291/391   Step: 65ms | Tot: 18s855ms | Loss: 50.279 | Acc: 10.922% (4180/3827 299/391 306/391 309/39 312/391 314/39 316/391 ]  Step: 67ms | Tot: 20s370ms | Loss: 50.272 | Acc: 10.850% (4472/4121 322/39 324/39 325/39 328/391 333/391 342/391 .]  Step: 65ms | Tot: 21s750ms | Loss: 50.263 | Acc: 10.869% (4772/4390 343/391 =======>..]  Step: 68ms | Tot: 22s343ms | Loss: 50.258 | Acc: 10.915% (4918/4505 352/391 ====>..]  Step: 69ms | Tot: 22s475ms | Loss: 50.258 | Acc: 10.904% (4941/4531 354/391 355/391 ===========>..]  Step: 64ms | Tot: 22s607ms | Loss: 50.257 | Acc: 10.905% (4969/4556 356/39 357/391 =>.]  Step: 69ms | Tot: 23s130ms | Loss: 50.254 | Acc: 10.888% (5073/4659 364/391 ========>.]  Step: 68ms | Tot: 23s522ms | Loss: 50.252 | Acc: 10.897% (5161/4736 370/391 =======================>.]  Step: 63ms | Tot: 23s787ms | Loss: 50.250 | Acc: 10.902% (5219/4787 374/39 377/391 ======>]  Step: 65ms | Tot: 24s370ms | Loss: 50.247 | Acc: 10.891% (5339/4902 383/391 387/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s620ms | Loss: 3.672 | Acc: 14.160% (1416/1000 79/79 .....]  Step: 63ms | Tot: 1s899ms | Loss: 3.656 | Acc: 14.509% (780/537 42/7 64/7 70/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(151.9397, device='cuda:0'), tensor(151.8093, device='cuda:0'), tensor(151.1989, device='cuda:0'), tensor(151.8883, device='cuda:0'), tensor(151.8699, device='cuda:0'), tensor(151.8861, device='cuda:0'), tensor(151.9213, device='cuda:0')]\n",
      "\n",
      "Epoch: 5\n",
      " [========================>]  Step: 67ms | Tot: 24s508ms | Loss: 49.949 | Acc: 12.096% (6048/5000 391/391 ]  Step: 68ms | Tot: 584ms | Loss: 50.070 | Acc: 11.094% (142/128 10/391 .......................]  Step: 65ms | Tot: 848ms | Loss: 50.076 | Acc: 11.217% (201/179 14/391 26/39 27/391 28/391 31/39 34/39 35/391 40/391 43/391 47/39 50/391 ....]  Step: 69ms | Tot: 3s277ms | Loss: 50.066 | Acc: 11.167% (729/652 51/391 ......]  Step: 61ms | Tot: 3s339ms | Loss: 50.064 | Acc: 11.238% (748/665 52/391 ...................]  Step: 69ms | Tot: 3s983ms | Loss: 50.057 | Acc: 11.379% (903/793 62/391 ...............]  Step: 68ms | Tot: 4s962ms | Loss: 50.048 | Acc: 11.465% (1130/985 77/391 .....]  Step: 63ms | Tot: 5s25ms | Loss: 50.049 | Acc: 11.438% (1142/998 78/391 .................]  Step: 62ms | Tot: 5s227ms | Loss: 50.049 | Acc: 11.372% (1179/1036 81/391 ...]  Step: 68ms | Tot: 5s295ms | Loss: 50.046 | Acc: 11.376% (1194/1049 82/391 92/39 94/39 96/391 108/39 111/391 112/391 .....]  Step: 64ms | Tot: 7s828ms | Loss: 50.030 | Acc: 11.654% (1805/1548 121/391 ==>.................]  Step: 71ms | Tot: 7s900ms | Loss: 50.029 | Acc: 11.693% (1826/1561 122/391 ........]  Step: 64ms | Tot: 8s313ms | Loss: 50.032 | Acc: 11.658% (1910/1638 128/39 149/391 ........]  Step: 63ms | Tot: 10s88ms | Loss: 50.021 | Acc: 11.875% (2356/1984 155/391 >..............]  Step: 66ms | Tot: 10s734ms | Loss: 50.013 | Acc: 11.899% (2513/2112 165/391 166/391 167/39 172/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s497ms | Loss: 3.598 | Acc: 15.280% (1528/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(148.6200, device='cuda:0'), tensor(148.6737, device='cuda:0'), tensor(149.4027, device='cuda:0'), tensor(148.6989, device='cuda:0'), tensor(148.6885, device='cuda:0'), tensor(148.7948, device='cuda:0'), tensor(148.8074, device='cuda:0')]\n",
      "\n",
      "Epoch: 6\n",
      " [========================>]  Step: 69ms | Tot: 23s419ms | Loss: 49.748 | Acc: 12.924% (6462/5000 391/391 45/39 348/391 ======================>..]  Step: 70ms | Tot: 20s825ms | Loss: 49.755 | Acc: 12.881% (5754/4467 349/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s563ms | Loss: 3.536 | Acc: 16.290% (1629/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(146.8329, device='cuda:0'), tensor(147.0265, device='cuda:0'), tensor(146.9765, device='cuda:0'), tensor(147.1895, device='cuda:0'), tensor(147.1476, device='cuda:0'), tensor(146.9179, device='cuda:0'), tensor(146.9308, device='cuda:0')]\n",
      "\n",
      "Epoch: 7\n",
      " [========================>]  Step: 61ms | Tot: 24s347ms | Loss: 49.604 | Acc: 13.714% (6857/5000 391/391 1   Step: 68ms | Tot: 2s209ms | Loss: 49.667 | Acc: 13.112% (621/473 37/391 58/391 194/391 .]  Step: 63ms | Tot: 11s779ms | Loss: 49.640 | Acc: 13.289% (3317/2496 195/391 .....]  Step: 68ms | Tot: 12s444ms | Loss: 49.636 | Acc: 13.304% (3491/2624 205/391 .......]  Step: 68ms | Tot: 13s90ms | Loss: 49.630 | Acc: 13.419% (3693/2752 215/391 219/391 234/391 241/391 ===============>.........]  Step: 62ms | Tot: 15s159ms | Loss: 49.623 | Acc: 13.509% (4271/3161 247/39 250/391 .]  Step: 64ms | Tot: 15s422ms | Loss: 49.621 | Acc: 13.533% (4348/3212 251/391 254/391 .......]  Step: 68ms | Tot: 15s954ms | Loss: 49.620 | Acc: 13.583% (4503/3315 259/391 268/391 ==========>.......]  Step: 64ms | Tot: 16s662ms | Loss: 49.619 | Acc: 13.582% (4694/3456 270/391 ....]  Step: 68ms | Tot: 17s245ms | Loss: 49.618 | Acc: 13.589% (4853/3571 279/391 =============>.......]  Step: 63ms | Tot: 17s309ms | Loss: 49.618 | Acc: 13.580% (4867/3584 280/391 ============>......]  Step: 70ms | Tot: 17s573ms | Loss: 49.617 | Acc: 13.565% (4931/3635 284/391 =====>......]  Step: 66ms | Tot: 17s843ms | Loss: 49.616 | Acc: 13.623% (5022/3686 288/39 290/39 294/39 296/391 ......]  Step: 69ms | Tot: 18s439ms | Loss: 49.615 | Acc: 13.623% (5179/3801 297/39 299/391 300/391 .]  Step: 69ms | Tot: 18s708ms | Loss: 49.613 | Acc: 13.650% (5259/3852 301/39 302/391 303/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s497ms | Loss: 3.484 | Acc: 17.210% (1721/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(145.0295, device='cuda:0'), tensor(145.2453, device='cuda:0'), tensor(145.0062, device='cuda:0'), tensor(145.1042, device='cuda:0'), tensor(145.2030, device='cuda:0'), tensor(145.3588, device='cuda:0'), tensor(145.3593, device='cuda:0')]\n",
      "\n",
      "Epoch: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 54ms | Tot: 24s308ms | Loss: 49.488 | Acc: 14.510% (7255/5000 391/391 1 ....................]  Step: 65ms | Tot: 3s77ms | Loss: 49.539 | Acc: 13.900% (943/678 53/391 54/391 63/391 ..........]  Step: 66ms | Tot: 3s868ms | Loss: 49.535 | Acc: 13.990% (1164/832 65/391 68/39 76/391 ..................]  Step: 66ms | Tot: 4s798ms | Loss: 49.533 | Acc: 13.944% (1410/10 79/391  81/391 ..........]  Step: 66ms | Tot: 5s445ms | Loss: 49.526 | Acc: 14.098% (1606/1139 89/39 92/39 104/391 >.................]  Step: 65ms | Tot: 7s82ms | Loss: 49.524 | Acc: 14.179% (2069/1459 114/391 .......]  Step: 67ms | Tot: 7s149ms | Loss: 49.524 | Acc: 14.219% (2093/1472 115/391 ===>.................]  Step: 67ms | Tot: 7s280ms | Loss: 49.522 | Acc: 14.276% (2138/1497 117/39 121/391 122/391 ==>.................]  Step: 69ms | Tot: 7s806ms | Loss: 49.524 | Acc: 14.294% (2287/16 125/391 ========>................]  Step: 61ms | Tot: 8s8ms | Loss: 49.527 | Acc: 14.258% (2336/1638 128/391 143/391 ..]  Step: 68ms | Tot: 9s231ms | Loss: 49.521 | Acc: 14.371% (2704/1881 147/391 ...........]  Step: 61ms | Tot: 9s565ms | Loss: 49.521 | Acc: 14.299% (2782/1945 152/391 161/391 =>..............]  Step: 68ms | Tot: 10s393ms | Loss: 49.516 | Acc: 14.266% (3013/2112 165/39 167/391 169/391 ........]  Step: 71ms | Tot: 10s726ms | Loss: 49.517 | Acc: 14.187% (3087/2176 170/391 ..]  Step: 61ms | Tot: 10s928ms | Loss: 49.519 | Acc: 14.162% (3136/2214 173/391 175/391 ===>.............]  Step: 65ms | Tot: 11s129ms | Loss: 49.519 | Acc: 14.187% (3196/2252 176/391 ===========>.............]  Step: 61ms | Tot: 11s331ms | Loss: 49.519 | Acc: 14.220% (3258/2291 179/391 ====>.............]  Step: 68ms | Tot: 11s400ms | Loss: 49.519 | Acc: 14.210% (3274/2304 180/391 ===>.............]  Step: 67ms | Tot: 11s855ms | Loss: 49.520 | Acc: 14.150% (3387/2393 187/39 191/39 192/391 201/391 ..........]  Step: 70ms | Tot: 12s854ms | Loss: 49.519 | Acc: 14.148% (3658/2585 202/391 ..........]  Step: 62ms | Tot: 12s917ms | Loss: 49.519 | Acc: 14.151% (3677/2598 203/391  204/391 ====>...........]  Step: 66ms | Tot: 13s670ms | Loss: 49.514 | Acc: 14.274% (3910/2739 214/391 .]  Step: 65ms | Tot: 13s735ms | Loss: 49.513 | Acc: 14.270% (3927/2752 215/391 ......]  Step: 62ms | Tot: 13s936ms | Loss: 49.511 | Acc: 14.288% (3987/2790 218/391 ..........]  Step: 62ms | Tot: 14s407ms | Loss: 49.509 | Acc: 14.344% (4131/2880 225/391 >..........]  Step: 67ms | Tot: 14s801ms | Loss: 49.508 | Acc: 14.343% (4241/2956 231/39 232/39 235/39 236/39 240/391 =====>.........]  Step: 65ms | Tot: 15s518ms | Loss: 49.506 | Acc: 14.379% (4454/3097 242/391 ========>.........]  Step: 69ms | Tot: 15s588ms | Loss: 49.506 | Acc: 14.368% (4469/3110 243/391 ===============>.........]  Step: 65ms | Tot: 15s653ms | Loss: 49.507 | Acc: 14.357% (4484/3123 244/391 ========>.........]  Step: 66ms | Tot: 15s720ms | Loss: 49.507 | Acc: 14.365% (4505/3136 245/391 248/391 =======>.........]  Step: 65ms | Tot: 16s122ms | Loss: 49.504 | Acc: 14.411% (4630/3212 251/391 ================>........]  Step: 69ms | Tot: 16s789ms | Loss: 49.503 | Acc: 14.422% (4818/3340 261/391 ....]  Step: 68ms | Tot: 16s857ms | Loss: 49.503 | Acc: 14.441% (4843/3353 262/39 263/39 267/39 268/391 269/39 285/391 ===============>....]  Step: 55ms | Tot: 20s409ms | Loss: 49.496 | Acc: 14.509% (5980/4121 322/391   Step: 68ms | Tot: 21s620ms | Loss: 49.493 | Acc: 14.509% (6370/4390 343/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s544ms | Loss: 3.435 | Acc: 18.060% (1806/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(144.2218, device='cuda:0'), tensor(144.1597, device='cuda:0'), tensor(144.3626, device='cuda:0'), tensor(144.7958, device='cuda:0'), tensor(144.9916, device='cuda:0'), tensor(144.3100, device='cuda:0'), tensor(144.3037, device='cuda:0')]\n",
      "\n",
      "Epoch: 9\n",
      " [========================>]  Step: 62ms | Tot: 24s318ms | Loss: 49.394 | Acc: 15.148% (7574/5000 391/391  ................]  Step: 66ms | Tot: 843ms | Loss: 49.433 | Acc: 15.513% (278/179 14/39 18/39 21/39 58/39 82/391 173/391 ===========>.............]  Step: 68ms | Tot: 10s491ms | Loss: 49.422 | Acc: 15.059% (3354/2227 174/39 193/39 206/391 .......]  Step: 68ms | Tot: 12s620ms | Loss: 49.418 | Acc: 14.919% (3972/2662 208/391 219/39 226/391 =================>.......]  Step: 62ms | Tot: 16s267ms | Loss: 49.407 | Acc: 15.069% (5150/3417 267/39 279/391 =>.......]  Step: 62ms | Tot: 17s155ms | Loss: 49.406 | Acc: 15.061% (5417/3596 281/391 ...]  Step: 69ms | Tot: 17s225ms | Loss: 49.405 | Acc: 15.057% (5435/3609 282/391 288/391 .]  Step: 68ms | Tot: 18s244ms | Loss: 49.401 | Acc: 15.124% (5769/3814 298/391 ==>.....]  Step: 63ms | Tot: 18s829ms | Loss: 49.401 | Acc: 15.080% (5926/3929 307/39 317/391  319/391 =============>....]  Step: 70ms | Tot: 19s865ms | Loss: 49.400 | Acc: 15.124% (6253/4134 323/391 ]  Step: 62ms | Tot: 21s199ms | Loss: 49.398 | Acc: 15.087% (6643/4403 344/391 ====================>..]  Step: 71ms | Tot: 21s402ms | Loss: 49.397 | Acc: 15.114% (6713/4441 347/39 353/391 ==>..]  Step: 76ms | Tot: 21s871ms | Loss: 49.397 | Acc: 15.126% (6854/4531 354/39 361/391 383/391 ===============>]  Step: 70ms | Tot: 24s1ms | Loss: 49.394 | Acc: 15.133% (7477/4940 386/391 388/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s579ms | Loss: 3.390 | Acc: 18.770% (1877/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(143.8009, device='cuda:0'), tensor(145.1761, device='cuda:0'), tensor(145.5326, device='cuda:0'), tensor(143.3979, device='cuda:0'), tensor(143.4100, device='cuda:0'), tensor(143.3314, device='cuda:0'), tensor(143.3410, device='cuda:0')]\n",
      "\n",
      "Epoch: 10\n",
      " [========================>]  Step: 61ms | Tot: 19s284ms | Loss: 49.314 | Acc: 15.736% (7868/5000 391/391  .........]  Step: 44ms | Tot: 3s346ms | Loss: 49.356 | Acc: 15.338% (1335/870 68/391 ===>.................]  Step: 46ms | Tot: 5s594ms | Loss: 49.337 | Acc: 15.638% (2322/1484 116/391 .....]  Step: 46ms | Tot: 6s402ms | Loss: 49.339 | Acc: 15.554% (2628/1689 132/391 142/39 160/391 .........]  Step: 49ms | Tot: 9s344ms | Loss: 49.341 | Acc: 15.469% (3762/2432 190/391 200/39 204/391 >.........]  Step: 47ms | Tot: 12s354ms | Loss: 49.328 | Acc: 15.547% (4975/3200 250/391 =>........]  Step: 49ms | Tot: 13s37ms | Loss: 49.327 | Acc: 15.589% (5268/3379 264/391 294/391 308/391 =======================>.]  Step: 47ms | Tot: 18s436ms | Loss: 49.314 | Acc: 15.758% (7564/4800 375/391 ===========>]  Step: 50ms | Tot: 18s536ms | Loss: 49.314 | Acc: 15.745% (7598/4825 377/391 ===========>]  Step: 53ms | Tot: 18s589ms | Loss: 49.314 | Acc: 15.747% (7619/4838 378/391 =============>]  Step: 51ms | Tot: 18s737ms | Loss: 49.315 | Acc: 15.746% (7679/4876 381/391 ========================>]  Step: 51ms | Tot: 18s788ms | Loss: 49.314 | Acc: 15.750% (7701/48 382/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s590ms | Loss: 3.352 | Acc: 19.410% (1941/1000 79/79 9 ..............]  Step: 45ms | Tot: 757ms | Loss: 3.352 | Acc: 19.118% (416/217 17/7 18/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(143.8509, device='cuda:0'), tensor(142.7272, device='cuda:0'), tensor(143.4786, device='cuda:0'), tensor(143.9166, device='cuda:0'), tensor(143.8954, device='cuda:0'), tensor(142.4787, device='cuda:0'), tensor(142.5112, device='cuda:0')]\n",
      "\n",
      "Epoch: 11\n",
      " [========================>]  Step: 60ms | Tot: 23s873ms | Loss: 49.238 | Acc: 16.468% (8234/5000 391/391 >..........]  Step: 69ms | Tot: 13s454ms | Loss: 49.254 | Acc: 16.105% (4762/2956 231/391 ==============>..........]  Step: 62ms | Tot: 13s585ms | Loss: 49.253 | Acc: 16.121% (4808/2982 233/39 234/39 236/391 ...]  Step: 64ms | Tot: 14s644ms | Loss: 49.251 | Acc: 16.118% (5137/3187 249/391 ==========>........]  Step: 68ms | Tot: 14s965ms | Loss: 49.251 | Acc: 16.154% (5252/3251 254/391 ...]  Step: 64ms | Tot: 15s30ms | Loss: 49.251 | Acc: 16.149% (5271/3264 255/39 264/391 .]  Step: 66ms | Tot: 15s694ms | Loss: 49.252 | Acc: 16.129% (5471/3392 265/391 266/39 275/391 277/39 278/39 282/39 285/391 286/391 .]  Step: 60ms | Tot: 17s194ms | Loss: 49.248 | Acc: 16.306% (6011/36 288/39 299/39 300/391 ====>.....]  Step: 68ms | Tot: 18s364ms | Loss: 49.244 | Acc: 16.371% (6412/3916 306/391 .]  Step: 63ms | Tot: 18s495ms | Loss: 49.245 | Acc: 16.358% (6449/3942 308/39 334/391   Step: 61ms | Tot: 20s625ms | Loss: 49.242 | Acc: 16.363% (7142/4364 341/391 =================>..]  Step: 62ms | Tot: 21s309ms | Loss: 49.241 | Acc: 16.406% (7371/4492 351/391 =================>..]  Step: 65ms | Tot: 21s926ms | Loss: 49.241 | Acc: 16.421% (7567/4608 360/391 366/391 ==========>.]  Step: 71ms | Tot: 22s703ms | Loss: 49.240 | Acc: 16.434% (7825/4761 372/391 ====>.]  Step: 72ms | Tot: 22s970ms | Loss: 49.239 | Acc: 16.450% (7917/4812 376/39 386/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s713ms | Loss: 3.315 | Acc: 19.960% (1996/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(143.3564, device='cuda:0'), tensor(144.7525, device='cuda:0'), tensor(144.5970, device='cuda:0'), tensor(143.0788, device='cuda:0'), tensor(143.1935, device='cuda:0'), tensor(141.7797, device='cuda:0'), tensor(141.8193, device='cuda:0')]\n",
      "\n",
      "Epoch: 12\n",
      " [========================>]  Step: 60ms | Tot: 24s140ms | Loss: 49.168 | Acc: 16.626% (8313/5000 391/391 .........]  Step: 69ms | Tot: 262ms | Loss: 49.227 | Acc: 14.844% (95/64 5/391 ............]  Step: 61ms | Tot: 464ms | Loss: 49.232 | Acc: 14.746% (151/102 8/39 17/391 ..]  Step: 60ms | Tot: 2s77ms | Loss: 49.199 | Acc: 15.625% (680/435 34/391 ..........]  Step: 69ms | Tot: 2s410ms | Loss: 49.201 | Acc: 15.805% (789/499 39/391 ....................]  Step: 67ms | Tot: 3s37ms | Loss: 49.194 | Acc: 16.024% (1005/627 49/391 ]  Step: 63ms | Tot: 5s116ms | Loss: 49.188 | Acc: 16.330% (1714/1049 82/391 .....]  Step: 68ms | Tot: 5s317ms | Loss: 49.187 | Acc: 16.360% (1780/1088 85/39 86/391 155/391 191/39 244/391 ======>.........]  Step: 67ms | Tot: 15s369ms | Loss: 49.178 | Acc: 16.514% (5200/3148 246/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s569ms | Loss: 3.281 | Acc: 20.730% (2073/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(140.9579, device='cuda:0'), tensor(140.1762, device='cuda:0'), tensor(141.4509, device='cuda:0'), tensor(141.1995, device='cuda:0'), tensor(141.1477, device='cuda:0'), tensor(141.0829, device='cuda:0'), tensor(141.0465, device='cuda:0')]\n",
      "\n",
      "Epoch: 13\n",
      " [========================>]  Step: 60ms | Tot: 23s418ms | Loss: 49.110 | Acc: 17.208% (8604/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s565ms | Loss: 3.256 | Acc: 21.120% (2112/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(141.0261, device='cuda:0'), tensor(142.1078, device='cuda:0'), tensor(142.0836, device='cuda:0'), tensor(141.5808, device='cuda:0'), tensor(141.6092, device='cuda:0'), tensor(140.3380, device='cuda:0'), tensor(140.4154, device='cuda:0')]\n",
      "\n",
      "Epoch: 14\n",
      " [========================>]  Step: 63ms | Tot: 20s490ms | Loss: 49.054 | Acc: 17.896% (8948/5000 391/391 .................]  Step: 47ms | Tot: 303ms | Loss: 49.140 | Acc: 16.629% (149/89 7/391 ....................]  Step: 51ms | Tot: 1s720ms | Loss: 49.097 | Acc: 17.231% (794/460 36/391 ..]  Step: 49ms | Tot: 1s816ms | Loss: 49.096 | Acc: 17.229% (838/486 38/391 .................]  Step: 51ms | Tot: 1s921ms | Loss: 49.094 | Acc: 17.324% (887/512 40/391 .................]  Step: 46ms | Tot: 2s15ms | Loss: 49.086 | Acc: 17.522% (942/5 42/39 43/391 46/391 47/391 48/391 50/391 .................]  Step: 49ms | Tot: 2s514ms | Loss: 49.098 | Acc: 17.713% (1179/665 52/391   Step: 51ms | Tot: 2s566ms | Loss: 49.098 | Acc: 17.674% (1199/678 53/391 >.....................]  Step: 52ms | Tot: 2s919ms | Loss: 49.087 | Acc: 17.812% (1368/768 60/39 61/ 64/39 65/391 72/391 79/391 ========>.....]  Step: 66ms | Tot: 15s412ms | Loss: 49.057 | Acc: 17.810% (7067/3968 310/391 =>.....]  Step: 69ms | Tot: 15s613ms | Loss: 49.056 | Acc: 17.826% (7142/4006 313/391 342/391 ====>...]  Step: 67ms | Tot: 17s538ms | Loss: 49.056 | Acc: 17.816% (7822/4390 343/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s582ms | Loss: 3.226 | Acc: 21.820% (2182/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(137.7215, device='cuda:0'), tensor(138.3536, device='cuda:0'), tensor(138.0580, device='cuda:0'), tensor(137.9197, device='cuda:0'), tensor(138.0249, device='cuda:0'), tensor(139.6628, device='cuda:0'), tensor(139.7254, device='cuda:0')]\n",
      "\n",
      "Epoch: 15\n",
      " [========================>]  Step: 65ms | Tot: 23s669ms | Loss: 48.993 | Acc: 18.080% (9040/5000 391/391 .....]  Step: 67ms | Tot: 1s80ms | Loss: 49.013 | Acc: 19.184% (442/230 18/391 25/391 ...................]  Step: 65ms | Tot: 1s663ms | Loss: 49.009 | Acc: 18.287% (632/345 27/391 100/39 137/391 263/391 272/39 318/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s558ms | Loss: 3.198 | Acc: 22.470% (2247/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(140.4390, device='cuda:0'), tensor(140.2119, device='cuda:0'), tensor(139.8264, device='cuda:0'), tensor(140.2477, device='cuda:0'), tensor(140.1830, device='cuda:0'), tensor(139.1683, device='cuda:0'), tensor(139.1635, device='cuda:0')]\n",
      "\n",
      "Epoch: 16\n",
      " [========================>]  Step: 56ms | Tot: 24s46ms | Loss: 48.944 | Acc: 18.604% (9302/5000 391/391  .........]  Step: 64ms | Tot: 552ms | Loss: 48.984 | Acc: 18.203% (233/128 10/39 52/391 >...............]  Step: 62ms | Tot: 8s976ms | Loss: 48.961 | Acc: 18.638% (3483/1868 146/391 ========>..............]  Step: 69ms | Tot: 9s753ms | Loss: 48.962 | Acc: 18.587% (3759/2022 158/391 159/391 165/39 169/391 ===============>.......]  Step: 67ms | Tot: 17s24ms | Loss: 48.952 | Acc: 18.545% (6504/3507 274/391 =======>......]  Step: 66ms | Tot: 18s289ms | Loss: 48.947 | Acc: 18.612% (7004/3763 294/391 298/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s575ms | Loss: 3.176 | Acc: 22.860% (2286/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(137.0320, device='cuda:0'), tensor(137.5553, device='cuda:0'), tensor(137.6066, device='cuda:0'), tensor(137.1573, device='cuda:0'), tensor(137.0540, device='cuda:0'), tensor(138.5050, device='cuda:0'), tensor(138.5186, device='cuda:0')]\n",
      "\n",
      "Epoch: 17\n",
      " [========================>]  Step: 51ms | Tot: 23s594ms | Loss: 48.886 | Acc: 18.990% (9495/5000 391/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s563ms | Loss: 3.153 | Acc: 23.160% (2316/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(140.6357, device='cuda:0'), tensor(140.1642, device='cuda:0'), tensor(139.7812, device='cuda:0'), tensor(140.1776, device='cuda:0'), tensor(140.1499, device='cuda:0'), tensor(137.9362, device='cuda:0'), tensor(137.9742, device='cuda:0')]\n",
      "\n",
      "Epoch: 18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 54ms | Tot: 22s745ms | Loss: 48.840 | Acc: 19.408% (9704/5000 391/391 91 ]  Step: 61ms | Tot: 3s154ms | Loss: 48.873 | Acc: 19.455% (1270/652 51/39 52/391 .................]  Step: 63ms | Tot: 3s425ms | Loss: 48.872 | Acc: 19.517% (1374/704 55/391 .............]  Step: 67ms | Tot: 4s989ms | Loss: 48.867 | Acc: 19.219% (1968/1024 80/391 104/39 163/39 166/391 ======>.............]  Step: 48ms | Tot: 10s897ms | Loss: 48.855 | Acc: 19.212% (4328/2252 176/391 .......]  Step: 50ms | Tot: 11s254ms | Loss: 48.856 | Acc: 19.215% (4501/2342 183/39 185/391 ====>............]  Step: 49ms | Tot: 11s783ms | Loss: 48.859 | Acc: 19.167% (4735/2470 193/391 ===>..........]  Step: 52ms | Tot: 13s810ms | Loss: 48.849 | Acc: 19.312% (5735/2969 232/391 259/391   Step: 46ms | Tot: 15s687ms | Loss: 48.851 | Acc: 19.257% (6606/3430 268/391 ==>......]  Step: 51ms | Tot: 17s251ms | Loss: 48.845 | Acc: 19.347% (7355/3801 297/391 ====>....]  Step: 52ms | Tot: 18s203ms | Loss: 48.844 | Acc: 19.368% (7809/4032 315/39 333/391 =====================>...]  Step: 49ms | Tot: 19s384ms | Loss: 48.842 | Acc: 19.351% (8372/4326 338/391 =================>..]  Step: 69ms | Tot: 19s952ms | Loss: 48.842 | Acc: 19.365% (8601/4441 347/391 ]  Step: 69ms | Tot: 20s221ms | Loss: 48.841 | Acc: 19.378% (8706/4492 351/391 ======================>..]  Step: 66ms | Tot: 20s673ms | Loss: 48.841 | Acc: 19.378% (8880/4582 358/391 ..]  Step: 63ms | Tot: 20s736ms | Loss: 48.841 | Acc: 19.377% (8904/4595 359/391 ==>.]  Step: 68ms | Tot: 20s937ms | Loss: 48.841 | Acc: 19.374% (8977/4633 362/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s636ms | Loss: 3.132 | Acc: 23.730% (2373/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(138.2236, device='cuda:0'), tensor(138.5338, device='cuda:0'), tensor(138.0969, device='cuda:0'), tensor(138.4467, device='cuda:0'), tensor(138.4867, device='cuda:0'), tensor(137.4068, device='cuda:0'), tensor(137.3909, device='cuda:0')]\n",
      "\n",
      "Epoch: 19\n",
      " [========================>]  Step: 61ms | Tot: 24s683ms | Loss: 48.794 | Acc: 19.584% (9792/5000 391/391 ..........]  Step: 67ms | Tot: 386ms | Loss: 48.901 | Acc: 18.080% (162/89 7/39 16/391 19/391 ...................]  Step: 67ms | Tot: 2s636ms | Loss: 48.831 | Acc: 19.196% (1032/537 42/391 73/39 74/391 135/391 ===>...............]  Step: 68ms | Tot: 9s872ms | Loss: 48.810 | Acc: 19.472% (3913/2009 157/391 .......]  Step: 68ms | Tot: 9s940ms | Loss: 48.809 | Acc: 19.472% (3938/2022 158/391 ............]  Step: 62ms | Tot: 10s3ms | Loss: 48.808 | Acc: 19.502% (3969/2035 159/391 171/39 183/391 ....]  Step: 71ms | Tot: 11s790ms | Loss: 48.812 | Acc: 19.426% (4625/2380 186/39 195/39 198/391 204/391 ..]  Step: 71ms | Tot: 13s61ms | Loss: 48.810 | Acc: 19.371% (5083/2624 205/39 233/39 249/391 =====>........]  Step: 64ms | Tot: 16s743ms | Loss: 48.801 | Acc: 19.412% (6535/3366 263/391 ...]  Step: 68ms | Tot: 16s811ms | Loss: 48.801 | Acc: 19.401% (6556/3379 264/39 265/391 =====>.......]  Step: 66ms | Tot: 17s821ms | Loss: 48.800 | Acc: 19.439% (6967/3584 280/391 ============>.......]  Step: 64ms | Tot: 17s954ms | Loss: 48.800 | Acc: 19.440% (7017/3609 282/391 =============>......]  Step: 67ms | Tot: 18s21ms | Loss: 48.799 | Acc: 19.448% (7045/3622 283/391 322/391 344/391 378/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s550ms | Loss: 3.109 | Acc: 23.950% (2395/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(136.0600, device='cuda:0'), tensor(136.8817, device='cuda:0'), tensor(136.7387, device='cuda:0'), tensor(136.2519, device='cuda:0'), tensor(136.1008, device='cuda:0'), tensor(136.8454, device='cuda:0'), tensor(136.8059, device='cuda:0')]\n",
      "\n",
      "Epoch: 20\n",
      " [========================>]  Step: 60ms | Tot: 23s563ms | Loss: 48.746 | Acc: 20.186% (10093/5000 391/391 ep: 67ms | Tot: 758ms | Loss: 48.772 | Acc: 19.892% (331/166 13/391 ....]  Step: 68ms | Tot: 1s19ms | Loss: 48.783 | Acc: 19.945% (434/217 17/39 18/39 35/391 50/391 162/391 165/39 246/391 ....]  Step: 65ms | Tot: 14s696ms | Loss: 48.752 | Acc: 20.110% (6358/3161 247/391 266/39 270/391 =======>.......]  Step: 69ms | Tot: 16s943ms | Loss: 48.750 | Acc: 20.099% (7255/3609 282/391 .]  Step: 65ms | Tot: 17s74ms | Loss: 48.749 | Acc: 20.125% (7316/3635 284/391 ================>..]  Step: 66ms | Tot: 20s998ms | Loss: 48.746 | Acc: 20.232% (9012/4454 348/391 \n",
      " [========================>]  Step: 46ms | Tot: 3s599ms | Loss: 3.091 | Acc: 24.390% (2439/1000 79/79 ..]  Step: 47ms | Tot: 1s310ms | Loss: 3.077 | Acc: 24.434% (907/371 29/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(135.4910, device='cuda:0'), tensor(136.0259, device='cuda:0'), tensor(135.3560, device='cuda:0'), tensor(135.4102, device='cuda:0'), tensor(135.3918, device='cuda:0'), tensor(136.2519, device='cuda:0'), tensor(136.2741, device='cuda:0')]\n",
      "\n",
      "Epoch: 21\n",
      " [========================>]  Step: 59ms | Tot: 24s124ms | Loss: 48.707 | Acc: 20.310% (10155/5000 391/391 p: 61ms | Tot: 201ms | Loss: 48.741 | Acc: 19.727% (101/51 4/39 8/391 21/391 ..]  Step: 67ms | Tot: 1s508ms | Loss: 48.726 | Acc: 21.094% (648/307 24/39 27/391 ................]  Step: 61ms | Tot: 2s99ms | Loss: 48.737 | Acc: 20.573% (869/422 33/391 .................]  Step: 69ms | Tot: 2s169ms | Loss: 48.737 | Acc: 20.634% (898/435 34/39 43/391 ===>.....................]  Step: 69ms | Tot: 3s149ms | Loss: 48.737 | Acc: 20.456% (1283/627 49/391 ...............]  Step: 63ms | Tot: 3s212ms | Loss: 48.736 | Acc: 20.516% (1313/640 50/391 53/391 ===>.....................]  Step: 65ms | Tot: 3s791ms | Loss: 48.729 | Acc: 20.538% (1551/755 59/391 ===>.....................]  Step: 61ms | Tot: 3s926ms | Loss: 48.736 | Acc: 20.402% (1593/780 61/39 68/39 69/39 70/391 ............]  Step: 70ms | Tot: 4s554ms | Loss: 48.730 | Acc: 20.467% (1860/9 71/391 ..]  Step: 65ms | Tot: 8s198ms | Loss: 48.722 | Acc: 20.318% (3433/1689 132/391 ..]  Step: 60ms | Tot: 8s396ms | Loss: 48.722 | Acc: 20.324% (3512/1728 135/39 140/391 154/391 156/39 192/391 352/39 383/39 385/391 \n",
      " [========================>]  Step: 41ms | Tot: 3s368ms | Loss: 3.069 | Acc: 24.900% (2490/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(134.5009, device='cuda:0'), tensor(134.5867, device='cuda:0'), tensor(133.9831, device='cuda:0'), tensor(134.2435, device='cuda:0'), tensor(134.3446, device='cuda:0'), tensor(135.7537, device='cuda:0'), tensor(135.7645, device='cuda:0')]\n",
      "\n",
      "Epoch: 22\n",
      " [========================>]  Step: 66ms | Tot: 22s408ms | Loss: 48.652 | Acc: 20.752% (10376/5000 391/391 ==========>....]  Step: 67ms | Tot: 17s513ms | Loss: 48.654 | Acc: 20.773% (8429/4057 317/39 327/391  339/391 ========>..]  Step: 61ms | Tot: 19s713ms | Loss: 48.650 | Acc: 20.827% (9357/4492 351/391 =============>..]  Step: 67ms | Tot: 19s913ms | Loss: 48.650 | Acc: 20.809% (9429/45 354/39 364/391 =====================>.]  Step: 68ms | Tot: 20s923ms | Loss: 48.651 | Acc: 20.791% (9820/4723 369/391 ===============>]  Step: 66ms | Tot: 21s669ms | Loss: 48.652 | Acc: 20.767% (10101/4864 380/39 386/39 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s667ms | Loss: 3.055 | Acc: 25.060% (2506/1000 79/79  .......]  Step: 47ms | Tot: 1s192ms | Loss: 3.039 | Acc: 24.760% (824/332 26/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(134.4248, device='cuda:0'), tensor(134.5191, device='cuda:0'), tensor(134.6093, device='cuda:0'), tensor(134.0561, device='cuda:0'), tensor(134.3022, device='cuda:0'), tensor(135.1786, device='cuda:0'), tensor(135.2219, device='cuda:0')]\n",
      "\n",
      "Epoch: 23\n",
      " [========================>]  Step: 65ms | Tot: 24s116ms | Loss: 48.607 | Acc: 21.008% (10504/5000 391/391 33/39 241/39 299/391 347/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s550ms | Loss: 3.035 | Acc: 25.570% (2557/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(133.3678, device='cuda:0'), tensor(133.3526, device='cuda:0'), tensor(132.9768, device='cuda:0'), tensor(133.2304, device='cuda:0'), tensor(133.2378, device='cuda:0'), tensor(134.6605, device='cuda:0'), tensor(134.6500, device='cuda:0')]\n",
      "\n",
      "Epoch: 24\n",
      " [========================>]  Step: 61ms | Tot: 24s53ms | Loss: 48.570 | Acc: 21.472% (10736/5000 391/391  1 ..........]  Step: 69ms | Tot: 3s214ms | Loss: 48.593 | Acc: 20.974% (1396/665 52/39 71/391 194/391 195/39 198/391 ======>............]  Step: 69ms | Tot: 12s463ms | Loss: 48.586 | Acc: 21.263% (5416/2547 199/39 200/391 ...]  Step: 65ms | Tot: 13s836ms | Loss: 48.577 | Acc: 21.423% (6060/2828 221/391 ]  Step: 65ms | Tot: 14s654ms | Loss: 48.574 | Acc: 21.414% (6414/2995 234/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s574ms | Loss: 3.016 | Acc: 25.870% (2587/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(132.8727, device='cuda:0'), tensor(132.9584, device='cuda:0'), tensor(132.8549, device='cuda:0'), tensor(132.8963, device='cuda:0'), tensor(133.0504, device='cuda:0'), tensor(134.1246, device='cuda:0'), tensor(134.1045, device='cuda:0')]\n",
      "\n",
      "Epoch: 25\n",
      " [========================>]  Step: 60ms | Tot: 25s284ms | Loss: 48.529 | Acc: 21.522% (10761/5000 391/391 ]  Step: 65ms | Tot: 1s760ms | Loss: 48.568 | Acc: 21.067% (782/371 29/39 40/391 ........]  Step: 63ms | Tot: 3s698ms | Loss: 48.555 | Acc: 21.478% (1622/755 59/391 =>....................]  Step: 62ms | Tot: 4s81ms | Loss: 48.558 | Acc: 21.538% (1792/832 65/391 ..............]  Step: 68ms | Tot: 5s484ms | Loss: 48.545 | Acc: 21.579% (2403/1113 87/39 92/391 ]  Step: 68ms | Tot: 5s937ms | Loss: 48.538 | Acc: 21.651% (2605/1203 94/39 100/391 =>..................]  Step: 68ms | Tot: 6s643ms | Loss: 48.541 | Acc: 21.510% (2891/1344 105/391 ........]  Step: 66ms | Tot: 6s709ms | Loss: 48.540 | Acc: 21.529% (2921/1356 106/39 113/39 114/39 141/391 143/391 194/391 ========>............]  Step: 71ms | Tot: 12s405ms | Loss: 48.547 | Acc: 21.273% (5337/2508 196/391 200/391 ........]  Step: 69ms | Tot: 14s331ms | Loss: 48.535 | Acc: 21.378% (6157/2880 225/391 ===========>..........]  Step: 60ms | Tot: 14s603ms | Loss: 48.536 | Acc: 21.363% (6262/2931 229/391 ======>..........]  Step: 70ms | Tot: 14s673ms | Loss: 48.537 | Acc: 21.352% (6286/2944 230/39 234/391 ========>.........]  Step: 65ms | Tot: 15s205ms | Loss: 48.535 | Acc: 21.333% (6499/3046 238/391 .....]  Step: 61ms | Tot: 15s984ms | Loss: 48.535 | Acc: 21.334% (6827/3200 250/391 ===========>........]  Step: 59ms | Tot: 16s468ms | Loss: 48.535 | Acc: 21.395% (7038/3289 257/391 274/391 =>......]  Step: 59ms | Tot: 18s447ms | Loss: 48.534 | Acc: 21.439% (7876/3673 287/391 ==========>......]  Step: 70ms | Tot: 18s843ms | Loss: 48.532 | Acc: 21.435% (8039/3750 293/391 =============>......]  Step: 68ms | Tot: 19s114ms | Loss: 48.532 | Acc: 21.451% (8155/3801 297/391 ==============>.....]  Step: 65ms | Tot: 19s580ms | Loss: 48.532 | Acc: 21.394% (8325/3891 304/391 ========>.....]  Step: 66ms | Tot: 19s850ms | Loss: 48.533 | Acc: 21.355% (8419/3942 308/391 310/391 =====>....]  Step: 69ms | Tot: 20s457ms | Loss: 48.533 | Acc: 21.394% (8681/4057 317/39 320/391 ====================>...]  Step: 60ms | Tot: 21s829ms | Loss: 48.530 | Acc: 21.471% (9289/4326 338/39 339/391 =============>..]  Step: 61ms | Tot: 22s558ms | Loss: 48.529 | Acc: 21.497% (9603/4467 349/391 361/391  363/391 384/39 386/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s563ms | Loss: 3.001 | Acc: 26.330% (2633/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(134.3483, device='cuda:0'), tensor(134.5828, device='cuda:0'), tensor(132.6138, device='cuda:0'), tensor(134.0020, device='cuda:0'), tensor(134.0105, device='cuda:0'), tensor(133.6388, device='cuda:0'), tensor(133.7003, device='cuda:0')]\n",
      "\n",
      "Epoch: 26\n",
      " [========================>]  Step: 60ms | Tot: 23s583ms | Loss: 48.313 | Acc: 23.004% (11502/5000 391/391  28/391 .....................]  Step: 65ms | Tot: 2s66ms | Loss: 48.492 | Acc: 21.802% (893/409 32/39 33/391 ............]  Step: 67ms | Tot: 2s338ms | Loss: 48.496 | Acc: 21.832% (1006/460 36/39 42/391 53/391 ....]  Step: 64ms | Tot: 3s519ms | Loss: 48.499 | Acc: 21.889% (1513/691 54/391 62/391 ............]  Step: 65ms | Tot: 4s105ms | Loss: 48.499 | Acc: 21.677% (1748/806 63/39 66/391 .................]  Step: 64ms | Tot: 4s438ms | Loss: 48.501 | Acc: 21.714% (1890/870 68/39 75/39 79/391 .]  Step: 69ms | Tot: 5s478ms | Loss: 48.492 | Acc: 21.828% (2347/1075 84/39 86/391 ...........]  Step: 66ms | Tot: 5s872ms | Loss: 48.488 | Acc: 21.953% (2529/1152 90/391 92/391 94/391 ====>..................]  Step: 65ms | Tot: 7s184ms | Loss: 48.489 | Acc: 22.038% (3103/1408 110/391 118/391 124/391 127/39 128/391  [=====================>...]  Step: 50ms | Tot: 20s671ms | Loss: 48.316 | Acc: 22.982% (10090/4390 343/391 ====>]  Step: 69ms | Tot: 23s328ms | Loss: 48.312 | Acc: 22.991% (11389/4953 387/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s561ms | Loss: 2.928 | Acc: 27.690% (2769/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(132.1483, device='cuda:0'), tensor(132.0721, device='cuda:0'), tensor(132.3092, device='cuda:0'), tensor(132.0343, device='cuda:0'), tensor(132.0127, device='cuda:0'), tensor(130.9879, device='cuda:0'), tensor(130.9513, device='cuda:0')]\n",
      "\n",
      "Epoch: 31\n",
      " [========================>]  Step: 68ms | Tot: 23s666ms | Loss: 48.275 | Acc: 23.188% (11594/5000 391/391  53/391 ..........]  Step: 59ms | Tot: 3s280ms | Loss: 48.300 | Acc: 22.949% (1645/7 56/391 ....................]  Step: 70ms | Tot: 3s480ms | Loss: 48.295 | Acc: 22.961% (1734/755 59/39 60/391 75/391 116/39 117/391 ..........]  Step: 68ms | Tot: 8s251ms | Loss: 48.286 | Acc: 23.212% (4011/1728 135/391 .....]  Step: 69ms | Tot: 8s384ms | Loss: 48.286 | Acc: 23.227% (4073/1753 137/391 146/391 ...........]  Step: 65ms | Tot: 10s745ms | Loss: 48.284 | Acc: 23.183% (5193/2240 175/39 245/391 258/391 259/39 266/39 303/391 330/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s565ms | Loss: 2.917 | Acc: 27.930% (2793/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(127.8212, device='cuda:0'), tensor(128.0459, device='cuda:0'), tensor(128.0721, device='cuda:0'), tensor(128.0990, device='cuda:0'), tensor(128.0880, device='cuda:0'), tensor(130.5037, device='cuda:0'), tensor(130.4720, device='cuda:0')]\n",
      "\n",
      "Epoch: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 57ms | Tot: 24s583ms | Loss: 48.239 | Acc: 23.342% (11671/5000 391/391 1 29/391 ..........]  Step: 65ms | Tot: 2s419ms | Loss: 48.269 | Acc: 22.871% (1171/512 40/391 55/391 56/391 .................]  Step: 61ms | Tot: 3s953ms | Loss: 48.260 | Acc: 22.986% (1883/819 64/391 ...]  Step: 68ms | Tot: 4s650ms | Loss: 48.250 | Acc: 23.115% (2219/960 75/391 109/391 .........]  Step: 69ms | Tot: 7s459ms | Loss: 48.246 | Acc: 23.190% (3562/1536 120/391 123/391 ..............]  Step: 69ms | Tot: 7s724ms | Loss: 48.248 | Acc: 23.154% (3675/1587 124/391 134/39 142/391 =====>...............]  Step: 69ms | Tot: 9s215ms | Loss: 48.246 | Acc: 23.140% (4354/1881 147/39 149/391 =========>...............]  Step: 64ms | Tot: 9s479ms | Loss: 48.248 | Acc: 23.075% (4460/1932 151/39 152/39 158/391 159/391 >..............]  Step: 64ms | Tot: 10s327ms | Loss: 48.244 | Acc: 23.104% (4850/2099 164/39 176/391 177/391 181/391 ........]  Step: 66ms | Tot: 11s749ms | Loss: 48.250 | Acc: 23.064% (5491/2380 186/391 .]  Step: 68ms | Tot: 11s818ms | Loss: 48.249 | Acc: 23.070% (5522/2393 187/39 188/391 190/39 191/39 198/39 200/391 ]  Step: 67ms | Tot: 12s809ms | Loss: 48.248 | Acc: 23.171% (5991/2585 202/391 =========>...........]  Step: 69ms | Tot: 13s132ms | Loss: 48.247 | Acc: 23.185% (6143/2649 207/391  208/391 219/391 ........]  Step: 66ms | Tot: 14s137ms | Loss: 48.239 | Acc: 23.339% (6632/2841 222/ 225/391 ==============>..........]  Step: 63ms | Tot: 14s870ms | Loss: 48.240 | Acc: 23.283% (6944/2982 233/391 ===============>.........]  Step: 69ms | Tot: 15s344ms | Loss: 48.241 | Acc: 23.242% (7140/3072 240/39 242/391 =========>........]  Step: 65ms | Tot: 16s402ms | Loss: 48.240 | Acc: 23.297% (7634/3276 256/391 =====>........]  Step: 69ms | Tot: 16s664ms | Loss: 48.240 | Acc: 23.281% (7748/3328 260/39 261/391 ===========>........]  Step: 61ms | Tot: 16s998ms | Loss: 48.241 | Acc: 23.269% (7893/3392 265/391 ===>.......]  Step: 68ms | Tot: 17s642ms | Loss: 48.241 | Acc: 23.267% (8190/3520 275/391 =========>.......]  Step: 68ms | Tot: 17s773ms | Loss: 48.240 | Acc: 23.268% (8250/3545 277/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s544ms | Loss: 2.907 | Acc: 28.110% (2811/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(128.5370, device='cuda:0'), tensor(128.3341, device='cuda:0'), tensor(133.3353, device='cuda:0'), tensor(128.3745, device='cuda:0'), tensor(128.3614, device='cuda:0'), tensor(130.0380, device='cuda:0'), tensor(130.0564, device='cuda:0')]\n",
      "\n",
      "Epoch: 33\n",
      " [========================>]  Step: 68ms | Tot: 23s588ms | Loss: 48.200 | Acc: 23.458% (11729/5000 391/391  64/39 69/391  183/39 386/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s556ms | Loss: 2.893 | Acc: 28.280% (2828/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(127.9086, device='cuda:0'), tensor(127.6834, device='cuda:0'), tensor(127.6335, device='cuda:0'), tensor(127.6951, device='cuda:0'), tensor(127.7316, device='cuda:0'), tensor(129.5060, device='cuda:0'), tensor(129.4686, device='cuda:0')]\n",
      "\n",
      "Epoch: 34\n",
      " [========================>]  Step: 61ms | Tot: 23s375ms | Loss: 48.156 | Acc: 23.880% (11940/5000 391/391  68ms | Tot: 771ms | Loss: 48.205 | Acc: 23.438% (390/166 13/39 22/391 ]  Step: 64ms | Tot: 1s420ms | Loss: 48.181 | Acc: 23.743% (699/294 23/391 ......]  Step: 69ms | Tot: 1s559ms | Loss: 48.183 | Acc: 23.625% (756/320 25/391 ...................]  Step: 62ms | Tot: 1s621ms | Loss: 48.180 | Acc: 23.708% (789/332 26/391 ...........]  Step: 69ms | Tot: 1s822ms | Loss: 48.183 | Acc: 23.761% (882/371 29/391 ................]  Step: 63ms | Tot: 1s885ms | Loss: 48.179 | Acc: 23.750% (912/384 30/391 .......]  Step: 66ms | Tot: 1s952ms | Loss: 48.183 | Acc: 23.614% (937/396 31/391 237/391 =====>.........]  Step: 68ms | Tot: 14s293ms | Loss: 48.159 | Acc: 23.773% (7364/3097 242/39 255/39 277/391 339/391 ===============>...]  Step: 64ms | Tot: 20s493ms | Loss: 48.156 | Acc: 23.859% (10414/4364 341/39 342/39 345/391 ================>..]  Step: 70ms | Tot: 20s895ms | Loss: 48.155 | Acc: 23.870% (10602/4441 347/391 348/39 349/391 ==========>]  Step: 48ms | Tot: 22s908ms | Loss: 48.157 | Acc: 23.865% (11669/4889 382/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s549ms | Loss: 2.884 | Acc: 28.540% (2854/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(130.1107, device='cuda:0'), tensor(129.8537, device='cuda:0'), tensor(129.8993, device='cuda:0'), tensor(129.7938, device='cuda:0'), tensor(129.8949, device='cuda:0'), tensor(128.9569, device='cuda:0'), tensor(128.9605, device='cuda:0')]\n",
      "\n",
      "Epoch: 35\n",
      " [========================>]  Step: 60ms | Tot: 22s655ms | Loss: 48.121 | Acc: 24.138% (12069/5000 391/391 1 =====>..............]  Step: 65ms | Tot: 9s417ms | Loss: 48.128 | Acc: 24.210% (5268/2176 170/39 223/39 272/391 ============>....]  Step: 68ms | Tot: 18s195ms | Loss: 48.124 | Acc: 24.106% (9843/4083 319/39 320/391 324/39 327/391 330/39 331/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s640ms | Loss: 2.875 | Acc: 28.800% (2880/1000 79/79 =================>.....]  Step: 45ms | Tot: 2s913ms | Loss: 2.884 | Acc: 28.552% (2339/819 64/79 ========>....]  Step: 54ms | Tot: 3s68ms | Loss: 2.878 | Acc: 28.708% (2462/857 67/79 ==========>..]  Step: 54ms | Tot: 3s269ms | Loss: 2.873 | Acc: 28.818% (2619/908 71/79 =====================>..]  Step: 45ms | Tot: 3s315ms | Loss: 2.876 | Acc: 28.722% (2647/921 72/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(125.6803, device='cuda:0'), tensor(125.9664, device='cuda:0'), tensor(125.9779, device='cuda:0'), tensor(125.9645, device='cuda:0'), tensor(126.0995, device='cuda:0'), tensor(128.4849, device='cuda:0'), tensor(128.3985, device='cuda:0')]\n",
      "\n",
      "Epoch: 36\n",
      " [========================>]  Step: 65ms | Tot: 22s352ms | Loss: 48.081 | Acc: 24.214% (12107/5000 391/391 ...]  Step: 69ms | Tot: 331ms | Loss: 48.157 | Acc: 23.958% (184/76 6/39 7/391 ....]  Step: 70ms | Tot: 2s77ms | Loss: 48.114 | Acc: 22.902% (1026/448 35/391 .]  Step: 60ms | Tot: 2s138ms | Loss: 48.118 | Acc: 22.743% (1048/460 36/39 301/391 302/391 \n",
      " [=>.......................]  Step: 45ms | Tot: 184ms | Loss: 2.856 | Acc: 29.375% (188/64 5/79 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 59ms | Tot: 23s430ms | Loss: 47.111 | Acc: 28.642% (14321/5000 391/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s444ms | Loss: 2.652 | Acc: 33.520% (3352/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(114.8551, device='cuda:0'), tensor(114.9987, device='cuda:0'), tensor(114.8402, device='cuda:0'), tensor(114.9087, device='cuda:0'), tensor(114.8295, device='cuda:0'), tensor(115.1983, device='cuda:0'), tensor(115.2155, device='cuda:0')]\n",
      "\n",
      "Epoch: 64\n",
      " [========================>]  Step: 55ms | Tot: 24s69ms | Loss: 47.081 | Acc: 28.700% (14350/5000 391/391   28/391 36/391 ............]  Step: 65ms | Tot: 4s429ms | Loss: 47.100 | Acc: 28.092% (2553/908 71/39 73/39 75/391 ...........]  Step: 67ms | Tot: 4s761ms | Loss: 47.090 | Acc: 28.289% (2752/972 76/39 93/391 94/391 98/391 ..........]  Step: 67ms | Tot: 6s505ms | Loss: 47.081 | Acc: 28.489% (3756/1318 103/391 117/391 =====>.................]  Step: 66ms | Tot: 7s877ms | Loss: 47.089 | Acc: 28.396% (4507/1587 124/39 161/391  173/391 187/39 189/39 217/39 218/391 \n",
      " [========================>]  Step: 41ms | Tot: 3s299ms | Loss: 2.646 | Acc: 33.740% (3374/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(112.5431, device='cuda:0'), tensor(112.6619, device='cuda:0'), tensor(112.3979, device='cuda:0'), tensor(112.4643, device='cuda:0'), tensor(112.4480, device='cuda:0'), tensor(114.7320, device='cuda:0'), tensor(114.7754, device='cuda:0')]\n",
      "\n",
      "Epoch: 65\n",
      " [========================>]  Step: 67ms | Tot: 23s366ms | Loss: 47.041 | Acc: 28.912% (14456/5000 391/391 ..........]  Step: 71ms | Tot: 9s289ms | Loss: 47.049 | Acc: 29.087% (6106/2099 164/39 166/39 174/39 177/391  181/39 186/39 220/391 230/391 ==============>..........]  Step: 70ms | Tot: 13s475ms | Loss: 47.046 | Acc: 28.937% (8593/2969 232/39 240/391 ===========>........]  Step: 75ms | Tot: 14s725ms | Loss: 47.044 | Acc: 28.937% (9334/3225 252/39 254/391 262/39 265/391 .....]  Step: 69ms | Tot: 16s479ms | Loss: 47.043 | Acc: 28.968% (10382/3584 280/39 282/391 288/391 ==>......]  Step: 70ms | Tot: 17s109ms | Loss: 47.043 | Acc: 28.992% (10762/3712 290/391 ===============>.....]  Step: 71ms | Tot: 18s220ms | Loss: 47.045 | Acc: 28.919% (11401/3942 308/39 354/391 ======================>..]  Step: 70ms | Tot: 21s248ms | Loss: 47.042 | Acc: 28.937% (13260/4582 358/391 ============>.]  Step: 69ms | Tot: 22s225ms | Loss: 47.042 | Acc: 28.906% (13801/4774 373/391  374/39 382/391 =====>]  Step: 68ms | Tot: 22s933ms | Loss: 47.042 | Acc: 28.933% (14221/4915 384/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s575ms | Loss: 2.642 | Acc: 33.430% (3343/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(114.1087, device='cuda:0'), tensor(114.1377, device='cuda:0'), tensor(113.9020, device='cuda:0'), tensor(114.2302, device='cuda:0'), tensor(114.1401, device='cuda:0'), tensor(114.3199, device='cuda:0'), tensor(114.2841, device='cuda:0')]\n",
      "\n",
      "Epoch: 66\n",
      " [========================>]  Step: 56ms | Tot: 21s533ms | Loss: 47.005 | Acc: 29.200% (14600/5000 391/391 .....................]  Step: 51ms | Tot: 2s399ms | Loss: 47.050 | Acc: 27.925% (1537/550 43/391  84/39 184/391 =>.............]  Step: 46ms | Tot: 10s344ms | Loss: 47.012 | Acc: 29.135% (7011/2406 188/39 190/39 200/391 ======>...........]  Step: 49ms | Tot: 11s866ms | Loss: 47.008 | Acc: 29.174% (8066/2764 216/391 218/39 252/391 =======>...]  Step: 48ms | Tot: 18s955ms | Loss: 47.006 | Acc: 29.251% (12805/4377 342/391 ======================>..]  Step: 54ms | Tot: 19s707ms | Loss: 47.005 | Acc: 29.235% (13322/4556 356/39 370/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s544ms | Loss: 2.634 | Acc: 33.790% (3379/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(114.0480, device='cuda:0'), tensor(113.5995, device='cuda:0'), tensor(113.5974, device='cuda:0'), tensor(113.5911, device='cuda:0'), tensor(113.7344, device='cuda:0'), tensor(113.8151, device='cuda:0'), tensor(113.8612, device='cuda:0')]\n",
      "\n",
      "Epoch: 67\n",
      " [========================>]  Step: 68ms | Tot: 23s633ms | Loss: 46.973 | Acc: 29.062% (14531/5000 391/391 39 32/391  52/391 ..................]  Step: 68ms | Tot: 4s941ms | Loss: 46.990 | Acc: 28.811% (3024/1049 82/391 =====>...................]  Step: 64ms | Tot: 5s142ms | Loss: 46.990 | Acc: 28.824% (3136/1088 85/391 88/39 97/391 110/391 116/39 226/391 =>.........]  Step: 65ms | Tot: 14s714ms | Loss: 46.978 | Acc: 29.160% (8958/3072 240/391 ======>.......]  Step: 66ms | Tot: 17s176ms | Loss: 46.977 | Acc: 29.104% (10468/3596 281/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s598ms | Loss: 2.628 | Acc: 33.890% (3389/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(113.2495, device='cuda:0'), tensor(113.0003, device='cuda:0'), tensor(113.2632, device='cuda:0'), tensor(113.2493, device='cuda:0'), tensor(113.2499, device='cuda:0'), tensor(113.4072, device='cuda:0'), tensor(113.4288, device='cuda:0')]\n",
      "\n",
      "Epoch: 68\n",
      " [========================>]  Step: 66ms | Tot: 23s783ms | Loss: 46.936 | Acc: 29.171% (14562/49920389/391 tep: 51ms | Tot: 3s980ms | Loss: 46.963 | Acc: 28.598% (2599/908 71/39 93/391 ...]  Step: 75ms | Tot: 5s851ms | Loss: 46.940 | Acc: 28.976% (3746/1292 101/39 103/391 ======>..................]  Step: 70ms | Tot: 6s368ms | Loss: 46.941 | Acc: 29.128% (4064/1395 109/391 =======>.................]  Step: 69ms | Tot: 7s409ms | Loss: 46.951 | Acc: 28.825% (4612/1600 125/391 ................]  Step: 69ms | Tot: 7s670ms | Loss: 46.950 | Acc: 28.870% (4767/1651 129/391 ..............]  Step: 68ms | Tot: 7s801ms | Loss: 46.950 | Acc: 28.865% (4840/1676 131/391 .........]  Step: 69ms | Tot: 8s448ms | Loss: 46.946 | Acc: 28.978% (5230/1804 141/391 .............]  Step: 69ms | Tot: 8s709ms | Loss: 46.947 | Acc: 28.998% (5382/1856 145/391 ....]  Step: 69ms | Tot: 9s369ms | Loss: 46.947 | Acc: 29.007% (5755/1984 155/391 163/391 =>..............]  Step: 70ms | Tot: 10s275ms | Loss: 46.945 | Acc: 29.082% (6291/2163 169/39 181/391 =====>.............]  Step: 68ms | Tot: 11s302ms | Loss: 46.948 | Acc: 29.033% (6875/2368 185/391 ===========>.............]  Step: 69ms | Tot: 11s433ms | Loss: 46.948 | Acc: 29.073% (6959/2393 187/391 197/391 ==========>............]  Step: 70ms | Tot: 12s220ms | Loss: 46.948 | Acc: 29.020% (7392/2547 199/391 237/39 259/391 360/391   Step: 53ms | Tot: 22s48ms | Loss: 46.938 | Acc: 29.162% (13475/4620 361/391 390/391 ================>]  Step: 65ms | Tot: 23s848ms | Loss: 46.936 | Acc: 29.170% (14585/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s546ms | Loss: 2.623 | Acc: 33.950% (3395/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(110.9855, device='cuda:0'), tensor(110.8873, device='cuda:0'), tensor(110.9887, device='cuda:0'), tensor(110.9693, device='cuda:0'), tensor(110.9074, device='cuda:0'), tensor(112.9601, device='cuda:0'), tensor(112.9465, device='cuda:0')]\n",
      "\n",
      "Epoch: 69\n",
      " [========================>]  Step: 66ms | Tot: 21s291ms | Loss: 46.906 | Acc: 29.510% (14755/5000 391/391 1 49/391 51/391 53/39 69/391 ............]  Step: 52ms | Tot: 4s378ms | Loss: 46.919 | Acc: 29.345% (2742/9 73/391 ............]  Step: 52ms | Tot: 4s431ms | Loss: 46.916 | Acc: 29.371% (2782/947 74/391 ====>....................]  Step: 45ms | Tot: 4s528ms | Loss: 46.916 | Acc: 29.215% (2842/972 76/39 80/391 ..]  Step: 55ms | Tot: 5s72ms | Loss: 46.912 | Acc: 29.256% (3258/1113 87/391 89/391 ===>..................]  Step: 53ms | Tot: 5s597ms | Loss: 46.916 | Acc: 29.082% (3648/1254 98/391 \n",
      " [=========>...............]  Step: 45ms | Tot: 1s372ms | Loss: 2.601 | Acc: 34.803% (1381/396 31/79 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 51ms | Tot: 23s507ms | Loss: 46.008 | Acc: 32.608% (16304/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s537ms | Loss: 2.503 | Acc: 36.380% (3638/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(102.6249, device='cuda:0'), tensor(102.8007, device='cuda:0'), tensor(102.6809, device='cuda:0'), tensor(102.4243, device='cuda:0'), tensor(102.5638, device='cuda:0'), tensor(101.2654, device='cuda:0'), tensor(101.2947, device='cuda:0')]\n",
      "\n",
      "Epoch: 97\n",
      " [========================>]  Step: 35ms | Tot: 23s336ms | Loss: 45.973 | Acc: 32.758% (16379/5000 391/391 91 ..]  Step: 66ms | Tot: 2s108ms | Loss: 46.005 | Acc: 32.612% (1461/448 35/391 49/391 97/39 139/391 143/39 145/39 181/391 187/39 188/39 192/39 197/39 199/391 ===>............]  Step: 70ms | Tot: 12s480ms | Loss: 45.987 | Acc: 32.505% (8363/2572 201/391 =======>............]  Step: 66ms | Tot: 12s611ms | Loss: 45.987 | Acc: 32.528% (8452/2598 203/39 212/39 218/391 259/39 297/391 298/391 302/391 ..]  Step: 68ms | Tot: 18s868ms | Loss: 45.976 | Acc: 32.779% (12713/3878 303/39 304/39 312/391 ===========>.....]  Step: 61ms | Tot: 19s507ms | Loss: 45.977 | Acc: 32.738% (13116/4006 313/391 316/39 317/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s563ms | Loss: 2.498 | Acc: 36.610% (3661/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(99.1454, device='cuda:0'), tensor(99.2163, device='cuda:0'), tensor(99.1006, device='cuda:0'), tensor(99.2581, device='cuda:0'), tensor(99.1312, device='cuda:0'), tensor(100.8847, device='cuda:0'), tensor(100.8867, device='cuda:0')]\n",
      "\n",
      "Epoch: 98\n",
      " [========================>]  Step: 64ms | Tot: 16s161ms | Loss: 45.941 | Acc: 32.730% (16365/5000 391/391 31/391 337/39 347/391 ====>..]  Step: 72ms | Tot: 14s135ms | Loss: 45.942 | Acc: 32.691% (15022/4595 359/39 361/39 363/391 ==============>.]  Step: 74ms | Tot: 14s767ms | Loss: 45.941 | Acc: 32.694% (15442/4723 369/391 373/39 385/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s599ms | Loss: 2.490 | Acc: 36.650% (3665/1000 79/79 ===============>..]  Step: 46ms | Tot: 3s273ms | Loss: 2.494 | Acc: 36.621% (3375/921 72/79 ==================>.]  Step: 45ms | Tot: 3s373ms | Loss: 2.495 | Acc: 36.613% (3468/947 74/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(100.3374, device='cuda:0'), tensor(100.1768, device='cuda:0'), tensor(100.2058, device='cuda:0'), tensor(100.5047, device='cuda:0'), tensor(100.3146, device='cuda:0'), tensor(100.4885, device='cuda:0'), tensor(100.4759, device='cuda:0')]\n",
      "\n",
      "Epoch: 99\n",
      " [========================>]  Step: 56ms | Tot: 22s925ms | Loss: 45.907 | Acc: 33.034% (16517/5000 391/391  37/39 40/391 ==>......................]  Step: 65ms | Tot: 2s658ms | Loss: 45.934 | Acc: 32.569% (1876/576 45/391 .......]  Step: 49ms | Tot: 3s788ms | Loss: 45.926 | Acc: 32.548% (2708/832 65/391 =>.................]  Step: 69ms | Tot: 6s678ms | Loss: 45.910 | Acc: 33.020% (4776/1446 113/391 .................]  Step: 67ms | Tot: 7s151ms | Loss: 45.908 | Acc: 32.995% (5068/1536 120/391 ...]  Step: 59ms | Tot: 9s383ms | Loss: 45.914 | Acc: 32.862% (6604/2009 157/391 ............]  Step: 65ms | Tot: 12s56ms | Loss: 45.912 | Acc: 32.879% (8459/2572 201/39 203/391 ==>............]  Step: 67ms | Tot: 12s256ms | Loss: 45.913 | Acc: 32.824% (8571/2611 204/39 210/39 216/391 .......]  Step: 68ms | Tot: 13s154ms | Loss: 45.910 | Acc: 32.899% (9180/2790 218/391 ======>..........]  Step: 69ms | Tot: 13s355ms | Loss: 45.908 | Acc: 32.947% (9320/2828 221/391   Step: 62ms | Tot: 13s418ms | Loss: 45.908 | Acc: 32.943% (9361/2841 222/391 ===>.]  Step: 48ms | Tot: 21s758ms | Loss: 45.907 | Acc: 33.009% (15591/4723 369/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s542ms | Loss: 2.487 | Acc: 36.960% (3696/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(99.9724, device='cuda:0'), tensor(99.6946, device='cuda:0'), tensor(99.9317, device='cuda:0'), tensor(99.8495, device='cuda:0'), tensor(99.9200, device='cuda:0'), tensor(100.0674, device='cuda:0'), tensor(100.0692, device='cuda:0')]\n",
      "\n",
      "Epoch: 100\n",
      " [========================>]  Step: 68ms | Tot: 23s981ms | Loss: 45.876 | Acc: 33.053% (16500/4992 389/391 1 ......]  Step: 61ms | Tot: 6s133ms | Loss: 45.871 | Acc: 33.257% (4342/1305 102/391 120/39 123/39 180/391 .......]  Step: 62ms | Tot: 11s128ms | Loss: 45.884 | Acc: 32.920% (7627/2316 181/39 189/391 .....]  Step: 64ms | Tot: 11s714ms | Loss: 45.886 | Acc: 32.891% (7999/2432 190/391 .........]  Step: 67ms | Tot: 11s914ms | Loss: 45.886 | Acc: 32.922% (8133/2470 193/39 199/391   Step: 67ms | Tot: 12s448ms | Loss: 45.884 | Acc: 32.906% (8466/2572 201/391 202/391 ......]  Step: 66ms | Tot: 12s782ms | Loss: 45.885 | Acc: 32.915% (8679/2636 206/39 232/391 323/391 .]  Step: 69ms | Tot: 19s825ms | Loss: 45.877 | Acc: 32.983% (13763/4172 326/391 ==========>....]  Step: 68ms | Tot: 19s893ms | Loss: 45.876 | Acc: 33.006% (13815/4185 327/391 ======>....]  Step: 62ms | Tot: 19s956ms | Loss: 45.877 | Acc: 32.994% (13852/4198 328/39 331/391 =====================>...]  Step: 65ms | Tot: 20s219ms | Loss: 45.877 | Acc: 32.989% (14019/4249 332/391 338/391 341/391 =================>...]  Step: 64ms | Tot: 20s865ms | Loss: 45.879 | Acc: 32.968% (14432/4377 342/39 351/391 ======>..]  Step: 64ms | Tot: 21s471ms | Loss: 45.875 | Acc: 33.028% (14881/4505 352/391 ==>..]  Step: 69ms | Tot: 21s672ms | Loss: 45.876 | Acc: 33.022% (15005/4544 355/391 ]  Step: 69ms | Tot: 21s874ms | Loss: 45.877 | Acc: 33.009% (15126/4582 358/391 359/39 361/391 ==========>.]  Step: 69ms | Tot: 22s145ms | Loss: 45.877 | Acc: 32.981% (15282/4633 362/391 =======================>.]  Step: 66ms | Tot: 22s277ms | Loss: 45.878 | Acc: 32.950% (15352/4659 364/391 =====>.]  Step: 67ms | Tot: 22s345ms | Loss: 45.877 | Acc: 32.967% (15402/46 365/391 ==============>.]  Step: 71ms | Tot: 22s610ms | Loss: 45.878 | Acc: 32.971% (15573/47 369/391 ==========>.]  Step: 61ms | Tot: 22s672ms | Loss: 45.878 | Acc: 32.977% (15618/4736 370/391 ================>]  Step: 65ms | Tot: 23s649ms | Loss: 45.876 | Acc: 33.024% (16274/4928 385/39 390/391 =======>]  Step: 68ms | Tot: 24s50ms | Loss: 45.876 | Acc: 33.058% (16529/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s546ms | Loss: 2.485 | Acc: 36.990% (3699/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(99.2190, device='cuda:0'), tensor(99.6323, device='cuda:0'), tensor(99.5185, device='cuda:0'), tensor(99.4297, device='cuda:0'), tensor(99.5537, device='cuda:0'), tensor(99.7225, device='cuda:0'), tensor(99.6925, device='cuda:0')]\n",
      "\n",
      "Epoch: 101\n",
      " [========================>]  Step: 61ms | Tot: 23s815ms | Loss: 45.847 | Acc: 33.048% (16524/5000 391/391 ........]  Step: 64ms | Tot: 1s344ms | Loss: 45.852 | Acc: 33.203% (935/281 22/391  269/39 279/39 300/39 303/391 ===============>.....]  Step: 66ms | Tot: 18s782ms | Loss: 45.848 | Acc: 32.977% (13043/3955 309/39 310/39 333/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s562ms | Loss: 2.480 | Acc: 37.180% (3718/1000 79/79 /79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(100.2320, device='cuda:0'), tensor(100.8907, device='cuda:0'), tensor(100.8593, device='cuda:0'), tensor(100.6233, device='cuda:0'), tensor(100.8132, device='cuda:0'), tensor(99.3161, device='cuda:0'), tensor(99.3393, device='cuda:0')]\n",
      "\n",
      "Epoch: 102\n",
      " [=======================>.]  Step: 59ms | Tot: 22s970ms | Loss: 45.815 | Acc: 33.080% (15582/4710 368/391 ......................]  Step: 68ms | Tot: 402ms | Loss: 45.896 | Acc: 31.027% (278/89 7/391 ........]  Step: 64ms | Tot: 675ms | Loss: 45.843 | Acc: 31.605% (445/140 11/391 30/391 .....................]  Step: 66ms | Tot: 1s930ms | Loss: 45.839 | Acc: 31.830% (1263/396 31/391 32/391 36/391 142/39 143/39 144/39 217/391 =============>...........]  Step: 69ms | Tot: 13s556ms | Loss: 45.815 | Acc: 33.106% (9238/2790 218/391 .........]  Step: 61ms | Tot: 13s618ms | Loss: 45.815 | Acc: 33.123% (9285/2803 219/391 244/39 259/39 261/391 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 67ms | Tot: 24s213ms | Loss: 44.919 | Acc: 35.664% (17832/5000 391/391 5/39 160/39 168/391 ..........]  Step: 62ms | Tot: 10s343ms | Loss: 44.917 | Acc: 35.668% (7807/2188 171/391 =====>.............]  Step: 70ms | Tot: 11s123ms | Loss: 44.917 | Acc: 35.669% (8355/2342 183/391 198/391   Step: 62ms | Tot: 12s242ms | Loss: 44.924 | Acc: 35.465% (9079/2560 200/39 231/391 ......]  Step: 64ms | Tot: 14s339ms | Loss: 44.916 | Acc: 35.694% (10691/2995 234/391 275/39 277/391 282/391 378/391 >]  Step: 68ms | Tot: 23s434ms | Loss: 44.920 | Acc: 35.643% (17291/4851 379/391 =================>]  Step: 68ms | Tot: 23s756ms | Loss: 44.919 | Acc: 35.663% (17529/4915 384/391 ===>]  Step: 67ms | Tot: 23s955ms | Loss: 44.919 | Acc: 35.661% (17665/4953 387/391 ========>]  Step: 65ms | Tot: 24s21ms | Loss: 44.919 | Acc: 35.654% (17707/4966 388/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s597ms | Loss: 2.403 | Acc: 38.540% (3854/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(88.3110, device='cuda:0'), tensor(88.5687, device='cuda:0'), tensor(88.4902, device='cuda:0'), tensor(88.5415, device='cuda:0'), tensor(88.4946, device='cuda:0'), tensor(88.6914, device='cuda:0'), tensor(88.6607, device='cuda:0')]\n",
      "\n",
      "Epoch: 131\n",
      " [========================>]  Step: 61ms | Tot: 22s585ms | Loss: 44.888 | Acc: 35.836% (17918/5000 391/391 9 257/391 ==============>...]  Step: 69ms | Tot: 18s925ms | Loss: 44.893 | Acc: 35.757% (15287/4275 334/39 337/39 338/391 ============>..]  Step: 64ms | Tot: 19s715ms | Loss: 44.892 | Acc: 35.755% (15835/4428 346/391 ===========>..]  Step: 68ms | Tot: 19s853ms | Loss: 44.892 | Acc: 35.783% (15939/4454 348/391 ]  Step: 63ms | Tot: 19s916ms | Loss: 44.892 | Acc: 35.796% (15991/4467 349/39 352/391 ..]  Step: 64ms | Tot: 20s179ms | Loss: 44.891 | Acc: 35.791% (16172/4518 353/391 ===============>.]  Step: 67ms | Tot: 20s690ms | Loss: 44.891 | Acc: 35.775% (16531/4620 361/39 362/39 370/39 372/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s621ms | Loss: 2.400 | Acc: 38.700% (3870/1000 79/79 ...................]  Step: 45ms | Tot: 630ms | Loss: 2.449 | Acc: 38.114% (683/179 14/79 >....................]  Step: 45ms | Tot: 730ms | Loss: 2.428 | Acc: 38.721% (793/204 16/79 ...........]  Step: 54ms | Tot: 785ms | Loss: 2.432 | Acc: 38.695% (842/217 17/79 .................]  Step: 45ms | Tot: 830ms | Loss: 2.439 | Acc: 38.585% (889/230 18/79 23/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(86.8320, device='cuda:0'), tensor(87.1393, device='cuda:0'), tensor(89.1920, device='cuda:0'), tensor(87.2185, device='cuda:0'), tensor(87.1493, device='cuda:0'), tensor(88.3345, device='cuda:0'), tensor(88.3533, device='cuda:0')]\n",
      "\n",
      "Epoch: 132\n",
      " [========================>]  Step: 56ms | Tot: 24s581ms | Loss: 44.857 | Acc: 35.968% (17984/5000 391/391  37/39 69/391 81/391 91/391 .....]  Step: 67ms | Tot: 5s829ms | Loss: 44.848 | Acc: 36.047% (4291/1190 93/39 95/391 ==========>..............]  Step: 72ms | Tot: 10s902ms | Loss: 44.861 | Acc: 35.987% (7969/2214 173/391 ===========>.............]  Step: 69ms | Tot: 11s433ms | Loss: 44.861 | Acc: 35.972% (8334/2316 181/39 183/39 219/391  230/391 ........]  Step: 69ms | Tot: 14s748ms | Loss: 44.858 | Acc: 35.927% (10715/2982 233/39 235/391 ====================>]  Step: 70ms | Tot: 23s980ms | Loss: 44.858 | Acc: 35.997% (17555/4876 381/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s564ms | Loss: 2.400 | Acc: 38.850% (3885/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(86.4913, device='cuda:0'), tensor(86.8046, device='cuda:0'), tensor(86.7944, device='cuda:0'), tensor(86.8901, device='cuda:0'), tensor(86.7512, device='cuda:0'), tensor(88.0021, device='cuda:0'), tensor(88.0078, device='cuda:0')]\n",
      "\n",
      "Epoch: 133\n",
      " [========================>]  Step: 68ms | Tot: 23s19ms | Loss: 44.821 | Acc: 35.974% (17987/5000 391/391  ...]  Step: 65ms | Tot: 4s403ms | Loss: 44.821 | Acc: 35.779% (3389/947 74/391 78/39 119/39 199/39 200/39 272/39 273/391 ==========>.......]  Step: 67ms | Tot: 16s150ms | Loss: 44.818 | Acc: 36.035% (12961/3596 281/391 283/39 287/391 ==========>......]  Step: 69ms | Tot: 16s612ms | Loss: 44.818 | Acc: 36.024% (13280/3686 288/391 ===============>......]  Step: 61ms | Tot: 16s674ms | Loss: 44.819 | Acc: 36.016% (13323/3699 289/391 =============>.....]  Step: 68ms | Tot: 17s382ms | Loss: 44.820 | Acc: 36.042% (13840/3840 300/391 ===================>.....]  Step: 70ms | Tot: 17s643ms | Loss: 44.821 | Acc: 36.027% (14019/3891 304/391 ===>.....]  Step: 71ms | Tot: 18s167ms | Loss: 44.822 | Acc: 35.983% (14370/3993 312/391 ===>....]  Step: 70ms | Tot: 18s429ms | Loss: 44.822 | Acc: 35.980% (14553/4044 316/391 320/39 332/39 334/391 373/391 =======================>.]  Step: 64ms | Tot: 21s921ms | Loss: 44.823 | Acc: 35.952% (17211/4787 374/39 383/39 390/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s572ms | Loss: 2.394 | Acc: 39.020% (3902/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(87.4993, device='cuda:0'), tensor(87.5383, device='cuda:0'), tensor(87.5262, device='cuda:0'), tensor(87.4498, device='cuda:0'), tensor(87.3766, device='cuda:0'), tensor(87.6421, device='cuda:0'), tensor(87.6485, device='cuda:0')]\n",
      "\n",
      "Epoch: 134\n",
      " [========================>]  Step: 66ms | Tot: 19s951ms | Loss: 44.789 | Acc: 36.226% (18113/5000 391/391 p: 53ms | Tot: 53ms | Loss: 44.923 | Acc: 38.281% (98/25 2/391 5/391 .........]  Step: 54ms | Tot: 254ms | Loss: 44.887 | Acc: 35.677% (274/76 6/39 9/391 10/391 ..........]  Step: 52ms | Tot: 507ms | Loss: 44.827 | Acc: 36.648% (516/140 11/391 ...............]  Step: 48ms | Tot: 1s25ms | Loss: 44.792 | Acc: 37.426% (1006/268 21/39 22/391 ...........]  Step: 53ms | Tot: 1s130ms | Loss: 44.794 | Acc: 37.126% (1093/294 23/39 32/39 33/391 ..............]  Step: 46ms | Tot: 1s841ms | Loss: 44.814 | Acc: 36.212% (1715/4 37/39 43/391 ..]  Step: 54ms | Tot: 2s714ms | Loss: 44.816 | Acc: 35.923% (2483/691 54/391 ..]  Step: 51ms | Tot: 3s611ms | Loss: 44.811 | Acc: 35.728% (3247/908 71/391 ====>..................]  Step: 51ms | Tot: 5s276ms | Loss: 44.791 | Acc: 36.104% (4760/1318 103/391 ..]  Step: 51ms | Tot: 5s892ms | Loss: 44.792 | Acc: 36.284% (5341/1472 115/391 ......]  Step: 46ms | Tot: 5s988ms | Loss: 44.790 | Acc: 36.291% (5435/1497 117/391 ............]  Step: 52ms | Tot: 6s40ms | Loss: 44.792 | Acc: 36.269% (5478/1510 118/39 141/391 ........]  Step: 48ms | Tot: 7s274ms | Loss: 44.794 | Acc: 36.196% (6579/1817 142/391 144/39 145/39 148/391 150/391 ==========>..............]  Step: 48ms | Tot: 8s359ms | Loss: 44.789 | Acc: 36.201% (7553/2086 163/391 ...........]  Step: 54ms | Tot: 8s413ms | Loss: 44.787 | Acc: 36.257% (7611/2099 164/391 =====>.............]  Step: 54ms | Tot: 9s18ms | Loss: 44.789 | Acc: 36.253% (8167/2252 176/391 ............]  Step: 48ms | Tot: 9s621ms | Loss: 44.793 | Acc: 36.133% (8695/2406 188/391 =>............]  Step: 47ms | Tot: 9s668ms | Loss: 44.794 | Acc: 36.099% (8733/2419 189/391 ====>............]  Step: 47ms | Tot: 9s822ms | Loss: 44.797 | Acc: 36.003% (8848/2457 192/391 ....]  Step: 47ms | Tot: 9s870ms | Loss: 44.796 | Acc: 36.035% (8902/2470 193/39 194/391 =============>...........]  Step: 46ms | Tot: 10s577ms | Loss: 44.797 | Acc: 35.968% (9530/2649 207/391 =============>...........]  Step: 46ms | Tot: 10s777ms | Loss: 44.795 | Acc: 36.030% (9731/2700 211/391 =============>...........]  Step: 52ms | Tot: 10s880ms | Loss: 44.794 | Acc: 36.051% (9829/2726 213/391 219/39 225/391 ==============>..........]  Step: 45ms | Tot: 11s785ms | Loss: 44.789 | Acc: 36.164% (10693/2956 231/391 ]  Step: 51ms | Tot: 11s836ms | Loss: 44.789 | Acc: 36.146% (10734/2969 232/391 233/39 246/391 ===============>.........]  Step: 49ms | Tot: 12s583ms | Loss: 44.792 | Acc: 36.156% (11431/3161 247/39 248/391 ==>.........]  Step: 46ms | Tot: 12s737ms | Loss: 44.791 | Acc: 36.188% (11580/3200 250/391 >........]  Step: 51ms | Tot: 12s835ms | Loss: 44.790 | Acc: 36.167% (11666/32 252/391 253/391 =================>.......]  Step: 46ms | Tot: 13s610ms | Loss: 44.791 | Acc: 36.142% (12352/3417 267/39 268/391   Step: 52ms | Tot: 13s714ms | Loss: 44.790 | Acc: 36.176% (12456/3443 269/391 278/391 279/39 284/391 ================>......]  Step: 46ms | Tot: 14s683ms | Loss: 44.787 | Acc: 36.279% (13374/3686 288/391 298/391 303/391 304/391 ==============>.....]  Step: 51ms | Tot: 15s540ms | Loss: 44.789 | Acc: 36.224% (14142/3904 305/391 ===================>.....]  Step: 45ms | Tot: 15s636ms | Loss: 44.789 | Acc: 36.225% (14235/3929 307/39 315/39 316/391 ======>....]  Step: 49ms | Tot: 16s689ms | Loss: 44.789 | Acc: 36.169% (15185/4198 328/391 ==================>...]  Step: 52ms | Tot: 16s788ms | Loss: 44.787 | Acc: 36.205% (15293/4224 330/391 =====================>...]  Step: 52ms | Tot: 17s152ms | Loss: 44.789 | Acc: 36.162% (15599/4313 337/39 345/391 ======================>..]  Step: 46ms | Tot: 17s667ms | Loss: 44.788 | Acc: 36.196% (16077/4441 347/391 ==============>..]  Step: 49ms | Tot: 17s866ms | Loss: 44.788 | Acc: 36.229% (16277/4492 351/39 352/391 =============>..]  Step: 53ms | Tot: 18s231ms | Loss: 44.790 | Acc: 36.215% (16595/4582 358/391 =======================>.]  Step: 46ms | Tot: 18s379ms | Loss: 44.790 | Acc: 36.208% (16731/4620 361/391 ========>.]  Step: 53ms | Tot: 18s433ms | Loss: 44.790 | Acc: 36.203% (16775/4633 362/39 372/391 ====>.]  Step: 53ms | Tot: 19s149ms | Loss: 44.790 | Acc: 36.195% (17420/4812 376/391 ========================>]  Step: 46ms | Tot: 19s297ms | Loss: 44.790 | Acc: 36.193% (17558/4851 379/391 ========>]  Step: 51ms | Tot: 19s348ms | Loss: 44.790 | Acc: 36.194% (17605/4864 380/39 381/39 388/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s559ms | Loss: 2.394 | Acc: 38.960% (3896/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(87.2446, device='cuda:0'), tensor(87.1002, device='cuda:0'), tensor(87.1181, device='cuda:0'), tensor(87.2083, device='cuda:0'), tensor(87.1712, device='cuda:0'), tensor(87.3247, device='cuda:0'), tensor(87.2887, device='cuda:0')]\n",
      "\n",
      "Epoch: 135\n",
      " [========================>]  Step: 65ms | Tot: 23s293ms | Loss: 44.764 | Acc: 35.818% (17909/5000 391/391 391 133/39 134/391 >...............]  Step: 61ms | Tot: 8s655ms | Loss: 44.765 | Acc: 35.817% (6556/1830 143/391 ======>.............]  Step: 69ms | Tot: 11s430ms | Loss: 44.770 | Acc: 35.737% (8554/2393 187/391 ..]  Step: 62ms | Tot: 11s560ms | Loss: 44.770 | Acc: 35.785% (8657/2419 189/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s880ms | Loss: 2.392 | Acc: 38.900% (3890/1000 79/79 ........]  Step: 55ms | Tot: 696ms | Loss: 2.424 | Acc: 38.906% (747/192 15/79 17/79 =====>...................]  Step: 55ms | Tot: 898ms | Loss: 2.420 | Acc: 39.104% (951/243 19/79 .....]  Step: 54ms | Tot: 998ms | Loss: 2.402 | Acc: 39.062% (1050/268 21/79 22/79 25/79 =>.................]  Step: 46ms | Tot: 1s244ms | Loss: 2.390 | Acc: 39.183% (1304/332 26/79 29/79 32/79 .......]  Step: 55ms | Tot: 1s600ms | Loss: 2.381 | Acc: 39.631% (1674/422 33/79 >..............]  Step: 45ms | Tot: 1s646ms | Loss: 2.390 | Acc: 39.568% (1722/435 34/79 ===========>.............]  Step: 46ms | Tot: 1s747ms | Loss: 2.392 | Acc: 39.410% (1816/460 36/79 =>.............]  Step: 54ms | Tot: 1s801ms | Loss: 2.396 | Acc: 39.253% (1859/473 37/79 38/7 39/79 41/79 42/79 ======>...........]  Step: 45ms | Tot: 2s148ms | Loss: 2.384 | Acc: 39.382% (2218/563 44/79 ===========>...........]  Step: 55ms | Tot: 2s203ms | Loss: 2.383 | Acc: 39.427% (2271/576 45/79 ]  Step: 45ms | Tot: 2s248ms | Loss: 2.381 | Acc: 39.419% (2321/588 46/79 =========>..........]  Step: 55ms | Tot: 2s304ms | Loss: 2.384 | Acc: 39.328% (2366/601 47/79 ==========>..........]  Step: 45ms | Tot: 2s349ms | Loss: 2.385 | Acc: 39.339% (2417/614 48/7 61/79 62/79 ========>..]  Step: 55ms | Tot: 3s610ms | Loss: 2.398 | Acc: 38.848% (3630/934 73/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(86.9508, device='cuda:0'), tensor(86.6971, device='cuda:0'), tensor(86.7775, device='cuda:0'), tensor(86.8759, device='cuda:0'), tensor(86.8271, device='cuda:0'), tensor(86.9604, device='cuda:0'), tensor(86.9666, device='cuda:0')]\n",
      "\n",
      "Epoch: 136\n",
      " [>........................]  Step: 62ms | Tot: 771ms | Loss: 44.792 | Acc: 34.856% (580/166 13/391 ....]  Step: 65ms | Tot: 639ms | Loss: 44.800 | Acc: 34.730% (489/140 11/391 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 58ms | Tot: 23s945ms | Loss: 43.919 | Acc: 38.234% (19117/5000 391/391 ===>..................]  Step: 65ms | Tot: 6s335ms | Loss: 43.911 | Acc: 38.210% (4842/1267 99/391 139/391 191/391 211/39 260/39 326/39 369/391 =========>]  Step: 69ms | Tot: 23s887ms | Loss: 43.919 | Acc: 38.237% (19088/4992 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s453ms | Loss: 2.339 | Acc: 39.860% (3986/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(78.0188, device='cuda:0'), tensor(78.1589, device='cuda:0'), tensor(78.1759, device='cuda:0'), tensor(78.0672, device='cuda:0'), tensor(78.1101, device='cuda:0'), tensor(78.2816, device='cuda:0'), tensor(78.2777, device='cuda:0')]\n",
      "\n",
      "Epoch: 163\n",
      " [========================>]  Step: 60ms | Tot: 18s314ms | Loss: 43.880 | Acc: 38.488% (19244/5000 391/391 ..........]  Step: 48ms | Tot: 248ms | Loss: 44.008 | Acc: 38.672% (297/76 6/39 8/391 ..............]  Step: 51ms | Tot: 449ms | Loss: 43.957 | Acc: 37.891% (485/128 10/391 ........]  Step: 47ms | Tot: 496ms | Loss: 43.958 | Acc: 37.784% (532/140 11/391 12/391 13/39 19/391 20/391 23/39 24/391 =>.......................]  Step: 45ms | Tot: 1s338ms | Loss: 43.918 | Acc: 37.807% (1355/358 28/39 72/391 343/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s660ms | Loss: 2.336 | Acc: 40.290% (4029/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(77.8934, device='cuda:0'), tensor(77.7592, device='cuda:0'), tensor(77.7658, device='cuda:0'), tensor(77.8319, device='cuda:0'), tensor(77.8144, device='cuda:0'), tensor(77.9586, device='cuda:0'), tensor(77.9692, device='cuda:0')]\n",
      "\n",
      "Epoch: 164\n",
      " [========================>]  Step: 63ms | Tot: 25s38ms | Loss: 43.851 | Acc: 38.370% (19185/50002 390/391   Step: 70ms | Tot: 2s117ms | Loss: 43.879 | Acc: 38.237% (1713/448 35/391 37/39 43/391   Step: 70ms | Tot: 2s895ms | Loss: 43.882 | Acc: 38.215% (2299/601 47/391 91/391 96/391 98/391 99/391 101/391 ....]  Step: 73ms | Tot: 6s553ms | Loss: 43.852 | Acc: 38.504% (5175/1344 105/391 =======>.................]  Step: 70ms | Tot: 6s928ms | Loss: 43.853 | Acc: 38.584% (5482/1420 111/391 113/39 127/391 131/391 ...........]  Step: 66ms | Tot: 8s466ms | Loss: 43.853 | Acc: 38.403% (6636/1728 135/391 .......]  Step: 70ms | Tot: 8s723ms | Loss: 43.848 | Acc: 38.534% (6856/1779 139/391 ...]  Step: 70ms | Tot: 8s851ms | Loss: 43.852 | Acc: 38.508% (6950/1804 141/39 145/391 ===>...............]  Step: 70ms | Tot: 9s236ms | Loss: 43.854 | Acc: 38.489% (7242/1881 147/391 157/391 169/39 171/39 198/391 200/391 >............]  Step: 64ms | Tot: 12s779ms | Loss: 43.854 | Acc: 38.513% (9958/2585 202/39 208/391 =======>...........]  Step: 64ms | Tot: 13s234ms | Loss: 43.853 | Acc: 38.588% (10323/2675 209/391 212/39 214/391  226/391 .....]  Step: 64ms | Tot: 14s464ms | Loss: 43.852 | Acc: 38.631% (11274/2918 228/391 232/391 ........]  Step: 67ms | Tot: 14s858ms | Loss: 43.850 | Acc: 38.612% (11565/2995 234/391 236/391 238/39 260/39 261/391 263/391 280/391 282/39 287/39 288/39 289/39 306/391 312/39 321/391 =====>...]  Step: 65ms | Tot: 21s353ms | Loss: 43.855 | Acc: 38.393% (16463/4288 335/39 339/391 ===>...]  Step: 65ms | Tot: 21s816ms | Loss: 43.855 | Acc: 38.386% (16804/43 342/39 346/391 347/391 =============>..]  Step: 66ms | Tot: 22s982ms | Loss: 43.855 | Acc: 38.375% (17683/4608 360/391 ==================>.]  Step: 65ms | Tot: 23s48ms | Loss: 43.855 | Acc: 38.359% (17725/4620 361/391 363/391 366/391 ====>.]  Step: 64ms | Tot: 23s584ms | Loss: 43.855 | Acc: 38.338% (18108/4723 369/391 =========>.]  Step: 67ms | Tot: 23s976ms | Loss: 43.854 | Acc: 38.337% (18402/4800 375/39 376/391 377/39 380/391 382/39 383/39 385/391 ==>]  Step: 68ms | Tot: 24s841ms | Loss: 43.852 | Acc: 38.356% (19049/4966 388/39 389/39 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s580ms | Loss: 2.333 | Acc: 40.320% (4032/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(76.7634, device='cuda:0'), tensor(76.9354, device='cuda:0'), tensor(76.8912, device='cuda:0'), tensor(76.7770, device='cuda:0'), tensor(76.9482, device='cuda:0'), tensor(77.6684, device='cuda:0'), tensor(77.6717, device='cuda:0')]\n",
      "\n",
      "Epoch: 165\n",
      " [========================>]  Step: 62ms | Tot: 22s402ms | Loss: 43.823 | Acc: 38.504% (19252/5000 391/391 9 84/39 86/391 193/391 ==============>..........]  Step: 68ms | Tot: 12s277ms | Loss: 43.825 | Acc: 38.613% (11417/2956 231/39 235/391 .]  Step: 68ms | Tot: 18s480ms | Loss: 43.825 | Acc: 38.546% (16282/4224 330/39 332/391 343/391 ]  Step: 64ms | Tot: 19s378ms | Loss: 43.827 | Acc: 38.467% (16938/4403 344/391 ======================>..]  Step: 69ms | Tot: 20s94ms | Loss: 43.825 | Acc: 38.499% (17494/4544 355/391 358/391 =======>..]  Step: 66ms | Tot: 20s358ms | Loss: 43.826 | Acc: 38.471% (17678/4595 359/391 ============>.]  Step: 68ms | Tot: 20s560ms | Loss: 43.826 | Acc: 38.471% (17826/4633 362/391 =======================>.]  Step: 63ms | Tot: 20s964ms | Loss: 43.825 | Acc: 38.485% (18128/4710 368/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s552ms | Loss: 2.333 | Acc: 40.130% (4013/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(77.9696, device='cuda:0'), tensor(77.8617, device='cuda:0'), tensor(77.9353, device='cuda:0'), tensor(77.9030, device='cuda:0'), tensor(77.8973, device='cuda:0'), tensor(77.3609, device='cuda:0'), tensor(77.3740, device='cuda:0')]\n",
      "\n",
      "Epoch: 166\n",
      " [========================>]  Step: 65ms | Tot: 22s696ms | Loss: 43.790 | Acc: 38.834% (19417/5000 390/391 ..................]  Step: 65ms | Tot: 3s484ms | Loss: 43.803 | Acc: 38.692% (2922/755 59/391  95/391 >..................]  Step: 68ms | Tot: 5s865ms | Loss: 43.786 | Acc: 38.958% (4837/1241 97/391 99/391 ======>..................]  Step: 67ms | Tot: 6s127ms | Loss: 43.786 | Acc: 38.900% (5029/1292 101/391 ..............]  Step: 48ms | Tot: 10s175ms | Loss: 43.785 | Acc: 39.049% (8497/2176 170/39 222/391 228/391 ..]  Step: 49ms | Tot: 16s757ms | Loss: 43.792 | Acc: 38.954% (14709/3776 295/391 335/39 377/39 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s625ms | Loss: 2.335 | Acc: 40.180% (4018/1000 79/79 ....]  Step: 55ms | Tot: 2s966ms | Loss: 2.350 | Acc: 40.276% (3351/832 65/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(76.8455, device='cuda:0'), tensor(76.9539, device='cuda:0'), tensor(76.2814, device='cuda:0'), tensor(76.9497, device='cuda:0'), tensor(76.9298, device='cuda:0'), tensor(77.0585, device='cuda:0'), tensor(77.0660, device='cuda:0')]\n",
      "\n",
      "Epoch: 167\n",
      " [========================>]  Step: 56ms | Tot: 23s633ms | Loss: 43.763 | Acc: 38.586% (19293/5000 391/391 1 .................]  Step: 67ms | Tot: 1s966ms | Loss: 43.792 | Acc: 37.598% (1540/409 32/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s566ms | Loss: 2.329 | Acc: 40.320% (4032/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(77.2089, device='cuda:0'), tensor(77.2994, device='cuda:0'), tensor(77.2836, device='cuda:0'), tensor(77.2619, device='cuda:0'), tensor(77.2989, device='cuda:0'), tensor(76.7618, device='cuda:0'), tensor(76.7716, device='cuda:0')]\n",
      "\n",
      "Epoch: 168\n",
      " [======>..................]  Step: 51ms | Tot: 5s184ms | Loss: 43.735 | Acc: 38.867% (5174/1331 104/391  Step: 51ms | Tot: 201ms | Loss: 43.769 | Acc: 39.375% (252/64 5/391 6/39 7/391 ................]  Step: 50ms | Tot: 402ms | Loss: 43.783 | Acc: 39.149% (451/115 9/391 .....................]  Step: 50ms | Tot: 452ms | Loss: 43.773 | Acc: 39.453% (505/128 10/39 27/39 28/391 ........]  Step: 52ms | Tot: 1s431ms | Loss: 43.772 | Acc: 38.389% (1425/371 29/39 37/391 ................]  Step: 51ms | Tot: 1s884ms | Loss: 43.770 | Acc: 38.014% (1849/486 38/391 48/39 50/391 56/391  60/39 61/391 ..................]  Step: 50ms | Tot: 3s298ms | Loss: 43.747 | Acc: 38.719% (3271/844 66/391 =>....................]  Step: 46ms | Tot: 3s548ms | Loss: 43.749 | Acc: 38.589% (3507/908 71/391 ====>....................]  Step: 45ms | Tot: 3s960ms | Loss: 43.744 | Acc: 38.766% (3920/1011 79/391 ........]  Step: 51ms | Tot: 4s488ms | Loss: 43.737 | Acc: 38.924% (4484/1152 90/391 92/391 96/391 ....]  Step: 51ms | Tot: 4s830ms | Loss: 43.738 | Acc: 38.837% (4822/1241 97/39 100/391 ................]  Step: 49ms | Tot: 5s81ms | Loss: 43.738 | Acc: 38.779% (5063/13 102/391 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 53ms | Tot: 22s713ms | Loss: 42.925 | Acc: 40.840% (20420/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s550ms | Loss: 2.301 | Acc: 41.020% (4102/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(68.9357, device='cuda:0'), tensor(68.8724, device='cuda:0'), tensor(68.9611, device='cuda:0'), tensor(69.0181, device='cuda:0'), tensor(68.9685, device='cuda:0'), tensor(69.0786, device='cuda:0'), tensor(69.0873, device='cuda:0')]\n",
      "\n",
      "Epoch: 195\n",
      " [========================>]  Step: 54ms | Tot: 24s792ms | Loss: 42.897 | Acc: 40.682% (20341/5000 391/391 391 ..............]  Step: 61ms | Tot: 2s40ms | Loss: 42.910 | Acc: 40.827% (1620/396 31/391  35/391 ................]  Step: 68ms | Tot: 2s370ms | Loss: 42.911 | Acc: 40.560% (1869/460 36/391 37/39 40/391 .............]  Step: 63ms | Tot: 2s837ms | Loss: 42.917 | Acc: 40.262% (2216/550 43/391 51/39 52/39 55/391 ....................]  Step: 63ms | Tot: 3s757ms | Loss: 42.918 | Acc: 40.433% (2950/729 57/391 .............]  Step: 69ms | Tot: 3s827ms | Loss: 42.919 | Acc: 40.396% (2999/742 58/391 ................]  Step: 65ms | Tot: 4s572ms | Loss: 42.906 | Acc: 40.806% (3604/883 69/391 ..................]  Step: 68ms | Tot: 4s834ms | Loss: 42.911 | Acc: 40.679% (3801/934 73/391 76/391 77/391 80/391 81/391 82/391 >...................]  Step: 69ms | Tot: 5s561ms | Loss: 42.906 | Acc: 40.737% (4380/10 84/391 ..]  Step: 62ms | Tot: 5s762ms | Loss: 42.901 | Acc: 40.823% (4546/11 87/391 =>..................]  Step: 70ms | Tot: 6s347ms | Loss: 42.902 | Acc: 40.690% (5000/1228 96/391 ........]  Step: 65ms | Tot: 6s479ms | Loss: 42.905 | Acc: 40.561% (5088/1254 98/391 99/39 122/391 .........]  Step: 62ms | Tot: 8s287ms | Loss: 42.904 | Acc: 40.550% (6488/1600 125/39 129/391 ..............]  Step: 67ms | Tot: 8s681ms | Loss: 42.902 | Acc: 40.559% (6801/1676 131/391 132/391 133/391 >................]  Step: 69ms | Tot: 8s882ms | Loss: 42.901 | Acc: 40.549% (6955/1715 134/391 140/391 ...........]  Step: 68ms | Tot: 9s537ms | Loss: 42.902 | Acc: 40.674% (7497/1843 144/391 .......]  Step: 68ms | Tot: 9s737ms | Loss: 42.900 | Acc: 40.763% (7670/1881 147/391 ====>...............]  Step: 65ms | Tot: 9s802ms | Loss: 42.898 | Acc: 40.810% (7731/1894 148/39 149/391 =========>...............]  Step: 68ms | Tot: 10s72ms | Loss: 42.898 | Acc: 40.789% (7936/1945 152/391 ............]  Step: 69ms | Tot: 10s648ms | Loss: 42.898 | Acc: 40.741% (8396/2060 161/391 167/39 171/391 ===========>.............]  Step: 68ms | Tot: 11s920ms | Loss: 42.897 | Acc: 40.716% (9381/2304 180/39 188/39 195/391 ....]  Step: 70ms | Tot: 13s112ms | Loss: 42.905 | Acc: 40.534% (10273/2534 198/391 >............]  Step: 64ms | Tot: 13s313ms | Loss: 42.903 | Acc: 40.563% (10436/2572 201/391  204/391 =======>...........]  Step: 66ms | Tot: 13s576ms | Loss: 42.903 | Acc: 40.598% (10653/2624 205/39 211/391 213/391 =====>...........]  Step: 65ms | Tot: 14s495ms | Loss: 42.901 | Acc: 40.671% (11401/2803 219/391 220/391 ====>..........]  Step: 68ms | Tot: 14s695ms | Loss: 42.899 | Acc: 40.755% (11581/28 222/391   Step: 70ms | Tot: 15s90ms | Loss: 42.901 | Acc: 40.687% (11874/2918 228/391 ........]  Step: 61ms | Tot: 15s291ms | Loss: 42.899 | Acc: 40.716% (12039/2956 231/391 =====>.........]  Step: 68ms | Tot: 15s694ms | Loss: 42.899 | Acc: 40.711% (12350/3033 237/39 249/39 250/39 266/391 270/391 ===========>.......]  Step: 69ms | Tot: 18s207ms | Loss: 42.898 | Acc: 40.756% (14346/3520 275/391 .......]  Step: 61ms | Tot: 18s339ms | Loss: 42.898 | Acc: 40.763% (14453/3545 277/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s553ms | Loss: 2.299 | Acc: 40.890% (4089/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(68.9715, device='cuda:0'), tensor(68.8581, device='cuda:0'), tensor(68.6562, device='cuda:0'), tensor(68.9426, device='cuda:0'), tensor(68.9136, device='cuda:0'), tensor(68.8136, device='cuda:0'), tensor(68.8181, device='cuda:0')]\n",
      "\n",
      "Epoch: 196\n",
      " [========================>]  Step: 61ms | Tot: 20s125ms | Loss: 42.863 | Acc: 40.780% (20390/5000 391/391 7/391 .............]  Step: 50ms | Tot: 854ms | Loss: 42.895 | Acc: 40.104% (924/230 18/391 ............]  Step: 52ms | Tot: 906ms | Loss: 42.898 | Acc: 40.132% (976/243 19/39 25/391 .]  Step: 52ms | Tot: 1s510ms | Loss: 42.888 | Acc: 40.323% (1600/396 31/391 .......]  Step: 50ms | Tot: 1s815ms | Loss: 42.892 | Acc: 40.160% (1902/473 37/39 39/391 48/391 ........]  Step: 50ms | Tot: 2s956ms | Loss: 42.878 | Acc: 40.559% (3063/755 59/391 ==>.....................]  Step: 51ms | Tot: 3s105ms | Loss: 42.885 | Acc: 40.360% (3203/793 62/391 67/39 90/39 91/39 95/39 100/39 110/391 112/391 .............]  Step: 50ms | Tot: 6s340ms | Loss: 42.876 | Acc: 40.475% (6476/1600 125/39 126/391 131/39 132/391 ............]  Step: 47ms | Tot: 6s899ms | Loss: 42.878 | Acc: 40.401% (7033/1740 136/391 ===>...............]  Step: 51ms | Tot: 7s260ms | Loss: 42.874 | Acc: 40.472% (7408/1830 143/391 144/391 145/391 ===>...............]  Step: 48ms | Tot: 7s409ms | Loss: 42.877 | Acc: 40.470% (7563/1868 146/391 147/39 148/39 160/391 165/39 169/391 =>.............]  Step: 50ms | Tot: 9s399ms | Loss: 42.874 | Acc: 40.367% (9559/2368 185/39 188/391 =====>............]  Step: 48ms | Tot: 9s650ms | Loss: 42.874 | Acc: 40.411% (9828/2432 190/39 196/391 ==>...........]  Step: 50ms | Tot: 10s561ms | Loss: 42.872 | Acc: 40.505% (10836/2675 209/391 .....]  Step: 49ms | Tot: 10s659ms | Loss: 42.871 | Acc: 40.566% (10956/2700 211/391 =========>...........]  Step: 51ms | Tot: 10s710ms | Loss: 42.870 | Acc: 40.588% (11014/2713 212/391 =====>...........]  Step: 51ms | Tot: 10s761ms | Loss: 42.869 | Acc: 40.585% (11065/2726 213/391 216/39 249/39 274/39 275/391 .....]  Step: 48ms | Tot: 13s919ms | Loss: 42.865 | Acc: 40.833% (14530/3558 278/39 284/39 287/391 ==>......]  Step: 50ms | Tot: 14s501ms | Loss: 42.866 | Acc: 40.805% (15147/3712 290/39 297/391 =========>......]  Step: 52ms | Tot: 14s910ms | Loss: 42.866 | Acc: 40.819% (15570/3814 298/391 ]  Step: 52ms | Tot: 15s59ms | Loss: 42.866 | Acc: 40.825% (15729/3852 301/39 313/39 314/391 ============>....]  Step: 50ms | Tot: 15s917ms | Loss: 42.868 | Acc: 40.723% (16576/4070 318/391 320/391 321/391 >....]  Step: 49ms | Tot: 16s262ms | Loss: 42.866 | Acc: 40.784% (16966/4160 325/391 326/39 327/39 328/391 ==>....]  Step: 51ms | Tot: 16s463ms | Loss: 42.866 | Acc: 40.789% (17177/4211 329/39 331/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s546ms | Loss: 2.299 | Acc: 40.980% (4098/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(68.5109, device='cuda:0'), tensor(68.3475, device='cuda:0'), tensor(68.4378, device='cuda:0'), tensor(68.4446, device='cuda:0'), tensor(68.4695, device='cuda:0'), tensor(68.5489, device='cuda:0'), tensor(68.5504, device='cuda:0')]\n",
      "\n",
      "Epoch: 197\n",
      " [========================>]  Step: 54ms | Tot: 23s744ms | Loss: 42.839 | Acc: 40.514% (20257/5000 391/391 .................]  Step: 67ms | Tot: 1s533ms | Loss: 42.852 | Acc: 39.875% (1276/320 25/39 35/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s577ms | Loss: 2.296 | Acc: 41.200% (4120/1000 79/79  \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(68.0825, device='cuda:0'), tensor(68.1871, device='cuda:0'), tensor(68.1877, device='cuda:0'), tensor(68.1927, device='cuda:0'), tensor(68.1228, device='cuda:0'), tensor(68.2811, device='cuda:0'), tensor(68.2874, device='cuda:0')]\n",
      "\n",
      "Epoch: 198\n",
      " [========================>]  Step: 70ms | Tot: 24s268ms | Loss: 42.801 | Acc: 40.954% (20477/5000 391/391 1 96/39 100/39 106/391 ..]  Step: 66ms | Tot: 6s656ms | Loss: 42.803 | Acc: 40.799% (5640/1382 108/39 109/39 111/39 131/391 141/391 148/391 ..............]  Step: 65ms | Tot: 9s410ms | Loss: 42.798 | Acc: 40.992% (7923/1932 151/391 .....]  Step: 68ms | Tot: 9s479ms | Loss: 42.798 | Acc: 40.975% (7972/1945 152/391 ........]  Step: 68ms | Tot: 9s865ms | Loss: 42.797 | Acc: 40.946% (8281/2022 158/39 160/391 164/391 =>..............]  Step: 67ms | Tot: 10s831ms | Loss: 42.796 | Acc: 40.900% (9057/2214 173/39 174/391 ]  Step: 67ms | Tot: 11s410ms | Loss: 42.796 | Acc: 40.921% (9533/2329 182/391 184/391 .....]  Step: 68ms | Tot: 11s611ms | Loss: 42.798 | Acc: 40.912% (9688/2368 185/391 ........]  Step: 62ms | Tot: 11s742ms | Loss: 42.798 | Acc: 40.959% (9804/2393 187/391 =====>............]  Step: 67ms | Tot: 12s5ms | Loss: 42.803 | Acc: 40.842% (9985/2444 191/391 192/391 =====>............]  Step: 66ms | Tot: 12s206ms | Loss: 42.803 | Acc: 40.814% (10135/2483 194/391 195/391 200/391 242/391 243/391 245/391 .........]  Step: 64ms | Tot: 15s843ms | Loss: 42.800 | Acc: 40.909% (13091/3200 250/391 252/391 255/391 263/39 265/391 ======>........]  Step: 70ms | Tot: 16s893ms | Loss: 42.802 | Acc: 40.939% (13939/3404 266/39 267/39 300/39 309/391 ==================>.]  Step: 69ms | Tot: 23s259ms | Loss: 42.802 | Acc: 40.968% (19612/4787 374/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s576ms | Loss: 2.293 | Acc: 41.370% (4137/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(68.3585, device='cuda:0'), tensor(68.3837, device='cuda:0'), tensor(68.3330, device='cuda:0'), tensor(68.3597, device='cuda:0'), tensor(68.3206, device='cuda:0'), tensor(68.0063, device='cuda:0'), tensor(68.0151, device='cuda:0')]\n",
      "\n",
      "Epoch: 199\n",
      " [========================>]  Step: 68ms | Tot: 21s446ms | Loss: 42.771 | Acc: 40.888% (20444/5000 391/391  .]  Step: 50ms | Tot: 251ms | Loss: 42.878 | Acc: 38.542% (296/76 6/391 7/391 ........]  Step: 50ms | Tot: 352ms | Loss: 42.867 | Acc: 39.062% (400/102 8/391 >........................]  Step: 50ms | Tot: 506ms | Loss: 42.824 | Acc: 39.986% (563/140 11/391 >........................]  Step: 46ms | Tot: 604ms | Loss: 42.820 | Acc: 40.144% (668/166 13/391 .....]  Step: 50ms | Tot: 654ms | Loss: 42.812 | Acc: 40.234% (721/179 14/391 ...............]  Step: 50ms | Tot: 705ms | Loss: 42.813 | Acc: 40.208% (772/1 15/391 ......]  Step: 51ms | Tot: 756ms | Loss: 42.819 | Acc: 40.186% (823/204 16/391 ......]  Step: 45ms | Tot: 906ms | Loss: 42.804 | Acc: 40.461% (984/2 19/391   Step: 49ms | Tot: 955ms | Loss: 42.800 | Acc: 40.664% (1041/256 20/391 =>.......................]  Step: 46ms | Tot: 1s107ms | Loss: 42.789 | Acc: 41.033% (1208/294 23/391 24/39 28/391 ....................]  Step: 50ms | Tot: 1s552ms | Loss: 42.792 | Acc: 40.601% (1663/409 32/391 60/391  61/39 64/391 68/391 ......]  Step: 50ms | Tot: 3s590ms | Loss: 42.780 | Acc: 40.408% (3724/921 72/39 76/39 85/391 =====>...................]  Step: 49ms | Tot: 4s326ms | Loss: 42.769 | Acc: 40.679% (4530/1113 87/39 88/391 89/39 90/391 ......]  Step: 46ms | Tot: 4s728ms | Loss: 42.767 | Acc: 40.798% (4961/1216 95/391 ..........]  Step: 57ms | Tot: 4s974ms | Loss: 42.772 | Acc: 40.703% (5210/1280 100/391 ===>...]  Step: 44ms | Tot: 18s334ms | Loss: 42.774 | Acc: 40.869% (17734/4339 339/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s531ms | Loss: 2.294 | Acc: 41.230% (4123/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(68.0365, device='cuda:0'), tensor(68.0661, device='cuda:0'), tensor(68.0740, device='cuda:0'), tensor(68.0901, device='cuda:0'), tensor(68.0717, device='cuda:0'), tensor(67.7446, device='cuda:0'), tensor(67.7554, device='cuda:0')]\n",
      "\n",
      "Epoch: 200\n",
      " [=================>.......]  Step: 52ms | Tot: 16s778ms | Loss: 42.756 | Acc: 40.938% (13991/3417 267/391 9 26/391 ......]  Step: 68ms | Tot: 1s703ms | Loss: 42.796 | Acc: 39.174% (1404/358 28/39 44/39 45/391  55/391 67/391 69/391 .............]  Step: 73ms | Tot: 4s929ms | Loss: 42.766 | Acc: 40.407% (4086/1011 79/391 90/391 96/39 97/391 .............]  Step: 74ms | Tot: 6s494ms | Loss: 42.756 | Acc: 40.633% (5357/1318 103/391   Step: 70ms | Tot: 7s225ms | Loss: 42.758 | Acc: 40.598% (5924/1459 114/391 116/391 120/39 122/39 128/39 140/39 146/39 149/391   Step: 71ms | Tot: 9s670ms | Loss: 42.753 | Acc: 40.954% (7968/1945 152/391 >...............]  Step: 69ms | Tot: 9s930ms | Loss: 42.754 | Acc: 40.956% (8178/1996 156/391 =>..............]  Step: 72ms | Tot: 10s61ms | Loss: 42.755 | Acc: 40.907% (8273/2022 158/391 ...]  Step: 70ms | Tot: 10s320ms | Loss: 42.756 | Acc: 40.890% (8479/2073 162/391 ....]  Step: 70ms | Tot: 10s449ms | Loss: 42.755 | Acc: 40.925% (8591/2099 164/39 166/391 168/391 ....]  Step: 70ms | Tot: 11s328ms | Loss: 42.754 | Acc: 40.906% (9320/2278 178/39 201/391 215/39 218/391 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 61ms | Tot: 24s873ms | Loss: 41.915 | Acc: 42.732% (21366/5000 391/391 ...............]  Step: 69ms | Tot: 6s838ms | Loss: 41.908 | Acc: 43.089% (5736/1331 104/39 110/391 ...............]  Step: 69ms | Tot: 7s312ms | Loss: 41.909 | Acc: 43.067% (6119/1420 111/391 118/391 ..............]  Step: 62ms | Tot: 7s927ms | Loss: 41.906 | Acc: 43.171% (6631/1536 120/391 121/39 136/391 .......]  Step: 67ms | Tot: 9s410ms | Loss: 41.909 | Acc: 43.002% (7871/1830 143/391 156/39 157/391 ...]  Step: 64ms | Tot: 10s380ms | Loss: 41.909 | Acc: 43.078% (8712/2022 158/39 191/39 207/391 213/391 .]  Step: 69ms | Tot: 13s919ms | Loss: 41.909 | Acc: 42.991% (11831/2752 215/39 223/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s602ms | Loss: 2.273 | Acc: 41.880% (4188/1000 79/79 =========>.....]  Step: 62ms | Tot: 2s913ms | Loss: 2.287 | Acc: 42.065% (3446/819 64/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(60.3478, device='cuda:0'), tensor(60.2791, device='cuda:0'), tensor(60.3083, device='cuda:0'), tensor(60.3074, device='cuda:0'), tensor(60.3065, device='cuda:0'), tensor(60.7296, device='cuda:0'), tensor(60.7454, device='cuda:0')]\n",
      "\n",
      "Epoch: 228\n",
      " [========================>]  Step: 70ms | Tot: 25s316ms | Loss: 41.892 | Acc: 43.002% (21501/5000 391/391 9 12/391 ..............]  Step: 62ms | Tot: 922ms | Loss: 41.941 | Acc: 42.083% (808/192 15/391 =>.......................]  Step: 69ms | Tot: 1s255ms | Loss: 41.920 | Acc: 42.578% (1090/256 20/39 21/391 22/391 .............]  Step: 67ms | Tot: 2s203ms | Loss: 41.914 | Acc: 42.455% (1902/448 35/391 .]  Step: 66ms | Tot: 3s157ms | Loss: 41.923 | Acc: 42.234% (2703/640 50/39 51/391 .....]  Step: 68ms | Tot: 4s370ms | Loss: 41.904 | Acc: 42.516% (3755/883 69/391 ..........]  Step: 61ms | Tot: 4s432ms | Loss: 41.903 | Acc: 42.522% (3810/896 70/391 ...............]  Step: 69ms | Tot: 4s632ms | Loss: 41.904 | Acc: 42.466% (3968/934 73/391 91/39 92/391 ==>..................]  Step: 68ms | Tot: 6s731ms | Loss: 41.881 | Acc: 43.345% (5881/1356 106/39 126/391  138/391  142/39 145/391 161/391 162/391 =====>..............]  Step: 64ms | Tot: 10s826ms | Loss: 41.883 | Acc: 43.355% (9323/2150 168/391 169/391 =======>...........]  Step: 69ms | Tot: 13s600ms | Loss: 41.890 | Acc: 43.346% (11707/2700 211/391 .....]  Step: 68ms | Tot: 14s640ms | Loss: 41.890 | Acc: 43.282% (12576/2905 227/391  232/39 257/391 265/391 ====>.......]  Step: 65ms | Tot: 17s207ms | Loss: 41.894 | Acc: 43.153% (14748/3417 267/391 .......]  Step: 65ms | Tot: 17s273ms | Loss: 41.894 | Acc: 43.167% (14808/3430 268/39 270/39 285/391 289/391 ====>......]  Step: 64ms | Tot: 18s896ms | Loss: 41.890 | Acc: 43.193% (16199/3750 293/39 317/391 319/391 .]  Step: 65ms | Tot: 21s250ms | Loss: 41.893 | Acc: 43.080% (18197/4224 330/391 =====================>...]  Step: 67ms | Tot: 21s317ms | Loss: 41.893 | Acc: 43.066% (18246/4236 331/39 333/391 =====>..]  Step: 62ms | Tot: 22s701ms | Loss: 41.893 | Acc: 43.026% (19386/4505 352/391 .]  Step: 62ms | Tot: 23s497ms | Loss: 41.894 | Acc: 42.969% (20020/4659 364/391 ===============>.]  Step: 69ms | Tot: 23s700ms | Loss: 41.893 | Acc: 42.977% (20189/4697 367/39 370/391 375/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s567ms | Loss: 2.274 | Acc: 41.950% (4195/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(60.2721, device='cuda:0'), tensor(60.4248, device='cuda:0'), tensor(60.3602, device='cuda:0'), tensor(60.4114, device='cuda:0'), tensor(60.3937, device='cuda:0'), tensor(60.4917, device='cuda:0'), tensor(60.5079, device='cuda:0')]\n",
      "\n",
      "Epoch: 229\n",
      " [========================>]  Step: 64ms | Tot: 21s407ms | Loss: 41.862 | Acc: 42.978% (21489/5000 391/391 .]  Step: 65ms | Tot: 2s987ms | Loss: 41.888 | Acc: 42.390% (3147/742 58/391 ==>..............]  Step: 52ms | Tot: 8s800ms | Loss: 41.870 | Acc: 42.910% (8733/2035 159/391 168/391 ==========>..............]  Step: 51ms | Tot: 9s316ms | Loss: 41.870 | Acc: 42.802% (9259/2163 169/391 ........]  Step: 51ms | Tot: 9s466ms | Loss: 41.870 | Acc: 42.787% (9420/2201 172/39 184/391 ........]  Step: 49ms | Tot: 10s132ms | Loss: 41.871 | Acc: 42.779% (10130/2368 185/391 186/391 193/39 194/391 ===>............]  Step: 48ms | Tot: 10s838ms | Loss: 41.874 | Acc: 42.588% (10848/2547 199/391 201/391 ========>............]  Step: 45ms | Tot: 11s87ms | Loss: 41.873 | Acc: 42.559% (11113/2611 204/39 205/391 =============>...........]  Step: 47ms | Tot: 11s601ms | Loss: 41.868 | Acc: 42.669% (11688/2739 214/391 ============>...........]  Step: 55ms | Tot: 11s802ms | Loss: 41.867 | Acc: 42.700% (11915/2790 218/391 ==============>..........]  Step: 48ms | Tot: 12s206ms | Loss: 41.866 | Acc: 42.772% (12373/2892 226/39 227/391 =======>..........]  Step: 48ms | Tot: 12s408ms | Loss: 41.869 | Acc: 42.694% (12569/2944 230/391 =========>..........]  Step: 53ms | Tot: 12s462ms | Loss: 41.868 | Acc: 42.691% (12623/2956 231/391 ......]  Step: 53ms | Tot: 12s663ms | Loss: 41.869 | Acc: 42.666% (12834/3008 235/391 =>.........]  Step: 53ms | Tot: 12s717ms | Loss: 41.868 | Acc: 42.694% (12897/3020 236/391 ===============>.........]  Step: 49ms | Tot: 12s967ms | Loss: 41.870 | Acc: 42.690% (13169/3084 241/391 ===============>.........]  Step: 53ms | Tot: 13s67ms | Loss: 41.871 | Acc: 42.676% (13274/3110 243/39 253/391 255/391 ========>.......]  Step: 54ms | Tot: 14s623ms | Loss: 41.864 | Acc: 42.897% (14990/3494 273/391 .....]  Step: 48ms | Tot: 14s672ms | Loss: 41.864 | Acc: 42.880% (15039/3507 274/391 275/39 276/391  277/391 =================>.......]  Step: 53ms | Tot: 14s872ms | Loss: 41.864 | Acc: 42.890% (15262/35 278/39 281/391 =============>.......]  Step: 51ms | Tot: 15s74ms | Loss: 41.864 | Acc: 42.886% (15480/3609 282/391 286/391 ========>......]  Step: 53ms | Tot: 15s328ms | Loss: 41.863 | Acc: 42.895% (15758/3673 287/391 ==>.....]  Step: 51ms | Tot: 16s453ms | Loss: 41.866 | Acc: 42.817% (16935/3955 309/39 310/391 ]  Step: 53ms | Tot: 16s868ms | Loss: 41.866 | Acc: 42.791% (17363/4057 317/39 369/391 =======================>.]  Step: 69ms | Tot: 20s76ms | Loss: 41.864 | Acc: 42.950% (20341/4736 370/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s553ms | Loss: 2.273 | Acc: 41.780% (4178/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(60.1535, device='cuda:0'), tensor(60.0711, device='cuda:0'), tensor(60.1814, device='cuda:0'), tensor(60.1726, device='cuda:0'), tensor(60.1480, device='cuda:0'), tensor(60.2573, device='cuda:0'), tensor(60.2708, device='cuda:0')]\n",
      "\n",
      "Epoch: 230\n",
      " [========================>]  Step: 63ms | Tot: 23s971ms | Loss: 41.828 | Acc: 42.868% (21434/5000 391/391 /391 131/39 132/391 135/39 141/39 173/39 200/39 202/391 272/391 274/39 278/39 279/39 280/391 282/39 289/39 291/391   Step: 69ms | Tot: 17s726ms | Loss: 41.832 | Acc: 43.086% (16104/3737 292/391 298/39 306/391 309/391 325/39 326/39 339/391 ======>]  Step: 65ms | Tot: 23s417ms | Loss: 41.830 | Acc: 42.875% (20964/4889 382/391 388/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s668ms | Loss: 2.275 | Acc: 41.950% (4195/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(59.6186, device='cuda:0'), tensor(59.6118, device='cuda:0'), tensor(59.6339, device='cuda:0'), tensor(59.5884, device='cuda:0'), tensor(59.6072, device='cuda:0'), tensor(60.0263, device='cuda:0'), tensor(60.0374, device='cuda:0')]\n",
      "\n",
      "Epoch: 231\n",
      " [========================>]  Step: 34ms | Tot: 23s151ms | Loss: 41.796 | Acc: 42.978% (21489/5000 391/391 ...............]  Step: 69ms | Tot: 2s632ms | Loss: 41.840 | Acc: 42.076% (2262/537 42/391 .]  Step: 69ms | Tot: 2s834ms | Loss: 41.840 | Acc: 42.083% (2424/576 45/391 47/39 57/391 ................]  Step: 68ms | Tot: 4s119ms | Loss: 41.826 | Acc: 42.536% (3539/832 65/39 71/391 .]  Step: 69ms | Tot: 4s589ms | Loss: 41.816 | Acc: 42.806% (3945/921 72/391 .........]  Step: 62ms | Tot: 4s652ms | Loss: 41.815 | Acc: 42.851% (4004/934 73/39 92/39 102/391 107/391 118/391 127/391 >................]  Step: 74ms | Tot: 8s836ms | Loss: 41.800 | Acc: 43.177% (7682/1779 139/39 140/391 ]  Step: 66ms | Tot: 9s211ms | Loss: 41.803 | Acc: 43.082% (7996/1856 145/39 147/391 149/391 ............]  Step: 63ms | Tot: 10s169ms | Loss: 41.798 | Acc: 43.110% (8829/2048 160/391 164/39 165/391 =====>..............]  Step: 64ms | Tot: 10s563ms | Loss: 41.796 | Acc: 43.157% (9170/2124 166/391 ..]  Step: 69ms | Tot: 11s298ms | Loss: 41.796 | Acc: 43.212% (9790/2265 177/39 181/391 183/39 187/39 192/39 201/391 ........]  Step: 70ms | Tot: 13s274ms | Loss: 41.800 | Acc: 43.135% (11429/2649 207/391 =======>...........]  Step: 61ms | Tot: 13s607ms | Loss: 41.796 | Acc: 43.238% (11733/2713 212/391 =============>...........]  Step: 70ms | Tot: 13s810ms | Loss: 41.797 | Acc: 43.201% (11889/2752 215/391 =========>.........]  Step: 66ms | Tot: 15s929ms | Loss: 41.802 | Acc: 43.007% (13652/3174 248/39 267/391 295/391 ======>.....]  Step: 62ms | Tot: 19s702ms | Loss: 41.801 | Acc: 43.078% (16928/3929 307/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s748ms | Loss: 2.274 | Acc: 41.950% (4195/1000 79/79 /79 31/79 ==========>..............]  Step: 55ms | Tot: 1s552ms | Loss: 2.274 | Acc: 42.211% (1783/422 33/79 ...]  Step: 55ms | Tot: 1s753ms | Loss: 2.288 | Acc: 41.997% (1989/473 37/7 41/79 ...]  Step: 54ms | Tot: 2s155ms | Loss: 2.270 | Acc: 42.118% (2426/5 45/79 =============>..........]  Step: 45ms | Tot: 2s201ms | Loss: 2.267 | Acc: 42.120% (2480/588 46/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(59.7542, device='cuda:0'), tensor(59.6946, device='cuda:0'), tensor(59.6820, device='cuda:0'), tensor(59.6758, device='cuda:0'), tensor(59.6877, device='cuda:0'), tensor(59.7914, device='cuda:0'), tensor(59.8047, device='cuda:0')]\n",
      "\n",
      "Epoch: 232\n",
      " [========================>]  Step: 64ms | Tot: 25s282ms | Loss: 41.762 | Acc: 43.200% (21600/5000 391/391 ...............]  Step: 59ms | Tot: 1s416ms | Loss: 41.793 | Acc: 42.318% (1300/307 24/39 25/39 29/391 .......]  Step: 73ms | Tot: 1s869ms | Loss: 41.790 | Acc: 42.314% (1679/396 31/391 ..........]  Step: 63ms | Tot: 2s577ms | Loss: 41.795 | Acc: 42.504% (2285/537 42/391 ..............]  Step: 74ms | Tot: 3s742ms | Loss: 41.787 | Acc: 42.725% (3336/780 61/391 =====>...................]  Step: 70ms | Tot: 5s247ms | Loss: 41.776 | Acc: 42.904% (4668/1088 85/391 .....]  Step: 72ms | Tot: 6s243ms | Loss: 41.769 | Acc: 43.093% (5571/1292 101/391 ...............]  Step: 64ms | Tot: 6s710ms | Loss: 41.769 | Acc: 43.063% (5953/1382 108/391 ..............]  Step: 63ms | Tot: 7s245ms | Loss: 41.771 | Acc: 43.050% (6392/1484 116/39 124/391 ...........]  Step: 64ms | Tot: 8s321ms | Loss: 41.767 | Acc: 43.093% (7281/1689 132/391 134/39 138/391 ==>................]  Step: 69ms | Tot: 8s927ms | Loss: 41.767 | Acc: 43.207% (7798/1804 141/391 .......]  Step: 61ms | Tot: 9s524ms | Loss: 41.769 | Acc: 43.099% (8275/1920 150/39 154/391 ...............]  Step: 71ms | Tot: 9s999ms | Loss: 41.770 | Acc: 43.058% (8653/2009 157/391 ====>..............]  Step: 60ms | Tot: 10s198ms | Loss: 41.769 | Acc: 43.052% (8817/2048 160/391 ======>..............]  Step: 69ms | Tot: 10s532ms | Loss: 41.768 | Acc: 43.097% (9102/2112 165/391 ..........]  Step: 64ms | Tot: 10s864ms | Loss: 41.768 | Acc: 43.116% (9382/2176 170/391 188/391 ....]  Step: 63ms | Tot: 12s883ms | Loss: 41.769 | Acc: 43.090% (11031/2560 200/391 ====>............]  Step: 71ms | Tot: 13s86ms | Loss: 41.769 | Acc: 43.115% (11203/2598 203/391 .........]  Step: 69ms | Tot: 13s485ms | Loss: 41.767 | Acc: 43.148% (11543/2675 209/391 ......]  Step: 67ms | Tot: 14s928ms | Loss: 41.766 | Acc: 43.168% (12764/2956 231/391 238/39 240/39 246/391 ================>........]  Step: 67ms | Tot: 16s671ms | Loss: 41.763 | Acc: 43.314% (14304/3302 258/391 ........]  Step: 69ms | Tot: 16s803ms | Loss: 41.763 | Acc: 43.341% (14424/3328 260/391 .]  Step: 62ms | Tot: 17s523ms | Loss: 41.762 | Acc: 43.332% (15031/3468 271/391 277/391 283/39 295/391 =========>......]  Step: 69ms | Tot: 19s336ms | Loss: 41.764 | Acc: 43.328% (16527/3814 298/391 .....]  Step: 70ms | Tot: 19s972ms | Loss: 41.766 | Acc: 43.233% (17044/3942 308/391 ==============>.....]  Step: 70ms | Tot: 20s103ms | Loss: 41.766 | Acc: 43.238% (17157/3968 310/39 316/391 >....]  Step: 69ms | Tot: 20s617ms | Loss: 41.765 | Acc: 43.239% (17600/4070 318/39 320/391 ====>....]  Step: 70ms | Tot: 20s880ms | Loss: 41.764 | Acc: 43.236% (17820/4121 322/391 ..]  Step: 70ms | Tot: 21s275ms | Loss: 41.764 | Acc: 43.228% (18149/4198 328/391 ===>...]  Step: 69ms | Tot: 21s405ms | Loss: 41.762 | Acc: 43.253% (18270/4224 330/391 ========>...]  Step: 70ms | Tot: 21s536ms | Loss: 41.763 | Acc: 43.242% (18376/4249 332/391 =====>...]  Step: 70ms | Tot: 21s667ms | Loss: 41.764 | Acc: 43.212% (18474/4275 334/391 ==========>...]  Step: 70ms | Tot: 21s797ms | Loss: 41.764 | Acc: 43.187% (18574/4300 336/391 ======>...]  Step: 70ms | Tot: 21s929ms | Loss: 41.765 | Acc: 43.186% (18684/4326 338/39 340/391 =>...]  Step: 70ms | Tot: 22s191ms | Loss: 41.765 | Acc: 43.199% (18911/4377 342/39 344/391 =>..]  Step: 70ms | Tot: 22s707ms | Loss: 41.764 | Acc: 43.201% (19354/4480 350/39 352/391 ======>..]  Step: 70ms | Tot: 22s969ms | Loss: 41.764 | Acc: 43.189% (19570/4531 354/391 ========>..]  Step: 70ms | Tot: 23s100ms | Loss: 41.764 | Acc: 43.210% (19690/4556 356/391  358/39 360/391 ==============>]  Step: 70ms | Tot: 24s623ms | Loss: 41.764 | Acc: 43.174% (21000/4864 380/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s565ms | Loss: 2.268 | Acc: 42.070% (4207/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(59.1006, device='cuda:0'), tensor(59.1564, device='cuda:0'), tensor(59.7757, device='cuda:0'), tensor(59.1571, device='cuda:0'), tensor(59.1526, device='cuda:0'), tensor(59.5600, device='cuda:0'), tensor(59.5708, device='cuda:0')]\n",
      "\n",
      "Epoch: 233\n",
      " [==>......................]  Step: 59ms | Tot: 2s118ms | Loss: 41.764 | Acc: 42.344% (1897/448 35/391 \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 61ms | Tot: 24s415ms | Loss: 41.675 | Acc: 43.546% (21773/5000 391/391 209/391 ========>...........]  Step: 63ms | Tot: 13s311ms | Loss: 41.676 | Acc: 43.678% (12076/2764 216/391 >........]  Step: 69ms | Tot: 16s315ms | Loss: 41.677 | Acc: 43.629% (14743/3379 264/391 ===========>........]  Step: 63ms | Tot: 16s379ms | Loss: 41.677 | Acc: 43.644% (14804/3392 265/391 309/39 310/391 324/39 326/391 327/39 330/39 337/39 341/391 =======================>.]  Step: 70ms | Tot: 22s743ms | Loss: 41.678 | Acc: 43.540% (20342/4672 365/391 ==================>.]  Step: 71ms | Tot: 22s875ms | Loss: 41.678 | Acc: 43.529% (20448/4697 367/391 371/391 ======>]  Step: 67ms | Tot: 23s519ms | Loss: 41.676 | Acc: 43.537% (21009/4825 377/391 ====================>]  Step: 70ms | Tot: 23s773ms | Loss: 41.676 | Acc: 43.524% (21226/4876 381/391 =>]  Step: 69ms | Tot: 24s289ms | Loss: 41.676 | Acc: 43.529% (21674/4979 389/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s531ms | Loss: 2.265 | Acc: 42.180% (4218/1000 79/79 Step: 45ms | Tot: 250ms | Loss: 2.305 | Acc: 41.536% (319/76 6/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(58.7593, device='cuda:0'), tensor(58.7679, device='cuda:0'), tensor(58.7824, device='cuda:0'), tensor(58.7446, device='cuda:0'), tensor(58.7435, device='cuda:0'), tensor(58.8639, device='cuda:0'), tensor(58.8778, device='cuda:0')]\n",
      "\n",
      "Epoch: 236\n",
      " [========================>]  Step: 67ms | Tot: 25s356ms | Loss: 41.639 | Acc: 43.461% (21640/49792388/391 ........]  Step: 61ms | Tot: 332ms | Loss: 41.731 | Acc: 41.406% (318/76 6/391 ................]  Step: 62ms | Tot: 666ms | Loss: 41.661 | Acc: 42.685% (601/140 11/39 30/391 33/391 ..................]  Step: 64ms | Tot: 2s552ms | Loss: 41.661 | Acc: 43.149% (2154/499 39/391 ...................]  Step: 63ms | Tot: 2s752ms | Loss: 41.664 | Acc: 42.820% (2302/537 42/391 ===>.....................]  Step: 66ms | Tot: 3s307ms | Loss: 41.666 | Acc: 42.562% (2724/640 50/391 ...................]  Step: 68ms | Tot: 3s650ms | Loss: 41.669 | Acc: 42.330% (2980/704 55/391 ..............]  Step: 68ms | Tot: 3s718ms | Loss: 41.667 | Acc: 42.327% (3034/716 56/391 .................]  Step: 70ms | Tot: 5s558ms | Loss: 41.645 | Acc: 43.242% (4594/1062 83/391 ======>..................]  Step: 67ms | Tot: 7s164ms | Loss: 41.642 | Acc: 43.254% (5924/1369 107/391 ==>.................]  Step: 62ms | Tot: 7s612ms | Loss: 41.647 | Acc: 43.222% (6307/1459 114/39 117/39 120/391 =======>.................]  Step: 61ms | Tot: 8s146ms | Loss: 41.643 | Acc: 43.366% (6772/1561 122/391 134/391 ==>...............]  Step: 71ms | Tot: 9s782ms | Loss: 41.645 | Acc: 43.330% (8153/1881 147/391 ............]  Step: 70ms | Tot: 10s971ms | Loss: 41.639 | Acc: 43.447% (9176/2112 165/391 186/391 >.............]  Step: 67ms | Tot: 12s462ms | Loss: 41.644 | Acc: 43.401% (10444/2406 188/391 ......]  Step: 65ms | Tot: 12s918ms | Loss: 41.647 | Acc: 43.309% (10810/2496 195/39 198/391 =>............]  Step: 68ms | Tot: 13s319ms | Loss: 41.645 | Acc: 43.350% (11153/2572 201/391 .........]  Step: 63ms | Tot: 13s383ms | Loss: 41.645 | Acc: 43.340% (11206/2585 202/391 225/391 ==>..........]  Step: 64ms | Tot: 14s908ms | Loss: 41.642 | Acc: 43.425% (12562/2892 226/391 235/391 .....]  Step: 65ms | Tot: 15s536ms | Loss: 41.643 | Acc: 43.465% (13130/3020 236/391 ==========>.........]  Step: 65ms | Tot: 15s601ms | Loss: 41.643 | Acc: 43.450% (13181/3033 237/39 241/39 271/39 272/391 280/391 282/391 =====>......]  Step: 64ms | Tot: 18s638ms | Loss: 41.645 | Acc: 43.395% (15775/3635 284/391 306/391 307/391 .]  Step: 66ms | Tot: 20s484ms | Loss: 41.643 | Acc: 43.408% (17391/4006 313/391 323/39 324/39 325/39 363/391 ==============>.]  Step: 64ms | Tot: 23s943ms | Loss: 41.640 | Acc: 43.401% (20388/4697 367/39 374/39 375/391 389/391 =========>]  Step: 68ms | Tot: 25s425ms | Loss: 41.639 | Acc: 43.456% (21693/4992 390/391 ===================>]  Step: 64ms | Tot: 25s489ms | Loss: 41.639 | Acc: 43.456% (21728/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s577ms | Loss: 2.271 | Acc: 41.880% (4188/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(58.2165, device='cuda:0'), tensor(58.2444, device='cuda:0'), tensor(58.2463, device='cuda:0'), tensor(58.2545, device='cuda:0'), tensor(58.2711, device='cuda:0'), tensor(58.6380, device='cuda:0'), tensor(58.6512, device='cuda:0')]\n",
      "\n",
      "Epoch: 237\n",
      " [========================>]  Step: 52ms | Tot: 23s574ms | Loss: 41.616 | Acc: 43.414% (21707/5000 391/391 39 54/391 .................]  Step: 70ms | Tot: 3s955ms | Loss: 41.645 | Acc: 42.498% (3427/806 63/39 70/391 112/ 115/391 =========>..........]  Step: 69ms | Tot: 14s384ms | Loss: 41.623 | Acc: 43.348% (13039/3008 235/391 240/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s560ms | Loss: 2.267 | Acc: 42.020% (4202/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(58.3199, device='cuda:0'), tensor(58.2864, device='cuda:0'), tensor(58.3008, device='cuda:0'), tensor(58.3079, device='cuda:0'), tensor(58.2898, device='cuda:0'), tensor(58.4041, device='cuda:0'), tensor(58.4193, device='cuda:0')]\n",
      "\n",
      "Epoch: 238\n",
      " [========================>]  Step: 60ms | Tot: 23s663ms | Loss: 41.588 | Acc: 43.316% (21658/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s562ms | Loss: 2.266 | Acc: 41.940% (4194/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(58.1475, device='cuda:0'), tensor(58.0777, device='cuda:0'), tensor(58.0812, device='cuda:0'), tensor(58.0460, device='cuda:0'), tensor(58.0791, device='cuda:0'), tensor(58.1792, device='cuda:0'), tensor(58.1946, device='cuda:0')]\n",
      "\n",
      "Epoch: 239\n",
      " [========================>]  Step: 61ms | Tot: 21s456ms | Loss: 41.548 | Acc: 43.660% (21830/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s593ms | Loss: 2.264 | Acc: 42.240% (4224/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(58.0936, device='cuda:0'), tensor(58.1473, device='cuda:0'), tensor(58.1116, device='cuda:0'), tensor(58.1606, device='cuda:0'), tensor(58.1331, device='cuda:0'), tensor(57.9519, device='cuda:0'), tensor(57.9700, device='cuda:0')]\n",
      "\n",
      "Epoch: 240\n",
      " [========================>]  Step: 61ms | Tot: 24s950ms | Loss: 41.526 | Acc: 43.496% (21748/5000 391/391 91  47/39 49/391 51/391 ......]  Step: 70ms | Tot: 3s462ms | Loss: 41.558 | Acc: 42.955% (3024/704 55/39 65/39 68/391 >....................]  Step: 71ms | Tot: 4s786ms | Loss: 41.529 | Acc: 43.875% (4212/960 75/39 76/391 .......]  Step: 59ms | Tot: 5s418ms | Loss: 41.531 | Acc: 43.731% (4702/1075 84/391 97/391 111/391 .......]  Step: 74ms | Tot: 7s571ms | Loss: 41.520 | Acc: 43.937% (6580/1497 117/391 =====>................]  Step: 62ms | Tot: 8s252ms | Loss: 41.525 | Acc: 43.762% (7114/1625 127/39 129/39 134/391 ..........]  Step: 67ms | Tot: 8s991ms | Loss: 41.524 | Acc: 43.824% (7741/1766 138/391 ======>................]  Step: 69ms | Tot: 9s60ms | Loss: 41.524 | Acc: 43.784% (7790/1779 139/391 155/39 158/391 =====>..............]  Step: 69ms | Tot: 11s49ms | Loss: 41.524 | Acc: 43.778% (9526/2176 170/39 171/39 173/391 ====>.............]  Step: 67ms | Tot: 12s67ms | Loss: 41.530 | Acc: 43.649% (10392/2380 186/391 207/39 218/39 240/391 242/391 =====>........]  Step: 66ms | Tot: 16s843ms | Loss: 41.526 | Acc: 43.574% (14613/3353 262/391   Step: 62ms | Tot: 16s976ms | Loss: 41.528 | Acc: 43.546% (14715/3379 264/391 ====>.......]  Step: 68ms | Tot: 17s246ms | Loss: 41.527 | Acc: 43.572% (14947/3430 268/391 269/39 280/391 281/391 >.......]  Step: 68ms | Tot: 18s115ms | Loss: 41.525 | Acc: 43.667% (15762/3609 282/391 ...]  Step: 68ms | Tot: 18s184ms | Loss: 41.525 | Acc: 43.656% (15814/3622 283/39 288/39 290/39 294/391 311/391 ====================>....]  Step: 59ms | Tot: 20s973ms | Loss: 41.527 | Acc: 43.554% (18230/4185 327/39 328/391   Step: 67ms | Tot: 21s953ms | Loss: 41.528 | Acc: 43.458% (19080/4390 343/391 ===============>..]  Step: 69ms | Tot: 22s153ms | Loss: 41.528 | Acc: 43.454% (19245/44 346/391 ===================>..]  Step: 70ms | Tot: 22s356ms | Loss: 41.527 | Acc: 43.468% (19418/4467 349/391 350/391 ====>]  Step: 65ms | Tot: 24s163ms | Loss: 41.528 | Acc: 43.453% (21080/4851 379/391 ===============>]  Step: 64ms | Tot: 24s364ms | Loss: 41.527 | Acc: 43.472% (21256/4889 382/391 =========>]  Step: 69ms | Tot: 24s433ms | Loss: 41.527 | Acc: 43.483% (21317/4902 383/391 ===============>]  Step: 68ms | Tot: 24s501ms | Loss: 41.527 | Acc: 43.469% (21366/4915 384/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s651ms | Loss: 2.265 | Acc: 42.170% (4217/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(57.9414, device='cuda:0'), tensor(57.8871, device='cuda:0'), tensor(57.8915, device='cuda:0'), tensor(57.9172, device='cuda:0'), tensor(57.9306, device='cuda:0'), tensor(57.7236, device='cuda:0'), tensor(57.7404, device='cuda:0')]\n",
      "\n",
      "Epoch: 241\n",
      " [========================>]  Step: 65ms | Tot: 24s711ms | Loss: 41.496 | Acc: 44.032% (22016/5000 391/391 .]  Step: 69ms | Tot: 709ms | Loss: 41.590 | Acc: 41.602% (639/153 12/391 ....................]  Step: 67ms | Tot: 777ms | Loss: 41.575 | Acc: 41.707% (694/166 13/39 14/39 18/39 20/391 22/391 ..]  Step: 62ms | Tot: 1s829ms | Loss: 41.539 | Acc: 43.211% (1604/371 29/391 33/39 50/39 52/391 ..................]  Step: 68ms | Tot: 3s370ms | Loss: 41.541 | Acc: 42.983% (2916/6 53/391 54/391 .....]  Step: 69ms | Tot: 3s877ms | Loss: 41.528 | Acc: 43.276% (3379/780 61/39 72/391 83/39 84/39 92/39 94/39 104/39 128/39 137/391 138/391 ......]  Step: 68ms | Tot: 10s865ms | Loss: 41.503 | Acc: 44.072% (9703/2201 172/39 178/39 224/391 ====>.....]  Step: 67ms | Tot: 18s977ms | Loss: 41.498 | Acc: 44.352% (17031/3840 300/391 364/391 =>.]  Step: 68ms | Tot: 23s164ms | Loss: 41.497 | Acc: 44.068% (20645/4684 366/391 374/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s557ms | Loss: 2.261 | Acc: 42.080% (4208/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(57.3106, device='cuda:0'), tensor(57.3488, device='cuda:0'), tensor(57.4033, device='cuda:0'), tensor(57.3859, device='cuda:0'), tensor(57.3938, device='cuda:0'), tensor(57.5010, device='cuda:0'), tensor(57.5181, device='cuda:0')]\n",
      "\n",
      "Epoch: 242\n",
      " [========================>]  Step: 51ms | Tot: 21s172ms | Loss: 41.461 | Acc: 43.594% (21797/5000 390/391 Step: 46ms | Tot: 2s624ms | Loss: 41.499 | Acc: 42.620% (2564/601 47/39 49/391 51/39 61/39 63/391 ]  Step: 46ms | Tot: 3s532ms | Loss: 41.488 | Acc: 42.728% (3555/832 65/391 ..]  Step: 65ms | Tot: 8s586ms | Loss: 41.466 | Acc: 43.219% (8464/1958 153/391 160/391 162/39 166/39 170/39 171/39 174/391 ...]  Step: 64ms | Tot: 10s91ms | Loss: 41.461 | Acc: 43.355% (9767/2252 176/391 .....]  Step: 68ms | Tot: 10s159ms | Loss: 41.460 | Acc: 43.401% (9833/2265 177/391 ........]  Step: 68ms | Tot: 10s228ms | Loss: 41.460 | Acc: 43.430% (9895/2278 178/391   Step: 62ms | Tot: 10s291ms | Loss: 41.460 | Acc: 43.423% (9949/2291 179/391 ======>...........]  Step: 65ms | Tot: 12s532ms | Loss: 41.461 | Acc: 43.557% (11931/2739 214/391 233/39 237/391 ===============>.........]  Step: 50ms | Tot: 14s272ms | Loss: 41.462 | Acc: 43.446% (13736/3161 247/39 248/391 ===>........]  Step: 48ms | Tot: 14s670ms | Loss: 41.459 | Acc: 43.483% (14193/3264 255/391 ===============>.......]  Step: 49ms | Tot: 15s443ms | Loss: 41.461 | Acc: 43.530% (15044/3456 270/39 271/391 =======>.......]  Step: 45ms | Tot: 15s700ms | Loss: 41.460 | Acc: 43.619% (15354/3520 275/39 351/39 364/391 372/391 ================>.]  Step: 43ms | Tot: 20s449ms | Loss: 41.463 | Acc: 43.613% (20990/48 376/39 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s547ms | Loss: 2.265 | Acc: 42.110% (4211/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(57.4760, device='cuda:0'), tensor(57.4444, device='cuda:0'), tensor(57.1440, device='cuda:0'), tensor(57.4741, device='cuda:0'), tensor(57.4608, device='cuda:0'), tensor(57.2724, device='cuda:0'), tensor(57.2905, device='cuda:0')]\n",
      "\n",
      "Epoch: 243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 63ms | Tot: 25s273ms | Loss: 41.432 | Acc: 44.108% (22054/5000 391/391 1 ..]  Step: 67ms | Tot: 2s943ms | Loss: 41.461 | Acc: 43.064% (2701/627 49/39 81/391 .................]  Step: 75ms | Tot: 5s123ms | Loss: 41.436 | Acc: 43.769% (4650/1062 83/391 93/39 96/391 114/391 136/391 ========>................]  Step: 64ms | Tot: 8s728ms | Loss: 41.430 | Acc: 44.175% (7803/1766 138/391 ]  Step: 70ms | Tot: 9s192ms | Loss: 41.435 | Acc: 44.068% (8179/1856 145/391 ..............]  Step: 69ms | Tot: 9s456ms | Loss: 41.434 | Acc: 44.107% (8412/1907 149/391 .........]  Step: 70ms | Tot: 9s587ms | Loss: 41.434 | Acc: 44.133% (8530/1932 151/391 =>...............]  Step: 70ms | Tot: 9s717ms | Loss: 41.435 | Acc: 44.118% (8640/1958 153/391 ==========>..............]  Step: 70ms | Tot: 10s113ms | Loss: 41.434 | Acc: 44.133% (8982/2035 159/391 .......]  Step: 68ms | Tot: 10s243ms | Loss: 41.435 | Acc: 44.114% (9091/2060 161/39 169/39 173/391 ...]  Step: 73ms | Tot: 12s37ms | Loss: 41.440 | Acc: 44.027% (10651/2419 189/391 .]  Step: 70ms | Tot: 13s594ms | Loss: 41.437 | Acc: 43.966% (11987/2726 213/391 .....]  Step: 70ms | Tot: 13s988ms | Loss: 41.438 | Acc: 43.975% (12327/2803 219/391 ====>..........]  Step: 63ms | Tot: 14s189ms | Loss: 41.436 | Acc: 43.989% (12500/2841 222/391 227/39 231/391 .]  Step: 70ms | Tot: 15s38ms | Loss: 41.437 | Acc: 43.993% (13233/3008 235/391 237/391 239/39 242/391 245/39 261/39 263/391 ===========>......]  Step: 71ms | Tot: 18s208ms | Loss: 41.436 | Acc: 44.214% (16016/3622 283/39 293/391 =========>.....]  Step: 69ms | Tot: 19s258ms | Loss: 41.436 | Acc: 44.299% (16954/3827 299/391 >.....]  Step: 68ms | Tot: 19s387ms | Loss: 41.436 | Acc: 44.311% (17072/3852 301/391 ==>....]  Step: 69ms | Tot: 20s297ms | Loss: 41.435 | Acc: 44.231% (17834/4032 315/391 ================>....]  Step: 69ms | Tot: 20s427ms | Loss: 41.436 | Acc: 44.218% (17942/4057 317/39 323/391 ]  Step: 67ms | Tot: 21s71ms | Loss: 41.434 | Acc: 44.206% (18503/4185 327/391 329/391 ====>...]  Step: 71ms | Tot: 22s123ms | Loss: 41.433 | Acc: 44.192% (19402/4390 343/391 =============>..]  Step: 70ms | Tot: 22s918ms | Loss: 41.433 | Acc: 44.181% (20076/4544 355/39 363/391 ==============>.]  Step: 68ms | Tot: 23s574ms | Loss: 41.433 | Acc: 44.167% (20635/4672 365/391 =====================>.]  Step: 70ms | Tot: 23s970ms | Loss: 41.433 | Acc: 44.133% (20958/4748 371/39 377/391 ===================>]  Step: 72ms | Tot: 24s889ms | Loss: 41.433 | Acc: 44.099% (21732/4928 385/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s496ms | Loss: 2.264 | Acc: 42.140% (4214/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(56.9628, device='cuda:0'), tensor(56.9101, device='cuda:0'), tensor(56.9836, device='cuda:0'), tensor(56.9525, device='cuda:0'), tensor(56.9361, device='cuda:0'), tensor(57.0540, device='cuda:0'), tensor(57.0679, device='cuda:0')]\n",
      "\n",
      "Epoch: 244\n",
      " [========================>]  Step: 58ms | Tot: 24s25ms | Loss: 41.400 | Acc: 43.954% (21977/5000 391/391    Step: 62ms | Tot: 903ms | Loss: 41.425 | Acc: 44.219% (849/192 15/39 19/39 24/39 45/391 ..............]  Step: 60ms | Tot: 2s941ms | Loss: 41.433 | Acc: 43.334% (2607/601 47/391 .]  Step: 68ms | Tot: 3s9ms | Loss: 41.432 | Acc: 43.457% (2670/614 48/391 .........]  Step: 67ms | Tot: 5s258ms | Loss: 41.410 | Acc: 43.852% (4715/1075 84/39 85/39 122/391 =====>................]  Step: 69ms | Tot: 8s102ms | Loss: 41.408 | Acc: 44.071% (7277/1651 129/39 130/391 142/39 164/391 ..............]  Step: 61ms | Tot: 10s447ms | Loss: 41.399 | Acc: 44.399% (9434/2124 166/39 176/391 .....]  Step: 67ms | Tot: 13s182ms | Loss: 41.409 | Acc: 44.040% (11838/2688 210/39 212/391  293/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s569ms | Loss: 2.264 | Acc: 42.290% (4229/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(57.0320, device='cuda:0'), tensor(57.0057, device='cuda:0'), tensor(57.0084, device='cuda:0'), tensor(56.9910, device='cuda:0'), tensor(56.9835, device='cuda:0'), tensor(56.8317, device='cuda:0'), tensor(56.8482, device='cuda:0')]\n",
      "\n",
      "Epoch: 245\n",
      " [========================>]  Step: 66ms | Tot: 24s917ms | Loss: 41.369 | Acc: 44.020% (22010/5000 391/391 ........]  Step: 70ms | Tot: 8s763ms | Loss: 41.377 | Acc: 43.882% (7976/1817 142/39 144/391 =>...............]  Step: 70ms | Tot: 9s610ms | Loss: 41.379 | Acc: 43.820% (8750/1996 156/391 ........]  Step: 70ms | Tot: 10s760ms | Loss: 41.374 | Acc: 43.862% (9769/2227 174/391 ==>.............]  Step: 69ms | Tot: 11s153ms | Loss: 41.373 | Acc: 43.967% (10130/2304 180/391  190/391 >............]  Step: 69ms | Tot: 12s456ms | Loss: 41.378 | Acc: 43.816% (11217/2560 200/391 ..........]  Step: 70ms | Tot: 12s585ms | Loss: 41.377 | Acc: 43.854% (11339/2585 202/391 ......]  Step: 69ms | Tot: 13s815ms | Loss: 41.371 | Acc: 44.032% (12512/2841 222/39 224/39 228/391 ============>..........]  Step: 69ms | Tot: 14s462ms | Loss: 41.371 | Acc: 43.992% (13064/2969 232/391   Step: 68ms | Tot: 14s724ms | Loss: 41.371 | Acc: 43.949% (13276/3020 236/391 238/391 250/391 ============>......]  Step: 70ms | Tot: 18s63ms | Loss: 41.372 | Acc: 44.024% (16229/3686 288/391 ======>......]  Step: 70ms | Tot: 18s325ms | Loss: 41.372 | Acc: 44.034% (16458/3737 292/391 295/391 305/391 ======>.....]  Step: 75ms | Tot: 19s396ms | Loss: 41.375 | Acc: 43.935% (17321/3942 308/39 309/391 =====>.....]  Step: 70ms | Tot: 19s660ms | Loss: 41.373 | Acc: 43.953% (17553/3993 312/391 ..]  Step: 69ms | Tot: 19s789ms | Loss: 41.373 | Acc: 43.942% (17661/4019 314/39 319/391 ==================>....]  Step: 61ms | Tot: 20s396ms | Loss: 41.373 | Acc: 43.956% (18173/4134 323/391 341/391 347/39 350/391 ]  Step: 62ms | Tot: 22s668ms | Loss: 41.371 | Acc: 43.956% (20086/4569 357/391 =======================>.]  Step: 65ms | Tot: 22s940ms | Loss: 41.372 | Acc: 43.932% (20300/4620 361/391 363/39 367/391 371/39 375/391 ==================>]  Step: 71ms | Tot: 24s80ms | Loss: 41.370 | Acc: 43.986% (21282/48 378/391 ==================>]  Step: 70ms | Tot: 24s605ms | Loss: 41.371 | Acc: 43.973% (21726/4940 386/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s619ms | Loss: 2.262 | Acc: 42.320% (4232/1000 79/79 /79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(56.5807, device='cuda:0'), tensor(56.4806, device='cuda:0'), tensor(56.4789, device='cuda:0'), tensor(56.5544, device='cuda:0'), tensor(56.4983, device='cuda:0'), tensor(56.6105, device='cuda:0'), tensor(56.6265, device='cuda:0')]\n",
      "\n",
      "Epoch: 246\n",
      " [========================>]  Step: 58ms | Tot: 20s282ms | Loss: 41.333 | Acc: 44.174% (22087/5000 391/391  18/391 ................]  Step: 52ms | Tot: 2s104ms | Loss: 41.335 | Acc: 43.571% (1952/448 35/391 ............]  Step: 48ms | Tot: 3s276ms | Loss: 41.323 | Acc: 44.545% (3250/729 57/391 58/39 59/39 62/391 ===>.....................]  Step: 51ms | Tot: 3s577ms | Loss: 41.322 | Acc: 44.296% (3572/8 63/391 ................]  Step: 49ms | Tot: 4s621ms | Loss: 41.319 | Acc: 44.343% (4711/1062 83/391 84/391 .......]  Step: 51ms | Tot: 4s723ms | Loss: 41.323 | Acc: 44.256% (4815/1088 85/391 ===>...................]  Step: 48ms | Tot: 4s874ms | Loss: 41.323 | Acc: 44.256% (4985/1126 88/39 89/391 ............]  Step: 52ms | Tot: 4s975ms | Loss: 41.324 | Acc: 44.227% (5095/1152 90/391 .............]  Step: 50ms | Tot: 5s124ms | Loss: 41.323 | Acc: 44.212% (5263/1190 93/391 ..............]  Step: 51ms | Tot: 5s176ms | Loss: 41.323 | Acc: 44.157% (5313/1203 94/391 ..............]  Step: 50ms | Tot: 5s227ms | Loss: 41.323 | Acc: 44.128% (5366/1216 95/391 ==>..................]  Step: 50ms | Tot: 5s428ms | Loss: 41.328 | Acc: 43.932% (5567/1267 99/39 106/391 ................]  Step: 50ms | Tot: 5s841ms | Loss: 41.326 | Acc: 44.064% (6035/1369 107/391 ..............]  Step: 50ms | Tot: 5s993ms | Loss: 41.330 | Acc: 44.041% (6201/1408 110/391 =>.................]  Step: 46ms | Tot: 6s295ms | Loss: 41.331 | Acc: 44.046% (6540/1484 116/391 117/391 118/391 ..]  Step: 52ms | Tot: 6s541ms | Loss: 41.330 | Acc: 44.131% (6835/1548 121/391 144/39 145/39 159/39 163/39 164/39 178/391   Step: 51ms | Tot: 9s917ms | Loss: 41.333 | Acc: 44.132% (10620/2406 188/39 192/391 ============>............]  Step: 52ms | Tot: 10s270ms | Loss: 41.337 | Acc: 44.050% (10995/2496 195/391 ============>............]  Step: 50ms | Tot: 10s321ms | Loss: 41.337 | Acc: 44.037% (11048/2508 196/391 .......]  Step: 48ms | Tot: 10s468ms | Loss: 41.335 | Acc: 44.084% (11229/25 199/391 ============>............]  Step: 52ms | Tot: 10s521ms | Loss: 41.335 | Acc: 44.102% (11290/2560 200/391 ..........]  Step: 51ms | Tot: 10s573ms | Loss: 41.334 | Acc: 44.108% (11348/2572 201/39 205/391 217/391 224/39 228/391 ==============>..........]  Step: 49ms | Tot: 11s943ms | Loss: 41.334 | Acc: 44.170% (12947/2931 229/391 ======>..........]  Step: 53ms | Tot: 11s996ms | Loss: 41.334 | Acc: 44.141% (12995/2944 230/391 ]  Step: 51ms | Tot: 12s247ms | Loss: 41.332 | Acc: 44.182% (13290/3008 235/39 242/39 243/391 ......]  Step: 50ms | Tot: 12s801ms | Loss: 41.336 | Acc: 44.045% (13869/3148 246/391 =====>.........]  Step: 50ms | Tot: 12s851ms | Loss: 41.336 | Acc: 44.050% (13927/3161 247/391 ===============>.........]  Step: 49ms | Tot: 13s3ms | Loss: 41.335 | Acc: 44.075% (14104/3200 250/391 =======>.........]  Step: 49ms | Tot: 13s52ms | Loss: 41.335 | Acc: 44.074% (14160/3212 251/391 ......]  Step: 50ms | Tot: 13s103ms | Loss: 41.334 | Acc: 44.066% (14214/3225 252/391 ===>........]  Step: 51ms | Tot: 13s154ms | Loss: 41.334 | Acc: 44.074% (14273/3238 253/3 257/391 ......]  Step: 52ms | Tot: 13s406ms | Loss: 41.335 | Acc: 44.089% (14560/3302 258/39 259/391 ..]  Step: 50ms | Tot: 13s969ms | Loss: 41.336 | Acc: 44.096% (15183/3443 269/39 270/391 276/391 =================>.......]  Step: 52ms | Tot: 14s526ms | Loss: 41.335 | Acc: 44.138% (15819/3584 280/39 287/39 288/39 308/391 =======>.....]  Step: 51ms | Tot: 16s66ms | Loss: 41.336 | Acc: 44.196% (17537/3968 310/39 321/391 ==============>....]  Step: 48ms | Tot: 17s13ms | Loss: 41.335 | Acc: 44.231% (18570/4198 328/391 ..]  Step: 54ms | Tot: 17s67ms | Loss: 41.335 | Acc: 44.237% (18629/4211 329/391 =====================>...]  Step: 47ms | Tot: 17s802ms | Loss: 41.336 | Acc: 44.196% (19404/4390 343/391 ===============>...]  Step: 47ms | Tot: 17s849ms | Loss: 41.337 | Acc: 44.168% (19448/4403 344/391 345/391 346/391 ======================>..]  Step: 52ms | Tot: 18s682ms | Loss: 41.335 | Acc: 44.175% (20356/4608 360/391 ==================>.]  Step: 53ms | Tot: 18s831ms | Loss: 41.336 | Acc: 44.142% (20510/4646 363/391 ===============>.]  Step: 46ms | Tot: 19s32ms | Loss: 41.335 | Acc: 44.159% (20744/4697 367/391 ======================>]  Step: 49ms | Tot: 19s594ms | Loss: 41.334 | Acc: 44.149% (21361/4838 378/391 380/391 ===========>]  Step: 49ms | Tot: 19s957ms | Loss: 41.335 | Acc: 44.150% (21757/4928 385/391 387/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s539ms | Loss: 2.263 | Acc: 42.170% (4217/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(56.0377, device='cuda:0'), tensor(56.0376, device='cuda:0'), tensor(56.0441, device='cuda:0'), tensor(56.0187, device='cuda:0'), tensor(56.0502, device='cuda:0'), tensor(56.3879, device='cuda:0'), tensor(56.4061, device='cuda:0')]\n",
      "\n",
      "Epoch: 247\n",
      " [========================>]  Step: 59ms | Tot: 24s340ms | Loss: 41.313 | Acc: 43.864% (21932/5000 391/391 91 .........]  Step: 68ms | Tot: 6s440ms | Loss: 41.333 | Acc: 43.363% (5717/1318 103/391 ...........]  Step: 69ms | Tot: 6s571ms | Loss: 41.333 | Acc: 43.393% (5832/1344 105/391 ......]  Step: 65ms | Tot: 6s702ms | Loss: 41.331 | Acc: 43.407% (5945/1369 107/391  115/39 154/391 168/39 171/39 174/39 176/391 177/391 ====>.............]  Step: 65ms | Tot: 11s190ms | Loss: 41.324 | Acc: 43.781% (9975/2278 178/39 180/391 ==========>.]  Step: 67ms | Tot: 22s794ms | Loss: 41.317 | Acc: 43.761% (20501/4684 366/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s593ms | Loss: 2.262 | Acc: 42.170% (4217/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(55.8061, device='cuda:0'), tensor(55.8167, device='cuda:0'), tensor(55.7985, device='cuda:0'), tensor(55.8140, device='cuda:0'), tensor(55.8476, device='cuda:0'), tensor(56.1721, device='cuda:0'), tensor(56.1893, device='cuda:0')]\n",
      "\n",
      "Epoch: 248\n",
      " [========================>]  Step: 55ms | Tot: 24s217ms | Loss: 41.276 | Acc: 44.088% (22044/5000 391/391 ..........]  Step: 55ms | Tot: 554ms | Loss: 41.340 | Acc: 43.099% (662/153 12/391 21/39 57/391 59/391 113/39 122/391 ...............]  Step: 69ms | Tot: 7s213ms | Loss: 41.284 | Acc: 43.737% (6886/1574 123/39 125/391 .......]  Step: 64ms | Tot: 7s548ms | Loss: 41.283 | Acc: 43.762% (7170/1638 128/39 129/39 131/391 210/391 211/39 214/391 ..]  Step: 69ms | Tot: 13s527ms | Loss: 41.278 | Acc: 44.105% (12533/2841 222/391 225/391 228/391 230/391 =====>.........]  Step: 68ms | Tot: 14s455ms | Loss: 41.280 | Acc: 44.031% (13301/3020 236/391 237/391 238/391 ============>.........]  Step: 65ms | Tot: 14s718ms | Loss: 41.280 | Acc: 43.997% (13516/3072 240/391 =========>.........]  Step: 67ms | Tot: 14s919ms | Loss: 41.282 | Acc: 43.969% (13676/31 243/39 246/391 ======>.........]  Step: 70ms | Tot: 15s322ms | Loss: 41.281 | Acc: 44.039% (14036/3187 249/39 254/391 259/391 ]  Step: 66ms | Tot: 16s192ms | Loss: 41.280 | Acc: 44.087% (14785/3353 262/391 ....]  Step: 68ms | Tot: 16s261ms | Loss: 41.281 | Acc: 44.056% (14831/3366 263/391 .....]  Step: 65ms | Tot: 16s393ms | Loss: 41.283 | Acc: 44.030% (14935/3392 265/391   Step: 69ms | Tot: 16s462ms | Loss: 41.282 | Acc: 44.061% (15002/3404 266/391 ==========>.......]  Step: 66ms | Tot: 16s594ms | Loss: 41.282 | Acc: 44.076% (15120/3430 268/391 269/39 270/39 271/39 273/39 281/391 284/391 287/391 288/39 295/39 302/391 316/391 =>.]  Step: 73ms | Tot: 22s866ms | Loss: 41.278 | Acc: 44.091% (20712/4697 367/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s571ms | Loss: 2.262 | Acc: 41.990% (4199/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(55.8456, device='cuda:0'), tensor(55.8610, device='cuda:0'), tensor(55.8498, device='cuda:0'), tensor(55.8145, device='cuda:0'), tensor(55.8625, device='cuda:0'), tensor(55.9508, device='cuda:0'), tensor(55.9705, device='cuda:0')]\n",
      "\n",
      "Epoch: 249\n",
      " [========================>]  Step: 61ms | Tot: 24s326ms | Loss: 41.249 | Acc: 44.216% (22108/5000 391/391 ========>..............]  Step: 69ms | Tot: 10s129ms | Loss: 41.250 | Acc: 44.306% (9244/2086 163/391 ......]  Step: 69ms | Tot: 10s199ms | Loss: 41.249 | Acc: 44.326% (9305/2099 164/39 200/391  388/391 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 44ms | Tot: 3s557ms | Loss: 2.261 | Acc: 42.180% (4218/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(55.8840, device='cuda:0'), tensor(55.9200, device='cuda:0'), tensor(55.7622, device='cuda:0'), tensor(55.9270, device='cuda:0'), tensor(55.8737, device='cuda:0'), tensor(55.7348, device='cuda:0'), tensor(55.7537, device='cuda:0')]\n",
      "\n",
      "Epoch: 250\n",
      " [========================>]  Step: 68ms | Tot: 24s183ms | Loss: 41.218 | Acc: 44.040% (22020/5000 390/391 ep: 69ms | Tot: 453ms | Loss: 41.318 | Acc: 41.699% (427/102 8/391 ...................]  Step: 63ms | Tot: 516ms | Loss: 41.311 | Acc: 42.101% (485/115 9/39 170/391 =====>.............]  Step: 63ms | Tot: 10s753ms | Loss: 41.217 | Acc: 44.048% (10205/2316 181/39 186/39 196/391 ...........]  Step: 69ms | Tot: 11s994ms | Loss: 41.219 | Acc: 44.008% (11266/2560 200/391 ========>..........]  Step: 71ms | Tot: 13s376ms | Loss: 41.214 | Acc: 44.211% (12563/2841 222/391 ..]  Step: 69ms | Tot: 13s638ms | Loss: 41.217 | Acc: 44.175% (12779/2892 226/391 ....]  Step: 71ms | Tot: 13s769ms | Loss: 41.219 | Acc: 44.103% (12871/2918 228/391 232/39 234/39 238/391 ======>.........]  Step: 70ms | Tot: 14s939ms | Loss: 41.219 | Acc: 44.071% (13877/3148 246/391 262/391 ================>........]  Step: 71ms | Tot: 16s90ms | Loss: 41.218 | Acc: 44.135% (14914/3379 264/391 ====>........]  Step: 69ms | Tot: 16s218ms | Loss: 41.218 | Acc: 44.185% (15044/3404 266/391 ========>......]  Step: 64ms | Tot: 17s431ms | Loss: 41.219 | Acc: 44.106% (16090/3648 285/39 302/39 311/391 315/39 322/39 333/391 ================>...]  Step: 69ms | Tot: 20s762ms | Loss: 41.218 | Acc: 44.084% (19016/4313 337/39 338/391 ========>...]  Step: 62ms | Tot: 20s892ms | Loss: 41.218 | Acc: 44.075% (19125/4339 339/39 345/391 ==============>.]  Step: 68ms | Tot: 22s921ms | Loss: 41.220 | Acc: 44.009% (20899/4748 371/391 ==============>]  Step: 68ms | Tot: 23s796ms | Loss: 41.219 | Acc: 44.020% (21693/4928 385/39 386/39 391/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s738ms | Loss: 2.259 | Acc: 42.380% (4238/1000 79/79 >....]  Step: 55ms | Tot: 3s164ms | Loss: 2.266 | Acc: 42.537% (3648/857 67/7 73/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(55.3955, device='cuda:0'), tensor(55.4078, device='cuda:0'), tensor(55.4104, device='cuda:0'), tensor(55.4239, device='cuda:0'), tensor(55.4226, device='cuda:0'), tensor(55.5161, device='cuda:0'), tensor(55.5371, device='cuda:0')]\n",
      "\n",
      "Epoch: 251\n",
      " [========================>]  Step: 52ms | Tot: 23s409ms | Loss: 41.190 | Acc: 44.194% (22097/5000 391/391 ................]  Step: 66ms | Tot: 1s90ms | Loss: 41.194 | Acc: 45.356% (1045/2 18/39 21/391 25/39 131/391 134/391 .....]  Step: 68ms | Tot: 8s371ms | Loss: 41.184 | Acc: 44.329% (7660/1728 135/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s551ms | Loss: 2.262 | Acc: 42.130% (4213/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(55.4119, device='cuda:0'), tensor(55.4572, device='cuda:0'), tensor(55.4720, device='cuda:0'), tensor(55.4558, device='cuda:0'), tensor(55.4296, device='cuda:0'), tensor(55.3023, device='cuda:0'), tensor(55.3192, device='cuda:0')]\n",
      "\n",
      "Epoch: 252\n",
      " [========================>]  Step: 68ms | Tot: 25s111ms | Loss: 41.157 | Acc: 44.342% (22171/5000 391/391 1 54/391 .........]  Step: 65ms | Tot: 4s869ms | Loss: 41.169 | Acc: 43.808% (4542/1036 81/391  88/391 89/391 >...................]  Step: 65ms | Tot: 5s454ms | Loss: 41.163 | Acc: 44.089% (5079/1152 90/391 93/391 99/391 .................]  Step: 69ms | Tot: 6s241ms | Loss: 41.167 | Acc: 44.026% (5748/1305 102/391 105/39 118/391 .......]  Step: 66ms | Tot: 7s491ms | Loss: 41.167 | Acc: 44.144% (6837/15 121/39 124/391 .....]  Step: 68ms | Tot: 8s4ms | Loss: 41.169 | Acc: 44.089% (7280/1651 129/39 133/391 143/391 ===>...............]  Step: 61ms | Tot: 9s419ms | Loss: 41.166 | Acc: 44.281% (8502/1920 150/391 162/391 .....]  Step: 62ms | Tot: 10s358ms | Loss: 41.164 | Acc: 44.412% (9323/2099 164/391 =>..............]  Step: 74ms | Tot: 10s557ms | Loss: 41.164 | Acc: 44.400% (9491/2137 167/391 .....]  Step: 69ms | Tot: 11s72ms | Loss: 41.162 | Acc: 44.446% (9956/2240 175/39 181/39 184/391 187/391 ==========>............]  Step: 71ms | Tot: 12s255ms | Loss: 41.168 | Acc: 44.195% (10918/2470 193/391 ============>............]  Step: 68ms | Tot: 12s515ms | Loss: 41.171 | Acc: 44.079% (11115/2521 197/391 ==>............]  Step: 69ms | Tot: 12s910ms | Loss: 41.169 | Acc: 44.135% (11468/2598 203/391 =============>...........]  Step: 68ms | Tot: 13s40ms | Loss: 41.169 | Acc: 44.108% (11574/2624 205/391 ==>...........]  Step: 75ms | Tot: 13s171ms | Loss: 41.169 | Acc: 44.101% (11685/2649 207/39 215/391 ....]  Step: 74ms | Tot: 13s826ms | Loss: 41.166 | Acc: 44.200% (12277/2777 217/391 ........]  Step: 68ms | Tot: 14s483ms | Loss: 41.166 | Acc: 44.194% (12841/2905 227/391 ..]  Step: 70ms | Tot: 15s10ms | Loss: 41.165 | Acc: 44.245% (13309/3008 235/391 239/39 245/391 249/391 ....]  Step: 74ms | Tot: 16s292ms | Loss: 41.162 | Acc: 44.329% (14469/3264 255/391 ..]  Step: 75ms | Tot: 16s682ms | Loss: 41.163 | Acc: 44.286% (14795/3340 261/391 264/39 265/39 273/39 283/391 ================>......]  Step: 70ms | Tot: 18s482ms | Loss: 41.162 | Acc: 44.337% (16401/3699 289/391 ==>......]  Step: 68ms | Tot: 18s745ms | Loss: 41.162 | Acc: 44.347% (16632/3750 293/39 295/391   Step: 69ms | Tot: 19s269ms | Loss: 41.160 | Acc: 44.378% (17098/3852 301/39 309/39 315/391 ]  Step: 68ms | Tot: 20s691ms | Loss: 41.159 | Acc: 44.304% (18317/4134 323/391 327/391 ======>...]  Step: 69ms | Tot: 21s206ms | Loss: 41.158 | Acc: 44.314% (18775/4236 331/39 335/391 =====================>...]  Step: 71ms | Tot: 21s601ms | Loss: 41.160 | Acc: 44.239% (19083/4313 337/39 347/391 ==================>..]  Step: 70ms | Tot: 22s357ms | Loss: 41.160 | Acc: 44.220% (19754/4467 349/391 =======>..]  Step: 70ms | Tot: 22s487ms | Loss: 41.160 | Acc: 44.240% (19876/4492 351/391 353/39 369/391 ===========>.]  Step: 71ms | Tot: 23s790ms | Loss: 41.159 | Acc: 44.270% (21023/4748 371/39 375/391 =============>]  Step: 68ms | Tot: 24s314ms | Loss: 41.158 | Acc: 44.307% (21494/4851 379/39 381/391 ===========>]  Step: 69ms | Tot: 24s575ms | Loss: 41.159 | Acc: 44.305% (21720/4902 383/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s554ms | Loss: 2.258 | Acc: 42.300% (4230/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(54.9985, device='cuda:0'), tensor(54.9735, device='cuda:0'), tensor(54.9978, device='cuda:0'), tensor(54.9685, device='cuda:0'), tensor(55.0098, device='cuda:0'), tensor(55.0863, device='cuda:0'), tensor(55.1036, device='cuda:0')]\n",
      "\n",
      "Epoch: 253\n",
      " [========================>]  Step: 62ms | Tot: 23s489ms | Loss: 41.125 | Acc: 44.326% (22163/5000 391/391 1 ====>....................]  Step: 62ms | Tot: 4s640ms | Loss: 41.125 | Acc: 44.373% (4203/947 74/391 84/391  86/391 ]  Step: 62ms | Tot: 5s487ms | Loss: 41.120 | Acc: 44.468% (4952/1113 87/391 105/39 109/391 =======>.................]  Step: 62ms | Tot: 7s424ms | Loss: 41.120 | Acc: 44.444% (6599/1484 116/39 128/39 130/391 ....]  Step: 67ms | Tot: 9s219ms | Loss: 41.119 | Acc: 44.630% (8169/1830 143/391 147/391 ==>...............]  Step: 71ms | Tot: 9s968ms | Loss: 41.121 | Acc: 44.668% (8805/1971 154/391 ===>..............]  Step: 68ms | Tot: 10s369ms | Loss: 41.120 | Acc: 44.727% (9160/2048 160/391 =>.............]  Step: 62ms | Tot: 11s540ms | Loss: 41.123 | Acc: 44.641% (10171/2278 178/391 ....]  Step: 66ms | Tot: 12s187ms | Loss: 41.124 | Acc: 44.577% (10727/2406 188/39 197/391 272/39 273/39 275/39 277/391 ===============>....]  Step: 68ms | Tot: 19s140ms | Loss: 41.127 | Acc: 44.294% (18313/4134 323/391 ==========>..]  Step: 64ms | Tot: 20s653ms | Loss: 41.126 | Acc: 44.345% (19753/4454 348/391 ===============>..]  Step: 69ms | Tot: 20s915ms | Loss: 41.125 | Acc: 44.371% (19992/4505 352/39 353/391 =======>..]  Step: 68ms | Tot: 21s46ms | Loss: 41.127 | Acc: 44.341% (20092/4531 354/ 356/39 359/391 ===============>.]  Step: 65ms | Tot: 21s581ms | Loss: 41.128 | Acc: 44.290% (20522/4633 362/39 364/391 .]  Step: 67ms | Tot: 21s781ms | Loss: 41.127 | Acc: 44.328% (20710/46 365/391 366/391 369/391 374/391 ===========>]  Step: 66ms | Tot: 22s772ms | Loss: 41.126 | Acc: 44.344% (21569/4864 380/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s454ms | Loss: 2.256 | Acc: 42.260% (4226/1000 79/79 9 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(54.5602, device='cuda:0'), tensor(54.5321, device='cuda:0'), tensor(54.5258, device='cuda:0'), tensor(54.5103, device='cuda:0'), tensor(54.5352, device='cuda:0'), tensor(54.8707, device='cuda:0'), tensor(54.8909, device='cuda:0')]\n",
      "\n",
      "Epoch: 254\n",
      " [========================>]  Step: 63ms | Tot: 19s917ms | Loss: 41.093 | Acc: 44.644% (22322/5000 391/391 .................]  Step: 47ms | Tot: 539ms | Loss: 41.100 | Acc: 43.229% (664/153 12/391 .................]  Step: 50ms | Tot: 1s317ms | Loss: 41.111 | Acc: 43.917% (1574/358 28/391 ...................]  Step: 50ms | Tot: 1s519ms | Loss: 41.118 | Acc: 43.823% (1795/409 32/391 ................]  Step: 48ms | Tot: 1s616ms | Loss: 41.113 | Acc: 43.957% (1913/435 34/39 36/391 ..........]  Step: 51ms | Tot: 1s768ms | Loss: 41.116 | Acc: 43.813% (2075/473 37/391 39/39 40/39 60/391 61/391 64/39 68/391 ..................]  Step: 50ms | Tot: 3s658ms | Loss: 41.102 | Acc: 44.333% (4256/960 75/391 .......]  Step: 47ms | Tot: 3s858ms | Loss: 41.102 | Acc: 44.195% (4469/1011 79/391 85/391 ................]  Step: 53ms | Tot: 4s214ms | Loss: 41.100 | Acc: 44.259% (4872/1100 86/391 ...................]  Step: 49ms | Tot: 4s412ms | Loss: 41.098 | Acc: 44.384% (5113/11 90/391 =====>...................]  Step: 52ms | Tot: 4s465ms | Loss: 41.098 | Acc: 44.385% (5170/1164 91/391 93/391 ..]  Step: 49ms | Tot: 4s612ms | Loss: 41.094 | Acc: 44.448% (5348/1203 94/39 95/391 .........]  Step: 47ms | Tot: 4s981ms | Loss: 41.095 | Acc: 44.524% (5756/1292 101/391 .....]  Step: 46ms | Tot: 5s78ms | Loss: 41.097 | Acc: 44.524% (5870/1318 103/39 104/39 112/391 123/391 ======>................]  Step: 52ms | Tot: 6s483ms | Loss: 41.101 | Acc: 44.465% (7399/1664 130/39 138/391 ..............]  Step: 45ms | Tot: 7s338ms | Loss: 41.097 | Acc: 44.510% (8375/1881 147/391 =========>...............]  Step: 47ms | Tot: 7s492ms | Loss: 41.097 | Acc: 44.531% (8550/1920 150/39 176/39 181/391 ============>............]  Step: 54ms | Tot: 9s662ms | Loss: 41.101 | Acc: 44.491% (10934/2457 192/391 ......]  Step: 54ms | Tot: 9s863ms | Loss: 41.102 | Acc: 44.475% (11158/2508 196/391 .........]  Step: 50ms | Tot: 9s913ms | Loss: 41.101 | Acc: 44.484% (11217/2521 197/39 204/39 213/391 214/391 ========>..........]  Step: 61ms | Tot: 11s606ms | Loss: 41.096 | Acc: 44.637% (13141/2944 230/391 =====>..........]  Step: 50ms | Tot: 11s806ms | Loss: 41.094 | Acc: 44.695% (13387/2995 234/391 .....]  Step: 50ms | Tot: 12s57ms | Loss: 41.095 | Acc: 44.734% (13685/3059 239/391 240/391 ===>.........]  Step: 52ms | Tot: 12s161ms | Loss: 41.095 | Acc: 44.729% (13798/3084 241/391 ===============>.........]  Step: 51ms | Tot: 12s310ms | Loss: 41.096 | Acc: 44.663% (13949/3123 244/391 ===============>.........]  Step: 52ms | Tot: 12s362ms | Loss: 41.096 | Acc: 44.700% (14018/31 245/391 ===============>.........]  Step: 50ms | Tot: 12s413ms | Loss: 41.096 | Acc: 44.706% (14077/3148 246/391 =========>.........]  Step: 46ms | Tot: 12s459ms | Loss: 41.096 | Acc: 44.702% (14133/3161 247/391 248/391 ================>........]  Step: 54ms | Tot: 12s898ms | Loss: 41.094 | Acc: 44.781% (14674/3276 256/391 ==============>........]  Step: 52ms | Tot: 13s98ms | Loss: 41.094 | Acc: 44.769% (14899/3328 260/391 ==============>.......]  Step: 46ms | Tot: 13s882ms | Loss: 41.096 | Acc: 44.753% (15753/3520 275/391 290/391 ==================>......]  Step: 51ms | Tot: 14s822ms | Loss: 41.094 | Acc: 44.814% (16807/3750 293/39 307/391 316/391 ====================>....]  Step: 46ms | Tot: 16s171ms | Loss: 41.096 | Acc: 44.688% (18247/4083 319/391 .]  Step: 54ms | Tot: 16s638ms | Loss: 41.095 | Acc: 44.696% (18765/4198 328/391 ==================>...]  Step: 47ms | Tot: 16s998ms | Loss: 41.095 | Acc: 44.690% (19163/4288 335/391 ========>...]  Step: 50ms | Tot: 17s251ms | Loss: 41.097 | Acc: 44.623% (19420/4352 340/39 341/391 ================>...]  Step: 46ms | Tot: 17s401ms | Loss: 41.096 | Acc: 44.634% (19596/4390 343/39 344/391 =>..]  Step: 55ms | Tot: 17s650ms | Loss: 41.095 | Acc: 44.608% (19870/4454 348/39 355/391 ================>..]  Step: 51ms | Tot: 18s110ms | Loss: 41.096 | Acc: 44.606% (20383/4569 357/391 ======================>..]  Step: 45ms | Tot: 18s208ms | Loss: 41.096 | Acc: 44.573% (20482/4595 359/391 360/39 363/39 378/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s439ms | Loss: 2.262 | Acc: 42.330% (4233/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(54.2787, device='cuda:0'), tensor(54.3228, device='cuda:0'), tensor(54.3193, device='cuda:0'), tensor(54.3332, device='cuda:0'), tensor(54.3303, device='cuda:0'), tensor(54.6581, device='cuda:0'), tensor(54.6756, device='cuda:0')]\n",
      "\n",
      "Epoch: 255\n",
      " [========================>]  Step: 58ms | Tot: 24s246ms | Loss: 41.077 | Acc: 44.146% (22073/5000 391/391 .]  Step: 66ms | Tot: 261ms | Loss: 41.220 | Acc: 41.406% (265/64 5/39 12/39 27/391 99/391 ======>..................]  Step: 69ms | Tot: 6s542ms | Loss: 41.079 | Acc: 44.381% (5908/1331 104/391 117/391  254/39 275/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s569ms | Loss: 2.257 | Acc: 42.280% (4228/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(54.5909, device='cuda:0'), tensor(54.5865, device='cuda:0'), tensor(54.6214, device='cuda:0'), tensor(54.5731, device='cuda:0'), tensor(54.5563, device='cuda:0'), tensor(54.4464, device='cuda:0'), tensor(54.4633, device='cuda:0')]\n",
      "\n",
      "Epoch: 256\n",
      " [========================>]  Step: 62ms | Tot: 23s405ms | Loss: 41.035 | Acc: 44.758% (22379/5000 391/391 293/391 ===========>......]  Step: 70ms | Tot: 17s698ms | Loss: 41.036 | Acc: 44.869% (16885/3763 294/391 ======>......]  Step: 67ms | Tot: 17s828ms | Loss: 41.037 | Acc: 44.843% (16990/3788 296/39 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s577ms | Loss: 2.256 | Acc: 42.320% (4232/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(53.8824, device='cuda:0'), tensor(53.9124, device='cuda:0'), tensor(53.9000, device='cuda:0'), tensor(53.9330, device='cuda:0'), tensor(53.9282, device='cuda:0'), tensor(54.2346, device='cuda:0'), tensor(54.2550, device='cuda:0')]\n",
      "\n",
      "Epoch: 257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 55ms | Tot: 22s697ms | Loss: 41.007 | Acc: 44.802% (22401/5000 391/391 ...............]  Step: 67ms | Tot: 4s640ms | Loss: 41.021 | Acc: 44.481% (4384/985 77/39 167/391   Step: 47ms | Tot: 12s30ms | Loss: 41.010 | Acc: 44.825% (11762/2624 205/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s537ms | Loss: 2.258 | Acc: 42.300% (4230/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(54.1130, device='cuda:0'), tensor(54.1477, device='cuda:0'), tensor(54.1323, device='cuda:0'), tensor(54.1786, device='cuda:0'), tensor(54.1372, device='cuda:0'), tensor(54.0222, device='cuda:0'), tensor(54.0428, device='cuda:0')]\n",
      "\n",
      "Epoch: 258\n",
      " [========================>]  Step: 61ms | Tot: 23s923ms | Loss: 40.974 | Acc: 44.844% (22422/5000 391/391 tep: 63ms | Tot: 201ms | Loss: 41.079 | Acc: 44.141% (226/51 4/391 13/391  14/39 60/39 62/39 122/391 123/391 160/39 351/391 ===========>..]  Step: 63ms | Tot: 21s491ms | Loss: 40.976 | Acc: 44.829% (20198/4505 352/391 \n",
      " [========================>]  Step: 61ms | Tot: 3s605ms | Loss: 2.255 | Acc: 42.380% (4238/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(53.7054, device='cuda:0'), tensor(53.7020, device='cuda:0'), tensor(53.6925, device='cuda:0'), tensor(53.7303, device='cuda:0'), tensor(53.7162, device='cuda:0'), tensor(53.8143, device='cuda:0'), tensor(53.8361, device='cuda:0')]\n",
      "\n",
      "Epoch: 259\n",
      " [========================>]  Step: 52ms | Tot: 22s911ms | Loss: 40.950 | Acc: 44.900% (22450/5000 391/391 ....................]  Step: 75ms | Tot: 632ms | Loss: 41.003 | Acc: 44.318% (624/140 11/391 ...............]  Step: 51ms | Tot: 6s702ms | Loss: 40.944 | Acc: 44.996% (6681/1484 116/391 144/391 146/39 152/39 162/39 280/391 283/391 300/391 303/391 307/39 309/391 310/391 ===============>.....]  Step: 62ms | Tot: 18s190ms | Loss: 40.948 | Acc: 45.105% (18071/4006 313/39 321/39 323/391 =================>....]  Step: 61ms | Tot: 19s75ms | Loss: 40.949 | Acc: 45.058% (18802/4172 326/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s564ms | Loss: 2.257 | Acc: 42.240% (4224/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(53.4791, device='cuda:0'), tensor(53.5026, device='cuda:0'), tensor(53.4710, device='cuda:0'), tensor(53.5162, device='cuda:0'), tensor(53.5219, device='cuda:0'), tensor(53.6062, device='cuda:0'), tensor(53.6238, device='cuda:0')]\n",
      "\n",
      "Epoch: 260\n",
      " [========================>]  Step: 57ms | Tot: 22s120ms | Loss: 40.915 | Acc: 44.898% (22449/5000 391/391 ...............]  Step: 63ms | Tot: 780ms | Loss: 40.942 | Acc: 44.231% (736/166 13/391 ..............]  Step: 63ms | Tot: 1s729ms | Loss: 40.924 | Acc: 44.392% (1591/358 28/39 29/391 34/391 35/391 ....................]  Step: 67ms | Tot: 2s443ms | Loss: 40.947 | Acc: 43.670% (2180/499 39/39 42/391 ....]  Step: 69ms | Tot: 2s840ms | Loss: 40.949 | Acc: 43.594% (2511/576 45/391 46/39 47/39 48/391 .]  Step: 66ms | Tot: 3s242ms | Loss: 40.948 | Acc: 43.627% (2848/652 51/39 53/391 =>.....................]  Step: 63ms | Tot: 3s576ms | Loss: 40.942 | Acc: 43.750% (3136/716 56/39 59/391 60/39 71/39 72/39 74/391 ......]  Step: 69ms | Tot: 5s484ms | Loss: 40.923 | Acc: 44.449% (4836/1088 85/391 87/391 .............]  Step: 67ms | Tot: 5s683ms | Loss: 40.920 | Acc: 44.576% (5021/11 88/ 90/39 93/391 ===>..................]  Step: 65ms | Tot: 6s622ms | Loss: 40.924 | Acc: 44.493% (5809/1305 102/391 113/39 123/391 131/ 134/391  149/391 .............]  Step: 66ms | Tot: 9s860ms | Loss: 40.919 | Acc: 44.788% (8714/1945 152/391 .]  Step: 65ms | Tot: 10s567ms | Loss: 40.919 | Acc: 44.939% (9376/2086 163/391 .........]  Step: 69ms | Tot: 11s847ms | Loss: 40.922 | Acc: 44.851% (10506/2342 183/391 254/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s546ms | Loss: 2.250 | Acc: 42.440% (4244/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(53.5427, device='cuda:0'), tensor(53.5168, device='cuda:0'), tensor(53.5017, device='cuda:0'), tensor(53.4861, device='cuda:0'), tensor(53.4600, device='cuda:0'), tensor(53.3961, device='cuda:0'), tensor(53.4145, device='cuda:0')]\n",
      "\n",
      "Epoch: 261\n",
      " [========================>]  Step: 59ms | Tot: 24s873ms | Loss: 40.897 | Acc: 44.724% (22362/5000 391/391 .........]  Step: 67ms | Tot: 704ms | Loss: 40.942 | Acc: 44.531% (684/153 12/391 .....]  Step: 62ms | Tot: 767ms | Loss: 40.929 | Acc: 44.712% (744/166 13/39 18/39 20/39 22/391 ................]  Step: 69ms | Tot: 1s805ms | Loss: 40.933 | Acc: 43.750% (1624/371 29/391 ...............]  Step: 62ms | Tot: 1s868ms | Loss: 40.935 | Acc: 43.672% (1677/384 30/391 .................]  Step: 61ms | Tot: 5s360ms | Loss: 40.913 | Acc: 44.301% (4820/1088 85/391 96/391 =>.................]  Step: 67ms | Tot: 7s730ms | Loss: 40.907 | Acc: 44.550% (6957/1561 122/391 124/391 163/391 ==>...........]  Step: 69ms | Tot: 13s717ms | Loss: 40.909 | Acc: 44.600% (12331/2764 216/391 =======>...........]  Step: 62ms | Tot: 13s779ms | Loss: 40.910 | Acc: 44.603% (12389/2777 217/391 218/391 =>...........]  Step: 69ms | Tot: 13s917ms | Loss: 40.909 | Acc: 44.613% (12506/2803 219/391 ==============>..........]  Step: 63ms | Tot: 13s980ms | Loss: 40.908 | Acc: 44.663% (12577/2816 220/391 245/39 257/39 281/391 ...]  Step: 63ms | Tot: 17s934ms | Loss: 40.902 | Acc: 44.806% (16173/3609 282/39 286/391 289/391 ======>.....]  Step: 67ms | Tot: 19s406ms | Loss: 40.901 | Acc: 44.818% (17497/3904 305/391 344/391 ===============>..]  Step: 65ms | Tot: 22s512ms | Loss: 40.898 | Acc: 44.750% (20220/4518 353/391 376/391 ======>]  Step: 70ms | Tot: 24s79ms | Loss: 40.898 | Acc: 44.746% (21650/4838 378/391 =========>]  Step: 62ms | Tot: 24s209ms | Loss: 40.898 | Acc: 44.757% (21770/4864 380/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s582ms | Loss: 2.256 | Acc: 42.430% (4243/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(52.8250, device='cuda:0'), tensor(52.8798, device='cuda:0'), tensor(52.8721, device='cuda:0'), tensor(52.8829, device='cuda:0'), tensor(52.9002, device='cuda:0'), tensor(53.1868, device='cuda:0'), tensor(53.2095, device='cuda:0')]\n",
      "\n",
      "Epoch: 262\n",
      " [========================>]  Step: 55ms | Tot: 24s668ms | Loss: 40.859 | Acc: 45.024% (22512/5000 391/391 8/39 31/39 32/39 35/391 ............]  Step: 67ms | Tot: 2s230ms | Loss: 40.897 | Acc: 44.510% (2051/460 36/39 86/39 96/39 100/391 ......]  Step: 68ms | Tot: 6s671ms | Loss: 40.869 | Acc: 44.774% (6075/1356 106/391 =>..................]  Step: 68ms | Tot: 6s871ms | Loss: 40.872 | Acc: 44.753% (6244/1395 109/39 110/39 150/391  165/391 .....]  Step: 60ms | Tot: 11s436ms | Loss: 40.868 | Acc: 44.750% (10425/2329 182/391 186/39 188/39 189/391 =====>..........]  Step: 70ms | Tot: 14s102ms | Loss: 40.863 | Acc: 44.877% (12867/2867 224/391 ....]  Step: 70ms | Tot: 14s634ms | Loss: 40.863 | Acc: 44.791% (13301/2969 232/391 .]  Step: 63ms | Tot: 14s698ms | Loss: 40.863 | Acc: 44.796% (13360/2982 233/39 244/391 .]  Step: 63ms | Tot: 15s617ms | Loss: 40.867 | Acc: 44.756% (14150/3161 247/3 250/391 254/39 278/391 ..]  Step: 66ms | Tot: 18s470ms | Loss: 40.863 | Acc: 44.925% (16791/3737 292/391 ========>.....]  Step: 66ms | Tot: 19s96ms | Loss: 40.863 | Acc: 44.958% (17379/3865 302/391 307/391 ..]  Step: 65ms | Tot: 20s296ms | Loss: 40.863 | Acc: 44.952% (18470/4108 321/391 ]  Step: 65ms | Tot: 22s821ms | Loss: 40.862 | Acc: 44.981% (20785/4620 361/39 382/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s595ms | Loss: 2.255 | Acc: 42.480% (4248/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(53.1266, device='cuda:0'), tensor(53.0968, device='cuda:0'), tensor(53.0898, device='cuda:0'), tensor(53.0880, device='cuda:0'), tensor(53.0819, device='cuda:0'), tensor(52.9802, device='cuda:0'), tensor(53.0032, device='cuda:0')]\n",
      "\n",
      "Epoch: 263\n",
      " [========================>]  Step: 61ms | Tot: 25s170ms | Loss: 40.819 | Acc: 45.254% (22627/5000 391/391 ..]  Step: 70ms | Tot: 1s673ms | Loss: 40.840 | Acc: 45.284% (1565/345 27/391 31/391 .........]  Step: 70ms | Tot: 2s67ms | Loss: 40.845 | Acc: 44.957% (1899/422 33/391 .......]  Step: 71ms | Tot: 2s328ms | Loss: 40.844 | Acc: 44.954% (2129/473 37/391 47/391 59/391 61/391 ........]  Step: 67ms | Tot: 4s7ms | Loss: 40.833 | Acc: 44.891% (3620/806 63/39 65/391 71/39 72/39 75/391 .]  Step: 69ms | Tot: 4s851ms | Loss: 40.821 | Acc: 45.056% (4383/972 76/39 79/391 82/39 91/39 93/39 95/391 ........]  Step: 67ms | Tot: 6s218ms | Loss: 40.813 | Acc: 45.578% (5659/1241 97/39 99/391 113/391 133/391 ==>................]  Step: 69ms | Tot: 8s660ms | Loss: 40.813 | Acc: 45.584% (7877/1728 135/391 136/391 137/391 ====>................]  Step: 68ms | Tot: 9s52ms | Loss: 40.813 | Acc: 45.573% (8225/1804 141/391 150/39 163/391 167/391 183/39 192/39 203/39 228/391 =====>..........]  Step: 62ms | Tot: 15s117ms | Loss: 40.818 | Acc: 45.382% (13651/3008 235/391 ......]  Step: 68ms | Tot: 16s368ms | Loss: 40.818 | Acc: 45.420% (14825/3264 255/39 256/391 =========>........]  Step: 67ms | Tot: 16s630ms | Loss: 40.818 | Acc: 45.421% (15058/3315 259/39 260/391 =>.......]  Step: 67ms | Tot: 17s135ms | Loss: 40.820 | Acc: 45.424% (15524/3417 267/391 =======>.......]  Step: 68ms | Tot: 17s267ms | Loss: 40.819 | Acc: 45.434% (15644/3443 269/391 ]  Step: 67ms | Tot: 17s861ms | Loss: 40.818 | Acc: 45.467% (16179/3558 278/391 ==========>.......]  Step: 68ms | Tot: 18s124ms | Loss: 40.818 | Acc: 45.445% (16404/3609 282/391 ===========>......]  Step: 64ms | Tot: 18s529ms | Loss: 40.818 | Acc: 45.478% (16765/3686 288/391 289/39 290/39 292/39 293/391 295/391 ]  Step: 69ms | Tot: 19s63ms | Loss: 40.820 | Acc: 45.413% (17206/3788 296/391 =>......]  Step: 63ms | Tot: 19s126ms | Loss: 40.821 | Acc: 45.391% (17256/3801 297/391 313/39 325/391   Step: 69ms | Tot: 21s554ms | Loss: 40.820 | Acc: 45.336% (19440/4288 335/39 337/391 ==============>...]  Step: 67ms | Tot: 21s818ms | Loss: 40.821 | Acc: 45.319% (19665/4339 339/39 341/391 =============>...]  Step: 67ms | Tot: 22s18ms | Loss: 40.820 | Acc: 45.367% (19860/4377 342/39 343/391 ===============>..]  Step: 71ms | Tot: 22s284ms | Loss: 40.819 | Acc: 45.378% (20097/4428 346/391 349/39 350/39 351/391 353/391  359/39 361/39 371/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s552ms | Loss: 2.256 | Acc: 42.290% (4229/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(52.7016, device='cuda:0'), tensor(52.6989, device='cuda:0'), tensor(52.6712, device='cuda:0'), tensor(52.6591, device='cuda:0'), tensor(52.6826, device='cuda:0'), tensor(52.7771, device='cuda:0'), tensor(52.7985, device='cuda:0')]\n",
      "\n",
      "Epoch: 264\n",
      " [========================>]  Step: 60ms | Tot: 22s398ms | Loss: 40.797 | Acc: 44.922% (22461/5000 391/391 31/391 ============>..]  Step: 48ms | Tot: 20s822ms | Loss: 40.799 | Acc: 44.924% (20701/4608 360/391 368/39 371/391 =======>.]  Step: 53ms | Tot: 21s458ms | Loss: 40.799 | Acc: 44.877% (21426/4774 373/391 =======>.]  Step: 46ms | Tot: 21s504ms | Loss: 40.799 | Acc: 44.901% (21495/4787 374/39 375/391 ===========>]  Step: 53ms | Tot: 21s660ms | Loss: 40.798 | Acc: 44.913% (21673/4825 377/391 385/391 386/39 388/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s438ms | Loss: 2.250 | Acc: 42.410% (4241/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(52.4726, device='cuda:0'), tensor(52.4731, device='cuda:0'), tensor(52.4514, device='cuda:0'), tensor(52.4573, device='cuda:0'), tensor(52.4778, device='cuda:0'), tensor(52.5716, device='cuda:0'), tensor(52.5924, device='cuda:0')]\n",
      "\n",
      "Epoch: 265\n",
      " [========================>]  Step: 62ms | Tot: 24s439ms | Loss: 40.761 | Acc: 45.540% (22770/5000 391/391 91  31/39 57/39 80/391 .........]  Step: 66ms | Tot: 5s18ms | Loss: 40.773 | Acc: 45.341% (4759/1049 82/39 85/39 97/391 ..........]  Step: 67ms | Tot: 6s39ms | Loss: 40.772 | Acc: 45.456% (5702/1254 98/39 106/391 108/39 138/391 .]  Step: 66ms | Tot: 8s651ms | Loss: 40.765 | Acc: 45.714% (8192/1792 140/39 152/391 .....]  Step: 72ms | Tot: 9s922ms | Loss: 40.765 | Acc: 45.723% (9364/2048 160/391 ==========>..............]  Step: 68ms | Tot: 10s52ms | Loss: 40.766 | Acc: 45.703% (9477/2073 162/391 ===========>.............]  Step: 71ms | Tot: 10s807ms | Loss: 40.767 | Acc: 45.631% (10163/2227 174/391 212/39 222/39 229/391  242/39 254/39 258/391 262/39 288/39 295/39 302/391 =========>.....]  Step: 75ms | Tot: 18s973ms | Loss: 40.767 | Acc: 45.577% (17735/3891 304/391 322/39 333/39 336/391 >...]  Step: 74ms | Tot: 21s141ms | Loss: 40.768 | Acc: 45.460% (19668/4326 338/391 340/39 343/39 356/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s591ms | Loss: 2.252 | Acc: 42.510% (4251/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(52.0580, device='cuda:0'), tensor(52.0575, device='cuda:0'), tensor(52.0450, device='cuda:0'), tensor(52.0525, device='cuda:0'), tensor(52.0661, device='cuda:0'), tensor(52.3681, device='cuda:0'), tensor(52.3890, device='cuda:0')]\n",
      "\n",
      "Epoch: 266\n",
      " [========================>]  Step: 64ms | Tot: 20s633ms | Loss: 40.737 | Acc: 45.146% (22573/5000 391/391 .........]  Step: 70ms | Tot: 2s296ms | Loss: 40.779 | Acc: 44.280% (3344/755 59/39 63/391 .................]  Step: 70ms | Tot: 2s690ms | Loss: 40.775 | Acc: 44.447% (3698/832 65/391 ..]  Step: 69ms | Tot: 2s819ms | Loss: 40.772 | Acc: 44.403% (3808/857 67/391 ====>....................]  Step: 69ms | Tot: 3s82ms | Loss: 40.765 | Acc: 44.564% (4050/908 71/39 73/391 ====>....................]  Step: 71ms | Tot: 3s346ms | Loss: 40.757 | Acc: 44.865% (4307/960 75/391 .............]  Step: 69ms | Tot: 3s738ms | Loss: 40.754 | Acc: 44.869% (4652/1036 81/391 ..............]  Step: 69ms | Tot: 4s382ms | Loss: 40.742 | Acc: 45.158% (5260/1164 91/391 =>...................]  Step: 72ms | Tot: 4s515ms | Loss: 40.740 | Acc: 45.144% (5374/1190 93/391 >................]  Step: 71ms | Tot: 7s125ms | Loss: 40.735 | Acc: 44.970% (7886/1753 137/391  175/39 232/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s571ms | Loss: 2.247 | Acc: 42.470% (4247/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(52.0436, device='cuda:0'), tensor(52.0378, device='cuda:0'), tensor(52.0546, device='cuda:0'), tensor(52.0532, device='cuda:0'), tensor(52.0335, device='cuda:0'), tensor(52.1641, device='cuda:0'), tensor(52.1867, device='cuda:0')]\n",
      "\n",
      "Epoch: 267\n",
      " [========================>]  Step: 65ms | Tot: 23s198ms | Loss: 40.709 | Acc: 45.188% (22594/5000 390/391 60/39 262/39 278/391 ======>.......]  Step: 62ms | Tot: 16s294ms | Loss: 40.711 | Acc: 45.399% (16271/3584 280/39 298/391  307/391 ==============>....]  Step: 60ms | Tot: 18s492ms | Loss: 40.712 | Acc: 45.235% (18181/4019 314/39 384/39 391/391 \n",
      " [========================>]  Step: 48ms | Tot: 3s551ms | Loss: 2.252 | Acc: 42.680% (4268/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(51.8745, device='cuda:0'), tensor(51.8636, device='cuda:0'), tensor(51.8720, device='cuda:0'), tensor(51.8552, device='cuda:0'), tensor(51.8568, device='cuda:0'), tensor(51.9608, device='cuda:0'), tensor(51.9849, device='cuda:0')]\n",
      "\n",
      "Epoch: 268\n",
      " [========================>]  Step: 65ms | Tot: 23s586ms | Loss: 40.679 | Acc: 45.190% (22595/5000 391/391 1 ====>....................]  Step: 49ms | Tot: 3s717ms | Loss: 40.700 | Acc: 44.788% (3841/857 67/39 89/39 116/391 139/39 141/39 148/39 163/391 164/39 172/391 195/39 197/391   Step: 70ms | Tot: 14s339ms | Loss: 40.681 | Acc: 45.231% (13895/3072 240/39 269/391 ===>.......]  Step: 68ms | Tot: 16s218ms | Loss: 40.681 | Acc: 45.347% (15730/3468 271/391 273/391 275/391 ==>.]  Step: 70ms | Tot: 22s615ms | Loss: 40.681 | Acc: 45.196% (21694/4800 375/39 377/391 \n",
      " [========================>]  Step: 41ms | Tot: 3s291ms | Loss: 2.251 | Acc: 42.770% (4277/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(51.8309, device='cuda:0'), tensor(51.8553, device='cuda:0'), tensor(51.8521, device='cuda:0'), tensor(51.8521, device='cuda:0'), tensor(51.8297, device='cuda:0'), tensor(51.7614, device='cuda:0'), tensor(51.7835, device='cuda:0')]\n",
      "\n",
      "Epoch: 269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 49ms | Tot: 19s199ms | Loss: 40.644 | Acc: 45.662% (22831/5000 391/391 ......]  Step: 46ms | Tot: 1s927ms | Loss: 40.675 | Acc: 44.996% (2419/537 42/391 62/391 70/39 71/391 95/391 ....]  Step: 51ms | Tot: 4s755ms | Loss: 40.657 | Acc: 45.526% (5769/1267 99/391 >..................]  Step: 50ms | Tot: 4s857ms | Loss: 40.653 | Acc: 45.645% (5901/1292 101/39 117/391 =======>.................]  Step: 45ms | Tot: 5s783ms | Loss: 40.661 | Acc: 45.443% (6980/1536 120/39 133/391 .....]  Step: 49ms | Tot: 6s599ms | Loss: 40.656 | Acc: 45.683% (8011/1753 137/391 =>................]  Step: 50ms | Tot: 6s701ms | Loss: 40.654 | Acc: 45.745% (8139/1779 139/391 ===>..............]  Step: 50ms | Tot: 7s729ms | Loss: 40.652 | Acc: 45.804% (9322/2035 159/391 >..............]  Step: 49ms | Tot: 7s929ms | Loss: 40.652 | Acc: 45.777% (9551/2086 163/391 >..............]  Step: 50ms | Tot: 7s980ms | Loss: 40.650 | Acc: 45.803% (9615/2099 164/39 165/39 166/39 167/39 197/391 ==>............]  Step: 50ms | Tot: 9s626ms | Loss: 40.656 | Acc: 45.608% (11559/2534 198/391 201/391 ============>............]  Step: 48ms | Tot: 9s878ms | Loss: 40.657 | Acc: 45.636% (11858/2598 203/391 ===========>...........]  Step: 50ms | Tot: 9s979ms | Loss: 40.656 | Acc: 45.621% (11971/2624 205/39 233/39 235/39 237/391 .]  Step: 46ms | Tot: 11s560ms | Loss: 40.652 | Acc: 45.611% (13895/3046 238/391 =>.........]  Step: 54ms | Tot: 12s200ms | Loss: 40.652 | Acc: 45.590% (14647/3212 251/391 ================>........]  Step: 51ms | Tot: 12s622ms | Loss: 40.651 | Acc: 45.626% (15126/3315 259/391 260/391 261/391 271/391 281/39 282/39 287/391 ==================>......]  Step: 53ms | Tot: 14s66ms | Loss: 40.649 | Acc: 45.638% (16824/3686 288/391 =============>......]  Step: 49ms | Tot: 14s164ms | Loss: 40.648 | Acc: 45.652% (16946/3712 290/39 292/391  323/391 ==========>....]  Step: 51ms | Tot: 15s791ms | Loss: 40.648 | Acc: 45.701% (18953/4147 324/391 325/391 ..]  Step: 50ms | Tot: 15s943ms | Loss: 40.649 | Acc: 45.683% (19121/4185 327/391 329/391 331/391 =========>...]  Step: 52ms | Tot: 16s247ms | Loss: 40.650 | Acc: 45.648% (19457/4262 333/391 335/39 339/391 ========>...]  Step: 52ms | Tot: 16s597ms | Loss: 40.651 | Acc: 45.577% (19835/4352 340/391 =============>...]  Step: 51ms | Tot: 16s648ms | Loss: 40.651 | Acc: 45.551% (19882/4364 341/391 .]  Step: 49ms | Tot: 17s60ms | Loss: 40.649 | Acc: 45.590% (20366/4467 349/391 354/391 ======================>..]  Step: 52ms | Tot: 17s357ms | Loss: 40.649 | Acc: 45.605% (20723/4544 355/391 365/391 =======================>.]  Step: 50ms | Tot: 17s972ms | Loss: 40.648 | Acc: 45.593% (21418/4697 367/391 =============>.]  Step: 49ms | Tot: 18s272ms | Loss: 40.647 | Acc: 45.620% (21781/4774 373/39 375/391 =======================>.]  Step: 49ms | Tot: 18s423ms | Loss: 40.647 | Acc: 45.618% (21955/4812 376/391 ===>]  Step: 49ms | Tot: 18s472ms | Loss: 40.647 | Acc: 45.627% (22018/4825 377/391 =====>]  Step: 52ms | Tot: 18s524ms | Loss: 40.647 | Acc: 45.623% (22074/4838 378/391 ========================>]  Step: 50ms | Tot: 18s830ms | Loss: 40.646 | Acc: 45.628% (22427/4915 384/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s618ms | Loss: 2.247 | Acc: 42.630% (4263/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(51.6611, device='cuda:0'), tensor(51.6401, device='cuda:0'), tensor(51.6273, device='cuda:0'), tensor(51.6669, device='cuda:0'), tensor(51.6416, device='cuda:0'), tensor(51.5581, device='cuda:0'), tensor(51.5816, device='cuda:0')]\n",
      "\n",
      "Epoch: 270\n",
      " [========================>]  Step: 63ms | Tot: 19s800ms | Loss: 40.613 | Acc: 45.722% (22861/5000 391/391 ep: 52ms | Tot: 565ms | Loss: 40.636 | Acc: 44.922% (690/153 12/39 16/391 .........]  Step: 52ms | Tot: 815ms | Loss: 40.625 | Acc: 45.634% (993/217 17/391 28/391 32/391 ..................]  Step: 51ms | Tot: 2s683ms | Loss: 40.639 | Acc: 44.893% (3103/691 54/391 ===>.....................]  Step: 50ms | Tot: 3s86ms | Loss: 40.633 | Acc: 45.186% (3586/793 62/391 ====>....................]  Step: 50ms | Tot: 3s187ms | Loss: 40.630 | Acc: 45.227% (3705/819 64/391 ...............]  Step: 50ms | Tot: 4s275ms | Loss: 40.618 | Acc: 45.625% (4964/1088 85/391   Step: 51ms | Tot: 4s326ms | Loss: 40.616 | Acc: 45.685% (5029/1100 86/391 87/391  98/391 .......]  Step: 50ms | Tot: 5s14ms | Loss: 40.608 | Acc: 45.883% (5873/1280 100/39 102/391 103/39 104/391 114/39 130/391 ...]  Step: 49ms | Tot: 7s23ms | Loss: 40.612 | Acc: 45.698% (8189/1792 140/39 144/39 146/391 =========>...............]  Step: 51ms | Tot: 7s373ms | Loss: 40.613 | Acc: 45.738% (8606/1881 147/391 ...]  Step: 51ms | Tot: 7s425ms | Loss: 40.611 | Acc: 45.819% (8680/1894 148/391 152/391 ======>...............]  Step: 49ms | Tot: 7s775ms | Loss: 40.611 | Acc: 45.786% (9084/1984 155/39 156/391 ........]  Step: 51ms | Tot: 7s927ms | Loss: 40.611 | Acc: 45.802% (9263/2022 158/391 ...]  Step: 49ms | Tot: 8s77ms | Loss: 40.613 | Acc: 45.764% (9431/2060 161/391 ......]  Step: 49ms | Tot: 8s126ms | Loss: 40.612 | Acc: 45.771% (9491/2073 162/391 ....]  Step: 52ms | Tot: 8s178ms | Loss: 40.611 | Acc: 45.797% (9555/2086 163/391 =====>.............]  Step: 55ms | Tot: 8s768ms | Loss: 40.611 | Acc: 45.757% (10191/2227 174/39 179/391 200/391 201/391 =============>...........]  Step: 53ms | Tot: 10s420ms | Loss: 40.615 | Acc: 45.601% (12024/2636 206/391 .]  Step: 49ms | Tot: 10s995ms | Loss: 40.614 | Acc: 45.665% (12684/2777 217/39 228/391 229/391 ]  Step: 50ms | Tot: 11s789ms | Loss: 40.614 | Acc: 45.732% (13639/29 233/391 244/391 254/391 ================>........]  Step: 49ms | Tot: 12s951ms | Loss: 40.613 | Acc: 45.779% (15001/3276 256/391 258/391 =========>........]  Step: 50ms | Tot: 13s253ms | Loss: 40.614 | Acc: 45.733% (15337/3353 262/391 ==============>........]  Step: 49ms | Tot: 13s354ms | Loss: 40.615 | Acc: 45.700% (15443/3379 264/391 ===============>.......]  Step: 48ms | Tot: 13s504ms | Loss: 40.616 | Acc: 45.713% (15623/3417 267/39 268/39 269/39 270/391 271/391 ========>.......]  Step: 50ms | Tot: 13s950ms | Loss: 40.615 | Acc: 45.720% (16152/3532 276/391 280/39 281/391 .....]  Step: 53ms | Tot: 14s250ms | Loss: 40.614 | Acc: 45.725% (16505/3609 282/391 298/391 ...]  Step: 54ms | Tot: 15s118ms | Loss: 40.614 | Acc: 45.783% (17522/3827 299/391 ...]  Step: 50ms | Tot: 15s168ms | Loss: 40.614 | Acc: 45.784% (17581/3840 300/391 ===============>.....]  Step: 49ms | Tot: 15s368ms | Loss: 40.615 | Acc: 45.731% (17795/38 304/391 305/391 ....]  Step: 52ms | Tot: 15s471ms | Loss: 40.616 | Acc: 45.685% (17894/3916 306/391 310/391 ]  Step: 54ms | Tot: 15s722ms | Loss: 40.616 | Acc: 45.704% (18194/3980 311/39 312/391 ==>....]  Step: 58ms | Tot: 16s449ms | Loss: 40.615 | Acc: 45.708% (19073/4172 326/391 335/391 339/39 353/39 359/391 =============>.]  Step: 51ms | Tot: 18s244ms | Loss: 40.616 | Acc: 45.683% (21109/4620 361/39 366/391 368/39 374/39 375/39 378/39 379/391 ======================>]  Step: 51ms | Tot: 19s205ms | Loss: 40.614 | Acc: 45.769% (22262/4864 380/391 ==================>]  Step: 51ms | Tot: 19s302ms | Loss: 40.614 | Acc: 45.762% (22376/4889 382/391 =========>]  Step: 52ms | Tot: 19s354ms | Loss: 40.613 | Acc: 45.757% (22432/4902 383/391 ========================>]  Step: 46ms | Tot: 19s555ms | Loss: 40.613 | Acc: 45.740% (22658/4953 387/391 =>]  Step: 54ms | Tot: 19s609ms | Loss: 40.613 | Acc: 45.743% (22718/4966 388/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s595ms | Loss: 2.252 | Acc: 42.480% (4248/1000 79/79  Step: 61ms | Tot: 1s576ms | Loss: 2.262 | Acc: 43.036% (1928/448 35/79 37/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(51.2039, device='cuda:0'), tensor(51.2268, device='cuda:0'), tensor(51.2316, device='cuda:0'), tensor(51.2349, device='cuda:0'), tensor(51.2502, device='cuda:0'), tensor(51.3606, device='cuda:0'), tensor(51.3814, device='cuda:0')]\n",
      "\n",
      "Epoch: 271\n",
      " [========================>]  Step: 68ms | Tot: 24s536ms | Loss: 40.590 | Acc: 45.306% (22653/5000 391/391 ............]  Step: 70ms | Tot: 646ms | Loss: 40.632 | Acc: 44.792% (688/153 12/391 13/39 79/391 =====>...................]  Step: 71ms | Tot: 5s178ms | Loss: 40.596 | Acc: 45.338% (5281/1164 91/391 ..............]  Step: 63ms | Tot: 5s924ms | Loss: 40.596 | Acc: 45.343% (5920/1305 102/391 .......]  Step: 63ms | Tot: 6s449ms | Loss: 40.594 | Acc: 45.270% (6374/1408 110/391   Step: 72ms | Tot: 6s827ms | Loss: 40.597 | Acc: 45.171% (6707/1484 116/391 129/391 ......]  Step: 59ms | Tot: 8s238ms | Loss: 40.596 | Acc: 45.153% (7918/1753 137/391 ============>............]  Step: 70ms | Tot: 11s601ms | Loss: 40.599 | Acc: 45.090% (10966/2432 190/39 198/39 214/391 ..]  Step: 58ms | Tot: 13s980ms | Loss: 40.599 | Acc: 45.033% (13200/2931 229/39 260/391 263/391 =======>.......]  Step: 63ms | Tot: 16s926ms | Loss: 40.591 | Acc: 45.332% (16073/3545 277/391 ===============>......]  Step: 60ms | Tot: 17s724ms | Loss: 40.591 | Acc: 45.321% (16765/3699 289/391 ...]  Step: 62ms | Tot: 19s58ms | Loss: 40.594 | Acc: 45.221% (17886/3955 309/39 315/39 318/391 =>...]  Step: 70ms | Tot: 20s722ms | Loss: 40.593 | Acc: 45.298% (19366/4275 334/391 ==========>...]  Step: 69ms | Tot: 21s115ms | Loss: 40.594 | Acc: 45.269% (19701/4352 340/391 ===========>..]  Step: 65ms | Tot: 21s580ms | Loss: 40.592 | Acc: 45.351% (20143/4441 347/391  349/391 >..]  Step: 72ms | Tot: 21s916ms | Loss: 40.592 | Acc: 45.357% (20436/4505 352/391 ==>..]  Step: 61ms | Tot: 22s115ms | Loss: 40.592 | Acc: 45.346% (20605/4544 355/39 359/391 361/391   Step: 62ms | Tot: 22s794ms | Loss: 40.592 | Acc: 45.315% (21171/4672 365/391 369/391 ==============>.]  Step: 70ms | Tot: 23s267ms | Loss: 40.591 | Acc: 45.331% (21585/4761 372/391 ===========>.]  Step: 61ms | Tot: 23s467ms | Loss: 40.592 | Acc: 45.308% (21748/48 375/391 387/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s643ms | Loss: 2.250 | Acc: 42.810% (4281/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(50.8044, device='cuda:0'), tensor(50.8483, device='cuda:0'), tensor(50.8493, device='cuda:0'), tensor(50.8447, device='cuda:0'), tensor(50.8647, device='cuda:0'), tensor(51.1607, device='cuda:0'), tensor(51.1847, device='cuda:0')]\n",
      "\n",
      "Epoch: 272\n",
      " [========================>]  Step: 70ms | Tot: 25s82ms | Loss: 40.560 | Acc: 45.348% (22674/5000 391/391  39 16/391 ................]  Step: 62ms | Tot: 1s253ms | Loss: 40.592 | Acc: 44.414% (1137/256 20/391 ................]  Step: 70ms | Tot: 1s455ms | Loss: 40.589 | Acc: 44.735% (1317/294 23/39 26/39 31/391 .......]  Step: 64ms | Tot: 2s39ms | Loss: 40.596 | Acc: 44.653% (1829/409 32/391 ]  Step: 69ms | Tot: 2s300ms | Loss: 40.598 | Acc: 44.510% (2051/460 36/391 37/391 ........]  Step: 64ms | Tot: 3s77ms | Loss: 40.597 | Acc: 44.808% (2753/614 48/39 50/391 ]  Step: 67ms | Tot: 3s735ms | Loss: 40.589 | Acc: 44.881% (3332/742 58/391 60/39 61/39 63/391 ..................]  Step: 65ms | Tot: 4s199ms | Loss: 40.582 | Acc: 45.060% (3749/832 65/39 70/391 71/391 72/391 74/391 77/391 88/391 ..........]  Step: 63ms | Tot: 6s401ms | Loss: 40.562 | Acc: 45.647% (5726/1254 98/391 103/39 105/391 ...]  Step: 66ms | Tot: 7s4ms | Loss: 40.558 | Acc: 45.685% (6257/1369 107/391 ....]  Step: 67ms | Tot: 7s204ms | Loss: 40.564 | Acc: 45.575% (6417/1408 110/39 111/391 113/391 .............]  Step: 63ms | Tot: 7s468ms | Loss: 40.565 | Acc: 45.525% (6643/14 114/39 125/39 129/391 136/391 ......]  Step: 64ms | Tot: 9s53ms | Loss: 40.560 | Acc: 45.624% (8059/1766 138/391 =>................]  Step: 68ms | Tot: 9s121ms | Loss: 40.561 | Acc: 45.633% (8119/1779 139/391 .]  Step: 70ms | Tot: 9s254ms | Loss: 40.563 | Acc: 45.584% (8227/1804 141/391 148/391 .]  Step: 67ms | Tot: 9s867ms | Loss: 40.563 | Acc: 45.490% (8734/1920 150/39 153/391 ..........]  Step: 64ms | Tot: 10s132ms | Loss: 40.560 | Acc: 45.531% (8975/1971 154/391 156/391 .............]  Step: 68ms | Tot: 10s334ms | Loss: 40.557 | Acc: 45.636% (9171/2009 157/391 =====>..............]  Step: 66ms | Tot: 10s867ms | Loss: 40.554 | Acc: 45.687% (9649/2112 165/391 182/391 190/391 191/391 ====>............]  Step: 68ms | Tot: 12s651ms | Loss: 40.567 | Acc: 45.345% (11144/2457 192/391 193/39 194/39 196/39 197/39 201/39 204/39 208/391 =======>...]  Step: 66ms | Tot: 22s86ms | Loss: 40.563 | Acc: 45.328% (20017/4416 345/391 347/391 =====>.]  Step: 67ms | Tot: 23s184ms | Loss: 40.562 | Acc: 45.358% (21017/4633 362/39 375/39 379/391 386/39 388/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s578ms | Loss: 2.251 | Acc: 42.600% (4260/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(50.6501, device='cuda:0'), tensor(50.6608, device='cuda:0'), tensor(50.6545, device='cuda:0'), tensor(50.6693, device='cuda:0'), tensor(50.6551, device='cuda:0'), tensor(50.9617, device='cuda:0'), tensor(50.9849, device='cuda:0')]\n",
      "\n",
      "Epoch: 273\n",
      " [========================>]  Step: 53ms | Tot: 24s375ms | Loss: 40.531 | Acc: 45.552% (22776/5000 391/391 1 39/391 ...]  Step: 65ms | Tot: 3s136ms | Loss: 40.555 | Acc: 45.067% (2942/652 51/391 112/39 119/391  178/391 192/39 195/391 ========>...........]  Step: 68ms | Tot: 12s757ms | Loss: 40.536 | Acc: 45.491% (11995/2636 206/391 ]  Step: 65ms | Tot: 12s823ms | Loss: 40.536 | Acc: 45.497% (12055/2649 207/391 212/39 213/391 =>...........]  Step: 67ms | Tot: 13s284ms | Loss: 40.533 | Acc: 45.564% (12481/2739 214/391 220/391 ==============>..........]  Step: 66ms | Tot: 14s72ms | Loss: 40.533 | Acc: 45.672% (13212/2892 226/391 .....]  Step: 69ms | Tot: 14s204ms | Loss: 40.534 | Acc: 45.635% (13318/2918 228/391 230/391 =========>..........]  Step: 66ms | Tot: 14s532ms | Loss: 40.532 | Acc: 45.698% (13629/2982 233/39 234/391 ===========>.........]  Step: 69ms | Tot: 14s939ms | Loss: 40.534 | Acc: 45.639% (13962/3059 239/391 ......]  Step: 69ms | Tot: 15s203ms | Loss: 40.535 | Acc: 45.618% (14189/3110 243/391 ============>.........]  Step: 61ms | Tot: 15s405ms | Loss: 40.534 | Acc: 45.617% (14364/3148 246/39 247/39 250/391 253/391 ==========>........]  Step: 61ms | Tot: 16s283ms | Loss: 40.532 | Acc: 45.659% (15137/3315 259/391 271/39 309/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s662ms | Loss: 2.254 | Acc: 42.590% (4259/1000 79/79  15/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(50.6723, device='cuda:0'), tensor(50.6358, device='cuda:0'), tensor(50.6363, device='cuda:0'), tensor(50.6422, device='cuda:0'), tensor(50.6346, device='cuda:0'), tensor(50.7634, device='cuda:0'), tensor(50.7869, device='cuda:0')]\n",
      "\n",
      "Epoch: 274\n",
      " [========================>]  Step: 63ms | Tot: 24s518ms | Loss: 40.503 | Acc: 45.470% (22735/5000 391/391 91 30/39 32/391 ]  Step: 70ms | Tot: 2s173ms | Loss: 40.499 | Acc: 46.228% (2071/448 35/39 42/391 ..........]  Step: 69ms | Tot: 2s770ms | Loss: 40.518 | Acc: 45.419% (2558/563 44/391 45/39 47/391 64/391 80/391 82/391 84/39 86/391 96/39 106/39 139/391 .............]  Step: 66ms | Tot: 8s852ms | Loss: 40.500 | Acc: 45.817% (8269/1804 141/391 145/39 149/391 151/391 153/391 154/391 163/391 165/391 170/39 171/391 173/39 194/391 .....]  Step: 67ms | Tot: 12s311ms | Loss: 40.512 | Acc: 45.468% (11407/2508 196/391 198/391 .....]  Step: 68ms | Tot: 12s513ms | Loss: 40.510 | Acc: 45.540% (11600/2547 199/39 228/39 229/391 .......]  Step: 68ms | Tot: 14s844ms | Loss: 40.506 | Acc: 45.604% (13776/3020 236/39 238/391 >.........]  Step: 69ms | Tot: 15s648ms | Loss: 40.506 | Acc: 45.576% (14526/3187 249/39 250/391 ...]  Step: 69ms | Tot: 16s345ms | Loss: 40.505 | Acc: 45.622% (15183/3328 260/391 262/39 266/391 ====>.....]  Step: 69ms | Tot: 19s81ms | Loss: 40.505 | Acc: 45.516% (17711/3891 304/391 ===================>.....]  Step: 67ms | Tot: 19s148ms | Loss: 40.505 | Acc: 45.505% (17765/3904 305/391 ...]  Step: 65ms | Tot: 19s473ms | Loss: 40.504 | Acc: 45.464% (18040/3968 310/391 =======>....]  Step: 70ms | Tot: 19s735ms | Loss: 40.504 | Acc: 45.479% (18279/4019 314/391 ========================>]  Step: 64ms | Tot: 24s62ms | Loss: 40.503 | Acc: 45.461% (22345/4915 384/391  389/39 390/391 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 50ms | Tot: 3s575ms | Loss: 2.250 | Acc: 42.490% (4249/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(50.6206, device='cuda:0'), tensor(50.6058, device='cuda:0'), tensor(50.6519, device='cuda:0'), tensor(50.6182, device='cuda:0'), tensor(50.6309, device='cuda:0'), tensor(50.5682, device='cuda:0'), tensor(50.5898, device='cuda:0')]\n",
      "\n",
      "Epoch: 275\n",
      " [========================>]  Step: 48ms | Tot: 22s934ms | Loss: 40.460 | Acc: 46.046% (23023/5000 391/391 ...............]  Step: 68ms | Tot: 2s279ms | Loss: 40.485 | Acc: 45.979% (2413/524 41/391 87/391 88/391 >..................]  Step: 67ms | Tot: 5s730ms | Loss: 40.445 | Acc: 46.612% (5668/1216 95/39 113/391  255/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s573ms | Loss: 2.252 | Acc: 42.470% (4247/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(50.4513, device='cuda:0'), tensor(50.4386, device='cuda:0'), tensor(50.4510, device='cuda:0'), tensor(50.4458, device='cuda:0'), tensor(50.4301, device='cuda:0'), tensor(50.3692, device='cuda:0'), tensor(50.3956, device='cuda:0')]\n",
      "\n",
      "Epoch: 276\n",
      " [========================>]  Step: 63ms | Tot: 24s460ms | Loss: 40.427 | Acc: 46.140% (23070/5000 391/391 ................]  Step: 69ms | Tot: 386ms | Loss: 40.508 | Acc: 45.089% (404/89 7/39 10/391 ...........]  Step: 69ms | Tot: 718ms | Loss: 40.454 | Acc: 46.029% (707/153 12/391 ....................]  Step: 68ms | Tot: 787ms | Loss: 40.444 | Acc: 45.853% (763/1 13/39 14/39 45/391 .]  Step: 69ms | Tot: 4s580ms | Loss: 40.438 | Acc: 46.062% (4422/960 75/39 85/391 .......]  Step: 62ms | Tot: 5s349ms | Loss: 40.423 | Acc: 46.444% (5172/1113 87/39 112/391 124/391 126/391 ]  Step: 54ms | Tot: 7s934ms | Loss: 40.424 | Acc: 46.478% (7853/1689 132/391 144/39 146/391 151/391 162/391 169/39 199/391 .....]  Step: 69ms | Tot: 16s783ms | Loss: 40.431 | Acc: 46.257% (16164/3494 273/391 >.......]  Step: 69ms | Tot: 17s44ms | Loss: 40.431 | Acc: 46.232% (16392/3545 277/391 ========>.......]  Step: 63ms | Tot: 17s108ms | Loss: 40.431 | Acc: 46.231% (16451/3558 278/39 280/391 ===============>.......]  Step: 66ms | Tot: 17s308ms | Loss: 40.432 | Acc: 46.213% (16622/3596 281/39 289/39 292/39 298/391 300/391  307/391 =====>.....]  Step: 65ms | Tot: 19s408ms | Loss: 40.431 | Acc: 46.166% (18496/4006 313/391 ===============>....]  Step: 68ms | Tot: 19s861ms | Loss: 40.431 | Acc: 46.135% (18897/4096 320/391 ]  Step: 66ms | Tot: 19s993ms | Loss: 40.430 | Acc: 46.157% (19024/4121 322/391 324/391 327/391 =================>...]  Step: 67ms | Tot: 20s659ms | Loss: 40.430 | Acc: 46.167% (19619/4249 332/391 ===========>...]  Step: 68ms | Tot: 20s858ms | Loss: 40.431 | Acc: 46.150% (19789/4288 335/391 ===========>...]  Step: 64ms | Tot: 20s923ms | Loss: 40.430 | Acc: 46.150% (19848/4300 336/391 ==>..]  Step: 68ms | Tot: 21s739ms | Loss: 40.431 | Acc: 46.123% (20604/4467 349/39 356/39 359/39 365/391 366/391 372/39 373/391 377/391 384/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s451ms | Loss: 2.246 | Acc: 42.600% (4260/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(50.0895, device='cuda:0'), tensor(50.0720, device='cuda:0'), tensor(50.0524, device='cuda:0'), tensor(50.0756, device='cuda:0'), tensor(50.0504, device='cuda:0'), tensor(50.1740, device='cuda:0'), tensor(50.1983, device='cuda:0')]\n",
      "\n",
      "Epoch: 277\n",
      " [========================>]  Step: 67ms | Tot: 24s352ms | Loss: 40.402 | Acc: 46.292% (23146/5000 391/391 ]  Step: 64ms | Tot: 1s45ms | Loss: 40.415 | Acc: 46.324% (1008/217 17/39 22/39 27/391 28/391 .]  Step: 69ms | Tot: 2s293ms | Loss: 40.429 | Acc: 45.660% (2104/460 36/391 40/391 .................]  Step: 63ms | Tot: 2s618ms | Loss: 40.440 | Acc: 45.389% (2382/524 41/391 ..................]  Step: 69ms | Tot: 2s818ms | Loss: 40.440 | Acc: 45.277% (2550/563 44/391 ................]  Step: 67ms | Tot: 3s18ms | Loss: 40.434 | Acc: 45.512% (2738/601 47/391 ..................]  Step: 65ms | Tot: 3s84ms | Loss: 40.429 | Acc: 45.654% (2805/614 48/391 50/39 53/391 56/391 66/391  67/391 72/39 78/391 ..........]  Step: 67ms | Tot: 5s142ms | Loss: 40.408 | Acc: 45.926% (4644/1011 79/391 80/39 81/391 ....]  Step: 70ms | Tot: 5s343ms | Loss: 40.402 | Acc: 46.018% (4830/1049 82/391 ...............]  Step: 68ms | Tot: 5s412ms | Loss: 40.400 | Acc: 46.047% (4892/1062 83/391 84/391 .................]  Step: 69ms | Tot: 5s614ms | Loss: 40.403 | Acc: 45.957% (5059/1100 86/391 ................]  Step: 63ms | Tot: 5s677ms | Loss: 40.399 | Acc: 46.022% (5125/1113 87/391 >...................]  Step: 68ms | Tot: 5s815ms | Loss: 40.400 | Acc: 46.085% (5250/1139 89/39 90/391 ........]  Step: 61ms | Tot: 6s79ms | Loss: 40.396 | Acc: 46.136% (5492/1190 93/391 ======>..................]  Step: 63ms | Tot: 6s413ms | Loss: 40.399 | Acc: 45.950% (5764/1254 98/391 .................]  Step: 68ms | Tot: 6s673ms | Loss: 40.397 | Acc: 46.055% (6013/1305 102/391 ........]  Step: 68ms | Tot: 6s804ms | Loss: 40.396 | Acc: 46.094% (6136/1331 104/39 110/391 ....]  Step: 69ms | Tot: 7s460ms | Loss: 40.401 | Acc: 46.039% (6718/1459 114/391   Step: 63ms | Tot: 7s662ms | Loss: 40.397 | Acc: 46.201% (6919/1497 117/391 123/391 125/39 126/391 134/391 ..............]  Step: 65ms | Tot: 9s116ms | Loss: 40.400 | Acc: 46.296% (8237/1779 139/39 146/39 271/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s566ms | Loss: 2.249 | Acc: 42.460% (4246/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(49.8974, device='cuda:0'), tensor(49.8730, device='cuda:0'), tensor(49.8512, device='cuda:0'), tensor(49.8515, device='cuda:0'), tensor(49.8835, device='cuda:0'), tensor(49.9796, device='cuda:0'), tensor(50.0047, device='cuda:0')]\n",
      "\n",
      "Epoch: 278\n",
      " [========================>]  Step: 53ms | Tot: 22s839ms | Loss: 40.380 | Acc: 45.664% (22832/5000 391/391 ..............]  Step: 66ms | Tot: 1s180ms | Loss: 40.415 | Acc: 45.970% (1118/243 19/391 ........]  Step: 69ms | Tot: 1s573ms | Loss: 40.393 | Acc: 46.031% (1473/320 25/39 37/391 .....................]  Step: 68ms | Tot: 2s482ms | Loss: 40.413 | Acc: 45.212% (2257/499 39/ 40/39 41/391 ........]  Step: 66ms | Tot: 2s744ms | Loss: 40.415 | Acc: 44.822% (2467/550 43/391 47/391 48/391 .......]  Step: 67ms | Tot: 3s331ms | Loss: 40.404 | Acc: 45.207% (3009/665 52/39 53/391 ...........]  Step: 53ms | Tot: 4s356ms | Loss: 40.391 | Acc: 45.742% (4157/908 71/391 ....]  Step: 43ms | Tot: 6s370ms | Loss: 40.386 | Acc: 46.036% (6364/1382 108/39 159/39 166/39 205/39 240/391 ==========>........]  Step: 45ms | Tot: 15s164ms | Loss: 40.384 | Acc: 45.788% (14828/3238 253/39 255/391 =========>........]  Step: 46ms | Tot: 15s365ms | Loss: 40.383 | Acc: 45.790% (15063/3289 257/391 ================>........]  Step: 50ms | Tot: 15s416ms | Loss: 40.384 | Acc: 45.782% (15119/3302 258/391 .]  Step: 51ms | Tot: 15s468ms | Loss: 40.384 | Acc: 45.765% (15172/33 259/391 ===========>.......]  Step: 48ms | Tot: 16s514ms | Loss: 40.382 | Acc: 45.839% (16370/3571 279/39 306/391 ==============>....]  Step: 69ms | Tot: 18s955ms | Loss: 40.383 | Acc: 45.725% (18963/4147 324/39 353/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s578ms | Loss: 2.246 | Acc: 42.780% (4278/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(49.6489, device='cuda:0'), tensor(49.6671, device='cuda:0'), tensor(49.6561, device='cuda:0'), tensor(49.6849, device='cuda:0'), tensor(49.6808, device='cuda:0'), tensor(49.7887, device='cuda:0'), tensor(49.8097, device='cuda:0')]\n",
      "\n",
      "Epoch: 279\n",
      " [========================>]  Step: 58ms | Tot: 24s191ms | Loss: 40.342 | Acc: 46.114% (23057/5000 391/391 ..]  Step: 69ms | Tot: 1s250ms | Loss: 40.350 | Acc: 46.875% (1260/268 21/391 .............]  Step: 70ms | Tot: 1s380ms | Loss: 40.347 | Acc: 46.705% (1375/294 23/391 ..............]  Step: 70ms | Tot: 1s511ms | Loss: 40.352 | Acc: 46.469% (1487/320 25/391 .................]  Step: 71ms | Tot: 1s642ms | Loss: 40.351 | Acc: 46.325% (1601/345 27/391 29/391 .............]  Step: 69ms | Tot: 2s550ms | Loss: 40.357 | Acc: 45.732% (2400/524 41/39 186/39 321/391 ==========>....]  Step: 63ms | Tot: 19s900ms | Loss: 40.345 | Acc: 46.060% (18984/4121 322/39 342/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s567ms | Loss: 2.252 | Acc: 42.650% (4265/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(49.6318, device='cuda:0'), tensor(49.6253, device='cuda:0'), tensor(49.6376, device='cuda:0'), tensor(49.6341, device='cuda:0'), tensor(49.6589, device='cuda:0'), tensor(49.5931, device='cuda:0'), tensor(49.6191, device='cuda:0')]\n",
      "\n",
      "Epoch: 280\n",
      " [========================>]  Step: 63ms | Tot: 23s116ms | Loss: 40.306 | Acc: 46.278% (23139/5000 391/391 ================>.]  Step: 68ms | Tot: 22s89ms | Loss: 40.307 | Acc: 46.250% (22141/4787 374/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s859ms | Loss: 2.248 | Acc: 42.510% (4251/1000 79/79  9/79 11/79 ===>.....................]  Step: 46ms | Tot: 562ms | Loss: 2.315 | Acc: 41.211% (633/153 12/7 13/79 20/79 21/79 22/7 23/79 24/79 .]  Step: 55ms | Tot: 1s220ms | Loss: 2.259 | Acc: 42.750% (1368/320 25/79 =======>.................]  Step: 45ms | Tot: 1s265ms | Loss: 2.257 | Acc: 42.758% (1423/332 26/79 27/79 =======>................]  Step: 55ms | Tot: 1s421ms | Loss: 2.262 | Acc: 42.592% (1581/371 29/79  30/7 32/79 ====>..............]  Step: 55ms | Tot: 1s621ms | Loss: 2.250 | Acc: 43.040% (1818/422 33/7 45/7 51/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(49.1276, device='cuda:0'), tensor(49.0908, device='cuda:0'), tensor(49.1070, device='cuda:0'), tensor(49.1128, device='cuda:0'), tensor(49.1073, device='cuda:0'), tensor(49.4010, device='cuda:0'), tensor(49.4243, device='cuda:0')]\n",
      "\n",
      "Epoch: 281\n",
      " [========================>]  Step: 64ms | Tot: 20s339ms | Loss: 40.285 | Acc: 46.142% (23071/50000390/391 /391 24/391 35/391 ==>......................]  Step: 51ms | Tot: 2s80ms | Loss: 40.290 | Acc: 46.094% (2478/537 42/391 ..........]  Step: 52ms | Tot: 2s982ms | Loss: 40.280 | Acc: 46.432% (3566/768 60/39 62/391 ............]  Step: 51ms | Tot: 3s131ms | Loss: 40.283 | Acc: 46.540% (3753/806 63/39 69/391 72/391 .....]  Step: 49ms | Tot: 4s189ms | Loss: 40.277 | Acc: 46.773% (5029/1075 84/391 .................]  Step: 46ms | Tot: 4s388ms | Loss: 40.275 | Acc: 46.857% (5278/11 88/391 92/391 .......]  Step: 51ms | Tot: 4s636ms | Loss: 40.269 | Acc: 46.934% (5587/1190 93/391 ..............]  Step: 52ms | Tot: 5s468ms | Loss: 40.280 | Acc: 46.754% (6583/1408 110/39 111/391 ]  Step: 46ms | Tot: 5s616ms | Loss: 40.282 | Acc: 46.695% (6754/1446 113/39 114/39 115/391 ......]  Step: 49ms | Tot: 5s866ms | Loss: 40.280 | Acc: 46.670% (7049/1510 118/391 ...............]  Step: 52ms | Tot: 5s918ms | Loss: 40.281 | Acc: 46.671% (7109/15 119/391 =======>.................]  Step: 51ms | Tot: 5s970ms | Loss: 40.281 | Acc: 46.667% (7168/1536 120/39 136/391 =========>...............]  Step: 47ms | Tot: 7s209ms | Loss: 40.288 | Acc: 46.412% (8614/1856 145/391 146/39 147/391 =======>..............]  Step: 49ms | Tot: 8s149ms | Loss: 40.287 | Acc: 46.237% (9706/2099 164/391 ==>..............]  Step: 51ms | Tot: 8s253ms | Loss: 40.288 | Acc: 46.216% (9820/2124 166/391 168/391 >..............]  Step: 55ms | Tot: 8s403ms | Loss: 40.288 | Acc: 46.154% (9984/2163 169/391 .........]  Step: 50ms | Tot: 8s453ms | Loss: 40.287 | Acc: 46.149% (10042/2176 170/391 ===========>.............]  Step: 50ms | Tot: 8s653ms | Loss: 40.290 | Acc: 46.080% (10263/2227 174/391 ====>.............]  Step: 52ms | Tot: 8s857ms | Loss: 40.290 | Acc: 46.045% (10491/2278 178/391 ====>.............]  Step: 47ms | Tot: 9s7ms | Loss: 40.290 | Acc: 45.999% (10657/2316 181/391 ......]  Step: 47ms | Tot: 9s55ms | Loss: 40.289 | Acc: 46.012% (10719/2329 182/391 ============>............]  Step: 46ms | Tot: 9s784ms | Loss: 40.293 | Acc: 45.927% (11581/2521 197/391 198/391 .....]  Step: 49ms | Tot: 11s355ms | Loss: 40.286 | Acc: 46.155% (13470/2918 228/391 ==============>..........]  Step: 53ms | Tot: 11s409ms | Loss: 40.286 | Acc: 46.145% (13526/2931 229/391 ........]  Step: 47ms | Tot: 11s654ms | Loss: 40.285 | Acc: 46.154% (13824/2995 234/39 237/391 ===========>.........]  Step: 51ms | Tot: 11s853ms | Loss: 40.287 | Acc: 46.120% (14050/30 238/391 258/39 259/391 260/39 270/39 271/ 274/39 275/391 >.......]  Step: 47ms | Tot: 13s832ms | Loss: 40.288 | Acc: 46.094% (16343/3545 277/391 ====>.......]  Step: 51ms | Tot: 13s884ms | Loss: 40.288 | Acc: 46.094% (16402/3558 278/391 280/391 281/391 282/391 ====>......]  Step: 51ms | Tot: 14s186ms | Loss: 40.289 | Acc: 46.069% (16747/3635 284/391 =>......]  Step: 50ms | Tot: 14s486ms | Loss: 40.288 | Acc: 46.080% (17105/3712 290/39 295/39 306/39 312/391 314/391 336/39 349/39 351/39 353/391 ====================>..]  Step: 47ms | Tot: 18s341ms | Loss: 40.288 | Acc: 46.061% (20871/4531 354/39 364/391 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s794ms | Loss: 2.251 | Acc: 42.590% (4259/1000 79/79 ======>.........]  Step: 46ms | Tot: 2s359ms | Loss: 2.250 | Acc: 43.078% (2757/640 50/79 .........]  Step: 55ms | Tot: 2s415ms | Loss: 2.253 | Acc: 43.076% (2812/652 51/79 ============>.......]  Step: 54ms | Tot: 2s717ms | Loss: 2.251 | Acc: 42.941% (3133/729 57/79 ============>......]  Step: 46ms | Tot: 2s863ms | Loss: 2.256 | Acc: 42.760% (3284/768 60/79 61/79 ====================>....]  Step: 55ms | Tot: 3s119ms | Loss: 2.267 | Acc: 42.632% (3547/832 65/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(49.2864, device='cuda:0'), tensor(49.2853, device='cuda:0'), tensor(49.2643, device='cuda:0'), tensor(49.2664, device='cuda:0'), tensor(49.2528, device='cuda:0'), tensor(49.2090, device='cuda:0'), tensor(49.2343, device='cuda:0')]\n",
      "\n",
      "Epoch: 282\n",
      " [========================>]  Step: 51ms | Tot: 24s345ms | Loss: 40.254 | Acc: 46.264% (23132/5000 391/391 4/39 21/391 >......................]  Step: 64ms | Tot: 2s630ms | Loss: 40.294 | Acc: 45.201% (2430/537 42/391 .....]  Step: 68ms | Tot: 3s466ms | Loss: 40.286 | Acc: 45.526% (3205/704 55/391 ===>.....................]  Step: 66ms | Tot: 3s667ms | Loss: 40.283 | Acc: 45.663% (3390/7 58/391 59/391 60/391 61/391 ....]  Step: 69ms | Tot: 4s958ms | Loss: 40.275 | Acc: 45.984% (4591/998 78/39 82/39 91/391 ............]  Step: 69ms | Tot: 6s454ms | Loss: 40.259 | Acc: 46.101% (5960/1292 101/391 ........]  Step: 67ms | Tot: 6s586ms | Loss: 40.259 | Acc: 46.132% (6082/1318 103/391 105/39 111/391 129/39 150/39 151/391 =========>...............]  Step: 66ms | Tot: 9s894ms | Loss: 40.261 | Acc: 46.246% (9116/19 154/39 157/391 161/39 163/39 171/39 184/391 .........]  Step: 66ms | Tot: 13s457ms | Loss: 40.262 | Acc: 46.350% (12459/2688 210/391 =======>........]  Step: 64ms | Tot: 16s141ms | Loss: 40.260 | Acc: 46.285% (14989/3238 253/391 .]  Step: 66ms | Tot: 17s524ms | Loss: 40.258 | Acc: 46.324% (16306/3520 275/391 .]  Step: 68ms | Tot: 18s88ms | Loss: 40.258 | Acc: 46.319% (16838/3635 284/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s557ms | Loss: 2.251 | Acc: 42.760% (4276/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(48.8922, device='cuda:0'), tensor(48.8950, device='cuda:0'), tensor(48.9040, device='cuda:0'), tensor(48.8782, device='cuda:0'), tensor(48.9011, device='cuda:0'), tensor(49.0192, device='cuda:0'), tensor(49.0432, device='cuda:0')]\n",
      "\n",
      "Epoch: 283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 61ms | Tot: 24s372ms | Loss: 40.227 | Acc: 46.300% (23150/5000 391/391 ...............]  Step: 66ms | Tot: 8s909ms | Loss: 40.224 | Acc: 46.421% (8794/1894 148/39 164/391 =====>..............]  Step: 69ms | Tot: 9s986ms | Loss: 40.222 | Acc: 46.482% (9817/2112 165/391 =======>..............]  Step: 68ms | Tot: 10s55ms | Loss: 40.222 | Acc: 46.494% (9879/2124 166/39 167/391 171/391 ======>.............]  Step: 65ms | Tot: 10s580ms | Loss: 40.224 | Acc: 46.453% (10346/2227 174/39 177/391 =>.............]  Step: 68ms | Tot: 10s852ms | Loss: 40.225 | Acc: 46.414% (10575/2278 178/391 ........]  Step: 65ms | Tot: 11s751ms | Loss: 40.232 | Acc: 46.370% (11396/2457 192/39 194/391 ........]  Step: 68ms | Tot: 11s952ms | Loss: 40.232 | Acc: 46.306% (11558/2496 195/391 =>............]  Step: 69ms | Tot: 12s21ms | Loss: 40.233 | Acc: 46.297% (11615/2508 196/391 ==>............]  Step: 62ms | Tot: 12s84ms | Loss: 40.232 | Acc: 46.292% (11673/25 197/391 198/39 207/391 209/39 248/39 250/391  256/391 276/391 278/39 356/391 ======================>..]  Step: 64ms | Tot: 22s435ms | Loss: 40.228 | Acc: 46.365% (21365/4608 360/391  362/39 364/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s507ms | Loss: 2.248 | Acc: 42.970% (4297/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(48.6835, device='cuda:0'), tensor(48.7361, device='cuda:0'), tensor(48.7108, device='cuda:0'), tensor(48.6899, device='cuda:0'), tensor(48.7019, device='cuda:0'), tensor(48.8275, device='cuda:0'), tensor(48.8536, device='cuda:0')]\n",
      "\n",
      "Epoch: 284\n",
      " [========================>]  Step: 65ms | Tot: 23s175ms | Loss: 40.196 | Acc: 46.240% (23120/5000 391/391 Step: 58ms | Tot: 3s959ms | Loss: 40.207 | Acc: 45.849% (3932/857 67/391 ======>..................]  Step: 73ms | Tot: 6s290ms | Loss: 40.193 | Acc: 46.337% (6287/1356 106/391 .........]  Step: 76ms | Tot: 8s96ms | Loss: 40.195 | Acc: 46.134% (8031/1740 136/39 144/39 150/391 156/39 285/39 336/391 ============>...]  Step: 69ms | Tot: 19s824ms | Loss: 40.199 | Acc: 46.126% (20074/4352 340/391 ======================>..]  Step: 63ms | Tot: 20s297ms | Loss: 40.197 | Acc: 46.168% (20506/4441 347/391 353/39 362/391 ===========>.]  Step: 68ms | Tot: 21s478ms | Loss: 40.198 | Acc: 46.179% (21575/46 365/391   Step: 69ms | Tot: 21s548ms | Loss: 40.197 | Acc: 46.194% (21641/4684 366/391 =================>.]  Step: 63ms | Tot: 21s679ms | Loss: 40.198 | Acc: 46.198% (21761/4710 368/391 372/39 378/391 384/391 ====>]  Step: 66ms | Tot: 22s982ms | Loss: 40.196 | Acc: 46.231% (22960/4966 388/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s548ms | Loss: 2.253 | Acc: 42.510% (4251/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(48.3403, device='cuda:0'), tensor(48.3299, device='cuda:0'), tensor(48.3710, device='cuda:0'), tensor(48.3545, device='cuda:0'), tensor(48.3694, device='cuda:0'), tensor(48.6380, device='cuda:0'), tensor(48.6651, device='cuda:0')]\n",
      "\n",
      "Epoch: 285\n",
      " [========================>]  Step: 71ms | Tot: 25s598ms | Loss: 40.156 | Acc: 46.736% (23368/5000 391/391 ..............]  Step: 68ms | Tot: 725ms | Loss: 40.191 | Acc: 45.182% (694/153 12/391 17/391 .........]  Step: 69ms | Tot: 1s108ms | Loss: 40.187 | Acc: 44.705% (1030/230 18/39 20/391 .............]  Step: 62ms | Tot: 1s373ms | Loss: 40.185 | Acc: 45.206% (1273/281 22/391 23/391 =>.......................]  Step: 64ms | Tot: 1s574ms | Loss: 40.181 | Acc: 45.312% (1450/320 25/391 ......................]  Step: 67ms | Tot: 1s774ms | Loss: 40.185 | Acc: 45.452% (1629/3 28/39 29/391 32/391 35/391 ..................]  Step: 64ms | Tot: 2s502ms | Loss: 40.177 | Acc: 45.673% (2280/499 39/391 41/39 55/39 56/39 58/391 60/391 .........]  Step: 67ms | Tot: 4s487ms | Loss: 40.169 | Acc: 46.286% (4088/883 69/391 70/391 ................]  Step: 69ms | Tot: 4s619ms | Loss: 40.171 | Acc: 46.204% (4199/908 71/391 ............]  Step: 68ms | Tot: 4s882ms | Loss: 40.167 | Acc: 46.375% (4452/960 75/391 77/391 .................]  Step: 70ms | Tot: 5s599ms | Loss: 40.160 | Acc: 46.503% (5119/1100 86/391 ...............]  Step: 65ms | Tot: 5s993ms | Loss: 40.156 | Acc: 46.671% (5496/1177 92/391 ................]  Step: 69ms | Tot: 6s194ms | Loss: 40.154 | Acc: 46.595% (5666/1216 95/391 ..............]  Step: 64ms | Tot: 6s597ms | Loss: 40.158 | Acc: 46.488% (6010/1292 101/39 109/39 113/39 124/391 127/391 ..]  Step: 64ms | Tot: 8s374ms | Loss: 40.161 | Acc: 46.490% (7617/1638 128/391 133/391  134/391 135/391 139/391 ...]  Step: 69ms | Tot: 9s360ms | Loss: 40.160 | Acc: 46.602% (8530/1830 143/391 .............]  Step: 64ms | Tot: 9s624ms | Loss: 40.163 | Acc: 46.556% (8760/1881 147/39 150/39 151/391 ....]  Step: 69ms | Tot: 9s956ms | Loss: 40.161 | Acc: 46.608% (9068/1945 152/391 159/391 161/391 .]  Step: 68ms | Tot: 15s331ms | Loss: 40.154 | Acc: 46.911% (14171/3020 236/391 ==========>.........]  Step: 69ms | Tot: 15s804ms | Loss: 40.156 | Acc: 46.872% (14579/3110 243/39 248/39 254/39 255/39 270/39 272/391 278/39 281/391 ======>.......]  Step: 66ms | Tot: 18s375ms | Loss: 40.156 | Acc: 46.867% (16917/3609 282/391 ....]  Step: 63ms | Tot: 18s577ms | Loss: 40.157 | Acc: 46.886% (17104/3648 285/391 ....]  Step: 65ms | Tot: 18s910ms | Loss: 40.156 | Acc: 46.932% (17421/3712 290/39 293/391 295/391 297/39 299/39 303/391 305/391 315/39 318/39 321/39 324/391 =>...]  Step: 64ms | Tot: 21s665ms | Loss: 40.157 | Acc: 46.804% (19890/4249 332/391 =================>...]  Step: 65ms | Tot: 21s998ms | Loss: 40.160 | Acc: 46.724% (20155/4313 337/391 ==============>.]  Step: 64ms | Tot: 23s530ms | Loss: 40.160 | Acc: 46.689% (21574/4620 361/391 ====================>]  Step: 67ms | Tot: 25s392ms | Loss: 40.157 | Acc: 46.714% (23200/4966 388/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s647ms | Loss: 2.251 | Acc: 42.870% (4287/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(48.3264, device='cuda:0'), tensor(48.3246, device='cuda:0'), tensor(48.3241, device='cuda:0'), tensor(48.3335, device='cuda:0'), tensor(48.3169, device='cuda:0'), tensor(48.4498, device='cuda:0'), tensor(48.4769, device='cuda:0')]\n",
      "\n",
      "Epoch: 286\n",
      " [========================>]  Step: 61ms | Tot: 24s134ms | Loss: 40.134 | Acc: 46.142% (23071/5000 391/391 ................]  Step: 62ms | Tot: 457ms | Loss: 40.210 | Acc: 44.141% (452/102 8/391 ...................]  Step: 65ms | Tot: 658ms | Loss: 40.181 | Acc: 45.170% (636/140 11/391 ............]  Step: 62ms | Tot: 859ms | Loss: 40.178 | Acc: 45.536% (816/179 14/39 19/391 .................]  Step: 67ms | Tot: 1s331ms | Loss: 40.171 | Acc: 45.573% (1225/268 21/39 22/39 23/391 =>.......................]  Step: 71ms | Tot: 1s534ms | Loss: 40.173 | Acc: 45.605% (1401/307 24/39 25/391 .................]  Step: 68ms | Tot: 1s664ms | Loss: 40.171 | Acc: 45.553% (1516/332 26/39 28/391 ...........]  Step: 68ms | Tot: 1s864ms | Loss: 40.175 | Acc: 45.205% (1678/3 29/391 .................]  Step: 64ms | Tot: 1s928ms | Loss: 40.173 | Acc: 45.312% (1740/384 30/39 31/391 ..................]  Step: 64ms | Tot: 2s269ms | Loss: 40.178 | Acc: 44.978% (2015/448 35/391 ......]  Step: 66ms | Tot: 3s48ms | Loss: 40.180 | Acc: 45.196% (2719/601 47/39 49/391 ..................]  Step: 69ms | Tot: 3s250ms | Loss: 40.175 | Acc: 45.203% (2893/640 50/39 211/39 233/391 ============>........]  Step: 70ms | Tot: 15s861ms | Loss: 40.136 | Acc: 46.180% (15073/3264 255/391 ======>........]  Step: 70ms | Tot: 15s993ms | Loss: 40.136 | Acc: 46.206% (15200/3289 257/39 259/391 ========>........]  Step: 63ms | Tot: 16s255ms | Loss: 40.136 | Acc: 46.205% (15436/3340 261/391 ====>........]  Step: 68ms | Tot: 16s456ms | Loss: 40.137 | Acc: 46.185% (15607/3379 264/391 =>........]  Step: 60ms | Tot: 16s586ms | Loss: 40.137 | Acc: 46.202% (15731/3404 266/391 272/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s561ms | Loss: 2.247 | Acc: 42.900% (4290/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(48.1606, device='cuda:0'), tensor(48.1277, device='cuda:0'), tensor(48.1196, device='cuda:0'), tensor(48.1521, device='cuda:0'), tensor(48.1397, device='cuda:0'), tensor(48.2620, device='cuda:0'), tensor(48.2879, device='cuda:0')]\n",
      "\n",
      "Epoch: 287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 63ms | Tot: 24s877ms | Loss: 40.105 | Acc: 46.390% (23195/5000 391/391 ..........]  Step: 71ms | Tot: 450ms | Loss: 40.172 | Acc: 44.629% (457/102 8/391 9/391 ..................]  Step: 63ms | Tot: 712ms | Loss: 40.130 | Acc: 46.159% (709/153 12/391 16/39 19/391 ...........]  Step: 66ms | Tot: 1s241ms | Loss: 40.113 | Acc: 46.445% (1189/256 20/391 =>.......................]  Step: 66ms | Tot: 1s308ms | Loss: 40.112 | Acc: 46.354% (1246/268 21/39 44/391 ...............]  Step: 66ms | Tot: 2s818ms | Loss: 40.148 | Acc: 45.365% (2613/576 45/39 50/39 69/39 91/391 ...]  Step: 66ms | Tot: 6s181ms | Loss: 40.113 | Acc: 46.078% (5721/1241 97/391 .................]  Step: 65ms | Tot: 6s514ms | Loss: 40.114 | Acc: 46.040% (6011/1305 102/39 104/391 ..........]  Step: 66ms | Tot: 6s714ms | Loss: 40.112 | Acc: 46.257% (6217/1344 105/391 >..................]  Step: 68ms | Tot: 6s847ms | Loss: 40.111 | Acc: 46.298% (6341/13 107/391 ...............]  Step: 62ms | Tot: 7s47ms | Loss: 40.115 | Acc: 46.229% (6509/1408 110/39 117/391 ]  Step: 64ms | Tot: 7s575ms | Loss: 40.114 | Acc: 46.220% (6981/1510 118/39 122/391 .........]  Step: 61ms | Tot: 8s583ms | Loss: 40.117 | Acc: 46.264% (7876/1702 133/391 ==>................]  Step: 69ms | Tot: 8s652ms | Loss: 40.117 | Acc: 46.216% (7927/1715 134/391 ====>................]  Step: 71ms | Tot: 8s788ms | Loss: 40.119 | Acc: 46.151% (8034/1740 136/391 =====>...............]  Step: 70ms | Tot: 9s471ms | Loss: 40.118 | Acc: 46.254% (8644/1868 146/39 151/391 =>...............]  Step: 70ms | Tot: 10s159ms | Loss: 40.115 | Acc: 46.369% (9259/1996 156/391 =====>..............]  Step: 64ms | Tot: 10s291ms | Loss: 40.115 | Acc: 46.390% (9382/2022 158/391 ..]  Step: 67ms | Tot: 10s945ms | Loss: 40.110 | Acc: 46.447% (9988/2150 168/391 ==>..............]  Step: 63ms | Tot: 11s147ms | Loss: 40.110 | Acc: 46.482% (10174/2188 171/391 ===>..............]  Step: 69ms | Tot: 11s216ms | Loss: 40.110 | Acc: 46.489% (10235/2201 172/391 173/391 ...........]  Step: 69ms | Tot: 11s479ms | Loss: 40.109 | Acc: 46.507% (10477/2252 176/39 185/39 187/39 194/391 ====>............]  Step: 66ms | Tot: 12s922ms | Loss: 40.113 | Acc: 46.327% (11741/2534 198/391 200/391 ============>............]  Step: 65ms | Tot: 13s186ms | Loss: 40.111 | Acc: 46.415% (12001/2585 202/391 206/391 214/39 235/39 247/391 271/391 285/391 ================>......]  Step: 70ms | Tot: 18s470ms | Loss: 40.110 | Acc: 46.518% (17327/3724 291/39 304/39 307/391 ..]  Step: 75ms | Tot: 20s547ms | Loss: 40.108 | Acc: 46.420% (19192/4134 323/391 ====================>....]  Step: 65ms | Tot: 20s673ms | Loss: 40.108 | Acc: 46.428% (19314/4160 325/391 ==============>....]  Step: 73ms | Tot: 20s809ms | Loss: 40.108 | Acc: 46.438% (19437/4185 327/ 328/391 .]  Step: 67ms | Tot: 21s476ms | Loss: 40.109 | Acc: 46.374% (20004/4313 337/39 338/39 354/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s570ms | Loss: 2.245 | Acc: 42.620% (4262/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(47.9443, device='cuda:0'), tensor(47.9431, device='cuda:0'), tensor(47.9569, device='cuda:0'), tensor(47.9590, device='cuda:0'), tensor(47.9479, device='cuda:0'), tensor(48.0738, device='cuda:0'), tensor(48.1033, device='cuda:0')]\n",
      "\n",
      "Epoch: 288\n",
      " [========================>]  Step: 62ms | Tot: 24s234ms | Loss: 40.078 | Acc: 46.408% (23204/5000 391/391 91 .............]  Step: 67ms | Tot: 5s221ms | Loss: 40.100 | Acc: 46.029% (5008/1088 85/391 88/391 89/391 .................]  Step: 64ms | Tot: 5s555ms | Loss: 40.095 | Acc: 46.224% (5325/1152 90/39 91/391 ........]  Step: 61ms | Tot: 5s825ms | Loss: 40.088 | Acc: 46.360% (5578/1203 94/39 112/39 121/391 .....]  Step: 59ms | Tot: 7s984ms | Loss: 40.086 | Acc: 46.271% (7581/1638 128/39 142/391 ..........]  Step: 68ms | Tot: 10s477ms | Loss: 40.079 | Acc: 46.515% (9943/2137 167/39 169/39 171/391 173/391 ======>.............]  Step: 68ms | Tot: 10s939ms | Loss: 40.083 | Acc: 46.341% (10321/2227 174/391 ...........]  Step: 69ms | Tot: 11s140ms | Loss: 40.083 | Acc: 46.319% (10494/2265 177/391 .............]  Step: 66ms | Tot: 11s525ms | Loss: 40.085 | Acc: 46.218% (10826/2342 183/391 185/391 =========>.............]  Step: 69ms | Tot: 11s725ms | Loss: 40.085 | Acc: 46.241% (11009/2380 186/39 190/39 191/391 195/391 ===>............]  Step: 67ms | Tot: 12s434ms | Loss: 40.089 | Acc: 46.133% (11633/2521 197/391 199/391 ........]  Step: 69ms | Tot: 12s635ms | Loss: 40.087 | Acc: 46.172% (11820/2560 200/39 202/391 ==============>......]  Step: 68ms | Tot: 17s839ms | Loss: 40.083 | Acc: 46.329% (16901/3648 285/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s504ms | Loss: 2.246 | Acc: 42.660% (4266/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(47.9216, device='cuda:0'), tensor(47.9293, device='cuda:0'), tensor(47.9132, device='cuda:0'), tensor(47.9111, device='cuda:0'), tensor(47.9164, device='cuda:0'), tensor(47.8864, device='cuda:0'), tensor(47.9166, device='cuda:0')]\n",
      "\n",
      "Epoch: 289\n",
      " [========================>]  Step: 63ms | Tot: 25s914ms | Loss: 40.045 | Acc: 46.566% (23283/5000 391/391 .......]  Step: 69ms | Tot: 384ms | Loss: 40.141 | Acc: 45.312% (406/89 7/391 ...................]  Step: 68ms | Tot: 586ms | Loss: 40.095 | Acc: 46.797% (599/128 10/391 11/391 ..........]  Step: 69ms | Tot: 1s615ms | Loss: 40.077 | Acc: 46.575% (1550/332 26/391 27/39 30/391 ..................]  Step: 63ms | Tot: 1s940ms | Loss: 40.077 | Acc: 46.497% (1845/396 31/391 35/391 ..................]  Step: 66ms | Tot: 2s403ms | Loss: 40.091 | Acc: 46.217% (2248/4 38/39 41/391 .................]  Step: 68ms | Tot: 2s674ms | Loss: 40.090 | Acc: 46.280% (2488/537 42/391 43/39 51/391 52/391 ................]  Step: 64ms | Tot: 3s523ms | Loss: 40.085 | Acc: 46.378% (3265/704 55/391 ..........]  Step: 63ms | Tot: 4s309ms | Loss: 40.069 | Acc: 46.455% (3984/857 67/391 ....]  Step: 67ms | Tot: 4s510ms | Loss: 40.064 | Acc: 46.507% (4167/896 70/391 ..........]  Step: 69ms | Tot: 4s579ms | Loss: 40.064 | Acc: 46.446% (4221/908 71/391 ...............]  Step: 63ms | Tot: 5s418ms | Loss: 40.060 | Acc: 46.661% (5017/1075 84/391 85/39 87/39 90/391 ................]  Step: 65ms | Tot: 5s881ms | Loss: 40.054 | Acc: 46.841% (5456/1164 91/391 .......]  Step: 65ms | Tot: 6s861ms | Loss: 40.048 | Acc: 46.949% (6370/1356 106/39 107/39 108/391 .................]  Step: 68ms | Tot: 7s192ms | Loss: 40.051 | Acc: 46.854% (6657/14 111/39 112/39 114/391 ======>.................]  Step: 67ms | Tot: 7s457ms | Loss: 40.052 | Acc: 46.760% (6883/1472 115/391 ............]  Step: 67ms | Tot: 7s868ms | Loss: 40.048 | Acc: 46.959% (7273/1548 121/39 126/391 ===>................]  Step: 65ms | Tot: 8s737ms | Loss: 40.049 | Acc: 46.770% (8022/1715 134/39 142/39 152/391 ====>...............]  Step: 71ms | Tot: 10s162ms | Loss: 40.047 | Acc: 46.779% (9281/1984 155/39 178/391 186/391 .]  Step: 62ms | Tot: 12s521ms | Loss: 40.052 | Acc: 46.624% (11339/2432 190/39 194/391 198/391 214/391 222/391 233/391 >.......]  Step: 68ms | Tot: 18s138ms | Loss: 40.046 | Acc: 46.646% (16300/3494 273/39 275/391 ============>.......]  Step: 66ms | Tot: 18s593ms | Loss: 40.045 | Acc: 46.685% (16732/3584 280/391   Step: 67ms | Tot: 18s726ms | Loss: 40.044 | Acc: 46.689% (16853/3609 282/391 283/391 ==============>......]  Step: 69ms | Tot: 18s929ms | Loss: 40.045 | Acc: 46.664% (17023/3648 285/39 296/391 ===================>.....]  Step: 65ms | Tot: 20s553ms | Loss: 40.047 | Acc: 46.597% (18430/3955 309/391 ================>....]  Step: 68ms | Tot: 21s16ms | Loss: 40.047 | Acc: 46.561% (18833/4044 316/391 320/39 322/39 325/391 326/391 =============>...]  Step: 66ms | Tot: 21s945ms | Loss: 40.046 | Acc: 46.589% (19679/4224 330/391 ==========>...]  Step: 69ms | Tot: 22s710ms | Loss: 40.048 | Acc: 46.567% (20385/4377 342/391 =========>...]  Step: 62ms | Tot: 22s773ms | Loss: 40.047 | Acc: 46.588% (20454/4390 343/39 349/39 352/391 .]  Step: 64ms | Tot: 24s219ms | Loss: 40.047 | Acc: 46.618% (21780/4672 365/391 ===========>.]  Step: 66ms | Tot: 24s285ms | Loss: 40.046 | Acc: 46.638% (21849/4684 366/391 380/39 385/39 386/391 =================>]  Step: 69ms | Tot: 25s719ms | Loss: 40.045 | Acc: 46.565% (23126/4966 388/39 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s567ms | Loss: 2.249 | Acc: 42.750% (4275/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(47.7347, device='cuda:0'), tensor(47.7183, device='cuda:0'), tensor(47.7421, device='cuda:0'), tensor(47.7269, device='cuda:0'), tensor(47.7293, device='cuda:0'), tensor(47.7001, device='cuda:0'), tensor(47.7308, device='cuda:0')]\n",
      "\n",
      "Epoch: 290\n",
      " [========================>]  Step: 65ms | Tot: 25s874ms | Loss: 40.017 | Acc: 46.564% (23282/50000389/391 ..................]  Step: 67ms | Tot: 515ms | Loss: 40.052 | Acc: 46.962% (541/115 9/391 20/391 ............]  Step: 66ms | Tot: 1s655ms | Loss: 40.017 | Acc: 47.055% (1566/332 26/39 30/39 34/391 ................]  Step: 70ms | Tot: 2s442ms | Loss: 40.044 | Acc: 46.402% (2257/486 38/391 ..................]  Step: 61ms | Tot: 2s504ms | Loss: 40.043 | Acc: 46.414% (2317/499 39/391 .....]  Step: 67ms | Tot: 2s705ms | Loss: 40.045 | Acc: 46.280% (2488/537 42/39 44/39 47/391 55/39 66/391 ...................]  Step: 65ms | Tot: 5s65ms | Loss: 40.027 | Acc: 46.354% (4628/998 78/391 ....]  Step: 69ms | Tot: 5s528ms | Loss: 40.024 | Acc: 46.406% (5049/1088 85/391 ........]  Step: 64ms | Tot: 5s730ms | Loss: 40.022 | Acc: 46.467% (5234/1126 88/391 96/391 ...........]  Step: 68ms | Tot: 6s455ms | Loss: 40.023 | Acc: 46.402% (5880/1267 99/39 104/391 120/391 ......]  Step: 74ms | Tot: 8s61ms | Loss: 40.023 | Acc: 46.284% (7287/1574 123/391 124/391 ......]  Step: 70ms | Tot: 8s325ms | Loss: 40.023 | Acc: 46.278% (7523/1625 127/391 132/39 152/39 158/39 182/391 >.............]  Step: 72ms | Tot: 12s209ms | Loss: 40.028 | Acc: 46.364% (10979/2368 185/391 ...]  Step: 62ms | Tot: 12s409ms | Loss: 40.028 | Acc: 46.380% (11161/24 188/391 ==>...........]  Step: 62ms | Tot: 13s628ms | Loss: 40.028 | Acc: 46.314% (12212/2636 206/391 ==============>..........]  Step: 68ms | Tot: 15s292ms | Loss: 40.023 | Acc: 46.354% (13706/2956 231/391 ==>..........]  Step: 63ms | Tot: 15s492ms | Loss: 40.022 | Acc: 46.371% (13889/29 234/391 244/391 =========>.........]  Step: 69ms | Tot: 16s503ms | Loss: 40.020 | Acc: 46.439% (14801/3187 249/39 256/391 ================>........]  Step: 68ms | Tot: 17s581ms | Loss: 40.021 | Acc: 46.427% (15748/3392 265/391 .....]  Step: 61ms | Tot: 18s310ms | Loss: 40.020 | Acc: 46.490% (16424/3532 276/391 =====>.......]  Step: 71ms | Tot: 18s511ms | Loss: 40.019 | Acc: 46.511% (16610/3571 279/391 283/391 ==>......]  Step: 70ms | Tot: 18s903ms | Loss: 40.020 | Acc: 46.478% (16955/3648 285/391 >......]  Step: 62ms | Tot: 19s502ms | Loss: 40.019 | Acc: 46.527% (17509/3763 294/391 =================>.....]  Step: 68ms | Tot: 20s113ms | Loss: 40.021 | Acc: 46.460% (18019/3878 303/391 =====>.....]  Step: 63ms | Tot: 20s445ms | Loss: 40.024 | Acc: 46.378% (18284/3942 308/391 ========>....]  Step: 62ms | Tot: 20s849ms | Loss: 40.023 | Acc: 46.355% (18631/4019 314/391 =========>....]  Step: 70ms | Tot: 21s445ms | Loss: 40.022 | Acc: 46.331% (19155/4134 323/391 ...]  Step: 70ms | Tot: 21s969ms | Loss: 40.021 | Acc: 46.349% (19637/4236 331/391 >...]  Step: 69ms | Tot: 22s484ms | Loss: 40.022 | Acc: 46.370% (20121/4339 339/391 =====>...]  Step: 70ms | Tot: 22s616ms | Loss: 40.022 | Acc: 46.339% (20226/4364 341/391 ====>...]  Step: 71ms | Tot: 22s878ms | Loss: 40.021 | Acc: 46.395% (20488/4416 345/39 349/391 ==>..]  Step: 72ms | Tot: 23s533ms | Loss: 40.020 | Acc: 46.439% (21102/4544 355/391 ========>..]  Step: 70ms | Tot: 23s795ms | Loss: 40.020 | Acc: 46.425% (21333/4595 359/39 361/39 363/391 ===============>.]  Step: 70ms | Tot: 24s826ms | Loss: 40.018 | Acc: 46.529% (22334/4800 375/39 379/391 390/391 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s596ms | Loss: 2.251 | Acc: 42.720% (4272/1000 79/79 =========>........]  Step: 45ms | Tot: 2s442ms | Loss: 2.250 | Acc: 43.084% (2978/691 54/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(47.4014, device='cuda:0'), tensor(47.3786, device='cuda:0'), tensor(47.3767, device='cuda:0'), tensor(47.3842, device='cuda:0'), tensor(47.3923, device='cuda:0'), tensor(47.5172, device='cuda:0'), tensor(47.5446, device='cuda:0')]\n",
      "\n",
      "Epoch: 291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 63ms | Tot: 25s684ms | Loss: 39.976 | Acc: 46.842% (23421/5000 391/391 7/391 ....................]  Step: 65ms | Tot: 534ms | Loss: 40.066 | Acc: 45.747% (527/115 9/391 .....................]  Step: 69ms | Tot: 1s145ms | Loss: 40.022 | Acc: 46.658% (1075/230 18/391 ................]  Step: 63ms | Tot: 1s208ms | Loss: 40.011 | Acc: 46.957% (1142/243 19/39 20/391 .....................]  Step: 69ms | Tot: 1s347ms | Loss: 40.013 | Acc: 46.763% (1257/268 21/391 ...............]  Step: 62ms | Tot: 1s410ms | Loss: 40.011 | Acc: 46.768% (1317/281 22/391 25/39 28/39 33/391 37/391 50/39 57/391 ............]  Step: 63ms | Tot: 4s189ms | Loss: 40.007 | Acc: 46.521% (3811/819 64/391 ..................]  Step: 62ms | Tot: 4s725ms | Loss: 39.998 | Acc: 46.658% (4300/921 72/39 82/391 ...............]  Step: 62ms | Tot: 5s673ms | Loss: 39.992 | Acc: 46.503% (5119/1100 86/391 100/391  106/391 ======>..................]  Step: 65ms | Tot: 7s153ms | Loss: 39.986 | Acc: 46.622% (6445/1382 108/39 110/39 120/391 124/39 127/39 136/391 ===>..............]  Step: 63ms | Tot: 10s646ms | Loss: 39.981 | Acc: 46.836% (9592/2048 160/391 ======>..............]  Step: 61ms | Tot: 11s59ms | Loss: 39.981 | Acc: 46.861% (9957/2124 166/391 ===========>.............]  Step: 59ms | Tot: 11s733ms | Loss: 39.981 | Acc: 46.911% (10568/2252 176/39 184/391 ..........]  Step: 70ms | Tot: 12s472ms | Loss: 39.981 | Acc: 46.871% (11219/2393 187/391 >............]  Step: 70ms | Tot: 12s601ms | Loss: 39.982 | Acc: 46.863% (11337/2419 189/391 ..]  Step: 70ms | Tot: 12s733ms | Loss: 39.984 | Acc: 46.810% (11444/2444 191/391 ..........]  Step: 61ms | Tot: 13s67ms | Loss: 39.986 | Acc: 46.747% (11728/2508 196/39 200/391 ========>............]  Step: 70ms | Tot: 13s539ms | Loss: 39.986 | Acc: 46.721% (12140/2598 203/391 .......]  Step: 62ms | Tot: 14s137ms | Loss: 39.982 | Acc: 46.838% (12710/2713 212/391 ..]  Step: 61ms | Tot: 15s75ms | Loss: 39.979 | Acc: 46.882% (13562/2892 226/39 234/391 ==>.........]  Step: 70ms | Tot: 15s941ms | Loss: 39.979 | Acc: 46.891% (14345/3059 239/391 =========>.........]  Step: 71ms | Tot: 16s73ms | Loss: 39.979 | Acc: 46.907% (14470/3084 241/39 261/39 274/391 >.......]  Step: 62ms | Tot: 18s556ms | Loss: 39.977 | Acc: 46.985% (16719/3558 278/39 284/391 ]  Step: 69ms | Tot: 19s161ms | Loss: 39.978 | Acc: 46.946% (17246/3673 287/391 ..]  Step: 63ms | Tot: 19s626ms | Loss: 39.977 | Acc: 46.984% (17681/3763 294/391 ==================>......]  Step: 71ms | Tot: 19s828ms | Loss: 39.978 | Acc: 46.938% (17844/3801 297/391 .....]  Step: 64ms | Tot: 20s27ms | Loss: 39.978 | Acc: 46.956% (18031/3840 300/39 304/39 308/391 ========>.....]  Step: 63ms | Tot: 20s705ms | Loss: 39.978 | Acc: 46.875% (18600/3968 310/391 312/391 315/391 320/391 ==>....]  Step: 70ms | Tot: 21s574ms | Loss: 39.980 | Acc: 46.824% (19359/4134 323/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s566ms | Loss: 2.248 | Acc: 42.920% (4292/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(47.0567, device='cuda:0'), tensor(47.0600, device='cuda:0'), tensor(47.0497, device='cuda:0'), tensor(47.0481, device='cuda:0'), tensor(47.0734, device='cuda:0'), tensor(47.3320, device='cuda:0'), tensor(47.3623, device='cuda:0')]\n",
      "\n",
      "Epoch: 292\n",
      " [========================>]  Step: 67ms | Tot: 25s815ms | Loss: 39.953 | Acc: 46.840% (23420/5000 391/391  17/391 20/391 ..................]  Step: 61ms | Tot: 1s588ms | Loss: 39.979 | Acc: 46.312% (1482/320 25/39 29/391 38/391 ...........]  Step: 66ms | Tot: 2s586ms | Loss: 39.994 | Acc: 45.801% (2345/512 40/391 ......]  Step: 64ms | Tot: 3s39ms | Loss: 40.006 | Acc: 45.977% (2766/601 47/391 ...................]  Step: 68ms | Tot: 3s302ms | Loss: 39.999 | Acc: 46.124% (3011/652 51/39 55/39 57/391 ....................]  Step: 64ms | Tot: 4s212ms | Loss: 39.987 | Acc: 46.238% (3847/832 65/391 ...............]  Step: 68ms | Tot: 4s349ms | Loss: 39.984 | Acc: 46.327% (3973/857 67/391 .............]  Step: 63ms | Tot: 4s412ms | Loss: 39.981 | Acc: 46.369% (4036/8 68/391 69/391 ...............]  Step: 62ms | Tot: 5s77ms | Loss: 39.978 | Acc: 46.384% (4631/998 78/391 81/391 ................]  Step: 63ms | Tot: 5s340ms | Loss: 39.976 | Acc: 46.380% (4868/1049 82/391 ..........]  Step: 68ms | Tot: 5s408ms | Loss: 39.975 | Acc: 46.395% (4929/1062 83/391 ...]  Step: 66ms | Tot: 6s388ms | Loss: 39.966 | Acc: 46.708% (5859/1254 98/391 =>..................]  Step: 68ms | Tot: 6s649ms | Loss: 39.963 | Acc: 46.775% (6107/1305 102/39 103/39 106/39 110/39 113/39 117/391 >.................]  Step: 68ms | Tot: 7s718ms | Loss: 39.965 | Acc: 46.835% (7074/1510 118/39 119/391 120/391 .................]  Step: 68ms | Tot: 8s52ms | Loss: 39.965 | Acc: 46.729% (7357/1574 123/391 129/39 132/391 ====>................]  Step: 68ms | Tot: 9s34ms | Loss: 39.964 | Acc: 46.773% (8262/1766 138/391 ..]  Step: 65ms | Tot: 9s233ms | Loss: 39.967 | Acc: 46.698% (8428/1804 141/39 145/391 ]  Step: 68ms | Tot: 10s413ms | Loss: 39.962 | Acc: 46.860% (9537/2035 159/39 160/391 163/391 164/39 177/39 179/39 186/39 195/391 =======>............]  Step: 68ms | Tot: 12s873ms | Loss: 39.966 | Acc: 46.672% (11709/2508 196/391 ..]  Step: 68ms | Tot: 13s5ms | Loss: 39.965 | Acc: 46.705% (11837/2534 198/391 ==>...........]  Step: 65ms | Tot: 13s989ms | Loss: 39.960 | Acc: 46.857% (12775/2726 213/391 =======>...........]  Step: 67ms | Tot: 14s57ms | Loss: 39.960 | Acc: 46.857% (12835/2739 214/391 231/391 >..........]  Step: 68ms | Tot: 15s255ms | Loss: 39.960 | Acc: 46.915% (13932/2969 232/391 237/39 240/391 241/39 242/391 ==========>.........]  Step: 65ms | Tot: 15s981ms | Loss: 39.961 | Acc: 46.836% (14568/3110 243/391 245/391 247/39 250/39 253/391 =>........]  Step: 65ms | Tot: 16s709ms | Loss: 39.956 | Acc: 46.937% (15260/3251 254/39 255/391 =======>........]  Step: 63ms | Tot: 17s172ms | Loss: 39.956 | Acc: 46.902% (15669/3340 261/39 262/391 266/391 269/39 280/39 285/39 288/391 =====>......]  Step: 61ms | Tot: 19s168ms | Loss: 39.957 | Acc: 46.867% (17457/3724 291/391 ....]  Step: 64ms | Tot: 19s432ms | Loss: 39.957 | Acc: 46.880% (17702/3776 295/39 301/391 .]  Step: 63ms | Tot: 20s29ms | Loss: 39.958 | Acc: 46.847% (18229/3891 304/391 306/39 307/391  308/39 309/391 ============>.....]  Step: 68ms | Tot: 20s429ms | Loss: 39.958 | Acc: 46.835% (18584/3968 310/39 312/391 314/391 =============>....]  Step: 68ms | Tot: 20s759ms | Loss: 39.958 | Acc: 46.793% (18867/4032 315/391 ==========>....]  Step: 63ms | Tot: 20s823ms | Loss: 39.958 | Acc: 46.774% (18919/4044 316/391 ===============>....]  Step: 68ms | Tot: 21s285ms | Loss: 39.958 | Acc: 46.764% (19334/4134 323/391 ...]  Step: 65ms | Tot: 21s680ms | Loss: 39.958 | Acc: 46.799% (19708/4211 329/391 ====>...]  Step: 69ms | Tot: 21s942ms | Loss: 39.958 | Acc: 46.760% (19931/4262 333/39 334/391 337/39 342/391 ================>...]  Step: 64ms | Tot: 22s608ms | Loss: 39.957 | Acc: 46.745% (20523/4390 343/3 346/391 350/391 =============>..]  Step: 67ms | Tot: 23s272ms | Loss: 39.957 | Acc: 46.742% (21120/4518 353/391 357/391 361/391 364/39 376/391 ======>]  Step: 67ms | Tot: 24s897ms | Loss: 39.955 | Acc: 46.813% (22590/4825 377/391 =====>]  Step: 63ms | Tot: 25s221ms | Loss: 39.954 | Acc: 46.824% (22895/4889 382/39 383/391 385/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s570ms | Loss: 2.246 | Acc: 43.010% (4301/1000 79/79 ...................]  Step: 60ms | Tot: 800ms | Loss: 2.286 | Acc: 43.359% (999/230 18/7 19/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(47.0205, device='cuda:0'), tensor(47.0345, device='cuda:0'), tensor(46.8689, device='cuda:0'), tensor(47.0183, device='cuda:0'), tensor(46.9989, device='cuda:0'), tensor(47.1494, device='cuda:0'), tensor(47.1784, device='cuda:0')]\n",
      "\n",
      "Epoch: 293\n",
      " [========================>]  Step: 63ms | Tot: 24s273ms | Loss: 39.934 | Acc: 46.780% (23390/50000390/391 ep: 67ms | Tot: 394ms | Loss: 39.917 | Acc: 47.879% (429/89 7/39 13/391 16/391 20/391 22/391 ...............]  Step: 68ms | Tot: 1s574ms | Loss: 39.893 | Acc: 47.625% (1524/3 25/391 .....................]  Step: 69ms | Tot: 2s30ms | Loss: 39.918 | Acc: 46.899% (1921/409 32/391 35/391 .................]  Step: 64ms | Tot: 2s294ms | Loss: 39.919 | Acc: 46.810% (2157/460 36/391 39/391 ..............]  Step: 66ms | Tot: 2s561ms | Loss: 39.933 | Acc: 46.445% (2378/512 40/391 ..................]  Step: 64ms | Tot: 2s625ms | Loss: 39.942 | Acc: 46.380% (2434/524 41/39 48/391 49/391 ....................]  Step: 67ms | Tot: 3s341ms | Loss: 39.935 | Acc: 46.725% (3110/665 52/391 .....]  Step: 68ms | Tot: 3s605ms | Loss: 39.933 | Acc: 46.666% (3345/716 56/391 .................]  Step: 68ms | Tot: 3s674ms | Loss: 39.931 | Acc: 46.752% (3411/729 57/39 58/391 59/39 60/391 ..................]  Step: 64ms | Tot: 3s938ms | Loss: 39.932 | Acc: 46.580% (3637/780 61/391 ..................]  Step: 69ms | Tot: 4s523ms | Loss: 39.922 | Acc: 46.853% (4198/896 70/391 ......]  Step: 62ms | Tot: 4s585ms | Loss: 39.923 | Acc: 46.809% (4254/908 71/391 ..................]  Step: 69ms | Tot: 4s723ms | Loss: 39.921 | Acc: 46.864% (4379/934 73/391 ]  Step: 63ms | Tot: 4s786ms | Loss: 39.918 | Acc: 46.907% (4443/947 74/391 ...............]  Step: 68ms | Tot: 4s986ms | Loss: 39.922 | Acc: 46.865% (4619/985 77/39 94/391 ===>..................]  Step: 63ms | Tot: 6s177ms | Loss: 39.913 | Acc: 47.081% (5725/1216 95/39 99/391 ............]  Step: 64ms | Tot: 7s145ms | Loss: 39.926 | Acc: 47.017% (6620/1408 110/391 ==>.................]  Step: 70ms | Tot: 7s791ms | Loss: 39.928 | Acc: 47.012% (7221/1536 120/391 =>.................]  Step: 68ms | Tot: 8s62ms | Loss: 39.930 | Acc: 46.976% (7456/1587 124/391 126/391 160/39 177/391 ...........]  Step: 61ms | Tot: 11s576ms | Loss: 39.926 | Acc: 46.901% (10746/2291 179/391 ====>.............]  Step: 62ms | Tot: 11s848ms | Loss: 39.929 | Acc: 46.832% (10970/2342 183/391 =======>.............]  Step: 69ms | Tot: 12s49ms | Loss: 39.932 | Acc: 46.778% (11137/2380 186/39 191/391 ====>............]  Step: 70ms | Tot: 12s584ms | Loss: 39.936 | Acc: 46.706% (11598/2483 194/391 ======>............]  Step: 60ms | Tot: 12s917ms | Loss: 39.936 | Acc: 46.710% (11898/2547 199/391 ========>..........]  Step: 69ms | Tot: 14s480ms | Loss: 39.933 | Acc: 46.864% (13317/2841 222/391 =>.........]  Step: 71ms | Tot: 15s511ms | Loss: 39.936 | Acc: 46.763% (14246/3046 238/39 242/39 248/391 ================>........]  Step: 70ms | Tot: 17s43ms | Loss: 39.935 | Acc: 46.911% (15732/3353 262/391 287/391 >]  Step: 60ms | Tot: 23s755ms | Loss: 39.936 | Acc: 46.755% (22921/4902 383/391 387/39 388/391 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s563ms | Loss: 2.249 | Acc: 42.690% (4269/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(46.7047, device='cuda:0'), tensor(46.6762, device='cuda:0'), tensor(46.6926, device='cuda:0'), tensor(46.6629, device='cuda:0'), tensor(46.6997, device='cuda:0'), tensor(46.9661, device='cuda:0'), tensor(46.9940, device='cuda:0')]\n",
      "\n",
      "Epoch: 294\n",
      " [========================>]  Step: 59ms | Tot: 21s640ms | Loss: 39.895 | Acc: 47.044% (23522/5000 391/391 ................]  Step: 68ms | Tot: 458ms | Loss: 40.010 | Acc: 44.727% (458/102 8/391 ....]  Step: 69ms | Tot: 528ms | Loss: 39.986 | Acc: 45.399% (523/1 9/391 12/39 19/391 ...]  Step: 65ms | Tot: 1s256ms | Loss: 39.939 | Acc: 46.719% (1196/256 20/391 22/391  24/391 ............]  Step: 71ms | Tot: 1s591ms | Loss: 39.940 | Acc: 46.688% (1494/320 25/391 ...................]  Step: 67ms | Tot: 2s244ms | Loss: 39.936 | Acc: 46.272% (2073/448 35/39 36/391 .......]  Step: 67ms | Tot: 2s375ms | Loss: 39.942 | Acc: 46.368% (2196/473 37/391 58/391 59/391 60/391 105/39 142/391 >...............]  Step: 65ms | Tot: 9s683ms | Loss: 39.897 | Acc: 47.132% (9351/1984 155/39 162/391  163/391 ===>..............]  Step: 49ms | Tot: 10s249ms | Loss: 39.895 | Acc: 47.270% (10044/2124 166/39 169/39 189/39 190/39 192/39 194/391  195/39 197/391 198/391 ......]  Step: 51ms | Tot: 11s923ms | Loss: 39.899 | Acc: 46.997% (11971/2547 199/391 202/391  203/391 215/391 >...........]  Step: 51ms | Tot: 12s748ms | Loss: 39.897 | Acc: 47.070% (13014/2764 216/39 217/39 218/391 ======>..........]  Step: 49ms | Tot: 13s404ms | Loss: 39.896 | Acc: 47.114% (13810/2931 229/391 251/391 ==>........]  Step: 51ms | Tot: 14s524ms | Loss: 39.893 | Acc: 47.284% (15252/3225 252/391 ..]  Step: 48ms | Tot: 14s775ms | Loss: 39.893 | Acc: 47.279% (15553/3289 257/39 266/391 .....]  Step: 50ms | Tot: 15s352ms | Loss: 39.895 | Acc: 47.232% (16263/3443 269/39 271/39 275/39 289/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s542ms | Loss: 2.248 | Acc: 42.890% (4289/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(46.6786, device='cuda:0'), tensor(46.6433, device='cuda:0'), tensor(46.6736, device='cuda:0'), tensor(46.6479, device='cuda:0'), tensor(46.6574, device='cuda:0'), tensor(46.7828, device='cuda:0'), tensor(46.8137, device='cuda:0')]\n",
      "\n",
      "Epoch: 295\n",
      " [========================>]  Step: 62ms | Tot: 24s100ms | Loss: 39.861 | Acc: 47.246% (23623/5000 391/391 175/39 176/391 ......]  Step: 67ms | Tot: 16s46ms | Loss: 39.860 | Acc: 47.403% (15897/3353 262/39 264/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s541ms | Loss: 2.245 | Acc: 42.970% (4297/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(46.5058, device='cuda:0'), tensor(46.4576, device='cuda:0'), tensor(46.4905, device='cuda:0'), tensor(46.4941, device='cuda:0'), tensor(46.4793, device='cuda:0'), tensor(46.6025, device='cuda:0'), tensor(46.6329, device='cuda:0')]\n",
      "\n",
      "Epoch: 296\n",
      " [========================>]  Step: 66ms | Tot: 24s405ms | Loss: 39.828 | Acc: 47.052% (23526/5000 390/391 9 55/391 57/391 .......]  Step: 70ms | Tot: 3s766ms | Loss: 39.855 | Acc: 45.990% (3532/7 60/391 61/391 75/39 82/39 91/391 93/39 120/391 122/391 >.................]  Step: 68ms | Tot: 7s857ms | Loss: 39.835 | Acc: 46.623% (7400/1587 124/391 126/391 ........]  Step: 68ms | Tot: 8s895ms | Loss: 39.833 | Acc: 46.735% (8375/1792 140/391 171/391 ...]  Step: 65ms | Tot: 14s204ms | Loss: 39.834 | Acc: 46.844% (13491/2880 225/39 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s576ms | Loss: 2.248 | Acc: 42.910% (4291/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(46.3374, device='cuda:0'), tensor(46.2855, device='cuda:0'), tensor(46.2892, device='cuda:0'), tensor(46.3026, device='cuda:0'), tensor(46.2832, device='cuda:0'), tensor(46.4200, device='cuda:0'), tensor(46.4541, device='cuda:0')]\n",
      "\n",
      "Epoch: 297\n",
      " [========================>]  Step: 68ms | Tot: 24s485ms | Loss: 39.799 | Acc: 47.344% (23672/5000 391/391 p: 67ms | Tot: 1s84ms | Loss: 39.823 | Acc: 47.352% (1091/230 18/39 25/39 40/39 41/39 42/39 149/391 183/391 .........]  Step: 68ms | Tot: 11s915ms | Loss: 39.801 | Acc: 47.377% (11522/2432 190/391 191/391 198/391 330/391 =======>...]  Step: 64ms | Tot: 20s863ms | Loss: 39.801 | Acc: 47.358% (20186/4262 333/39 370/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s561ms | Loss: 2.251 | Acc: 42.710% (4271/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(45.9510, device='cuda:0'), tensor(45.9913, device='cuda:0'), tensor(45.9679, device='cuda:0'), tensor(45.9768, device='cuda:0'), tensor(45.9792, device='cuda:0'), tensor(46.2407, device='cuda:0'), tensor(46.2736, device='cuda:0')]\n",
      "\n",
      "Epoch: 298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 52ms | Tot: 23s753ms | Loss: 39.766 | Acc: 47.028% (23514/5000 391/391 .................]  Step: 66ms | Tot: 3s677ms | Loss: 39.778 | Acc: 46.593% (3638/780 61/391 63/391 .................]  Step: 59ms | Tot: 4s8ms | Loss: 39.773 | Acc: 46.650% (3941/844 66/39 217/391 =============>...........]  Step: 65ms | Tot: 13s203ms | Loss: 39.762 | Acc: 47.349% (13273/2803 219/391 230/391 245/391 ........]  Step: 68ms | Tot: 14s949ms | Loss: 39.762 | Acc: 47.283% (14949/3161 247/39 267/39 276/391 284/391 =============>......]  Step: 64ms | Tot: 17s734ms | Loss: 39.766 | Acc: 47.200% (17581/3724 291/39 303/391 >....]  Step: 69ms | Tot: 19s183ms | Loss: 39.769 | Acc: 47.074% (18920/4019 314/391 =============>....]  Step: 67ms | Tot: 19s454ms | Loss: 39.770 | Acc: 47.047% (19150/4070 318/391 ===============>....]  Step: 69ms | Tot: 19s970ms | Loss: 39.770 | Acc: 47.038% (19628/4172 326/391 ====================>....]  Step: 65ms | Tot: 20s36ms | Loss: 39.769 | Acc: 47.040% (19689/4185 327/391 ====================>....]  Step: 65ms | Tot: 20s101ms | Loss: 39.770 | Acc: 47.032% (19746/4198 328/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s576ms | Loss: 2.251 | Acc: 42.920% (4292/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(45.9756, device='cuda:0'), tensor(45.9276, device='cuda:0'), tensor(45.9425, device='cuda:0'), tensor(45.9191, device='cuda:0'), tensor(45.9265, device='cuda:0'), tensor(46.0629, device='cuda:0'), tensor(46.0943, device='cuda:0')]\n",
      "\n",
      "Epoch: 299\n",
      " [========================>]  Step: 68ms | Tot: 24s831ms | Loss: 39.735 | Acc: 47.530% (23765/5000 391/391 ............]  Step: 67ms | Tot: 340ms | Loss: 39.825 | Acc: 46.484% (357/76 6/391 49/39 79/39 81/391 82/391 .............]  Step: 69ms | Tot: 6s762ms | Loss: 39.729 | Acc: 47.972% (6693/1395 109/391 111/39 116/39 120/39 122/391 ........]  Step: 71ms | Tot: 7s680ms | Loss: 39.730 | Acc: 47.898% (7541/1574 123/391 125/391 .......]  Step: 69ms | Tot: 8s13ms | Loss: 39.731 | Acc: 47.821% (7835/1638 128/391 ===>................]  Step: 66ms | Tot: 8s216ms | Loss: 39.731 | Acc: 47.853% (8024/1676 131/391 154/391 ............]  Step: 67ms | Tot: 9s768ms | Loss: 39.726 | Acc: 47.947% (9574/1996 156/39 178/391 225/391 226/391 =======>.........]  Step: 68ms | Tot: 15s607ms | Loss: 39.738 | Acc: 47.531% (15149/3187 249/391 ....]  Step: 69ms | Tot: 15s808ms | Loss: 39.737 | Acc: 47.576% (15346/3225 252/391 269/391 .....]  Step: 67ms | Tot: 19s127ms | Loss: 39.739 | Acc: 47.600% (18583/3904 305/391 ====================>....]  Step: 68ms | Tot: 20s288ms | Loss: 39.738 | Acc: 47.583% (19612/4121 322/39 337/391 ===================>..]  Step: 65ms | Tot: 22s44ms | Loss: 39.737 | Acc: 47.564% (21187/4454 348/39 376/391 379/391 ========================>]  Step: 69ms | Tot: 24s104ms | Loss: 39.736 | Acc: 47.514% (23111/4864 380/391 >]  Step: 65ms | Tot: 24s569ms | Loss: 39.736 | Acc: 47.531% (23545/4953 387/391 389/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s579ms | Loss: 2.246 | Acc: 43.250% (4325/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(45.7534, device='cuda:0'), tensor(45.7535, device='cuda:0'), tensor(45.7590, device='cuda:0'), tensor(45.7318, device='cuda:0'), tensor(45.7591, device='cuda:0'), tensor(45.8827, device='cuda:0'), tensor(45.9142, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "#This is similar to the original paper's hyper-parameters for VGG. Also fails. \n",
    "\n",
    "\n",
    "best_sbp_acc = best_base_acc = 0 #reset best accuracy to save after running SBP\n",
    "\n",
    "equal_weights = [1,1,1,1,1,1,1]\n",
    "lr_x = [] #learning rate decay\n",
    "\n",
    "\n",
    "def learning_rate_calc(optimizer, epoch):\n",
    "    if epoch < 250:\n",
    "        return 1e-5\n",
    "    else: \n",
    "        return 1e-5 * (300-epoch)/(300-250)\n",
    "\n",
    "sbp_learningrate = 1e-5\n",
    "finetune_epoch = 300 ## that seems excessive\n",
    "equal_optimizer = optim.Adam(sbp_equal_net.parameters(),lr=sbp_learningrate, betas=[0.95,0.999])\n",
    "#equal_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_x)\n",
    "\n",
    "for epoch in range(0,300):\n",
    "    SBP_net_train(epoch,sbp_equal_net,optimizer=equal_optimizer,criterion=nn.CrossEntropyLoss(),lr_adjust=learning_rate_calc)\n",
    "    SBP_net_test(epoch,sbp_equal_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try New Initialize Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sbp_acc = best_base_acc = 0 #reset best accuracy to save after running SBP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 64ms | Tot: 22s529ms | Loss: 50.622 | Acc: 13.110% (6555/5000 391/391  43/391 51/391 .............]  Step: 63ms | Tot: 6s197ms | Loss: 52.345 | Acc: 2.683% (340/1267 99/391 123/39 126/39 146/39 156/39 242/391 256/39 280/391 ========>....]  Step: 64ms | Tot: 17s882ms | Loss: 50.833 | Acc: 10.308% (4209/4083 319/39 321/391 .]  Step: 58ms | Tot: 18s569ms | Loss: 50.801 | Acc: 10.731% (4519/4211 329/391 ======================>..]  Step: 63ms | Tot: 19s659ms | Loss: 50.749 | Acc: 11.403% (5050/4428 346/391 ]  Step: 67ms | Tot: 20s608ms | Loss: 50.708 | Acc: 11.964% (5513/4608 360/391 ==>.]  Step: 65ms | Tot: 21s409ms | Loss: 50.671 | Acc: 12.477% (5957/4774 373/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s649ms | Loss: 4.084 | Acc: 28.760% (2876/1000 79/79 /79 43/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(136.4969, device='cuda:0'), tensor(136.6378, device='cuda:0'), tensor(135.9762, device='cuda:0'), tensor(135.9727, device='cuda:0'), tensor(135.8758, device='cuda:0'), tensor(136.9909, device='cuda:0'), tensor(136.4814, device='cuda:0')]\n",
      "\n",
      "Epoch: 1\n",
      " [========================>]  Step: 68ms | Tot: 25s55ms | Loss: 48.965 | Acc: 35.976% (17988/5000 391/391   50/391 52/391 .................]  Step: 67ms | Tot: 3s471ms | Loss: 49.478 | Acc: 29.536% (2344/793 62/391 ..........]  Step: 66ms | Tot: 4s615ms | Loss: 49.450 | Acc: 30.301% (3064/1011 79/391 .............]  Step: 65ms | Tot: 4s680ms | Loss: 49.448 | Acc: 30.342% (3107/1024 80/391 ]  Step: 65ms | Tot: 4s814ms | Loss: 49.444 | Acc: 30.431% (3194/1049 82/391 118/391 130/391 141/391 ..........]  Step: 51ms | Tot: 10s435ms | Loss: 49.312 | Acc: 32.441% (6893/2124 166/391 ======>............]  Step: 68ms | Tot: 12s282ms | Loss: 49.270 | Acc: 32.825% (8193/2496 195/391 ..........]  Step: 62ms | Tot: 12s604ms | Loss: 49.261 | Acc: 33.023% (8454/2560 200/39 207/391 ====>...........]  Step: 67ms | Tot: 13s453ms | Loss: 49.240 | Acc: 33.293% (9077/2726 213/39 226/391 229/391 ===============>.........]  Step: 64ms | Tot: 15s423ms | Loss: 49.192 | Acc: 33.936% (10599/3123 244/391 ==========>.........]  Step: 69ms | Tot: 15s493ms | Loss: 49.190 | Acc: 33.964% (10651/3136 245/391 246/391 >........]  Step: 64ms | Tot: 16s413ms | Loss: 49.165 | Acc: 34.309% (11418/3328 260/391 ..]  Step: 60ms | Tot: 16s753ms | Loss: 49.158 | Acc: 34.381% (11662/3392 265/391 ===========>.......]  Step: 70ms | Tot: 17s76ms | Loss: 49.150 | Acc: 34.473% (11914/3456 270/391 ====>......]  Step: 67ms | Tot: 18s614ms | Loss: 49.112 | Acc: 34.803% (13097/3763 294/39 303/391 313/391 ======>....]  Step: 56ms | Tot: 20s287ms | Loss: 49.074 | Acc: 35.071% (14320/4083 319/39 339/391 =================>...]  Step: 69ms | Tot: 22s44ms | Loss: 49.034 | Acc: 35.437% (15649/4416 345/391 ===============>..]  Step: 64ms | Tot: 22s176ms | Loss: 49.031 | Acc: 35.496% (15766/4441 347/391 ======================>..]  Step: 69ms | Tot: 22s570ms | Loss: 49.022 | Acc: 35.537% (16057/4518 353/391 ==================>.]  Step: 66ms | Tot: 23s100ms | Loss: 49.010 | Acc: 35.585% (16443/4620 361/391 \n",
      " [========================>]  Step: 64ms | Tot: 3s937ms | Loss: 3.476 | Acc: 39.210% (3921/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(126.5271, device='cuda:0'), tensor(126.4764, device='cuda:0'), tensor(126.6217, device='cuda:0'), tensor(126.4917, device='cuda:0'), tensor(126.4697, device='cuda:0'), tensor(126.0857, device='cuda:0'), tensor(125.8198, device='cuda:0')]\n",
      "\n",
      "Epoch: 2\n",
      " [========================>]  Step: 66ms | Tot: 23s326ms | Loss: 47.825 | Acc: 44.256% (22128/5000 391/391 91 74/39 81/391 >...................]  Step: 70ms | Tot: 6s26ms | Loss: 48.240 | Acc: 41.863% (5037/1203 94/391 ==>..................]  Step: 69ms | Tot: 6s540ms | Loss: 48.226 | Acc: 42.028% (5541/1318 103/391 .............]  Step: 59ms | Tot: 6s742ms | Loss: 48.221 | Acc: 42.055% (5706/1356 106/391 ==>..............]  Step: 63ms | Tot: 10s23ms | Loss: 48.139 | Acc: 42.607% (8944/2099 164/39 167/391 =>...........]  Step: 31ms | Tot: 13s118ms | Loss: 48.067 | Acc: 42.872% (11908/2777 217/39 225/391 =>.........]  Step: 60ms | Tot: 14s901ms | Loss: 48.019 | Acc: 43.188% (13820/3200 250/391 ==========>........]  Step: 69ms | Tot: 15s102ms | Loss: 48.014 | Acc: 43.225% (13998/3238 253/391 ....]  Step: 63ms | Tot: 15s165ms | Loss: 48.013 | Acc: 43.239% (14058/3251 254/391 ===========>.......]  Step: 69ms | Tot: 16s787ms | Loss: 47.978 | Acc: 43.459% (15520/3571 279/39 300/391 304/39 313/39 355/391 360/391 372/391 =================>.]  Step: 67ms | Tot: 22s157ms | Loss: 47.849 | Acc: 44.184% (21095/4774 373/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s685ms | Loss: 2.999 | Acc: 43.610% (4361/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(116.2558, device='cuda:0'), tensor(116.3695, device='cuda:0'), tensor(116.0863, device='cuda:0'), tensor(116.0046, device='cuda:0'), tensor(116.0401, device='cuda:0'), tensor(116.5868, device='cuda:0'), tensor(117.3422, device='cuda:0')]\n",
      "\n",
      "Epoch: 3\n",
      " [========================>]  Step: 65ms | Tot: 24s390ms | Loss: 46.838 | Acc: 48.220% (24110/5000 391/391 ................]  Step: 66ms | Tot: 2s109ms | Loss: 47.271 | Acc: 45.265% (1912/422 33/39 54/391 .........]  Step: 61ms | Tot: 3s491ms | Loss: 47.251 | Acc: 45.384% (3195/704 55/391 ....]  Step: 66ms | Tot: 6s443ms | Loss: 47.188 | Acc: 46.225% (5976/1292 101/391 ..........]  Step: 65ms | Tot: 6s509ms | Loss: 47.186 | Acc: 46.239% (6037/1305 102/391 ..............]  Step: 61ms | Tot: 6s711ms | Loss: 47.182 | Acc: 46.310% (6224/1344 105/391 109/39 123/391 136/391 170/391 ............]  Step: 61ms | Tot: 10s912ms | Loss: 47.102 | Acc: 47.053% (10299/2188 171/39 212/391 ======>...........]  Step: 64ms | Tot: 13s880ms | Loss: 47.044 | Acc: 47.255% (13186/2790 218/391 ========>..........]  Step: 68ms | Tot: 14s523ms | Loss: 47.033 | Acc: 47.338% (13815/2918 228/39 229/39 233/39 292/391 =========>......]  Step: 66ms | Tot: 18s786ms | Loss: 46.948 | Acc: 47.946% (18227/3801 297/39 302/391 312/391 =========>..]  Step: 52ms | Tot: 22s419ms | Loss: 46.877 | Acc: 48.138% (21997/4569 357/39 361/391 \n",
      " [========================>]  Step: 46ms | Tot: 3s601ms | Loss: 2.666 | Acc: 46.030% (4603/1000 79/79 9 23/79   Step: 55ms | Tot: 1s108ms | Loss: 2.660 | Acc: 45.573% (1400/307 24/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(106.8116, device='cuda:0'), tensor(106.7177, device='cuda:0'), tensor(106.6758, device='cuda:0'), tensor(106.6513, device='cuda:0'), tensor(106.5643, device='cuda:0'), tensor(107.7705, device='cuda:0'), tensor(108.1797, device='cuda:0')]\n",
      "\n",
      "Epoch: 4\n",
      " [========================>]  Step: 68ms | Tot: 24s853ms | Loss: 45.977 | Acc: 50.768% (25384/5000 391/391 ...................]  Step: 62ms | Tot: 1s78ms | Loss: 46.402 | Acc: 47.702% (1038/217 17/391 18/391  21/39 36/391 ..........]  Step: 60ms | Tot: 2s439ms | Loss: 46.373 | Acc: 48.417% (2355/486 38/391 80/39 81/391 =====>...................]  Step: 70ms | Tot: 5s276ms | Loss: 46.311 | Acc: 49.507% (5323/1075 84/391 =========>...............]  Step: 62ms | Tot: 9s503ms | Loss: 46.230 | Acc: 49.985% (9725/1945 152/391 =========>...............]  Step: 62ms | Tot: 9s777ms | Loss: 46.227 | Acc: 50.035% (9991/1996 156/391 160/391 ==========>..............]  Step: 54ms | Tot: 10s524ms | Loss: 46.212 | Acc: 50.144% (10783/2150 168/391 169/391   Step: 64ms | Tot: 11s616ms | Loss: 46.197 | Acc: 50.059% (11854/2368 185/39 208/391 .........]  Step: 49ms | Tot: 13s398ms | Loss: 46.165 | Acc: 50.193% (13749/2739 214/391 ........]  Step: 49ms | Tot: 13s704ms | Loss: 46.158 | Acc: 50.241% (14148/2816 220/391 .]  Step: 69ms | Tot: 14s848ms | Loss: 46.137 | Acc: 50.317% (15393/3059 239/391 .]  Step: 67ms | Tot: 14s915ms | Loss: 46.136 | Acc: 50.316% (15457/3072 240/39 251/39 259/39 271/391 =================>.......]  Step: 66ms | Tot: 16s927ms | Loss: 46.101 | Acc: 50.500% (17582/3481 272/391 ====>......]  Step: 69ms | Tot: 18s284ms | Loss: 46.079 | Acc: 50.634% (18925/3737 292/391 ..]  Step: 63ms | Tot: 18s348ms | Loss: 46.078 | Acc: 50.645% (18994/3750 293/39 313/391 ==>....]  Step: 66ms | Tot: 20s426ms | Loss: 46.046 | Acc: 50.649% (21005/4147 324/391 ================>...]  Step: 67ms | Tot: 21s18ms | Loss: 46.036 | Acc: 50.699% (21610/4262 333/391  387/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s774ms | Loss: 2.439 | Acc: 47.330% (4733/1000 79/79  =>...................]  Step: 47ms | Tot: 840ms | Loss: 2.437 | Acc: 46.484% (1071/230 18/79 ..........]  Step: 46ms | Tot: 1s847ms | Loss: 2.434 | Acc: 47.155% (2354/499 39/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(98.9498, device='cuda:0'), tensor(98.9681, device='cuda:0'), tensor(99.0663, device='cuda:0'), tensor(99.0367, device='cuda:0'), tensor(98.9886, device='cuda:0'), tensor(99.6964, device='cuda:0'), tensor(99.7973, device='cuda:0')]\n",
      "\n",
      "Epoch: 5\n",
      " [========================>]  Step: 65ms | Tot: 24s905ms | Loss: 45.206 | Acc: 52.804% (26402/5000 391/391  45/39 47/391 .....................]  Step: 69ms | Tot: 3s230ms | Loss: 45.541 | Acc: 52.078% (3333/640 50/39 51/391 .....................]  Step: 70ms | Tot: 3s633ms | Loss: 45.534 | Acc: 51.897% (3720/716 56/39 59/391 ..]  Step: 70ms | Tot: 4s954ms | Loss: 45.515 | Acc: 51.562% (5148/998 78/391 =====>...................]  Step: 69ms | Tot: 5s85ms | Loss: 45.512 | Acc: 51.572% (5281/1024 80/391 .........]  Step: 69ms | Tot: 5s217ms | Loss: 45.507 | Acc: 51.648% (5421/1049 82/391 ]  Step: 67ms | Tot: 5s784ms | Loss: 45.496 | Acc: 51.708% (6023/1164 91/391 ====>................]  Step: 70ms | Tot: 8s75ms | Loss: 45.461 | Acc: 51.735% (8410/1625 127/39 152/391 .............]  Step: 66ms | Tot: 9s903ms | Loss: 45.434 | Acc: 51.830% (10283/1984 155/391 =========>...............]  Step: 69ms | Tot: 9s973ms | Loss: 45.434 | Acc: 51.793% (10342/1996 156/391 ==========>..............]  Step: 64ms | Tot: 10s105ms | Loss: 45.432 | Acc: 51.775% (10471/2022 158/391 ==========>..............]  Step: 65ms | Tot: 10s518ms | Loss: 45.425 | Acc: 51.867% (10888/2099 164/391 =====>............]  Step: 68ms | Tot: 13s153ms | Loss: 45.392 | Acc: 51.796% (13525/2611 204/391 ..........]  Step: 66ms | Tot: 14s365ms | Loss: 45.369 | Acc: 52.011% (14846/2854 223/391 239/391 ==========>.........]  Step: 62ms | Tot: 15s499ms | Loss: 45.352 | Acc: 52.100% (16005/3072 240/391 244/39 286/391 ====>.....]  Step: 61ms | Tot: 19s350ms | Loss: 45.290 | Acc: 52.505% (20229/3852 301/391 ===============>....]  Step: 63ms | Tot: 20s171ms | Loss: 45.278 | Acc: 52.570% (21129/4019 314/391 ==>..]  Step: 65ms | Tot: 22s554ms | Loss: 45.239 | Acc: 52.711% (23952/4544 355/391 ==================>..]  Step: 66ms | Tot: 22s754ms | Loss: 45.237 | Acc: 52.686% (24143/4582 358/391 ==========>..]  Step: 54ms | Tot: 22s890ms | Loss: 45.235 | Acc: 52.702% (24285/4608 360/39 387/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s754ms | Loss: 2.284 | Acc: 48.180% (4818/1000 79/79 /79 56/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(91.8363, device='cuda:0'), tensor(91.8560, device='cuda:0'), tensor(91.8947, device='cuda:0'), tensor(91.8801, device='cuda:0'), tensor(91.8891, device='cuda:0'), tensor(92.2297, device='cuda:0'), tensor(92.4095, device='cuda:0')]\n",
      "\n",
      "Epoch: 6\n",
      " [========================>]  Step: 59ms | Tot: 24s432ms | Loss: 44.495 | Acc: 53.842% (26921/5000 391/391  ==>......................]  Step: 65ms | Tot: 1s792ms | Loss: 44.833 | Acc: 52.723% (2227/422 33/391 ]  Step: 57ms | Tot: 4s707ms | Loss: 44.782 | Acc: 53.008% (5428/1024 80/391 =>...................]  Step: 69ms | Tot: 5s607ms | Loss: 44.763 | Acc: 53.333% (6417/1203 94/39 99/391 =>..................]  Step: 69ms | Tot: 6s575ms | Loss: 44.751 | Acc: 53.139% (7414/1395 109/391 ===>.................]  Step: 70ms | Tot: 7s445ms | Loss: 44.739 | Acc: 53.100% (8428/1587 124/391 ====>................]  Step: 60ms | Tot: 7s647ms | Loss: 44.736 | Acc: 53.113% (8634/1625 127/391 ==>................]  Step: 69ms | Tot: 8s159ms | Loss: 44.727 | Acc: 53.194% (9192/1728 135/391 ....]  Step: 63ms | Tot: 8s223ms | Loss: 44.727 | Acc: 53.171% (9256/1740 136/391 139/39 159/391 ....]  Step: 70ms | Tot: 10s693ms | Loss: 44.690 | Acc: 53.388% (11959/2240 175/391 ....]  Step: 65ms | Tot: 12s361ms | Loss: 44.670 | Acc: 53.269% (13705/2572 201/391 ====>............]  Step: 64ms | Tot: 12s564ms | Loss: 44.668 | Acc: 53.255% (13906/2611 204/391 ..]  Step: 68ms | Tot: 12s762ms | Loss: 44.665 | Acc: 53.310% (14125/2649 207/39 241/391 249/391 ..]  Step: 64ms | Tot: 15s722ms | Loss: 44.621 | Acc: 53.616% (17157/3200 250/391 ============>........]  Step: 68ms | Tot: 15s922ms | Loss: 44.617 | Acc: 53.678% (17383/3238 253/391 ..]  Step: 65ms | Tot: 17s348ms | Loss: 44.599 | Acc: 53.715% (18839/3507 274/391 ==============>.......]  Step: 66ms | Tot: 17s414ms | Loss: 44.598 | Acc: 53.707% (18905/3520 275/391 =======>.......]  Step: 74ms | Tot: 17s550ms | Loss: 44.596 | Acc: 53.709% (19043/3545 277/391 ============>......]  Step: 70ms | Tot: 18s60ms | Loss: 44.588 | Acc: 53.750% (19608/3648 285/391 323/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s552ms | Loss: 2.176 | Acc: 48.720% (4872/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(84.9032, device='cuda:0'), tensor(84.9379, device='cuda:0'), tensor(84.8159, device='cuda:0'), tensor(84.8714, device='cuda:0'), tensor(84.6508, device='cuda:0'), tensor(85.2766, device='cuda:0'), tensor(85.1808, device='cuda:0')]\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 68ms | Tot: 23s146ms | Loss: 43.822 | Acc: 54.662% (27331/5000 391/391  Step: 71ms | Tot: 1s62ms | Loss: 44.140 | Acc: 54.609% (1398/256 20/391 30/391 ==>......................]  Step: 48ms | Tot: 2s104ms | Loss: 44.139 | Acc: 53.652% (2747/512 40/391 .......]  Step: 42ms | Tot: 2s619ms | Loss: 44.131 | Acc: 53.799% (3512/652 51/391 >....................]  Step: 67ms | Tot: 3s564ms | Loss: 44.112 | Acc: 53.717% (4538/844 66/391 ..................]  Step: 67ms | Tot: 3s631ms | Loss: 44.114 | Acc: 53.638% (4600/857 67/391 ......]  Step: 64ms | Tot: 3s696ms | Loss: 44.113 | Acc: 53.653% (4670/870 68/391 .................]  Step: 66ms | Tot: 3s831ms | Loss: 44.110 | Acc: 53.683% (4810/896 70/391 71/391 ............]  Step: 66ms | Tot: 4s31ms | Loss: 44.108 | Acc: 53.660% (5014/934 73/391 82/391 95/391 ............]  Step: 64ms | Tot: 6s137ms | Loss: 44.066 | Acc: 53.936% (7249/1344 105/391 ..........]  Step: 62ms | Tot: 7s772ms | Loss: 44.045 | Acc: 54.087% (9000/1664 130/391 =====>...............]  Step: 68ms | Tot: 8s700ms | Loss: 44.034 | Acc: 54.096% (9971/1843 144/391 >...............]  Step: 66ms | Tot: 8s831ms | Loss: 44.033 | Acc: 54.120% (10114/1868 146/39 148/39 198/391 ===>............]  Step: 69ms | Tot: 12s142ms | Loss: 43.988 | Acc: 54.142% (13791/2547 199/391 ==========>........]  Step: 51ms | Tot: 15s143ms | Loss: 43.931 | Acc: 54.597% (18170/3328 260/39 265/391 ]  Step: 64ms | Tot: 18s292ms | Loss: 43.887 | Acc: 54.573% (21934/4019 314/391 323/39 336/39 352/391 =>..]  Step: 65ms | Tot: 20s816ms | Loss: 43.853 | Acc: 54.659% (24837/4544 355/39 383/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s767ms | Loss: 2.107 | Acc: 48.900% (4890/1000 79/79 79   Step: 51ms | Tot: 3s617ms | Loss: 2.109 | Acc: 49.013% (4768/972 76/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(78.2654, device='cuda:0'), tensor(78.2457, device='cuda:0'), tensor(78.2459, device='cuda:0'), tensor(78.2703, device='cuda:0'), tensor(78.2636, device='cuda:0'), tensor(78.8594, device='cuda:0'), tensor(78.9793, device='cuda:0')]\n",
      "\n",
      "Epoch: 8\n",
      " [========================>]  Step: 55ms | Tot: 24s578ms | Loss: 43.185 | Acc: 55.886% (27943/5000 391/391 .......]  Step: 65ms | Tot: 456ms | Loss: 43.500 | Acc: 55.990% (645/115 9/39 35/39 36/391 ==>......................]  Step: 64ms | Tot: 2s917ms | Loss: 43.492 | Acc: 55.120% (3316/601 47/391 ..............]  Step: 65ms | Tot: 4s582ms | Loss: 43.460 | Acc: 55.240% (5303/960 75/39 87/391 =>.................]  Step: 68ms | Tot: 7s134ms | Loss: 43.415 | Acc: 55.275% (8278/1497 117/39 118/391 151/391 .............]  Step: 67ms | Tot: 9s428ms | Loss: 43.383 | Acc: 55.454% (10931/1971 154/391 =====>..............]  Step: 67ms | Tot: 10s687ms | Loss: 43.367 | Acc: 55.555% (12302/2214 173/391 ===>............]  Step: 66ms | Tot: 11s931ms | Loss: 43.356 | Acc: 55.444% (13626/2457 192/39 194/391 202/391 ===========>...........]  Step: 62ms | Tot: 13s629ms | Loss: 43.331 | Acc: 55.667% (15462/2777 217/39 219/391 222/391 ..........]  Step: 64ms | Tot: 14s165ms | Loss: 43.324 | Acc: 55.715% (16046/2880 225/391 ========>..........]  Step: 65ms | Tot: 14s364ms | Loss: 43.323 | Acc: 55.650% (16241/2918 228/391 .]  Step: 56ms | Tot: 15s986ms | Loss: 43.297 | Acc: 55.910% (18106/3238 253/391 268/39 269/391 287/391 353/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s643ms | Loss: 2.051 | Acc: 49.540% (4954/1000 79/79  \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(72.4186, device='cuda:0'), tensor(72.5711, device='cuda:0'), tensor(72.5119, device='cuda:0'), tensor(72.5217, device='cuda:0'), tensor(72.5427, device='cuda:0'), tensor(72.9359, device='cuda:0'), tensor(73.0867, device='cuda:0')]\n",
      "\n",
      "Epoch: 9\n",
      " [========================>]  Step: 60ms | Tot: 24s919ms | Loss: 42.562 | Acc: 56.300% (28150/5000 391/391 391 23/39 60/39 96/391 =>..................]  Step: 64ms | Tot: 6s232ms | Loss: 42.799 | Acc: 55.734% (7134/1280 100/39 127/39 135/39 141/39 153/391 156/391 ...]  Step: 69ms | Tot: 10s555ms | Loss: 42.743 | Acc: 55.974% (11965/2137 167/391 ===========>.............]  Step: 67ms | Tot: 11s262ms | Loss: 42.737 | Acc: 55.890% (12734/2278 178/391 ..........]  Step: 66ms | Tot: 12s38ms | Loss: 42.728 | Acc: 55.835% (13579/2432 190/391 192/39 201/39 202/391 218/391 ==============>..........]  Step: 65ms | Tot: 14s434ms | Loss: 42.697 | Acc: 55.957% (16259/2905 227/391 .]  Step: 69ms | Tot: 14s503ms | Loss: 42.697 | Acc: 55.924% (16321/2918 228/391 ======>..........]  Step: 64ms | Tot: 14s887ms | Loss: 42.689 | Acc: 56.023% (16780/2995 234/391 239/391 ===============>.........]  Step: 66ms | Tot: 15s349ms | Loss: 42.683 | Acc: 56.072% (17297/3084 241/391 ....]  Step: 65ms | Tot: 17s463ms | Loss: 42.653 | Acc: 56.287% (20029/3558 278/391 .....]  Step: 65ms | Tot: 18s957ms | Loss: 42.635 | Acc: 56.318% (21626/3840 300/391 ===============>.....]  Step: 69ms | Tot: 19s156ms | Loss: 42.633 | Acc: 56.304% (21837/3878 303/391 ============>.....]  Step: 65ms | Tot: 19s287ms | Loss: 42.632 | Acc: 56.291% (21976/3904 305/39 310/39 313/391 324/39 329/391 ===========>...]  Step: 69ms | Tot: 21s881ms | Loss: 42.599 | Acc: 56.286% (24784/4403 344/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s563ms | Loss: 2.015 | Acc: 49.710% (4971/1000 79/79 /79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(66.8745, device='cuda:0'), tensor(66.8835, device='cuda:0'), tensor(66.9159, device='cuda:0'), tensor(66.9118, device='cuda:0'), tensor(66.9136, device='cuda:0'), tensor(67.4447, device='cuda:0'), tensor(67.6218, device='cuda:0')]\n",
      "\n",
      "Epoch: 10\n",
      " [========================>]  Step: 58ms | Tot: 22s794ms | Loss: 41.960 | Acc: 56.636% (28318/5000 391/391 ................]  Step: 67ms | Tot: 1s561ms | Loss: 42.257 | Acc: 56.190% (1870/332 26/391 =>....................]  Step: 49ms | Tot: 3s545ms | Loss: 42.226 | Acc: 56.013% (4732/844 66/391   Step: 49ms | Tot: 4s860ms | Loss: 42.201 | Acc: 55.953% (6589/1177 92/391 ======>..................]  Step: 55ms | Tot: 5s117ms | Loss: 42.196 | Acc: 55.992% (6952/1241 97/391 ........]  Step: 54ms | Tot: 5s217ms | Loss: 42.195 | Acc: 55.990% (7095/1267 99/391 149/391 ...........]  Step: 66ms | Tot: 8s289ms | Loss: 42.157 | Acc: 55.865% (10869/1945 152/391 214/391 218/391 >.....]  Step: 65ms | Tot: 17s646ms | Loss: 42.031 | Acc: 56.626% (21817/3852 301/391 ]  Step: 73ms | Tot: 17s782ms | Loss: 42.029 | Acc: 56.619% (21959/3878 303/ 306/391 339/391 ======================>..]  Step: 51ms | Tot: 20s592ms | Loss: 41.992 | Acc: 56.660% (25311/4467 349/391 ===============>..]  Step: 53ms | Tot: 20s694ms | Loss: 41.990 | Acc: 56.657% (25455/4492 351/391 373/391   Step: 46ms | Tot: 22s132ms | Loss: 41.968 | Acc: 56.630% (27545/4864 380/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s825ms | Loss: 1.992 | Acc: 49.770% (4977/1000 79/79 /7 57/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(61.8523, device='cuda:0'), tensor(61.8639, device='cuda:0'), tensor(61.8635, device='cuda:0'), tensor(61.8665, device='cuda:0'), tensor(61.8783, device='cuda:0'), tensor(62.3656, device='cuda:0'), tensor(62.4422, device='cuda:0')]\n",
      "\n",
      "Epoch: 11\n",
      " [========================>]  Step: 70ms | Tot: 23s931ms | Loss: 41.363 | Acc: 57.336% (28668/5000 391/391 .]  Step: 66ms | Tot: 2s403ms | Loss: 41.663 | Acc: 56.136% (2946/524 41/391 ....................]  Step: 68ms | Tot: 2s472ms | Loss: 41.663 | Acc: 56.101% (3016/537 42/391 43/391 ===>.....................]  Step: 68ms | Tot: 2s876ms | Loss: 41.650 | Acc: 56.462% (3469/614 48/391 ===>.....................]  Step: 67ms | Tot: 3s9ms | Loss: 41.648 | Acc: 56.312% (3604/640 50/391 ................]  Step: 66ms | Tot: 3s493ms | Loss: 41.646 | Acc: 56.290% (4179/742 58/39 60/391 71/391 ..............]  Step: 71ms | Tot: 5s246ms | Loss: 41.606 | Acc: 56.477% (6217/1100 86/39 88/391 ...............]  Step: 63ms | Tot: 5s919ms | Loss: 41.593 | Acc: 56.500% (7015/1241 97/391 .................]  Step: 64ms | Tot: 6s855ms | Loss: 41.584 | Acc: 56.482% (8025/1420 111/391 120/391 .........]  Step: 70ms | Tot: 8s187ms | Loss: 41.565 | Acc: 56.765% (9591/1689 132/39 133/391 142/391 ...........]  Step: 66ms | Tot: 9s460ms | Loss: 41.550 | Acc: 56.928% (11076/1945 152/39 160/391 ========>.............]  Step: 65ms | Tot: 10s932ms | Loss: 41.534 | Acc: 56.978% (12763/2240 175/391 177/39 208/391 .......]  Step: 66ms | Tot: 13s135ms | Loss: 41.509 | Acc: 57.001% (15322/2688 210/391 .......]  Step: 65ms | Tot: 13s336ms | Loss: 41.506 | Acc: 57.039% (15551/2726 213/391   Step: 67ms | Tot: 14s152ms | Loss: 41.495 | Acc: 57.080% (16439/2880 225/39 272/391 ===============>..]  Step: 63ms | Tot: 21s385ms | Loss: 41.395 | Acc: 57.327% (25609/4467 349/391 \n",
      " [========================>]  Step: 46ms | Tot: 3s763ms | Loss: 1.976 | Acc: 49.940% (4994/1000 79/79  \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(57.2142, device='cuda:0'), tensor(57.2104, device='cuda:0'), tensor(57.1982, device='cuda:0'), tensor(57.2164, device='cuda:0'), tensor(57.1370, device='cuda:0'), tensor(57.6846, device='cuda:0'), tensor(57.9341, device='cuda:0')]\n",
      "\n",
      "Epoch: 12\n",
      " [========================>]  Step: 63ms | Tot: 23s85ms | Loss: 40.780 | Acc: 57.578% (28789/5000 391/391    Step: 64ms | Tot: 6s688ms | Loss: 41.000 | Acc: 56.492% (8388/1484 116/39 123/391 =>............]  Step: 70ms | Tot: 11s352ms | Loss: 40.934 | Acc: 56.984% (14442/2534 198/391 204/391 ========>...........]  Step: 69ms | Tot: 11s936ms | Loss: 40.927 | Acc: 57.046% (15115/2649 207/391 208/39 217/39 228/39 256/39 307/391 ======>.....]  Step: 65ms | Tot: 18s10ms | Loss: 40.842 | Acc: 57.525% (22826/3968 310/391 ...]  Step: 64ms | Tot: 18s494ms | Loss: 40.837 | Acc: 57.517% (23338/4057 317/391 ====>....]  Step: 65ms | Tot: 19s160ms | Loss: 40.829 | Acc: 57.554% (24090/4185 327/391 ================>....]  Step: 68ms | Tot: 19s228ms | Loss: 40.828 | Acc: 57.546% (24160/4198 328/391 =====>..]  Step: 44ms | Tot: 20s388ms | Loss: 40.813 | Acc: 57.588% (25652/4454 348/391 =============>]  Step: 60ms | Tot: 23s22ms | Loss: 40.782 | Acc: 57.554% (28731/4992 390/391 \n",
      " [========================>]  Step: 59ms | Tot: 3s728ms | Loss: 1.960 | Acc: 50.090% (5009/1000 79/79 ============>...]  Step: 46ms | Tot: 3s299ms | Loss: 1.958 | Acc: 50.179% (4496/896 70/7 72/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(52.9738, device='cuda:0'), tensor(52.9748, device='cuda:0'), tensor(52.9563, device='cuda:0'), tensor(52.9672, device='cuda:0'), tensor(52.9245, device='cuda:0'), tensor(53.3449, device='cuda:0'), tensor(53.4812, device='cuda:0')]\n",
      "\n",
      "Epoch: 13\n",
      " [========================>]  Step: 63ms | Tot: 23s459ms | Loss: 40.203 | Acc: 57.984% (28992/5000 391/391 p: 70ms | Tot: 739ms | Loss: 40.510 | Acc: 56.055% (861/153 12/391 ...............]  Step: 68ms | Tot: 1s272ms | Loss: 40.483 | Acc: 57.617% (1475/256 20/391 ]  Step: 66ms | Tot: 1s667ms | Loss: 40.473 | Acc: 57.602% (1917/332 26/39 39/391 .................]  Step: 63ms | Tot: 3s373ms | Loss: 40.477 | Acc: 56.881% (3786/665 52/39 91/391 ......]  Step: 62ms | Tot: 9s573ms | Loss: 40.377 | Acc: 57.672% (11885/2060 161/391 .....]  Step: 70ms | Tot: 10s16ms | Loss: 40.372 | Acc: 57.678% (12403/2150 168/391 ==>.............]  Step: 66ms | Tot: 11s239ms | Loss: 40.360 | Acc: 57.658% (13801/2393 187/39 209/391 >...........]  Step: 67ms | Tot: 12s762ms | Loss: 40.344 | Acc: 57.653% (15497/2688 210/391 .]  Step: 65ms | Tot: 12s896ms | Loss: 40.341 | Acc: 57.731% (15666/2713 212/391 ==========>.....]  Step: 64ms | Tot: 18s449ms | Loss: 40.268 | Acc: 57.932% (22691/3916 306/391 ===========>.....]  Step: 68ms | Tot: 18s650ms | Loss: 40.266 | Acc: 57.949% (22920/3955 309/391 ==========>....]  Step: 65ms | Tot: 19s35ms | Loss: 40.261 | Acc: 57.944% (23363/4032 315/391 360/391 ============>.]  Step: 66ms | Tot: 22s304ms | Loss: 40.217 | Acc: 57.967% (27676/4774 373/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s658ms | Loss: 1.952 | Acc: 49.980% (4998/1000 79/79 /79 58/79 ...]  Step: 48ms | Tot: 2s825ms | Loss: 1.955 | Acc: 49.834% (3891/780 61/7 73/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(48.9581, device='cuda:0'), tensor(48.9618, device='cuda:0'), tensor(48.9125, device='cuda:0'), tensor(48.9363, device='cuda:0'), tensor(48.9143, device='cuda:0'), tensor(49.3374, device='cuda:0'), tensor(49.4604, device='cuda:0')]\n",
      "\n",
      "Epoch: 14\n",
      " [========================>]  Step: 69ms | Tot: 23s500ms | Loss: 39.626 | Acc: 58.426% (29213/5000 391/391 ..........]  Step: 67ms | Tot: 201ms | Loss: 39.892 | Acc: 60.547% (310/51 4/391 .....................]  Step: 64ms | Tot: 266ms | Loss: 39.928 | Acc: 59.219% (379/64 5/391 .....................]  Step: 67ms | Tot: 334ms | Loss: 39.953 | Acc: 58.203% (447/76 6/391 ....................]  Step: 58ms | Tot: 465ms | Loss: 39.952 | Acc: 57.324% (587/102 8/391  23/39 80/39 81/391 >...................]  Step: 66ms | Tot: 5s432ms | Loss: 39.868 | Acc: 57.922% (6376/1100 86/39 88/391 89/391 ===>................]  Step: 66ms | Tot: 8s276ms | Loss: 39.820 | Acc: 58.215% (9836/1689 132/391 ............]  Step: 65ms | Tot: 8s342ms | Loss: 39.819 | Acc: 58.218% (9911/1702 133/391 ======>..............]  Step: 69ms | Tot: 10s239ms | Loss: 39.795 | Acc: 58.510% (12507/2137 167/39 185/391 ======>............]  Step: 69ms | Tot: 12s77ms | Loss: 39.777 | Acc: 58.287% (14623/2508 196/391 ===>............]  Step: 63ms | Tot: 12s410ms | Loss: 39.773 | Acc: 58.318% (15004/2572 201/39 206/391 =============>...........]  Step: 63ms | Tot: 13s531ms | Loss: 39.759 | Acc: 58.358% (16359/2803 219/391 ==============>..........]  Step: 67ms | Tot: 13s667ms | Loss: 39.756 | Acc: 58.406% (16522/2828 221/391 =======>.........]  Step: 63ms | Tot: 14s714ms | Loss: 39.742 | Acc: 58.373% (17708/3033 237/391 =======>.........]  Step: 67ms | Tot: 14s853ms | Loss: 39.742 | Acc: 58.355% (17852/3059 239/39 240/391 320/391 328/391 373/391 374/391 ====================>]  Step: 67ms | Tot: 22s570ms | Loss: 39.635 | Acc: 58.438% (28200/4825 377/391 ====>]  Step: 63ms | Tot: 22s834ms | Loss: 39.632 | Acc: 58.446% (28503/4876 381/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s718ms | Loss: 1.943 | Acc: 50.120% (5012/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(45.2309, device='cuda:0'), tensor(45.2456, device='cuda:0'), tensor(45.2313, device='cuda:0'), tensor(45.2204, device='cuda:0'), tensor(45.2500, device='cuda:0'), tensor(45.6374, device='cuda:0'), tensor(45.7360, device='cuda:0')]\n",
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 69ms | Tot: 23s791ms | Loss: 39.050 | Acc: 59.016% (29508/5000 391/391 ....]  Step: 66ms | Tot: 335ms | Loss: 39.377 | Acc: 58.203% (447/76 6/391 .............]  Step: 70ms | Tot: 535ms | Loss: 39.353 | Acc: 57.639% (664/115 9/391 36/391 .........]  Step: 51ms | Tot: 2s502ms | Loss: 39.345 | Acc: 56.942% (3207/563 44/391  45/39 71/39 76/391 >..................]  Step: 69ms | Tot: 5s753ms | Loss: 39.280 | Acc: 58.002% (7350/1267 99/391 ======>..................]  Step: 68ms | Tot: 6s501ms | Loss: 39.268 | Acc: 58.246% (8201/1408 110/391 ========>................]  Step: 68ms | Tot: 7s753ms | Loss: 39.255 | Acc: 58.267% (9621/1651 129/391 =>.............]  Step: 61ms | Tot: 10s504ms | Loss: 39.217 | Acc: 58.612% (13054/2227 174/39 206/39 245/391 ========>........]  Step: 57ms | Tot: 15s465ms | Loss: 39.151 | Acc: 59.058% (19352/3276 256/391 ==================>..]  Step: 69ms | Tot: 21s255ms | Loss: 39.077 | Acc: 59.065% (26688/4518 353/391 =======================>.]  Step: 68ms | Tot: 22s193ms | Loss: 39.067 | Acc: 59.037% (27733/4697 367/391 =======>.]  Step: 64ms | Tot: 22s519ms | Loss: 39.064 | Acc: 59.033% (28109/4761 372/39 373/39 377/39 386/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s732ms | Loss: 1.937 | Acc: 50.100% (5010/1000 79/79 ]  Step: 50ms | Tot: 2s469ms | Loss: 1.939 | Acc: 49.850% (3318/665 52/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(41.8070, device='cuda:0'), tensor(41.8368, device='cuda:0'), tensor(41.8425, device='cuda:0'), tensor(41.8552, device='cuda:0'), tensor(41.8408, device='cuda:0'), tensor(42.2194, device='cuda:0'), tensor(42.3814, device='cuda:0')]\n",
      "\n",
      "Epoch: 16\n",
      " [========================>]  Step: 62ms | Tot: 23s834ms | Loss: 38.486 | Acc: 59.146% (29573/5000 391/391 ...]  Step: 64ms | Tot: 3s758ms | Loss: 38.752 | Acc: 58.284% (5073/870 68/391 ...................]  Step: 70ms | Tot: 4s767ms | Loss: 38.727 | Acc: 58.333% (6272/1075 84/391   Step: 66ms | Tot: 4s833ms | Loss: 38.727 | Acc: 58.309% (6344/1088 85/39 93/391 ....]  Step: 56ms | Tot: 6s209ms | Loss: 38.701 | Acc: 58.608% (8252/1408 110/391 ==>.................]  Step: 61ms | Tot: 6s271ms | Loss: 38.699 | Acc: 58.678% (8337/1420 111/391 ....]  Step: 66ms | Tot: 6s873ms | Loss: 38.689 | Acc: 58.763% (9026/1536 120/39 130/39 142/391 ===>...............]  Step: 69ms | Tot: 8s452ms | Loss: 38.675 | Acc: 58.669% (10889/1856 145/391 174/39 175/39 194/391 ============>............]  Step: 68ms | Tot: 11s642ms | Loss: 38.633 | Acc: 58.884% (14999/2547 199/391 =======>............]  Step: 65ms | Tot: 11s845ms | Loss: 38.631 | Acc: 58.857% (15218/2585 202/391 206/391 ======>..........]  Step: 65ms | Tot: 13s8ms | Loss: 38.615 | Acc: 58.949% (16600/2816 220/391 ==========>..........]  Step: 67ms | Tot: 13s75ms | Loss: 38.613 | Acc: 58.976% (16683/2828 221/39 224/391 ........]  Step: 69ms | Tot: 13s341ms | Loss: 38.611 | Acc: 58.920% (16969/2880 225/391 230/391 ============>........]  Step: 64ms | Tot: 14s988ms | Loss: 38.591 | Acc: 58.938% (19011/3225 252/391 256/391 ========>.......]  Step: 80ms | Tot: 16s75ms | Loss: 38.579 | Acc: 58.965% (20303/3443 269/391 ===============>.......]  Step: 61ms | Tot: 16s277ms | Loss: 38.576 | Acc: 59.016% (20547/3481 272/391 =================>.......]  Step: 66ms | Tot: 16s623ms | Loss: 38.572 | Acc: 59.011% (20923/3545 277/391  281/39 284/391 >.....]  Step: 71ms | Tot: 18s261ms | Loss: 38.552 | Acc: 59.135% (22935/3878 303/39 308/391 323/39 336/39 386/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s691ms | Loss: 1.935 | Acc: 50.410% (5041/1000 79/79 /79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(38.7008, device='cuda:0'), tensor(38.6870, device='cuda:0'), tensor(38.6970, device='cuda:0'), tensor(38.6814, device='cuda:0'), tensor(38.7104, device='cuda:0'), tensor(39.0567, device='cuda:0'), tensor(39.1804, device='cuda:0')]\n",
      "\n",
      "Epoch: 17\n",
      " [========================>]  Step: 67ms | Tot: 23s960ms | Loss: 37.920 | Acc: 59.332% (29666/5000 391/391 .........]  Step: 65ms | Tot: 1s338ms | Loss: 38.165 | Acc: 59.339% (1671/281 22/39 23/391 ...........]  Step: 68ms | Tot: 3s384ms | Loss: 38.183 | Acc: 58.275% (4028/691 54/391 ..............]  Step: 65ms | Tot: 3s449ms | Loss: 38.181 | Acc: 58.324% (4106/704 55/391  57/391 >.....................]  Step: 72ms | Tot: 3s923ms | Loss: 38.183 | Acc: 58.140% (4614/793 62/39 92/391 =======>.................]  Step: 66ms | Tot: 7s395ms | Loss: 38.120 | Acc: 58.782% (8728/1484 116/391 ========>................]  Step: 69ms | Tot: 8s475ms | Loss: 38.110 | Acc: 58.896% (9951/1689 132/39 136/391 ..]  Step: 66ms | Tot: 8s812ms | Loss: 38.105 | Acc: 58.982% (10343/1753 137/391 139/391 ===>................]  Step: 68ms | Tot: 9s12ms | Loss: 38.102 | Acc: 59.018% (10576/1792 140/391 .]  Step: 68ms | Tot: 9s275ms | Loss: 38.103 | Acc: 58.984% (10872/1843 144/391 ..........]  Step: 66ms | Tot: 10s105ms | Loss: 38.090 | Acc: 59.108% (11954/2022 158/39 178/39 194/39 196/391 242/391 244/391 ..]  Step: 66ms | Tot: 15s190ms | Loss: 38.030 | Acc: 59.126% (18542/3136 245/391 ==========>.......]  Step: 66ms | Tot: 16s263ms | Loss: 38.010 | Acc: 59.268% (20407/3443 269/391 271/391 ===>......]  Step: 69ms | Tot: 17s755ms | Loss: 37.992 | Acc: 59.301% (22392/3776 295/391 296/391 =>.....]  Step: 66ms | Tot: 18s352ms | Loss: 37.985 | Acc: 59.290% (23071/3891 304/391 =================>..]  Step: 67ms | Tot: 21s358ms | Loss: 37.949 | Acc: 59.377% (26601/4480 350/391 ========>..]  Step: 62ms | Tot: 21s490ms | Loss: 37.947 | Acc: 59.379% (26754/4505 352/391  381/391 ===========>]  Step: 64ms | Tot: 23s892ms | Loss: 37.921 | Acc: 59.325% (29615/4992 390/391 \n",
      " [========================>]  Step: 47ms | Tot: 3s810ms | Loss: 1.936 | Acc: 50.270% (5027/1000 79/79  \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(35.7580, device='cuda:0'), tensor(35.7920, device='cuda:0'), tensor(35.7816, device='cuda:0'), tensor(35.7862, device='cuda:0'), tensor(35.7791, device='cuda:0'), tensor(36.1370, device='cuda:0'), tensor(36.2707, device='cuda:0')]\n",
      "\n",
      "Epoch: 18\n",
      " [========================>]  Step: 67ms | Tot: 24s142ms | Loss: 37.354 | Acc: 59.746% (29873/5000 391/391 91   Step: 49ms | Tot: 4s672ms | Loss: 37.606 | Acc: 59.056% (5745/972 76/391 77/39 86/39 95/39 133/39 145/391 ===>...............]  Step: 69ms | Tot: 9s654ms | Loss: 37.534 | Acc: 59.320% (11921/2009 157/391 ...........]  Step: 64ms | Tot: 9s927ms | Loss: 37.530 | Acc: 59.317% (12224/2060 161/39 163/391 ............]  Step: 68ms | Tot: 10s260ms | Loss: 37.524 | Acc: 59.413% (12624/21 166/39 206/39 215/391 =======>..........]  Step: 67ms | Tot: 14s193ms | Loss: 37.472 | Acc: 59.495% (17820/2995 234/391 238/391 ======>.....]  Step: 65ms | Tot: 18s846ms | Loss: 37.418 | Acc: 59.740% (23399/3916 306/391 =============>.....]  Step: 69ms | Tot: 19s46ms | Loss: 37.415 | Acc: 59.714% (23618/3955 309/391 =========>...]  Step: 66ms | Tot: 20s691ms | Loss: 37.396 | Acc: 59.740% (25693/4300 336/39 382/391 ==================>]  Step: 69ms | Tot: 23s863ms | Loss: 37.358 | Acc: 59.740% (29593/4953 387/391 \n",
      " [========================>]  Step: 46ms | Tot: 3s816ms | Loss: 1.933 | Acc: 50.040% (5004/1000 79/79 ..]  Step: 62ms | Tot: 532ms | Loss: 1.978 | Acc: 49.023% (753/153 12/79 ===>...................]  Step: 45ms | Tot: 831ms | Loss: 1.950 | Acc: 49.479% (1140/230 18/7 20/7 21/79 .......]  Step: 45ms | Tot: 1s31ms | Loss: 1.938 | Acc: 49.538% (1395/281 22/7 30/7 38/7 49/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(33.0875, device='cuda:0'), tensor(33.0702, device='cuda:0'), tensor(33.0937, device='cuda:0'), tensor(33.0878, device='cuda:0'), tensor(33.0913, device='cuda:0'), tensor(33.4402, device='cuda:0'), tensor(33.5860, device='cuda:0')]\n",
      "\n",
      "Epoch: 19\n",
      " [========================>]  Step: 60ms | Tot: 24s410ms | Loss: 36.791 | Acc: 60.000% (30000/5000 391/391 ...................]  Step: 68ms | Tot: 714ms | Loss: 37.094 | Acc: 59.583% (1144/192 15/391 16/391 61/391 ====>....................]  Step: 67ms | Tot: 3s720ms | Loss: 37.044 | Acc: 59.509% (4875/819 64/39 65/39 67/391 =>...................]  Step: 66ms | Tot: 5s413ms | Loss: 37.017 | Acc: 59.653% (6872/1152 90/391 .................]  Step: 64ms | Tot: 5s754ms | Loss: 37.014 | Acc: 59.613% (7249/1216 95/391 =>..................]  Step: 67ms | Tot: 6s87ms | Loss: 37.013 | Acc: 59.539% (7621/1280 100/391   Step: 63ms | Tot: 7s159ms | Loss: 36.996 | Acc: 59.522% (8914/1497 117/391 118/391 =======>.................]  Step: 69ms | Tot: 7s489ms | Loss: 36.994 | Acc: 59.516% (9294/1561 122/391 =====>.................]  Step: 64ms | Tot: 7s554ms | Loss: 36.994 | Acc: 59.502% (9368/1574 123/39 126/39 133/391 158/391 192/391 =======>............]  Step: 68ms | Tot: 12s23ms | Loss: 36.947 | Acc: 59.495% (14926/2508 196/391 .....]  Step: 64ms | Tot: 12s672ms | Loss: 36.937 | Acc: 59.576% (15709/2636 206/391 230/391 ===>.........]  Step: 66ms | Tot: 14s659ms | Loss: 36.909 | Acc: 59.807% (18143/3033 237/391 ....]  Step: 71ms | Tot: 17s119ms | Loss: 36.880 | Acc: 59.892% (21082/3520 275/39 292/391 ==============>......]  Step: 67ms | Tot: 18s421ms | Loss: 36.865 | Acc: 59.886% (22613/3776 295/39 315/39 324/391 347/391 355/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s629ms | Loss: 1.929 | Acc: 50.210% (5021/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(30.5962, device='cuda:0'), tensor(30.5878, device='cuda:0'), tensor(30.6013, device='cuda:0'), tensor(30.6017, device='cuda:0'), tensor(30.5977, device='cuda:0'), tensor(30.9490, device='cuda:0'), tensor(31.0946, device='cuda:0')]\n",
      "\n",
      "Epoch: 20\n",
      " [========================>]  Step: 69ms | Tot: 24s358ms | Loss: 36.233 | Acc: 60.036% (30018/5000 391/391 ..........]  Step: 64ms | Tot: 584ms | Loss: 36.541 | Acc: 59.531% (762/128 10/391 .]  Step: 66ms | Tot: 1s725ms | Loss: 36.508 | Acc: 59.347% (2127/358 28/391 ..................]  Step: 67ms | Tot: 2s651ms | Loss: 36.512 | Acc: 59.412% (3194/537 42/39 43/39 44/391 ====>....................]  Step: 70ms | Tot: 4s834ms | Loss: 36.481 | Acc: 59.560% (5794/972 76/391 ====>....................]  Step: 68ms | Tot: 5s34ms | Loss: 36.479 | Acc: 59.494% (6016/1011 79/391 ...........]  Step: 65ms | Tot: 7s587ms | Loss: 36.432 | Acc: 59.573% (9608/1612 126/391  128/391 ]  Step: 69ms | Tot: 9s738ms | Loss: 36.403 | Acc: 59.885% (12341/2060 161/391 .......]  Step: 65ms | Tot: 9s803ms | Loss: 36.402 | Acc: 59.920% (12425/2073 162/391 ======>..............]  Step: 67ms | Tot: 10s193ms | Loss: 36.397 | Acc: 59.998% (12902/2150 168/391 ...]  Step: 65ms | Tot: 10s326ms | Loss: 36.397 | Acc: 59.977% (13051/2176 170/391 ============>............]  Step: 70ms | Tot: 11s728ms | Loss: 36.385 | Acc: 59.855% (14710/2457 192/391 ======>............]  Step: 62ms | Tot: 11s859ms | Loss: 36.384 | Acc: 59.810% (14852/2483 194/391 =========>...........]  Step: 70ms | Tot: 13s313ms | Loss: 36.360 | Acc: 59.930% (16723/2790 218/391 ======>..........]  Step: 63ms | Tot: 13s445ms | Loss: 36.358 | Acc: 59.979% (16890/2816 220/391 =========>.........]  Step: 67ms | Tot: 14s815ms | Loss: 36.343 | Acc: 59.981% (18503/3084 241/391 246/39 250/391 ....]  Step: 67ms | Tot: 15s869ms | Loss: 36.330 | Acc: 60.083% (19765/3289 257/391 ====>........]  Step: 64ms | Tot: 16s2ms | Loss: 36.330 | Acc: 60.036% (19903/3315 259/39 260/391 ...]  Step: 37ms | Tot: 16s529ms | Loss: 36.324 | Acc: 60.008% (20585/3430 268/39 305/391 =============>.....]  Step: 66ms | Tot: 18s875ms | Loss: 36.295 | Acc: 60.029% (23666/3942 308/391 ====================>....]  Step: 66ms | Tot: 19s775ms | Loss: 36.285 | Acc: 60.047% (24672/4108 321/39 326/391 328/391 336/391 =================>...]  Step: 68ms | Tot: 20s943ms | Loss: 36.271 | Acc: 60.025% (26046/4339 339/391 352/391 =======================>.]  Step: 70ms | Tot: 22s662ms | Loss: 36.252 | Acc: 60.032% (28047/4672 365/39 369/391 ====>.]  Step: 63ms | Tot: 23s129ms | Loss: 36.247 | Acc: 60.081% (28608/4761 372/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s716ms | Loss: 1.930 | Acc: 50.250% (5025/1000 79/79 8/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(28.2861, device='cuda:0'), tensor(28.3058, device='cuda:0'), tensor(28.2941, device='cuda:0'), tensor(28.2992, device='cuda:0'), tensor(28.2929, device='cuda:0'), tensor(28.6420, device='cuda:0'), tensor(28.7801, device='cuda:0')]\n",
      "\n",
      "Epoch: 21\n",
      " [========================>]  Step: 69ms | Tot: 23s866ms | Loss: 35.672 | Acc: 60.480% (30240/5000 391/391 .............]  Step: 69ms | Tot: 1s70ms | Loss: 35.962 | Acc: 59.293% (1442/243 19/391 =>.......................]  Step: 69ms | Tot: 1s879ms | Loss: 35.958 | Acc: 59.399% (2433/409 32/39 57/391  78/39 104/391 ..............]  Step: 79ms | Tot: 9s95ms | Loss: 35.858 | Acc: 59.591% (11289/1894 148/391 =======>...............]  Step: 62ms | Tot: 9s157ms | Loss: 35.858 | Acc: 59.574% (11362/1907 149/391 ....]  Step: 62ms | Tot: 12s205ms | Loss: 35.824 | Acc: 59.916% (14955/2496 195/39 208/391 ===============>.......]  Step: 61ms | Tot: 15s961ms | Loss: 35.765 | Acc: 60.282% (20679/3430 268/39 276/391 321/391 ===============>....]  Step: 70ms | Tot: 19s476ms | Loss: 35.724 | Acc: 60.418% (24902/4121 322/391 331/39 332/391 ================>...]  Step: 69ms | Tot: 20s576ms | Loss: 35.711 | Acc: 60.479% (26243/4339 339/391 =======>...]  Step: 64ms | Tot: 20s641ms | Loss: 35.711 | Acc: 60.455% (26310/4352 340/391 ================>..]  Step: 69ms | Tot: 21s436ms | Loss: 35.700 | Acc: 60.511% (27264/4505 352/391 =================>..]  Step: 66ms | Tot: 21s638ms | Loss: 35.698 | Acc: 60.506% (27494/4544 355/391 ================>..]  Step: 66ms | Tot: 21s910ms | Loss: 35.695 | Acc: 60.502% (27802/4595 359/391 ======================>..]  Step: 69ms | Tot: 21s980ms | Loss: 35.694 | Acc: 60.514% (27885/4608 360/391 ============>.]  Step: 59ms | Tot: 22s112ms | Loss: 35.693 | Acc: 60.506% (28036/4633 362/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s749ms | Loss: 1.932 | Acc: 50.270% (5027/1000 79/79 p: 46ms | Tot: 264ms | Loss: 2.016 | Acc: 49.219% (378/76 6/79 16/7 17/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(26.1586, device='cuda:0'), tensor(26.1729, device='cuda:0'), tensor(26.1652, device='cuda:0'), tensor(26.1662, device='cuda:0'), tensor(26.1644, device='cuda:0'), tensor(26.5128, device='cuda:0'), tensor(26.6607, device='cuda:0')]\n",
      "\n",
      "Epoch: 22\n",
      " [========================>]  Step: 65ms | Tot: 23s969ms | Loss: 35.119 | Acc: 60.426% (30213/5000 391/391 ...................]  Step: 61ms | Tot: 940ms | Loss: 35.388 | Acc: 59.229% (1213/204 16/391 .....................]  Step: 69ms | Tot: 2s200ms | Loss: 35.383 | Acc: 59.418% (2738/460 36/391 ..................]  Step: 65ms | Tot: 2s265ms | Loss: 35.383 | Acc: 59.291% (2808/473 37/391 ..................]  Step: 63ms | Tot: 2s535ms | Loss: 35.394 | Acc: 59.413% (3118/524 41/391 ...........]  Step: 70ms | Tot: 5s131ms | Loss: 35.349 | Acc: 59.961% (6140/1024 80/391 =====>...................]  Step: 66ms | Tot: 5s198ms | Loss: 35.350 | Acc: 59.925% (6213/1036 81/391 =====>...................]  Step: 67ms | Tot: 5s332ms | Loss: 35.346 | Acc: 60.081% (6383/1062 83/391 84/39 227/391 240/391 241/391 ====>.........]  Step: 65ms | Tot: 14s885ms | Loss: 35.224 | Acc: 60.166% (19176/3187 249/39 317/39 337/391 ===================>]  Step: 68ms | Tot: 23s86ms | Loss: 35.129 | Acc: 60.446% (29169/4825 377/391 ===========>]  Step: 65ms | Tot: 23s151ms | Loss: 35.128 | Acc: 60.437% (29242/4838 378/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s745ms | Loss: 1.928 | Acc: 50.460% (5046/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(24.1890, device='cuda:0'), tensor(24.2005, device='cuda:0'), tensor(24.1944, device='cuda:0'), tensor(24.1963, device='cuda:0'), tensor(24.1930, device='cuda:0'), tensor(24.5438, device='cuda:0'), tensor(24.6713, device='cuda:0')]\n",
      "\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 67ms | Tot: 23s738ms | Loss: 34.561 | Acc: 60.820% (30410/5000 391/391 ...................]  Step: 64ms | Tot: 1s666ms | Loss: 34.833 | Acc: 60.426% (2243/371 29/391 .................]  Step: 64ms | Tot: 3s524ms | Loss: 34.829 | Acc: 59.614% (4731/793 62/391 107/391 ...........]  Step: 65ms | Tot: 6s350ms | Loss: 34.777 | Acc: 60.026% (8298/1382 108/391 =>.................]  Step: 69ms | Tot: 6s549ms | Loss: 34.779 | Acc: 59.987% (8523/1420 111/391 ..........]  Step: 64ms | Tot: 6s614ms | Loss: 34.778 | Acc: 59.975% (8598/1433 112/391 142/391 160/39 212/391 =======>...........]  Step: 68ms | Tot: 12s557ms | Loss: 34.697 | Acc: 60.424% (16474/2726 213/39 215/391 ==============>..........]  Step: 61ms | Tot: 13s103ms | Loss: 34.690 | Acc: 60.453% (17101/2828 221/39 264/391 ==>.......]  Step: 65ms | Tot: 16s38ms | Loss: 34.651 | Acc: 60.615% (20871/3443 269/391 ===>.......]  Step: 66ms | Tot: 16s105ms | Loss: 34.650 | Acc: 60.631% (20954/3456 270/391 286/391  288/391 ....]  Step: 66ms | Tot: 17s378ms | Loss: 34.634 | Acc: 60.724% (22463/3699 289/391 =============>......]  Step: 69ms | Tot: 17s448ms | Loss: 34.632 | Acc: 60.760% (22554/3712 290/39 350/391 358/391 ====>.]  Step: 71ms | Tot: 22s624ms | Loss: 34.572 | Acc: 60.818% (29115/4787 374/391 375/39 384/39 387/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s622ms | Loss: 1.931 | Acc: 50.430% (5043/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(22.3765, device='cuda:0'), tensor(22.3736, device='cuda:0'), tensor(22.3725, device='cuda:0'), tensor(22.3743, device='cuda:0'), tensor(22.3742, device='cuda:0'), tensor(22.7271, device='cuda:0'), tensor(22.8541, device='cuda:0')]\n",
      "\n",
      "Epoch: 24\n",
      " [================>........]  Step: 65ms | Tot: 15s451ms | Loss: 34.108 | Acc: 60.417% (20184/3340 261/391 ]  Step: 64ms | Tot: 8s577ms | Loss: 34.198 | Acc: 59.947% (10896/1817 142/391 184/391   Step: 67ms | Tot: 15s385ms | Loss: 34.109 | Acc: 60.385% (20096/3328 260/391 \r"
     ]
    }
   ],
   "source": [
    "#This is the approach I've had the most success with in lowering the sparsity gradually from 0 to 1. \n",
    "#But it monotonically increases sparsity while destryoing the accuracy. \n",
    "\n",
    "sbp_learningrate = 2e-5\n",
    "sbp_parameters = [\n",
    "    {'params': sbp_net.block1.conv1.weight},\n",
    "    {'params': sbp_net.block2.conv1.weight},\n",
    "    {'params': sbp_net.block3.conv1.weight},\n",
    "    {'params': sbp_net.block4.conv1.weight},\n",
    "    {'params': sbp_net.block5.conv1.weight},\n",
    "    \n",
    "    {'params': sbp_net.block1.bn1.weight},\n",
    "    {'params': sbp_net.block2.bn1.weight},\n",
    "    {'params': sbp_net.block3.bn1.weight},\n",
    "    {'params': sbp_net.block4.bn1.weight},\n",
    "    {'params': sbp_net.block5.bn1.weight},\n",
    "    \n",
    "    {'params': sbp_net.block1.conv1.log_sigma, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.block2.conv1.log_sigma, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.block3.conv1.log_sigma, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.block4.conv1.log_sigma, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.block5.conv1.log_sigma, 'lr': 10*sbp_learningrate},\n",
    "\n",
    "    {'params': sbp_net.block1.conv1.mu, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.block2.conv1.mu, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.block3.conv1.mu, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.block4.conv1.mu, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.block5.conv1.mu, 'lr': 10*sbp_learningrate},\n",
    "\n",
    "    {'params': sbp_net.lsbp1.mu, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.lsbp1.log_sigma, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.lsbp2.mu, 'lr': 10*sbp_learningrate},\n",
    "    {'params': sbp_net.lsbp2.log_sigma, 'lr': 10*sbp_learningrate},\n",
    "    \n",
    "    {'params': sbp_net.last.weight},\n",
    "\n",
    "    \n",
    " ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "finetune_epoch = 300 ## that seems excessive\n",
    "\n",
    "sbp_net = SBPConv_AlexNet(cfg,kl_weights=all_ones).to(device)\n",
    "sbp_net = transfer_weights(sbp_net)\n",
    "\n",
    "sbp_optimizer = optim.Adam(sbp_parameters,lr=sbp_learningrate, betas=[0.95,0.999])\n",
    "sbp_scheduler = optim.lr_scheduler.StepLR(sbp_optimizer,step_size=250, gamma=0.1)\n",
    "\n",
    "#epoch 45 is close to the last epoch of death. \n",
    "for epoch in range(0,45):\n",
    "    SBP_net_train(epoch,sbp_net,optimizer=sbp_optimizer,criterion=nn.CrossEntropyLoss(),scheduler=sbp_scheduler)\n",
    "    SBP_net_test(epoch,sbp_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 45ms | Tot: 3s769ms | Loss: 1.982 | Acc: 49.540% (4954/1000 79/79 1/79 \n",
      "Saving..\n",
      "Sparsity:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "SNRS:  [tensor(4.2766, device='cuda:0'), tensor(4.2796, device='cuda:0'), tensor(4.2981, device='cuda:0'), tensor(4.2887, device='cuda:0'), tensor(4.2776, device='cuda:0'), tensor(4.8969, device='cuda:0'), tensor(4.8912, device='cuda:0')]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49.54"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_net_test(44,sbp_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational complexity:       0.04 GMac\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(-1):\n",
    "    flops, params = get_model_complexity_info(best_net, (3, 32, 32), as_strings=True, print_per_layer_stat=False)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computational complexity:       0.0 GMac\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "#have to remove the sbp layers before calling this! B/c ptflops will not support the custom layers. \n",
    "with torch.cuda.device(-1):\n",
    "    flops, params = get_model_complexity_info(sbp_net, (3, 32, 32), as_strings=True, print_per_layer_stat=False)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try Warm-up learning Rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_net.kl_weights = [1] * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 62ms | Tot: 24s517ms | Loss: 12.203 | Acc: 63.534% (31767/5000 391/391 /391 33/39 53/39 85/39 159/39 179/391 ==>.............]  Step: 68ms | Tot: 11s266ms | Loss: 12.244 | Acc: 62.491% (14638/2342 183/391 ========>.............]  Step: 68ms | Tot: 11s400ms | Loss: 12.245 | Acc: 62.492% (14798/2368 185/391 ==>.............]  Step: 66ms | Tot: 11s466ms | Loss: 12.247 | Acc: 62.479% (14875/2380 186/39 187/391 191/391 208/39 219/39 267/391 ==========>.......]  Step: 69ms | Tot: 17s119ms | Loss: 12.238 | Acc: 62.785% (22261/3545 277/391 278/391 ============>.......]  Step: 65ms | Tot: 17s249ms | Loss: 12.237 | Acc: 62.808% (22430/3571 279/391 ...]  Step: 65ms | Tot: 17s384ms | Loss: 12.238 | Acc: 62.781% (22581/3596 281/391 =======>......]  Step: 66ms | Tot: 17s845ms | Loss: 12.236 | Acc: 62.828% (23161/3686 288/391 289/391 290/391 291/391 293/391 ]  Step: 68ms | Tot: 18s874ms | Loss: 12.236 | Acc: 62.747% (24416/3891 304/391   Step: 61ms | Tot: 18s935ms | Loss: 12.236 | Acc: 62.746% (24496/3904 305/391 312/391 318/39 321/39 326/391 332/39 354/39 356/39 374/391 ======>]  Step: 69ms | Tot: 23s666ms | Loss: 12.208 | Acc: 63.449% (30699/4838 378/391 ==================>]  Step: 69ms | Tot: 23s868ms | Loss: 12.207 | Acc: 63.458% (30947/4876 381/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s579ms | Loss: 13.709 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8206, device='cuda:0'), tensor(0.7660, device='cuda:0'), tensor(0.8003, device='cuda:0'), tensor(0.8122, device='cuda:0'), tensor(0.7609, device='cuda:0'), tensor(1.6786, device='cuda:0'), tensor(1.3710, device='cuda:0')]\n",
      "\n",
      "Epoch: 1\n",
      " [========================>]  Step: 62ms | Tot: 24s991ms | Loss: 12.142 | Acc: 64.820% (32410/5000 391/391  Step: 68ms | Tot: 786ms | Loss: 11.942 | Acc: 71.454% (1189/166 13/39 18/391 =>.......................]  Step: 69ms | Tot: 1s179ms | Loss: 11.946 | Acc: 71.094% (1729/243 19/391 ......]  Step: 61ms | Tot: 1s240ms | Loss: 11.958 | Acc: 70.547% (1806/256 20/391 =>.......................]  Step: 66ms | Tot: 1s625ms | Loss: 11.988 | Acc: 69.531% (2314/332 26/391 28/391 29/39 30/39 33/391 ...................]  Step: 63ms | Tot: 2s150ms | Loss: 12.008 | Acc: 68.658% (2988/435 34/391 50/39 51/39 62/391 64/39 95/39 102/391 ....]  Step: 67ms | Tot: 8s73ms | Loss: 12.151 | Acc: 64.475% (10481/1625 127/39 132/39 186/39 202/391 253/391 ...]  Step: 65ms | Tot: 16s124ms | Loss: 12.173 | Acc: 64.109% (20843/3251 254/391 ]  Step: 70ms | Tot: 16s829ms | Loss: 12.173 | Acc: 64.195% (21775/3392 265/391 ================>........]  Step: 61ms | Tot: 16s891ms | Loss: 12.174 | Acc: 64.189% (21855/3404 266/391 270/391 ..]  Step: 69ms | Tot: 18s334ms | Loss: 12.170 | Acc: 64.236% (23680/3686 288/391 =>......]  Step: 67ms | Tot: 18s402ms | Loss: 12.170 | Acc: 64.227% (23759/3699 289/39 294/39 296/391 300/39 301/39 313/391 321/391 324/391 =======>....]  Step: 67ms | Tot: 21s6ms | Loss: 12.160 | Acc: 64.464% (27147/4211 329/39 336/391 ===================>...]  Step: 66ms | Tot: 21s581ms | Loss: 12.157 | Acc: 64.536% (27921/4326 338/39 343/39 344/391 349/391 353/391 ============>..]  Step: 69ms | Tot: 23s15ms | Loss: 12.149 | Acc: 64.655% (29793/4608 360/39 362/391 =>.]  Step: 69ms | Tot: 23s217ms | Loss: 12.149 | Acc: 64.648% (30038/4646 363/391 =======>.]  Step: 62ms | Tot: 23s279ms | Loss: 12.149 | Acc: 64.646% (30120/4659 364/391 ================>.]  Step: 68ms | Tot: 23s742ms | Loss: 12.147 | Acc: 64.730% (30739/4748 371/391 =====>.]  Step: 68ms | Tot: 23s873ms | Loss: 12.147 | Acc: 64.735% (30907/4774 373/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s576ms | Loss: 13.805 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8193, device='cuda:0'), tensor(0.7646, device='cuda:0'), tensor(0.7988, device='cuda:0'), tensor(0.8108, device='cuda:0'), tensor(0.7595, device='cuda:0'), tensor(1.6753, device='cuda:0'), tensor(1.3681, device='cuda:0')]\n",
      "\n",
      "Epoch: 2\n",
      " [========================>]  Step: 63ms | Tot: 24s215ms | Loss: 12.105 | Acc: 65.358% (32679/5000 391/391 ....]  Step: 65ms | Tot: 631ms | Loss: 11.875 | Acc: 72.940% (1027/140 11/391 47/39 61/391 ..]  Step: 67ms | Tot: 4s680ms | Loss: 12.080 | Acc: 66.283% (6448/972 76/391 .........]  Step: 69ms | Tot: 6s284ms | Loss: 12.101 | Acc: 65.633% (8569/1305 102/391 ........]  Step: 62ms | Tot: 6s347ms | Loss: 12.103 | Acc: 65.595% (8648/1318 103/391 104/39 118/391 119/391 120/39 121/391 ..............]  Step: 67ms | Tot: 7s860ms | Loss: 12.116 | Acc: 65.160% (10509/1612 126/391 ........]  Step: 61ms | Tot: 9s153ms | Loss: 12.129 | Acc: 64.924% (12133/1868 146/39 149/391 150/39 153/39 154/39 156/391 157/391 ===>..............]  Step: 68ms | Tot: 10s223ms | Loss: 12.132 | Acc: 64.878% (13453/2073 162/39 164/391 ====>..............]  Step: 68ms | Tot: 10s423ms | Loss: 12.132 | Acc: 64.891% (13705/21 165/391 .........]  Step: 62ms | Tot: 10s486ms | Loss: 12.133 | Acc: 64.886% (13787/2124 166/39 170/391 ==>.............]  Step: 67ms | Tot: 11s978ms | Loss: 12.137 | Acc: 64.644% (15556/2406 188/391 ==>............]  Step: 67ms | Tot: 12s643ms | Loss: 12.141 | Acc: 64.556% (16361/2534 198/391 201/391 ======>...........]  Step: 69ms | Tot: 13s874ms | Loss: 12.143 | Acc: 64.572% (17853/2764 216/391 217/391 218/391 225/391 .........]  Step: 62ms | Tot: 15s691ms | Loss: 12.139 | Acc: 64.696% (20123/3110 243/391 ==>........]  Step: 44ms | Tot: 16s771ms | Loss: 12.137 | Acc: 64.745% (21713/3353 262/39 284/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s530ms | Loss: 13.908 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8180, device='cuda:0'), tensor(0.7632, device='cuda:0'), tensor(0.7974, device='cuda:0'), tensor(0.8093, device='cuda:0'), tensor(0.7580, device='cuda:0'), tensor(1.6720, device='cuda:0'), tensor(1.3653, device='cuda:0')]\n",
      "\n",
      "Epoch: 3\n",
      " [========================>]  Step: 51ms | Tot: 24s76ms | Loss: 12.058 | Acc: 66.086% (33043/5000 391/391  9 54/391 75/391 76/391 ...............]  Step: 69ms | Tot: 4s879ms | Loss: 12.058 | Acc: 66.216% (6611/998 78/391 ]  Step: 61ms | Tot: 4s940ms | Loss: 12.058 | Acc: 66.169% (6691/1011 79/391 87/391 88/391 >..................]  Step: 68ms | Tot: 6s917ms | Loss: 12.072 | Acc: 65.838% (9270/1408 110/39 112/39 114/391 =>...............]  Step: 72ms | Tot: 9s429ms | Loss: 12.083 | Acc: 65.436% (12480/1907 149/391 177/391 179/391 =>.............]  Step: 65ms | Tot: 11s925ms | Loss: 12.085 | Acc: 65.450% (15666/2393 187/39 192/391 ==>............]  Step: 65ms | Tot: 12s455ms | Loss: 12.088 | Acc: 65.337% (16308/2496 195/391 ......]  Step: 66ms | Tot: 13s284ms | Loss: 12.087 | Acc: 65.448% (17425/2662 208/39 214/39 216/391 217/391 ....]  Step: 69ms | Tot: 15s221ms | Loss: 12.085 | Acc: 65.391% (19837/3033 237/39 263/39 265/391 266/391 ======>.......]  Step: 67ms | Tot: 17s469ms | Loss: 12.085 | Acc: 65.530% (22815/3481 272/391 293/39 302/391 =>....]  Step: 74ms | Tot: 19s641ms | Loss: 12.079 | Acc: 65.637% (26381/4019 314/391 ===================>]  Step: 64ms | Tot: 23s612ms | Loss: 12.061 | Acc: 66.049% (32380/4902 383/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s614ms | Loss: 13.950 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8168, device='cuda:0'), tensor(0.7619, device='cuda:0'), tensor(0.7960, device='cuda:0'), tensor(0.8078, device='cuda:0'), tensor(0.7567, device='cuda:0'), tensor(1.6688, device='cuda:0'), tensor(1.3624, device='cuda:0')]\n",
      "\n",
      "Epoch: 4\n",
      " [========================>]  Step: 68ms | Tot: 24s960ms | Loss: 12.020 | Acc: 66.518% (33206/49920389/391 ..............]  Step: 68ms | Tot: 2s322ms | Loss: 11.929 | Acc: 69.371% (3463/499 39/39 41/391 49/391 51/391 58/391 ====>....................]  Step: 71ms | Tot: 4s8ms | Loss: 11.974 | Acc: 67.716% (5634/832 65/39 71/39 94/391 ............]  Step: 69ms | Tot: 9s233ms | Loss: 12.026 | Acc: 66.491% (12511/1881 147/391 158/39 168/391 ==>.............]  Step: 67ms | Tot: 11s170ms | Loss: 12.032 | Acc: 66.242% (14923/2252 176/391 =>............]  Step: 65ms | Tot: 13s86ms | Loss: 12.033 | Acc: 66.169% (17278/2611 204/39 207/391 ===========>...........]  Step: 60ms | Tot: 13s488ms | Loss: 12.032 | Acc: 66.205% (17796/2688 210/391 ==============>..........]  Step: 71ms | Tot: 14s724ms | Loss: 12.035 | Acc: 66.175% (19482/2944 230/391 ==>..........]  Step: 62ms | Tot: 14s993ms | Loss: 12.034 | Acc: 66.219% (19834/2995 234/391  242/391 300/391 =============>.....]  Step: 69ms | Tot: 19s131ms | Loss: 12.034 | Acc: 66.201% (25506/3852 301/391 306/39 310/391 313/391 320/391 ==========>....]  Step: 67ms | Tot: 20s643ms | Loss: 12.034 | Acc: 66.206% (27457/4147 324/39 331/391 332/391 333/391 334/39 348/391 ===============>..]  Step: 69ms | Tot: 22s420ms | Loss: 12.027 | Acc: 66.375% (29821/44 351/39 357/391 358/391 368/391  369/391 374/391 ===============>.]  Step: 62ms | Tot: 24s44ms | Loss: 12.021 | Acc: 66.531% (32020/4812 376/391 379/391 ==============>]  Step: 65ms | Tot: 24s760ms | Loss: 12.021 | Acc: 66.519% (32951/4953 387/391 =========>]  Step: 67ms | Tot: 24s828ms | Loss: 12.020 | Acc: 66.527% (33040/4966 388/391 390/391 ===>]  Step: 70ms | Tot: 25s30ms | Loss: 12.019 | Acc: 66.532% (33266/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s488ms | Loss: 13.952 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8155, device='cuda:0'), tensor(0.7605, device='cuda:0'), tensor(0.7946, device='cuda:0'), tensor(0.8064, device='cuda:0'), tensor(0.7553, device='cuda:0'), tensor(1.6655, device='cuda:0'), tensor(1.3596, device='cuda:0')]\n",
      "\n",
      "Epoch: 5\n",
      " [========================>]  Step: 61ms | Tot: 24s841ms | Loss: 11.989 | Acc: 66.878% (33439/5000 391/391  69ms | Tot: 271ms | Loss: 11.789 | Acc: 73.594% (471/64 5/391 .......]  Step: 69ms | Tot: 341ms | Loss: 11.812 | Acc: 72.526% (557/76 6/391 .................]  Step: 62ms | Tot: 403ms | Loss: 11.821 | Acc: 72.210% (647/89 7/391 8/39 10/391 11/391 .............]  Step: 68ms | Tot: 735ms | Loss: 11.814 | Acc: 72.656% (1116/153 12/391 26/391 ]  Step: 69ms | Tot: 2s117ms | Loss: 11.888 | Acc: 69.673% (2943/422 33/391 .......]  Step: 63ms | Tot: 2s181ms | Loss: 11.892 | Acc: 69.416% (3021/435 34/391 38/391 ...........]  Step: 64ms | Tot: 2s836ms | Loss: 11.933 | Acc: 68.466% (3856/563 44/391 47/39 48/391 50/391 51/391 ..............]  Step: 66ms | Tot: 3s370ms | Loss: 11.952 | Acc: 67.999% (4526/665 52/391 59/391 61/391 66/39 72/391 ..................]  Step: 68ms | Tot: 4s952ms | Loss: 11.961 | Acc: 67.732% (6589/972 76/391 77/391 84/39 87/391 ...]  Step: 65ms | Tot: 6s971ms | Loss: 11.983 | Acc: 67.084% (9102/1356 106/39 111/39 112/39 113/ 114/39 123/39 124/391 130/39 132/391 =>................]  Step: 67ms | Tot: 8s789ms | Loss: 11.997 | Acc: 66.739% (11447/1715 134/391 ..............]  Step: 67ms | Tot: 9s60ms | Loss: 11.997 | Acc: 66.735% (11788/1766 138/391 ...]  Step: 67ms | Tot: 9s322ms | Loss: 12.003 | Acc: 66.610% (12107/1817 142/391 ===>...............]  Step: 70ms | Tot: 9s584ms | Loss: 12.004 | Acc: 66.583% (12443/1868 146/39 148/39 155/39 157/39 159/39 161/391 165/39 173/391 178/391 179/391   Step: 67ms | Tot: 11s864ms | Loss: 12.006 | Acc: 66.454% (15396/23 181/391 203/391 .........]  Step: 61ms | Tot: 13s390ms | Loss: 12.013 | Acc: 66.308% (17484/2636 206/391 207/391 ======>..........]  Step: 69ms | Tot: 14s469ms | Loss: 12.010 | Acc: 66.452% (18968/2854 223/39 225/391 ]  Step: 68ms | Tot: 16s24ms | Loss: 12.015 | Acc: 66.353% (21063/3174 248/39 249/391 ...]  Step: 67ms | Tot: 16s850ms | Loss: 12.012 | Acc: 66.421% (22190/3340 261/391 ===========>.......]  Step: 71ms | Tot: 18s181ms | Loss: 12.008 | Acc: 66.445% (23984/3609 282/391 284/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s809ms | Loss: 14.120 | Acc: 1.000% (100/1000 79/79 ==========>.........]  Step: 46ms | Tot: 2s363ms | Loss: 14.187 | Acc: 0.844% (54/640 50/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8143, device='cuda:0'), tensor(0.7592, device='cuda:0'), tensor(0.7932, device='cuda:0'), tensor(0.8050, device='cuda:0'), tensor(0.7539, device='cuda:0'), tensor(1.6623, device='cuda:0'), tensor(1.3568, device='cuda:0')]\n",
      "\n",
      "Epoch: 6\n",
      " [========================>]  Step: 56ms | Tot: 24s716ms | Loss: 11.959 | Acc: 67.244% (33622/5000 391/391 4/39 37/39 38/391 ............]  Step: 63ms | Tot: 2s491ms | Loss: 11.894 | Acc: 68.932% (3794/550 43/391 .................]  Step: 69ms | Tot: 2s693ms | Loss: 11.905 | Acc: 68.767% (4049/588 46/39 57/391 ]  Step: 68ms | Tot: 4s452ms | Loss: 11.935 | Acc: 67.936% (6261/921 72/391 >....................]  Step: 68ms | Tot: 4s776ms | Loss: 11.946 | Acc: 67.563% (6659/985 77/39 78/39 91/391  93/391 ...............]  Step: 69ms | Tot: 5s874ms | Loss: 11.950 | Acc: 67.628% (8137/1203 94/39 99/391 101/391 ......]  Step: 67ms | Tot: 6s399ms | Loss: 11.950 | Acc: 67.540% (8818/13 102/391 ]  Step: 72ms | Tot: 6s847ms | Loss: 11.950 | Acc: 67.524% (9421/1395 109/391 120/391 .]  Step: 68ms | Tot: 7s629ms | Loss: 11.950 | Acc: 67.388% (10437/1548 121/391 .]  Step: 63ms | Tot: 7s692ms | Loss: 11.951 | Acc: 67.354% (10518/1561 122/39 127/391 ..]  Step: 68ms | Tot: 8s146ms | Loss: 11.955 | Acc: 67.169% (11091/1651 129/39 137/391 ..........]  Step: 66ms | Tot: 8s713ms | Loss: 11.956 | Acc: 67.210% (11872/1766 138/39 143/391 ======>...............]  Step: 65ms | Tot: 9s376ms | Loss: 11.965 | Acc: 67.066% (12705/1894 148/391 158/391 161/391 .........]  Step: 68ms | Tot: 10s274ms | Loss: 11.971 | Acc: 67.019% (13897/2073 162/391 ..]  Step: 69ms | Tot: 10s405ms | Loss: 11.972 | Acc: 67.006% (14066/20 164/39 166/391 .........]  Step: 65ms | Tot: 11s364ms | Loss: 11.977 | Acc: 66.786% (15302/2291 179/391 180/391 .]  Step: 68ms | Tot: 11s695ms | Loss: 11.977 | Acc: 66.844% (15743/2355 184/391 ====>.............]  Step: 62ms | Tot: 11s758ms | Loss: 11.977 | Acc: 66.816% (15822/2368 185/391 =>...........]  Step: 66ms | Tot: 13s654ms | Loss: 11.981 | Acc: 66.726% (18363/2752 215/391 ==========>.........]  Step: 68ms | Tot: 15s220ms | Loss: 11.983 | Acc: 66.673% (20482/3072 240/391 242/39 244/39 247/391 249/391 .........]  Step: 65ms | Tot: 15s885ms | Loss: 11.981 | Acc: 66.731% (21354/3200 250/39 252/39 253/391 254/391 ===>........]  Step: 65ms | Tot: 16s220ms | Loss: 11.981 | Acc: 66.749% (21787/3264 255/39 258/391 ========>........]  Step: 66ms | Tot: 16s559ms | Loss: 11.982 | Acc: 66.728% (22207/3328 260/391 ==========>........]  Step: 64ms | Tot: 16s623ms | Loss: 11.981 | Acc: 66.744% (22298/33 261/391 =======>........]  Step: 68ms | Tot: 16s691ms | Loss: 11.981 | Acc: 66.764% (22390/3353 262/39 270/391 ===>...]  Step: 66ms | Tot: 21s736ms | Loss: 11.968 | Acc: 67.021% (29339/4377 342/391 343/391 350/391 ==============>..]  Step: 63ms | Tot: 22s436ms | Loss: 11.963 | Acc: 67.145% (30339/4518 353/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s635ms | Loss: 14.129 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8131, device='cuda:0'), tensor(0.7579, device='cuda:0'), tensor(0.7919, device='cuda:0'), tensor(0.8036, device='cuda:0'), tensor(0.7526, device='cuda:0'), tensor(1.6590, device='cuda:0'), tensor(1.3540, device='cuda:0')]\n",
      "\n",
      "Epoch: 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 58ms | Tot: 22s640ms | Loss: 11.935 | Acc: 67.326% (33663/5000 391/391 1 ........]  Step: 63ms | Tot: 1s968ms | Loss: 11.874 | Acc: 68.549% (3071/448 35/391 .........]  Step: 70ms | Tot: 7s94ms | Loss: 11.943 | Acc: 66.927% (10280/1536 120/391 >.................]  Step: 62ms | Tot: 7s157ms | Loss: 11.944 | Acc: 66.923% (10365/1548 121/391 ..........]  Step: 48ms | Tot: 8s473ms | Loss: 11.956 | Acc: 66.643% (12369/1856 145/39 173/391 179/39 284/39 308/391 309/39 376/391 380/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s601ms | Loss: 14.114 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8119, device='cuda:0'), tensor(0.7566, device='cuda:0'), tensor(0.7905, device='cuda:0'), tensor(0.8021, device='cuda:0'), tensor(0.7513, device='cuda:0'), tensor(1.6557, device='cuda:0'), tensor(1.3512, device='cuda:0')]\n",
      "\n",
      "Epoch: 8\n",
      " [========================>]  Step: 66ms | Tot: 20s565ms | Loss: 11.915 | Acc: 67.266% (33633/5000 391/391 .....................]  Step: 54ms | Tot: 547ms | Loss: 11.776 | Acc: 71.810% (1103/153 12/391 ..]  Step: 49ms | Tot: 747ms | Loss: 11.783 | Acc: 70.996% (1454/204 16/391 ..................]  Step: 54ms | Tot: 802ms | Loss: 11.791 | Acc: 70.680% (1538/217 17/391 =>.......................]  Step: 47ms | Tot: 1s213ms | Loss: 11.804 | Acc: 70.031% (2241/320 25/39 32/39 33/391 ==>......................]  Step: 52ms | Tot: 1s768ms | Loss: 11.834 | Acc: 69.184% (3188/460 36/39 52/391 ===>.....................]  Step: 49ms | Tot: 2s799ms | Loss: 11.876 | Acc: 68.094% (4881/716 56/391 ]  Step: 49ms | Tot: 2s848ms | Loss: 11.877 | Acc: 68.147% (4972/729 57/391 ..................]  Step: 48ms | Tot: 3s253ms | Loss: 11.889 | Acc: 67.812% (5642/832 65/39 72/391 .......]  Step: 49ms | Tot: 3s656ms | Loss: 11.890 | Acc: 67.905% (6345/934 73/391 75/39 76/391 ..................]  Step: 54ms | Tot: 5s506ms | Loss: 11.920 | Acc: 67.001% (9348/1395 109/391 112/391 113/391 .....]  Step: 50ms | Tot: 5s907ms | Loss: 11.919 | Acc: 67.014% (10036/1497 117/391 119/391 130/39 131/391 ............]  Step: 49ms | Tot: 7s935ms | Loss: 11.934 | Acc: 66.799% (13253/1984 155/391 162/391  166/391 167/391 ===============>.........]  Step: 46ms | Tot: 12s671ms | Loss: 11.934 | Acc: 66.673% (20994/3148 246/39 272/391 ..]  Step: 53ms | Tot: 14s68ms | Loss: 11.930 | Acc: 66.893% (23375/3494 273/391 274/391 275/391 =============>......]  Step: 49ms | Tot: 15s166ms | Loss: 11.929 | Acc: 66.919% (25183/3763 294/391 ......]  Step: 48ms | Tot: 15s215ms | Loss: 11.929 | Acc: 66.923% (25270/3776 295/39 297/391 308/391 =>.....]  Step: 54ms | Tot: 15s922ms | Loss: 11.929 | Acc: 66.922% (26469/3955 309/391 ===================>.....]  Step: 46ms | Tot: 16s70ms | Loss: 11.928 | Acc: 66.950% (26737/3993 312/39 314/39 315/391 316/39 321/391 ]  Step: 55ms | Tot: 16s820ms | Loss: 11.926 | Acc: 67.023% (28053/4185 327/391 ============>...]  Step: 49ms | Tot: 17s182ms | Loss: 11.925 | Acc: 67.047% (28664/4275 334/39 343/391 359/391 375/39 377/391 ===================>]  Step: 70ms | Tot: 19s831ms | Loss: 11.916 | Acc: 67.274% (32722/48 380/391 =======>]  Step: 61ms | Tot: 20s32ms | Loss: 11.916 | Acc: 67.271% (32979/4902 383/391 ===============>]  Step: 69ms | Tot: 20s233ms | Loss: 11.916 | Acc: 67.236% (33220/4940 386/391 ===============>]  Step: 70ms | Tot: 20s498ms | Loss: 11.916 | Acc: 67.252% (33572/4992 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s603ms | Loss: 14.460 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8108, device='cuda:0'), tensor(0.7553, device='cuda:0'), tensor(0.7892, device='cuda:0'), tensor(0.8008, device='cuda:0'), tensor(0.7499, device='cuda:0'), tensor(1.6525, device='cuda:0'), tensor(1.3484, device='cuda:0')]\n",
      "\n",
      "Epoch: 9\n",
      " [========================>]  Step: 62ms | Tot: 24s843ms | Loss: 11.890 | Acc: 67.754% (33877/5000 391/391  ...................]  Step: 69ms | Tot: 838ms | Loss: 11.747 | Acc: 72.377% (1297/179 14/39 15/391 ....................]  Step: 65ms | Tot: 972ms | Loss: 11.764 | Acc: 72.119% (1477/204 16/39 37/391 46/391 .........]  Step: 71ms | Tot: 3s181ms | Loss: 11.848 | Acc: 69.165% (4338/627 49/391 53/391 69/3 72/391 =>....................]  Step: 70ms | Tot: 5s42ms | Loss: 11.877 | Acc: 68.364% (6738/985 77/391 ...........]  Step: 68ms | Tot: 5s568ms | Loss: 11.883 | Acc: 68.143% (7414/1088 85/39 96/391 106/391 111/391 117/39 123/391 >................]  Step: 71ms | Tot: 8s310ms | Loss: 11.902 | Acc: 67.526% (10977/1625 127/391 134/391 .........]  Step: 61ms | Tot: 9s180ms | Loss: 11.901 | Acc: 67.439% (12085/1792 140/39 143/391 ====>..............]  Step: 69ms | Tot: 10s695ms | Loss: 11.909 | Acc: 67.317% (14045/2086 163/39 168/391 ..]  Step: 73ms | Tot: 11s228ms | Loss: 11.909 | Acc: 67.242% (14718/2188 171/391 178/391 >.............]  Step: 76ms | Tot: 11s894ms | Loss: 11.908 | Acc: 67.295% (15591/23 181/39 189/391 ==========>............]  Step: 69ms | Tot: 12s541ms | Loss: 11.910 | Acc: 67.241% (16439/2444 191/391 ..........]  Step: 70ms | Tot: 12s671ms | Loss: 11.910 | Acc: 67.256% (16615/2470 193/391 ===>............]  Step: 70ms | Tot: 13s65ms | Loss: 11.911 | Acc: 67.219% (17122/2547 199/39 201/391 .]  Step: 70ms | Tot: 13s454ms | Loss: 11.910 | Acc: 67.245% (17645/2624 205/391 ====>...........]  Step: 69ms | Tot: 13s715ms | Loss: 11.910 | Acc: 67.273% (17997/2675 209/391 .........]  Step: 69ms | Tot: 14s376ms | Loss: 11.909 | Acc: 67.295% (18864/2803 219/391 ========>..........]  Step: 73ms | Tot: 14s506ms | Loss: 11.908 | Acc: 67.311% (19041/2828 221/391 =========>.......]  Step: 63ms | Tot: 18s120ms | Loss: 11.910 | Acc: 67.309% (24296/3609 282/39 287/39 289/39 311/39 324/39 326/391 ===>.]  Step: 69ms | Tot: 23s621ms | Loss: 11.893 | Acc: 67.749% (32086/4736 370/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s923ms | Loss: 14.280 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8096, device='cuda:0'), tensor(0.7541, device='cuda:0'), tensor(0.7879, device='cuda:0'), tensor(0.7994, device='cuda:0'), tensor(0.7486, device='cuda:0'), tensor(1.6492, device='cuda:0'), tensor(1.3456, device='cuda:0')]\n",
      "\n",
      "Epoch: 10\n",
      " [========================>]  Step: 62ms | Tot: 25s311ms | Loss: 11.872 | Acc: 67.624% (33812/5000 391/391 : 62ms | Tot: 202ms | Loss: 11.655 | Acc: 73.242% (375/51 4/39 30/391 ...................]  Step: 64ms | Tot: 3s559ms | Loss: 11.840 | Acc: 68.339% (4986/729 57/391 ...]  Step: 68ms | Tot: 3s628ms | Loss: 11.844 | Acc: 68.305% (5071/742 58/39 60/391 62/391 66/391 69/391 73/391 75/391 .....]  Step: 69ms | Tot: 4s819ms | Loss: 11.855 | Acc: 67.866% (6602/972 76/391 89/39 99/39 115/391 116/391 121/39 123/39 125/39 126/391  142/39 143/391 155/391 157/39 173/391 178/391 .............]  Step: 65ms | Tot: 11s619ms | Loss: 11.887 | Acc: 67.140% (15469/2304 180/391  182/39 183/39 185/391 186/391 =>.............]  Step: 63ms | Tot: 12s84ms | Loss: 11.887 | Acc: 67.100% (16061/2393 187/391 =====>............]  Step: 68ms | Tot: 12s727ms | Loss: 11.892 | Acc: 66.981% (16890/2521 197/391 ========>............]  Step: 62ms | Tot: 12s789ms | Loss: 11.892 | Acc: 67.002% (16981/2534 198/391 =========>............]  Step: 67ms | Tot: 12s990ms | Loss: 11.892 | Acc: 66.993% (17236/2572 201/39 209/391 210/391  212/391 228/39 233/391 235/391 =====>.........]  Step: 65ms | Tot: 15s323ms | Loss: 11.892 | Acc: 67.092% (20353/3033 237/391 .....]  Step: 68ms | Tot: 16s98ms | Loss: 11.891 | Acc: 67.150% (21402/3187 249/39 255/39 256/391 263/39 265/39 271/391 >.......]  Step: 63ms | Tot: 17s845ms | Loss: 11.889 | Acc: 67.213% (23745/3532 276/391 282/391 ....]  Step: 64ms | Tot: 18s300ms | Loss: 11.888 | Acc: 67.229% (24353/3622 283/39 290/39 291/391 ====>.....]  Step: 67ms | Tot: 19s469ms | Loss: 11.887 | Acc: 67.252% (25911/3852 301/391 ...]  Step: 63ms | Tot: 19s532ms | Loss: 11.887 | Acc: 67.231% (25989/3865 302/39 306/39 310/391 ==============>.....]  Step: 67ms | Tot: 20s188ms | Loss: 11.886 | Acc: 67.223% (26846/3993 312/39 322/391 ==========>....]  Step: 68ms | Tot: 20s903ms | Loss: 11.885 | Acc: 67.250% (27804/4134 323/391 ====>....]  Step: 62ms | Tot: 20s966ms | Loss: 11.885 | Acc: 67.260% (27894/4147 324/391 341/39 348/391 362/391 ===========>.]  Step: 67ms | Tot: 23s487ms | Loss: 11.877 | Acc: 67.480% (31354/4646 363/391 ====================>.]  Step: 67ms | Tot: 23s555ms | Loss: 11.878 | Acc: 67.482% (31441/4659 364/39 369/391 371/39 372/391 =>.]  Step: 66ms | Tot: 24s215ms | Loss: 11.876 | Acc: 67.538% (32332/4787 374/391 ============>.]  Step: 68ms | Tot: 24s283ms | Loss: 11.876 | Acc: 67.554% (32426/4800 375/391 380/39 381/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s512ms | Loss: 14.362 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8095, device='cuda:0'), tensor(0.7539, device='cuda:0'), tensor(0.7877, device='cuda:0'), tensor(0.7992, device='cuda:0'), tensor(0.7485, device='cuda:0'), tensor(1.6489, device='cuda:0'), tensor(1.3453, device='cuda:0')]\n",
      "\n",
      "Epoch: 11\n",
      " [========================>]  Step: 56ms | Tot: 21s988ms | Loss: 11.866 | Acc: 67.766% (33883/5000 391/391 1 63/39 67/391 ....]  Step: 52ms | Tot: 9s605ms | Loss: 11.873 | Acc: 67.486% (14685/2176 170/391 216/391 =>.....]  Step: 65ms | Tot: 17s378ms | Loss: 11.881 | Acc: 67.332% (26631/3955 309/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s612ms | Loss: 14.418 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8094, device='cuda:0'), tensor(0.7538, device='cuda:0'), tensor(0.7876, device='cuda:0'), tensor(0.7991, device='cuda:0'), tensor(0.7484, device='cuda:0'), tensor(1.6486, device='cuda:0'), tensor(1.3450, device='cuda:0')]\n",
      "\n",
      "Epoch: 12\n",
      " [========================>]  Step: 53ms | Tot: 22s929ms | Loss: 11.875 | Acc: 67.590% (33795/5000 391/391 .............]  Step: 45ms | Tot: 1s594ms | Loss: 11.781 | Acc: 70.439% (2795/396 31/391 .....]  Step: 51ms | Tot: 1s699ms | Loss: 11.794 | Acc: 70.170% (2964/422 33/39 61/391 ........]  Step: 50ms | Tot: 4s783ms | Loss: 11.862 | Acc: 68.223% (7772/1139 89/391 .............]  Step: 48ms | Tot: 4s984ms | Loss: 11.865 | Acc: 68.128% (8110/1190 93/39 95/391 ...........]  Step: 45ms | Tot: 5s186ms | Loss: 11.865 | Acc: 68.057% (8450/1241 97/39 362/391 370/391 371/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s724ms | Loss: 14.289 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8093, device='cuda:0'), tensor(0.7537, device='cuda:0'), tensor(0.7875, device='cuda:0'), tensor(0.7990, device='cuda:0'), tensor(0.7483, device='cuda:0'), tensor(1.6482, device='cuda:0'), tensor(1.3447, device='cuda:0')]\n",
      "\n",
      "Epoch: 13\n",
      " [========================>]  Step: 67ms | Tot: 22s98ms | Loss: 11.863 | Acc: 67.890% (33945/5000 391/391  91 ............]  Step: 68ms | Tot: 4s29ms | Loss: 11.840 | Acc: 68.517% (5876/857 67/391 .........]  Step: 50ms | Tot: 5s197ms | Loss: 11.852 | Acc: 68.120% (7673/1126 88/391 .....]  Step: 49ms | Tot: 5s449ms | Loss: 11.856 | Acc: 68.086% (8105/1190 93/391 94/39 95/391 96/391 98/39 99/39 100/39 102/391 ....]  Step: 47ms | Tot: 8s126ms | Loss: 11.877 | Acc: 67.513% (12444/1843 144/391 =========>...............]  Step: 52ms | Tot: 8s280ms | Loss: 11.877 | Acc: 67.517% (12704/1881 147/391 ...]  Step: 48ms | Tot: 8s790ms | Loss: 11.876 | Acc: 67.526% (13570/2009 157/391 158/391 .....]  Step: 53ms | Tot: 12s121ms | Loss: 11.883 | Acc: 67.404% (18981/2816 220/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s637ms | Loss: 14.337 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8091, device='cuda:0'), tensor(0.7536, device='cuda:0'), tensor(0.7873, device='cuda:0'), tensor(0.7988, device='cuda:0'), tensor(0.7481, device='cuda:0'), tensor(1.6479, device='cuda:0'), tensor(1.3444, device='cuda:0')]\n",
      "\n",
      "Epoch: 14\n",
      " [========================>]  Step: 60ms | Tot: 24s623ms | Loss: 11.867 | Acc: 67.716% (33858/5000 391/391 1 56/391 .................]  Step: 64ms | Tot: 3s472ms | Loss: 11.842 | Acc: 67.726% (5028/742 58/391 .................]  Step: 65ms | Tot: 3s796ms | Loss: 11.847 | Acc: 67.622% (5453/806 63/391 ................]  Step: 64ms | Tot: 4s67ms | Loss: 11.848 | Acc: 67.607% (5798/857 67/391 ....]  Step: 63ms | Tot: 5s209ms | Loss: 11.856 | Acc: 67.362% (7329/1088 85/391 ...........]  Step: 70ms | Tot: 5s794ms | Loss: 11.860 | Acc: 67.304% (8098/1203 94/391 ..]  Step: 62ms | Tot: 5s924ms | Loss: 11.863 | Acc: 67.212% (8259/1228 96/391 ................]  Step: 68ms | Tot: 6s366ms | Loss: 11.865 | Acc: 67.210% (8861/1318 103/391 104/391 110/391 ...]  Step: 66ms | Tot: 6s952ms | Loss: 11.871 | Acc: 67.104% (9620/1433 112/391 ..............]  Step: 68ms | Tot: 7s21ms | Loss: 11.871 | Acc: 67.070% (9701/1446 113/391 114/391 124/39 130/391 155/391 161/39 166/391 167/391 168/391 177/39 216/391 =============>...........]  Step: 70ms | Tot: 13s620ms | Loss: 11.887 | Acc: 67.151% (18652/2777 217/39 222/391 .]  Step: 65ms | Tot: 14s149ms | Loss: 11.889 | Acc: 67.181% (19348/2880 225/391 226/39 252/39 258/391 303/391 341/391 ============>]  Step: 66ms | Tot: 23s858ms | Loss: 11.868 | Acc: 67.752% (32868/4851 379/39 383/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s589ms | Loss: 14.411 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8090, device='cuda:0'), tensor(0.7534, device='cuda:0'), tensor(0.7872, device='cuda:0'), tensor(0.7987, device='cuda:0'), tensor(0.7480, device='cuda:0'), tensor(1.6476, device='cuda:0'), tensor(1.3442, device='cuda:0')]\n",
      "\n",
      "Epoch: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 65ms | Tot: 24s855ms | Loss: 11.861 | Acc: 67.782% (33891/5000 391/391 ...........]  Step: 69ms | Tot: 770ms | Loss: 11.702 | Acc: 71.635% (1192/166 13/39 20/391 .......]  Step: 67ms | Tot: 1s353ms | Loss: 11.722 | Acc: 71.165% (2004/281 22/3 23/391 ............]  Step: 66ms | Tot: 1s991ms | Loss: 11.760 | Acc: 70.508% (2888/409 32/391 .................]  Step: 68ms | Tot: 2s446ms | Loss: 11.801 | Acc: 69.752% (3482/499 39/39 53/391 ...................]  Step: 66ms | Tot: 3s556ms | Loss: 11.828 | Acc: 68.862% (4936/7 56/391 ....................]  Step: 62ms | Tot: 4s445ms | Loss: 11.841 | Acc: 68.661% (6152/896 70/39 73/39 101/391 .................]  Step: 67ms | Tot: 6s543ms | Loss: 11.850 | Acc: 68.272% (9001/1318 103/391 ............]  Step: 65ms | Tot: 6s674ms | Loss: 11.850 | Acc: 68.222% (9169/1344 105/391 106/39 112/391 113/391 114/39 131/391  143/391 ===>...............]  Step: 68ms | Tot: 9s629ms | Loss: 11.872 | Acc: 67.679% (13081/1932 151/39 153/391 154/391 158/391 164/391 ........]  Step: 65ms | Tot: 10s759ms | Loss: 11.870 | Acc: 67.759% (14571/2150 168/391 169/39 172/391 258/39 259/391 289/391 ===========>......]  Step: 69ms | Tot: 18s700ms | Loss: 11.872 | Acc: 67.541% (25417/3763 294/391 310/391 .....]  Step: 66ms | Tot: 19s849ms | Loss: 11.871 | Acc: 67.541% (26973/3993 312/391 313/39 314/391 338/391 ========>...]  Step: 63ms | Tot: 21s565ms | Loss: 11.866 | Acc: 67.644% (29352/4339 339/39 362/391 380/391  382/391 ===================>]  Step: 66ms | Tot: 24s602ms | Loss: 11.862 | Acc: 67.749% (33560/4953 387/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s621ms | Loss: 14.282 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8089, device='cuda:0'), tensor(0.7533, device='cuda:0'), tensor(0.7871, device='cuda:0'), tensor(0.7986, device='cuda:0'), tensor(0.7479, device='cuda:0'), tensor(1.6473, device='cuda:0'), tensor(1.3439, device='cuda:0')]\n",
      "\n",
      "Epoch: 16\n",
      " [========================>]  Step: 67ms | Tot: 23s224ms | Loss: 11.852 | Acc: 68.182% (34091/5000 391/391 91 ............]  Step: 71ms | Tot: 2s129ms | Loss: 11.765 | Acc: 69.462% (3023/435 34/391 ...........]  Step: 64ms | Tot: 2s330ms | Loss: 11.790 | Acc: 68.771% (3257/473 37/391 48/39 55/391 .................]  Step: 66ms | Tot: 3s621ms | Loss: 11.821 | Acc: 68.558% (5002/729 57/391 61/391 120/39 125/391 127/39 158/391 283/391 285/39 286/39 334/39 338/391 348/391 ==========>..]  Step: 52ms | Tot: 20s735ms | Loss: 11.855 | Acc: 68.136% (30525/4480 350/391 \n",
      " [========================>]  Step: 51ms | Tot: 3s671ms | Loss: 14.305 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8088, device='cuda:0'), tensor(0.7532, device='cuda:0'), tensor(0.7870, device='cuda:0'), tensor(0.7984, device='cuda:0'), tensor(0.7477, device='cuda:0'), tensor(1.6469, device='cuda:0'), tensor(1.3436, device='cuda:0')]\n",
      "\n",
      "Epoch: 17\n",
      " [========================>]  Step: 61ms | Tot: 24s216ms | Loss: 11.848 | Acc: 67.928% (33964/5000 391/391 ......]  Step: 69ms | Tot: 1s635ms | Loss: 11.739 | Acc: 70.775% (2446/345 27/39 67/39 69/39 70/391 .........]  Step: 57ms | Tot: 7s675ms | Loss: 11.845 | Acc: 67.865% (10511/1548 121/39 174/39 179/39 221/391 ........]  Step: 68ms | Tot: 13s883ms | Loss: 11.861 | Acc: 67.464% (19257/2854 223/391 363/391 ==>.]  Step: 65ms | Tot: 22s520ms | Loss: 11.852 | Acc: 67.868% (31708/4672 365/39 366/39 367/391 373/391 ========>.]  Step: 64ms | Tot: 23s176ms | Loss: 11.850 | Acc: 67.906% (32595/4800 375/391 ========>.]  Step: 68ms | Tot: 23s244ms | Loss: 11.850 | Acc: 67.919% (32688/4812 376/391 ==>]  Step: 68ms | Tot: 23s376ms | Loss: 11.849 | Acc: 67.956% (32880/4838 378/39 383/39 385/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s616ms | Loss: 14.339 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8087, device='cuda:0'), tensor(0.7531, device='cuda:0'), tensor(0.7868, device='cuda:0'), tensor(0.7983, device='cuda:0'), tensor(0.7476, device='cuda:0'), tensor(1.6466, device='cuda:0'), tensor(1.3433, device='cuda:0')]\n",
      "\n",
      "Epoch: 18\n",
      " [========================>]  Step: 63ms | Tot: 24s949ms | Loss: 11.849 | Acc: 68.043% (33967/4992 390/391 ................]  Step: 61ms | Tot: 202ms | Loss: 11.628 | Acc: 73.281% (469/64 5/391 ...................]  Step: 69ms | Tot: 402ms | Loss: 11.681 | Acc: 72.656% (744/102 8/391 ..................]  Step: 64ms | Tot: 534ms | Loss: 11.687 | Acc: 73.047% (935/128 10/391 ..]  Step: 67ms | Tot: 602ms | Loss: 11.683 | Acc: 72.656% (1023/140 11/391 13/391 ...................]  Step: 66ms | Tot: 1s654ms | Loss: 11.746 | Acc: 70.631% (2441/345 27/391 ........]  Step: 69ms | Tot: 1s723ms | Loss: 11.745 | Acc: 70.647% (2532/358 28/391 29/391 30/391 ....]  Step: 69ms | Tot: 1s925ms | Loss: 11.754 | Acc: 70.766% (2808/396 31/391 ..........]  Step: 64ms | Tot: 1s989ms | Loss: 11.765 | Acc: 70.410% (2884/409 32/391 ...................]  Step: 67ms | Tot: 3s670ms | Loss: 11.825 | Acc: 68.805% (5020/729 57/391 .........]  Step: 65ms | Tot: 3s935ms | Loss: 11.832 | Acc: 68.788% (5371/780 61/391 .........]  Step: 69ms | Tot: 4s4ms | Loss: 11.832 | Acc: 68.750% (5456/793 62/391 ..]  Step: 70ms | Tot: 4s137ms | Loss: 11.832 | Acc: 68.628% (5622/819 64/39 67/39 68/39 75/391 .................]  Step: 67ms | Tot: 5s537ms | Loss: 11.841 | Acc: 68.189% (7419/1088 85/39 86/391 88/391 .................]  Step: 66ms | Tot: 5s803ms | Loss: 11.841 | Acc: 68.285% (7779/1139 89/391 90/39 92/39 94/39 100/39 101/391 ............]  Step: 68ms | Tot: 6s899ms | Loss: 11.846 | Acc: 68.124% (9243/1356 106/39 107/391 ]  Step: 63ms | Tot: 7s165ms | Loss: 11.853 | Acc: 67.955% (9568/1408 110/39 122/391 >.................]  Step: 68ms | Tot: 8s21ms | Loss: 11.854 | Acc: 67.886% (10688/1574 123/391 .........]  Step: 62ms | Tot: 8s152ms | Loss: 11.854 | Acc: 67.875% (10860/16 125/391 ............]  Step: 68ms | Tot: 8s759ms | Loss: 11.854 | Acc: 67.807% (11717/1728 135/391 141/391 ........]  Step: 70ms | Tot: 9s432ms | Loss: 11.856 | Acc: 67.845% (12592/1856 145/39 146/391 >...............]  Step: 66ms | Tot: 9s757ms | Loss: 11.855 | Acc: 67.823% (13022/1920 150/39 151/39 156/391 159/391 168/391 ..............]  Step: 66ms | Tot: 11s169ms | Loss: 11.857 | Acc: 67.699% (14818/2188 171/391 .......]  Step: 66ms | Tot: 11s493ms | Loss: 11.859 | Acc: 67.676% (15246/2252 176/39 178/39 179/39 181/391 184/39 188/391 193/391 ===>............]  Step: 65ms | Tot: 12s682ms | Loss: 11.866 | Acc: 67.566% (16778/2483 194/391 196/391 197/39 214/39 215/39 217/39 334/391 ===============>...]  Step: 64ms | Tot: 21s437ms | Loss: 11.856 | Acc: 67.887% (29197/4300 336/39 343/39 355/39 360/39 375/391 385/391 386/391 ============>]  Step: 68ms | Tot: 25s18ms | Loss: 11.847 | Acc: 68.068% (34034/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s638ms | Loss: 14.362 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8086, device='cuda:0'), tensor(0.7529, device='cuda:0'), tensor(0.7867, device='cuda:0'), tensor(0.7981, device='cuda:0'), tensor(0.7475, device='cuda:0'), tensor(1.6463, device='cuda:0'), tensor(1.3431, device='cuda:0')]\n",
      "\n",
      "Epoch: 19\n",
      " [========================>]  Step: 62ms | Tot: 25s113ms | Loss: 11.839 | Acc: 68.204% (34102/5000 391/391 ......]  Step: 67ms | Tot: 1s767ms | Loss: 11.728 | Acc: 71.094% (2639/371 29/39 40/391 .]  Step: 65ms | Tot: 2s667ms | Loss: 11.792 | Acc: 69.513% (3826/550 43/391 50/391 .....]  Step: 63ms | Tot: 3s642ms | Loss: 11.816 | Acc: 69.060% (5127/742 58/391 >.....................]  Step: 63ms | Tot: 3s905ms | Loss: 11.822 | Acc: 68.926% (5470/793 62/39 76/391 82/391 91/39 92/391 ........]  Step: 67ms | Tot: 6s164ms | Loss: 11.831 | Acc: 68.533% (8509/1241 97/391 ..........]  Step: 67ms | Tot: 6s296ms | Loss: 11.834 | Acc: 68.474% (8677/1267 99/391 >..................]  Step: 68ms | Tot: 6s364ms | Loss: 11.835 | Acc: 68.438% (8760/12 100/391 ........]  Step: 63ms | Tot: 6s428ms | Loss: 11.832 | Acc: 68.510% (8857/1292 101/391 .............]  Step: 68ms | Tot: 6s497ms | Loss: 11.835 | Acc: 68.451% (8937/1305 102/39 106/391 ...............]  Step: 65ms | Tot: 7s798ms | Loss: 11.843 | Acc: 68.193% (10649/1561 122/391 >................]  Step: 68ms | Tot: 8s757ms | Loss: 11.844 | Acc: 68.146% (11950/1753 137/391 =>................]  Step: 63ms | Tot: 8s958ms | Loss: 11.844 | Acc: 68.170% (12216/1792 140/39 144/39 148/39 156/39 157/391  161/39 162/39 166/39 167/391 177/391 .]  Step: 64ms | Tot: 11s571ms | Loss: 11.856 | Acc: 67.951% (15656/2304 180/391 182/39 183/391 =====>.............]  Step: 70ms | Tot: 12s37ms | Loss: 11.858 | Acc: 67.894% (16251/2393 187/391 =======>............]  Step: 67ms | Tot: 12s167ms | Loss: 11.860 | Acc: 67.857% (16416/2419 189/391  191/391 195/391 =>............]  Step: 73ms | Tot: 12s829ms | Loss: 11.863 | Acc: 67.733% (17253/2547 199/391 ....]  Step: 63ms | Tot: 12s892ms | Loss: 11.863 | Acc: 67.738% (17341/2560 200/391 202/391 ........]  Step: 66ms | Tot: 13s347ms | Loss: 11.863 | Acc: 67.742% (17949/2649 207/39 228/39 230/391 231/39 234/391 =======>.........]  Step: 69ms | Tot: 15s322ms | Loss: 11.862 | Acc: 67.697% (20710/3059 239/391 249/39 250/391 =====>.......]  Step: 65ms | Tot: 17s705ms | Loss: 11.857 | Acc: 67.833% (23964/3532 276/391 283/391 ==========>......]  Step: 63ms | Tot: 18s291ms | Loss: 11.856 | Acc: 67.843% (24749/3648 285/391 ...]  Step: 65ms | Tot: 18s938ms | Loss: 11.856 | Acc: 67.823% (25610/3776 295/391 ===============>......]  Step: 69ms | Tot: 19s7ms | Loss: 11.856 | Acc: 67.829% (25699/3788 296/391 ..]  Step: 62ms | Tot: 19s139ms | Loss: 11.857 | Acc: 67.804% (25863/3814 298/39 311/391 ===============>....]  Step: 61ms | Tot: 20s512ms | Loss: 11.855 | Acc: 67.797% (27683/4083 319/391 321/391 ....]  Step: 65ms | Tot: 20s712ms | Loss: 11.853 | Acc: 67.845% (27963/41 322/391 324/39 332/391 339/391 ============>...]  Step: 70ms | Tot: 21s862ms | Loss: 11.848 | Acc: 67.962% (29577/4352 340/39 342/391 355/391 360/39 365/391 ========>]  Step: 65ms | Tot: 24s467ms | Loss: 11.840 | Acc: 68.207% (33263/4876 381/391 389/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s594ms | Loss: 14.410 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7528, device='cuda:0'), tensor(0.7866, device='cuda:0'), tensor(0.7980, device='cuda:0'), tensor(0.7474, device='cuda:0'), tensor(1.6460, device='cuda:0'), tensor(1.3428, device='cuda:0')]\n",
      "\n",
      "Epoch: 20\n",
      " [========================>]  Step: 70ms | Tot: 23s111ms | Loss: 11.850 | Acc: 67.756% (33737/4979 389/391 91 ......]  Step: 63ms | Tot: 4s768ms | Loss: 11.839 | Acc: 67.858% (7383/1088 85/39 87/391 ....]  Step: 65ms | Tot: 5s714ms | Loss: 11.847 | Acc: 67.716% (8581/1267 99/39 111/391 125/391 127/391 =====>...............]  Step: 67ms | Tot: 8s833ms | Loss: 11.858 | Acc: 67.451% (12778/1894 148/39 150/391 154/391 158/391 ..]  Step: 67ms | Tot: 10s193ms | Loss: 11.861 | Acc: 67.377% (14575/2163 169/391 ]  Step: 64ms | Tot: 10s258ms | Loss: 11.861 | Acc: 67.362% (14658/2176 170/391 =>..............]  Step: 66ms | Tot: 10s325ms | Loss: 11.862 | Acc: 67.315% (14734/2188 171/39 250/39 258/391 =======>........]  Step: 69ms | Tot: 15s450ms | Loss: 11.865 | Acc: 67.372% (22335/3315 259/391 ...]  Step: 62ms | Tot: 15s513ms | Loss: 11.865 | Acc: 67.368% (22420/3328 260/391 ================>]  Step: 69ms | Tot: 23s181ms | Loss: 11.850 | Acc: 67.756% (33824/4992 390/391 ======>]  Step: 60ms | Tot: 23s242ms | Loss: 11.849 | Acc: 67.772% (33886/5000 391/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s583ms | Loss: 14.360 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7528, device='cuda:0'), tensor(0.7866, device='cuda:0'), tensor(0.7980, device='cuda:0'), tensor(0.7474, device='cuda:0'), tensor(1.6459, device='cuda:0'), tensor(1.3428, device='cuda:0')]\n",
      "\n",
      "Epoch: 21\n",
      " [========================>]  Step: 63ms | Tot: 24s432ms | Loss: 11.847 | Acc: 68.034% (34017/5000 391/391 .]  Step: 67ms | Tot: 271ms | Loss: 11.650 | Acc: 72.344% (463/64 5/39 10/391 12/39 21/39 92/391 105/39 129/39 131/391 175/391 188/391 189/391 190/39 191/39 366/391 =======>.]  Step: 68ms | Tot: 22s870ms | Loss: 11.851 | Acc: 68.009% (31948/4697 367/391 368/391 =============>.]  Step: 68ms | Tot: 23s194ms | Loss: 11.850 | Acc: 68.017% (32387/4761 372/391 ======>]  Step: 66ms | Tot: 24s225ms | Loss: 11.849 | Acc: 68.009% (33776/4966 388/391 \n",
      " [========================>]  Step: 47ms | Tot: 3s705ms | Loss: 14.320 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7528, device='cuda:0'), tensor(0.7866, device='cuda:0'), tensor(0.7980, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6459, device='cuda:0'), tensor(1.3427, device='cuda:0')]\n",
      "\n",
      "Epoch: 22\n",
      " [========================>]  Step: 69ms | Tot: 23s387ms | Loss: 11.848 | Acc: 67.926% (33963/5000 391/391 9 118/391 .............]  Step: 68ms | Tot: 7s465ms | Loss: 11.863 | Acc: 67.543% (10634/1574 123/391 =======>.................]  Step: 69ms | Tot: 7s534ms | Loss: 11.865 | Acc: 67.471% (10709/1587 124/39 213/39 232/39 235/391   Step: 67ms | Tot: 14s450ms | Loss: 11.866 | Acc: 67.524% (20657/3059 239/391 =============>.........]  Step: 68ms | Tot: 14s652ms | Loss: 11.865 | Acc: 67.533% (20919/3097 242/391 252/391 =========>........]  Step: 69ms | Tot: 15s781ms | Loss: 11.865 | Acc: 67.537% (22390/3315 259/391 265/391 =====>.......]  Step: 70ms | Tot: 16s317ms | Loss: 11.866 | Acc: 67.559% (23089/3417 267/39 268/39 270/39 280/391 =========>......]  Step: 67ms | Tot: 17s566ms | Loss: 11.863 | Acc: 67.641% (24762/3660 286/391 ]  Step: 69ms | Tot: 17s981ms | Loss: 11.864 | Acc: 67.592% (25263/3737 292/39 293/39 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s604ms | Loss: 14.300 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7528, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7980, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6459, device='cuda:0'), tensor(1.3427, device='cuda:0')]\n",
      "\n",
      "Epoch: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 65ms | Tot: 21s58ms | Loss: 11.847 | Acc: 67.864% (33932/5000 391/391  ...]  Step: 68ms | Tot: 1s477ms | Loss: 11.687 | Acc: 72.062% (2306/320 25/391 =>.......................]  Step: 67ms | Tot: 1s544ms | Loss: 11.693 | Acc: 71.785% (2389/332 26/391 41/391 ...............]  Step: 66ms | Tot: 3s980ms | Loss: 11.823 | Acc: 68.798% (5724/832 65/39 67/391 ..................]  Step: 52ms | Tot: 4s423ms | Loss: 11.824 | Acc: 68.739% (6423/934 73/391 ....................]  Step: 51ms | Tot: 4s475ms | Loss: 11.825 | Acc: 68.761% (6513/947 74/39 101/391 ..........]  Step: 54ms | Tot: 6s637ms | Loss: 11.840 | Acc: 68.281% (10051/1472 115/391 .............]  Step: 54ms | Tot: 7s49ms | Loss: 11.841 | Acc: 68.166% (10732/1574 123/391 ========>................]  Step: 48ms | Tot: 7s302ms | Loss: 11.845 | Acc: 67.963% (11135/1638 128/391 .........]  Step: 46ms | Tot: 7s504ms | Loss: 11.846 | Acc: 67.951% (11481/1689 132/39 133/39 134/39 135/391 .]  Step: 44ms | Tot: 8s235ms | Loss: 11.852 | Acc: 67.798% (12670/1868 146/391 >...............]  Step: 54ms | Tot: 8s289ms | Loss: 11.851 | Acc: 67.857% (12768/1881 147/39 155/39 166/39 167/391 177/391 ......]  Step: 53ms | Tot: 9s902ms | Loss: 11.860 | Acc: 67.789% (15445/2278 178/391 ...]  Step: 52ms | Tot: 10s995ms | Loss: 11.865 | Acc: 67.623% (17225/2547 199/39 200/391  201/39 205/39 206/391 ........]  Step: 51ms | Tot: 12s745ms | Loss: 11.862 | Acc: 67.694% (20189/2982 233/391 ============>..........]  Step: 52ms | Tot: 12s797ms | Loss: 11.862 | Acc: 67.702% (20278/2995 234/391 247/391 264/391 ===============>.......]  Step: 53ms | Tot: 14s554ms | Loss: 11.863 | Acc: 67.590% (23186/3430 268/39 271/391 ....]  Step: 52ms | Tot: 14s754ms | Loss: 11.861 | Acc: 67.636% (23548/34 272/39 309/39 311/391 =======>.....]  Step: 54ms | Tot: 16s917ms | Loss: 11.858 | Acc: 67.669% (27111/4006 313/39 320/391 ======>....]  Step: 53ms | Tot: 17s322ms | Loss: 11.858 | Acc: 67.669% (27804/4108 321/39 322/39 323/391 ======>]  Step: 50ms | Tot: 20s330ms | Loss: 11.847 | Acc: 67.894% (32850/4838 378/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s596ms | Loss: 14.350 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7528, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7980, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6459, device='cuda:0'), tensor(1.3427, device='cuda:0')]\n",
      "\n",
      "Epoch: 24\n",
      " [========================>]  Step: 60ms | Tot: 22s991ms | Loss: 11.844 | Acc: 68.036% (34018/5000 391/391 ====>....................]  Step: 49ms | Tot: 4s306ms | Loss: 11.814 | Acc: 68.408% (6392/934 73/391 .................]  Step: 68ms | Tot: 5s718ms | Loss: 11.833 | Acc: 68.009% (8444/1241 97/391 ====>...............]  Step: 51ms | Tot: 8s225ms | Loss: 11.847 | Acc: 67.793% (12322/1817 142/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s580ms | Loss: 14.399 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7528, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7980, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6458, device='cuda:0'), tensor(1.3427, device='cuda:0')]\n",
      "\n",
      "Epoch: 25\n",
      " [========================>]  Step: 68ms | Tot: 24s983ms | Loss: 11.844 | Acc: 68.174% (34087/5000 391/391 ..............]  Step: 66ms | Tot: 2s407ms | Loss: 11.796 | Acc: 69.431% (3466/499 39/391 ..]  Step: 69ms | Tot: 2s477ms | Loss: 11.802 | Acc: 69.258% (3546/512 40/391 41/39 42/391 ]  Step: 68ms | Tot: 4s93ms | Loss: 11.830 | Acc: 68.466% (5784/844 66/391 ..................]  Step: 68ms | Tot: 5s18ms | Loss: 11.834 | Acc: 68.200% (7071/1036 81/391 ........]  Step: 62ms | Tot: 5s81ms | Loss: 11.832 | Acc: 68.197% (7158/1049 82/391 =======>.................]  Step: 63ms | Tot: 7s492ms | Loss: 11.846 | Acc: 67.949% (10524/1548 121/391 .........]  Step: 66ms | Tot: 7s992ms | Loss: 11.850 | Acc: 67.757% (11188/1651 129/391 ========>................]  Step: 64ms | Tot: 8s57ms | Loss: 11.849 | Acc: 67.800% (11282/1664 130/391 .]  Step: 68ms | Tot: 8s125ms | Loss: 11.850 | Acc: 67.814% (11371/1676 131/391 135/39 136/391 ========>................]  Step: 66ms | Tot: 8s519ms | Loss: 11.852 | Acc: 67.781% (11886/1753 137/391 .....]  Step: 67ms | Tot: 8s912ms | Loss: 11.853 | Acc: 67.810% (12412/1830 143/39 144/391 ...........]  Step: 67ms | Tot: 9s177ms | Loss: 11.854 | Acc: 67.793% (12756/1881 147/391 149/391 152/391 161/391 ........]  Step: 64ms | Tot: 10s793ms | Loss: 11.858 | Acc: 67.851% (14938/2201 172/391 173/391 =======>.............]  Step: 67ms | Tot: 10s993ms | Loss: 11.860 | Acc: 67.812% (15190/22 175/39 177/391 =====>.............]  Step: 68ms | Tot: 11s255ms | Loss: 11.861 | Acc: 67.772% (15528/2291 179/39 180/39 183/391 ===========>.............]  Step: 62ms | Tot: 11s718ms | Loss: 11.862 | Acc: 67.839% (16151/2380 186/39 192/391 ======>............]  Step: 69ms | Tot: 12s243ms | Loss: 11.865 | Acc: 67.683% (16807/2483 194/391 .........]  Step: 69ms | Tot: 12s374ms | Loss: 11.865 | Acc: 67.678% (16979/2508 196/39 198/391 ...]  Step: 69ms | Tot: 12s636ms | Loss: 11.866 | Acc: 67.672% (17324/2560 200/391 ======>...........]  Step: 69ms | Tot: 13s89ms | Loss: 11.869 | Acc: 67.584% (17907/2649 207/391 208/39 219/39 220/ 223/391 224/391 ....]  Step: 67ms | Tot: 14s249ms | Loss: 11.866 | Acc: 67.632% (19478/2880 225/391 ==============>..........]  Step: 65ms | Tot: 14s575ms | Loss: 11.867 | Acc: 67.605% (19903/2944 230/39 232/391 245/391 ==>.........]  Step: 69ms | Tot: 15s817ms | Loss: 11.865 | Acc: 67.690% (21574/3187 249/391 251/391 =>........]  Step: 69ms | Tot: 16s17ms | Loss: 11.865 | Acc: 67.721% (21844/3225 252/391 ...]  Step: 62ms | Tot: 16s79ms | Loss: 11.865 | Acc: 67.731% (21934/3238 253/391 257/391 .......]  Step: 68ms | Tot: 17s619ms | Loss: 11.860 | Acc: 67.884% (24069/3545 277/39 278/391 ===>......]  Step: 65ms | Tot: 18s6ms | Loss: 11.861 | Acc: 67.883% (24590/3622 283/39 284/391 ===========>......]  Step: 68ms | Tot: 18s206ms | Loss: 11.861 | Acc: 67.865% (24844/36 286/391 317/391 ====================>....]  Step: 68ms | Tot: 20s829ms | Loss: 11.856 | Acc: 67.969% (28449/4185 327/391 ==========>....]  Step: 63ms | Tot: 20s892ms | Loss: 11.856 | Acc: 67.976% (28539/4198 328/391 ..]  Step: 67ms | Tot: 20s960ms | Loss: 11.856 | Acc: 67.983% (28629/4211 329/391 ===============>...]  Step: 68ms | Tot: 21s93ms | Loss: 11.854 | Acc: 68.002% (28811/4236 331/391 ================>...]  Step: 68ms | Tot: 21s161ms | Loss: 11.854 | Acc: 68.013% (28903/4249 332/39 333/391 ..]  Step: 68ms | Tot: 21s484ms | Loss: 11.855 | Acc: 67.987% (29327/4313 337/391 338/391 357/391 359/391 ========>.]  Step: 66ms | Tot: 23s675ms | Loss: 11.847 | Acc: 68.131% (32354/4748 371/391 ==>.]  Step: 64ms | Tot: 23s875ms | Loss: 11.846 | Acc: 68.128% (32614/4787 374/39 381/39 382/391 ===================>]  Step: 68ms | Tot: 24s459ms | Loss: 11.845 | Acc: 68.156% (33413/4902 383/39 390/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s586ms | Loss: 14.310 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7528, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7980, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6458, device='cuda:0'), tensor(1.3426, device='cuda:0')]\n",
      "\n",
      "Epoch: 26\n",
      " [========================>]  Step: 71ms | Tot: 23s706ms | Loss: 11.840 | Acc: 68.102% (34051/5000 391/391 ........]  Step: 66ms | Tot: 271ms | Loss: 11.629 | Acc: 74.688% (478/64 5/391 ..........]  Step: 67ms | Tot: 1s190ms | Loss: 11.732 | Acc: 71.176% (1731/243 19/391 21/391 .................]  Step: 69ms | Tot: 1s390ms | Loss: 11.747 | Acc: 70.916% (1997/281 22/391 23/391 35/39 37/39 38/39 53/391 .....................]  Step: 66ms | Tot: 3s601ms | Loss: 11.811 | Acc: 68.862% (4936/7 56/391 ..................]  Step: 69ms | Tot: 3s671ms | Loss: 11.814 | Acc: 68.777% (5018/729 57/391 ............]  Step: 63ms | Tot: 4s47ms | Loss: 11.819 | Acc: 68.663% (5537/806 63/391 67/391 69/391 ...........]  Step: 69ms | Tot: 4s711ms | Loss: 11.819 | Acc: 68.654% (6415/934 73/391 ....]  Step: 65ms | Tot: 5s167ms | Loss: 11.820 | Acc: 68.623% (7027/1024 80/39 345/39 357/39 358/391 ==========>..]  Step: 69ms | Tot: 21s634ms | Loss: 11.844 | Acc: 67.977% (31237/4595 359/391 372/39 373/391 378/39 379/391 ========================>]  Step: 68ms | Tot: 23s310ms | Loss: 11.841 | Acc: 68.076% (33548/4928 385/391 ==============>]  Step: 69ms | Tot: 23s634ms | Loss: 11.841 | Acc: 68.085% (33988/4992 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s599ms | Loss: 14.337 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7528, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6458, device='cuda:0'), tensor(1.3426, device='cuda:0')]\n",
      "\n",
      "Epoch: 27\n",
      " [========================>]  Step: 61ms | Tot: 24s968ms | Loss: 11.851 | Acc: 67.664% (33832/5000 391/391 15/39 19/39 20/391 28/391 ................]  Step: 68ms | Tot: 1s816ms | Loss: 11.769 | Acc: 69.720% (2588/371 29/39 30/39 33/391 34/39 35/391 .....]  Step: 65ms | Tot: 3s9ms | Loss: 11.814 | Acc: 68.617% (4128/601 47/39 49/39 53/39 55/391 ..................]  Step: 68ms | Tot: 3s674ms | Loss: 11.819 | Acc: 68.353% (4987/729 57/39 64/391 65/39 67/391 ................]  Step: 69ms | Tot: 4s399ms | Loss: 11.832 | Acc: 67.969% (5916/870 68/391 ...............]  Step: 62ms | Tot: 4s461ms | Loss: 11.831 | Acc: 67.980% (6004/883 69/391 ....................]  Step: 68ms | Tot: 4s662ms | Loss: 11.836 | Acc: 67.849% (6253/921 72/391 73/391 75/391 76/391 ................]  Step: 67ms | Tot: 5s63ms | Loss: 11.840 | Acc: 67.528% (6742/998 78/391 .................]  Step: 62ms | Tot: 5s126ms | Loss: 11.839 | Acc: 67.524% (6828/1011 79/391 152/39 153/391 ====>...............]  Step: 69ms | Tot: 9s838ms | Loss: 11.860 | Acc: 67.553% (13316/1971 154/39 155/391 .]  Step: 68ms | Tot: 9s971ms | Loss: 11.860 | Acc: 67.553% (13489/1996 156/39 166/391 173/391 174/391 179/39 180/39 181/391 213/39 238/39 272/3 275/391 =======>.......]  Step: 69ms | Tot: 17s617ms | Loss: 11.861 | Acc: 67.438% (23997/3558 278/391 287/391 290/391 ...]  Step: 69ms | Tot: 18s936ms | Loss: 11.863 | Acc: 67.437% (25723/3814 298/391 .]  Step: 70ms | Tot: 19s197ms | Loss: 11.862 | Acc: 67.459% (26077/3865 302/391 ...]  Step: 68ms | Tot: 19s591ms | Loss: 11.864 | Acc: 67.411% (26576/3942 308/391 ===>.....]  Step: 69ms | Tot: 19s722ms | Loss: 11.863 | Acc: 67.414% (26750/3968 310/39 340/391 ===========>...]  Step: 66ms | Tot: 21s813ms | Loss: 11.861 | Acc: 67.491% (29545/4377 342/39 348/391 =============>..]  Step: 70ms | Tot: 22s598ms | Loss: 11.857 | Acc: 67.587% (30625/4531 354/39 365/391 ==>.]  Step: 70ms | Tot: 23s515ms | Loss: 11.855 | Acc: 67.616% (31850/4710 368/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s676ms | Loss: 14.334 | Acc: 1.000% (100/1000 79/79 ========>.......]  Step: 56ms | Tot: 2s507ms | Loss: 14.367 | Acc: 0.909% (64/704 55/7 56/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6457, device='cuda:0'), tensor(1.3426, device='cuda:0')]\n",
      "\n",
      "Epoch: 28\n",
      " [========================>]  Step: 56ms | Tot: 23s856ms | Loss: 11.848 | Acc: 67.812% (33906/5000 391/391 ........]  Step: 65ms | Tot: 2s27ms | Loss: 11.743 | Acc: 70.565% (3071/435 34/391 .....................]  Step: 68ms | Tot: 2s96ms | Loss: 11.750 | Acc: 70.402% (3154/448 35/391 ========>.............]  Step: 44ms | Tot: 10s891ms | Loss: 11.857 | Acc: 67.651% (16193/2393 187/391 229/391 235/391 237/391 238/391 254/391 256/391 262/39 267/39 269/39 271/39 273/391 283/391 ====>......]  Step: 65ms | Tot: 17s397ms | Loss: 11.865 | Acc: 67.443% (25035/3712 290/39 294/39 303/391 ===================>.....]  Step: 68ms | Tot: 18s689ms | Loss: 11.863 | Acc: 67.503% (26785/3968 310/391 315/391 319/391 321/391 332/391  336/39 338/391  340/391 348/391 ======================>..]  Step: 66ms | Tot: 21s211ms | Loss: 11.854 | Acc: 67.693% (30240/4467 349/391 ================>..]  Step: 63ms | Tot: 21s475ms | Loss: 11.853 | Acc: 67.732% (30604/4518 353/39 354/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s694ms | Loss: 14.213 | Acc: 1.000% (100/1000 79/79 79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6457, device='cuda:0'), tensor(1.3426, device='cuda:0')]\n",
      "\n",
      "Epoch: 29\n",
      " [========================>]  Step: 67ms | Tot: 24s79ms | Loss: 11.845 | Acc: 67.906% (33953/5000 391/391   276/39 277/39 279/391 =========>.......]  Step: 63ms | Tot: 17s89ms | Loss: 11.861 | Acc: 67.599% (24314/3596 281/39 282/391 =============>......]  Step: 65ms | Tot: 17s291ms | Loss: 11.860 | Acc: 67.608% (24577/3635 284/391 287/391 ==>.....]  Step: 61ms | Tot: 18s842ms | Loss: 11.858 | Acc: 67.639% (26666/3942 308/39 315/391 ===============>....]  Step: 62ms | Tot: 19s697ms | Loss: 11.854 | Acc: 67.737% (28092/4147 324/391 =========>....]  Step: 72ms | Tot: 19s769ms | Loss: 11.853 | Acc: 67.740% (28180/4160 325/391 ========>..]  Step: 64ms | Tot: 21s588ms | Loss: 11.850 | Acc: 67.807% (30638/4518 353/391 ======================>..]  Step: 68ms | Tot: 21s657ms | Loss: 11.849 | Acc: 67.816% (30729/4531 354/391 364/391   Step: 69ms | Tot: 22s438ms | Loss: 11.848 | Acc: 67.839% (31781/4684 366/39 368/39 369/391 =>.]  Step: 66ms | Tot: 22s839ms | Loss: 11.847 | Acc: 67.851% (32308/4761 372/39 384/391 386/391 ==>]  Step: 71ms | Tot: 23s810ms | Loss: 11.846 | Acc: 67.908% (33639/4953 387/391 =====>]  Step: 65ms | Tot: 24s12ms | Loss: 11.846 | Acc: 67.893% (33892/4992 390/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s616ms | Loss: 14.228 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6457, device='cuda:0'), tensor(1.3425, device='cuda:0')]\n",
      "\n",
      "Epoch: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 64ms | Tot: 25s395ms | Loss: 11.844 | Acc: 67.918% (33959/5000 391/391 91 61/391 62/39 85/39 92/391 ................]  Step: 62ms | Tot: 7s11ms | Loss: 11.844 | Acc: 67.865% (9816/1446 113/39 121/39 134/391 =>................]  Step: 65ms | Tot: 8s405ms | Loss: 11.844 | Acc: 67.940% (11740/1728 135/391 137/391 ====>................]  Step: 69ms | Tot: 8s604ms | Loss: 11.845 | Acc: 67.969% (12006/1766 138/391 142/391 =>...............]  Step: 68ms | Tot: 9s264ms | Loss: 11.846 | Acc: 67.890% (12861/1894 148/391 ...]  Step: 60ms | Tot: 9s395ms | Loss: 11.847 | Acc: 67.849% (13027/1920 150/39 151/391 .......]  Step: 63ms | Tot: 9s875ms | Loss: 11.847 | Acc: 67.829% (13631/2009 157/39 165/391 ==>..............]  Step: 70ms | Tot: 10s612ms | Loss: 11.846 | Acc: 67.825% (14585/2150 168/39 179/391 181/391 187/391 .......]  Step: 62ms | Tot: 12s145ms | Loss: 11.851 | Acc: 67.736% (16560/2444 191/391 201/391 217/39 221/391 .......]  Step: 61ms | Tot: 14s696ms | Loss: 11.851 | Acc: 67.744% (19857/2931 229/391 =========>..........]  Step: 65ms | Tot: 14s967ms | Loss: 11.851 | Acc: 67.741% (20203/2982 233/39 235/391 =====>.........]  Step: 69ms | Tot: 15s704ms | Loss: 11.854 | Acc: 67.658% (21131/3123 244/391 ======>.........]  Step: 70ms | Tot: 15s967ms | Loss: 11.854 | Acc: 67.666% (21480/3174 248/391 =====>.........]  Step: 64ms | Tot: 16s168ms | Loss: 11.854 | Acc: 67.654% (21736/3212 251/39 254/39 256/391 ...]  Step: 63ms | Tot: 17s620ms | Loss: 11.854 | Acc: 67.643% (23637/3494 273/391 275/391 ..]  Step: 70ms | Tot: 17s957ms | Loss: 11.856 | Acc: 67.617% (24061/3558 278/391 =============>......]  Step: 63ms | Tot: 18s825ms | Loss: 11.857 | Acc: 67.622% (25188/3724 291/39 295/39 297/391 ==============>.....]  Step: 64ms | Tot: 19s366ms | Loss: 11.857 | Acc: 67.629% (25883/3827 299/391 ========>.....]  Step: 61ms | Tot: 19s501ms | Loss: 11.857 | Acc: 67.642% (26061/3852 301/391 305/391 ============>.....]  Step: 62ms | Tot: 20s178ms | Loss: 11.856 | Acc: 67.642% (26927/3980 311/391   Step: 62ms | Tot: 20s449ms | Loss: 11.856 | Acc: 67.619% (27264/4032 315/39 318/391 ===============>....]  Step: 66ms | Tot: 20s848ms | Loss: 11.856 | Acc: 67.613% (27781/4108 321/391 ======>...]  Step: 66ms | Tot: 22s315ms | Loss: 11.851 | Acc: 67.798% (29853/4403 344/39 346/39 347/39 350/39 352/391 357/391 ============>.]  Step: 65ms | Tot: 24s405ms | Loss: 11.845 | Acc: 67.965% (32710/4812 376/391 ==========>]  Step: 68ms | Tot: 24s473ms | Loss: 11.844 | Acc: 67.973% (32801/4825 377/39 390/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s725ms | Loss: 14.310 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8084, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6456, device='cuda:0'), tensor(1.3425, device='cuda:0')]\n",
      "\n",
      "Epoch: 31\n",
      " [========================>]  Step: 63ms | Tot: 23s868ms | Loss: 11.839 | Acc: 68.232% (34116/5000 391/391 ......]  Step: 69ms | Tot: 1s130ms | Loss: 11.715 | Acc: 71.094% (1729/243 19/391 ................]  Step: 70ms | Tot: 1s393ms | Loss: 11.705 | Acc: 71.501% (2105/294 23/391 ...................]  Step: 69ms | Tot: 1s524ms | Loss: 11.704 | Acc: 71.500% (2288/320 25/391 ......]  Step: 69ms | Tot: 1s594ms | Loss: 11.713 | Acc: 71.274% (2372/332 26/391 .................]  Step: 63ms | Tot: 1s796ms | Loss: 11.730 | Acc: 70.851% (2630/371 29/39 95/391 ........]  Step: 70ms | Tot: 6s387ms | Loss: 11.832 | Acc: 68.098% (8978/1318 103/391 =>..................]  Step: 70ms | Tot: 6s518ms | Loss: 11.834 | Acc: 68.110% (9154/1344 105/39 106/39 107/39 213/39 221/39 358/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s605ms | Loss: 14.302 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7473, device='cuda:0'), tensor(1.6456, device='cuda:0'), tensor(1.3425, device='cuda:0')]\n",
      "\n",
      "Epoch: 32\n",
      " [========================>]  Step: 55ms | Tot: 21s747ms | Loss: 11.839 | Acc: 68.292% (34146/5000 391/391 1 95/39 122/39 134/391 136/391 137/391 138/391 ...............]  Step: 67ms | Tot: 9s27ms | Loss: 11.852 | Acc: 67.979% (13226/1945 152/391 =>...............]  Step: 67ms | Tot: 9s360ms | Loss: 11.854 | Acc: 67.939% (13653/2009 157/39 159/39 161/391 175/39 195/39 199/39 200/391 ........]  Step: 50ms | Tot: 12s168ms | Loss: 11.866 | Acc: 67.651% (17665/2611 204/39 211/391 ==============>..........]  Step: 49ms | Tot: 13s97ms | Loss: 11.862 | Acc: 67.790% (19350/2854 223/391 ============>..........]  Step: 49ms | Tot: 13s193ms | Loss: 11.862 | Acc: 67.747% (19511/2880 225/39 227/391 ==============>..........]  Step: 46ms | Tot: 13s496ms | Loss: 11.861 | Acc: 67.776% (20040/2956 231/39 241/391 ]  Step: 49ms | Tot: 14s232ms | Loss: 11.860 | Acc: 67.848% (21364/3148 246/391 .......]  Step: 51ms | Tot: 14s283ms | Loss: 11.860 | Acc: 67.868% (21457/3161 247/391 248/39 252/391   Step: 52ms | Tot: 14s638ms | Loss: 11.860 | Acc: 67.870% (22066/3251 254/39 258/39 259/391 ========>........]  Step: 53ms | Tot: 14s941ms | Loss: 11.861 | Acc: 67.797% (22563/3328 260/391 268/391 270/39 274/39 275/391 ===>.......]  Step: 52ms | Tot: 15s747ms | Loss: 11.858 | Acc: 67.850% (23970/3532 276/391 290/391 ==================>......]  Step: 50ms | Tot: 16s632ms | Loss: 11.858 | Acc: 67.857% (25536/37 294/391 .]  Step: 50ms | Tot: 16s683ms | Loss: 11.858 | Acc: 67.850% (25620/3776 295/391 =====>..]  Step: 51ms | Tot: 20s110ms | Loss: 11.842 | Acc: 68.249% (31449/4608 360/39 388/39 389/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s630ms | Loss: 14.469 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6456, device='cuda:0'), tensor(1.3425, device='cuda:0')]\n",
      "\n",
      "Epoch: 33\n",
      " [========================>]  Step: 54ms | Tot: 23s10ms | Loss: 11.847 | Acc: 67.870% (33935/5000 391/391  ............]  Step: 45ms | Tot: 3s736ms | Loss: 11.814 | Acc: 68.329% (5685/832 65/391 67/391 89/391 93/391 =================>.......]  Step: 69ms | Tot: 16s335ms | Loss: 11.858 | Acc: 67.545% (24208/3584 280/391   Step: 60ms | Tot: 16s468ms | Loss: 11.857 | Acc: 67.559% (24386/3609 282/391 ]  Step: 67ms | Tot: 16s535ms | Loss: 11.858 | Acc: 67.552% (24470/3622 283/391 307/391 ============>.....]  Step: 61ms | Tot: 18s108ms | Loss: 11.857 | Acc: 67.577% (26728/3955 309/391 369/39 375/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s610ms | Loss: 14.313 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7865, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6455, device='cuda:0'), tensor(1.3425, device='cuda:0')]\n",
      "\n",
      "Epoch: 34\n",
      " [========================>]  Step: 66ms | Tot: 24s206ms | Loss: 11.841 | Acc: 68.048% (34024/5000 391/391 >..........]  Step: 65ms | Tot: 13s691ms | Loss: 11.857 | Acc: 67.618% (19647/2905 227/391 ==============>..........]  Step: 68ms | Tot: 13s760ms | Loss: 11.858 | Acc: 67.609% (19731/2918 228/391 .....]  Step: 68ms | Tot: 14s274ms | Loss: 11.858 | Acc: 67.591% (20418/3020 236/391 ============>........]  Step: 69ms | Tot: 16s91ms | Loss: 11.856 | Acc: 67.729% (22887/3379 264/391 265/391 ]  Step: 70ms | Tot: 16s415ms | Loss: 11.857 | Acc: 67.710% (23314/3443 269/391 =======>.......]  Step: 65ms | Tot: 16s546ms | Loss: 11.856 | Acc: 67.721% (23491/3468 271/391 293/391 =======>.....]  Step: 69ms | Tot: 19s160ms | Loss: 11.854 | Acc: 67.786% (27071/3993 312/391 313/391 320/391 ==============>....]  Step: 69ms | Tot: 19s946ms | Loss: 11.852 | Acc: 67.812% (28123/4147 324/39 325/391 ================>....]  Step: 67ms | Tot: 20s78ms | Loss: 11.850 | Acc: 67.859% (28316/4172 326/391 ==================>..]  Step: 63ms | Tot: 21s996ms | Loss: 11.846 | Acc: 67.936% (30957/4556 356/391 ==>]  Step: 68ms | Tot: 24s12ms | Loss: 11.843 | Acc: 68.055% (33799/4966 388/391 =========>]  Step: 62ms | Tot: 24s75ms | Loss: 11.843 | Acc: 68.045% (33881/4979 389/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s609ms | Loss: 14.349 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6455, device='cuda:0'), tensor(1.3424, device='cuda:0')]\n",
      "\n",
      "Epoch: 35\n",
      " [========================>]  Step: 66ms | Tot: 24s145ms | Loss: 11.848 | Acc: 67.884% (33942/5000 391/391 Step: 68ms | Tot: 1s707ms | Loss: 11.728 | Acc: 71.317% (2556/358 28/39 31/391 .]  Step: 62ms | Tot: 2s39ms | Loss: 11.748 | Acc: 70.691% (2986/422 33/39 40/391 ...]  Step: 67ms | Tot: 2s562ms | Loss: 11.778 | Acc: 69.779% (3662/524 41/391 ...............]  Step: 67ms | Tot: 3s522ms | Loss: 11.816 | Acc: 68.764% (4929/716 56/391 84/391 .]  Step: 62ms | Tot: 5s310ms | Loss: 11.842 | Acc: 67.878% (7472/1100 86/391 ..............]  Step: 66ms | Tot: 5s877ms | Loss: 11.838 | Acc: 67.952% (8263/1216 95/39 245/391 ===>.........]  Step: 72ms | Tot: 15s106ms | Loss: 11.864 | Acc: 67.420% (21488/3187 249/391 ....]  Step: 69ms | Tot: 15s368ms | Loss: 11.864 | Acc: 67.459% (21846/3238 253/391 261/391 =====>.......]  Step: 71ms | Tot: 16s775ms | Loss: 11.861 | Acc: 67.517% (23766/3520 275/391 ===========>.......]  Step: 71ms | Tot: 16s904ms | Loss: 11.861 | Acc: 67.523% (23941/3545 277/391 287/39 295/39 311/391 314/391 317/391 ..]  Step: 71ms | Tot: 19s722ms | Loss: 11.859 | Acc: 67.660% (27800/4108 321/39 333/391 334/39 336/391   Step: 68ms | Tot: 22s116ms | Loss: 11.852 | Acc: 67.792% (31152/4595 359/39 372/39 374/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s490ms | Loss: 14.209 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6455, device='cuda:0'), tensor(1.3424, device='cuda:0')]\n",
      "\n",
      "Epoch: 36\n",
      " [========================>]  Step: 61ms | Tot: 25s627ms | Loss: 11.848 | Acc: 67.794% (33897/5000 391/391 .........]  Step: 68ms | Tot: 1s147ms | Loss: 11.708 | Acc: 72.204% (1756/243 19/391 ......]  Step: 62ms | Tot: 1s209ms | Loss: 11.707 | Acc: 72.344% (1852/256 20/391 35/391 42/391 45/391 51/39 55/391 ...]  Step: 65ms | Tot: 3s773ms | Loss: 11.815 | Acc: 68.631% (5183/755 59/391 ..............]  Step: 61ms | Tot: 4s690ms | Loss: 11.829 | Acc: 68.461% (6397/934 73/39 74/39 82/39 85/391 =====>...................]  Step: 66ms | Tot: 5s811ms | Loss: 11.839 | Acc: 68.047% (7839/1152 90/391 91/39 92/391 ...........]  Step: 68ms | Tot: 6s696ms | Loss: 11.847 | Acc: 67.961% (8960/1318 103/391 107/391 110/391 116/39 117/39 120/39 130/39 133/39 139/39 141/391 ............]  Step: 68ms | Tot: 9s500ms | Loss: 11.852 | Acc: 67.689% (12563/1856 145/391 150/391 151/39 152/391 =========>...............]  Step: 68ms | Tot: 10s157ms | Loss: 11.854 | Acc: 67.586% (13409/1984 155/391 162/391 164/391 ==>..............]  Step: 68ms | Tot: 10s839ms | Loss: 11.855 | Acc: 67.547% (14266/2112 165/391 ========>..............]  Step: 63ms | Tot: 10s903ms | Loss: 11.855 | Acc: 67.540% (14351/2124 166/39 168/391 172/39 180/391 ..........]  Step: 69ms | Tot: 12s82ms | Loss: 11.856 | Acc: 67.489% (15895/2355 184/391 197/39 199/391 ..]  Step: 68ms | Tot: 13s374ms | Loss: 11.861 | Acc: 67.341% (17584/2611 204/391 ======>...........]  Step: 66ms | Tot: 13s576ms | Loss: 11.860 | Acc: 67.338% (17842/2649 207/391 210/391 215/391 222/39 225/391 =======>..........]  Step: 66ms | Tot: 15s310ms | Loss: 11.861 | Acc: 67.322% (20078/2982 233/391 234/391 ..]  Step: 67ms | Tot: 15s510ms | Loss: 11.863 | Acc: 67.267% (20320/3020 236/391 246/391 249/391 =========>........]  Step: 67ms | Tot: 17s65ms | Loss: 11.860 | Acc: 67.377% (22423/3328 260/391   Step: 67ms | Tot: 17s264ms | Loss: 11.860 | Acc: 67.372% (22680/3366 263/391 >........]  Step: 69ms | Tot: 17s396ms | Loss: 11.861 | Acc: 67.338% (22841/3392 265/391 267/391 ===>.......]  Step: 63ms | Tot: 17s661ms | Loss: 11.862 | Acc: 67.368% (23196/3443 269/391 >.......]  Step: 65ms | Tot: 17s862ms | Loss: 11.861 | Acc: 67.409% (23469/3481 272/391 ==========>.......]  Step: 68ms | Tot: 17s931ms | Loss: 11.860 | Acc: 67.425% (23561/3494 273/391 275/391 ==========>.......]  Step: 65ms | Tot: 18s194ms | Loss: 11.860 | Acc: 67.464% (23920/3545 277/39 279/391  281/391 282/391 284/391 287/391 293/391 295/39 296/391 =======>.....]  Step: 67ms | Tot: 19s971ms | Loss: 11.860 | Acc: 67.465% (26252/3891 304/391 ===================>.....]  Step: 67ms | Tot: 20s172ms | Loss: 11.860 | Acc: 67.480% (26517/3929 307/391 309/391 ...]  Step: 68ms | Tot: 21s744ms | Loss: 11.856 | Acc: 67.570% (28628/4236 331/39 332/39 335/39 339/391 =>..]  Step: 66ms | Tot: 23s259ms | Loss: 11.852 | Acc: 67.741% (30695/4531 354/391 356/391 362/39 365/39 373/391 ======================>]  Step: 66ms | Tot: 24s811ms | Loss: 11.849 | Acc: 67.774% (32792/4838 378/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s608ms | Loss: 14.308 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6455, device='cuda:0'), tensor(1.3424, device='cuda:0')]\n",
      "\n",
      "Epoch: 37\n",
      " [========================>]  Step: 63ms | Tot: 24s752ms | Loss: 11.850 | Acc: 67.826% (33913/5000 391/391 .................]  Step: 69ms | Tot: 514ms | Loss: 11.700 | Acc: 72.309% (833/115 9/391 .................]  Step: 69ms | Tot: 1s230ms | Loss: 11.764 | Acc: 70.469% (1804/256 20/391 ]  Step: 66ms | Tot: 1s362ms | Loss: 11.768 | Acc: 70.241% (1978/281 22/39 27/39 45/391 73/391 74/391 75/391 84/391 85/39 93/39 99/391 101/391 102/39 104/39 108/39 128/39 141/39 146/391 149/391 158/391 ...]  Step: 68ms | Tot: 10s482ms | Loss: 11.867 | Acc: 67.235% (14114/2099 164/391 >..............]  Step: 63ms | Tot: 10s546ms | Loss: 11.867 | Acc: 67.244% (14202/2112 165/39 177/391 ...........]  Step: 64ms | Tot: 11s383ms | Loss: 11.868 | Acc: 67.218% (15315/2278 178/39 184/39 192/391 206/39 207/391 ===========>]  Step: 66ms | Tot: 24s86ms | Loss: 11.851 | Acc: 67.778% (33054/4876 381/39 383/391 386/39 389/391 390/391 \n",
      " [========================>]  Step: 45ms | Tot: 3s604ms | Loss: 14.374 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7527, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7979, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6454, device='cuda:0'), tensor(1.3424, device='cuda:0')]\n",
      "\n",
      "Epoch: 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 60ms | Tot: 23s925ms | Loss: 11.847 | Acc: 67.768% (33884/5000 391/391 ..........]  Step: 68ms | Tot: 1s705ms | Loss: 11.741 | Acc: 70.508% (2527/358 28/39 36/391 ................]  Step: 64ms | Tot: 5s156ms | Loss: 11.834 | Acc: 68.301% (7606/1113 87/391 88/391 .................]  Step: 66ms | Tot: 5s550ms | Loss: 11.838 | Acc: 68.246% (8124/1190 93/391 ............]  Step: 70ms | Tot: 6s579ms | Loss: 11.845 | Acc: 67.926% (9564/1408 110/39 127/391 ===>................]  Step: 69ms | Tot: 7s728ms | Loss: 11.848 | Acc: 67.731% (11097/1638 128/39 130/391 ==>................]  Step: 68ms | Tot: 8s183ms | Loss: 11.848 | Acc: 67.714% (11701/1728 135/391 ............]  Step: 63ms | Tot: 8s315ms | Loss: 11.848 | Acc: 67.741% (11879/1753 137/39 154/391 156/39 179/39 182/391 ====>.............]  Step: 69ms | Tot: 11s450ms | Loss: 11.860 | Acc: 67.440% (16056/2380 186/39 187/391 ........]  Step: 63ms | Tot: 13s531ms | Loss: 11.862 | Acc: 67.272% (19030/2828 221/391 ........]  Step: 70ms | Tot: 13s732ms | Loss: 11.862 | Acc: 67.282% (19291/2867 224/39 228/39 240/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s636ms | Loss: 14.447 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7526, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7978, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6454, device='cuda:0'), tensor(1.3423, device='cuda:0')]\n",
      "\n",
      "Epoch: 39\n",
      " [========================>]  Step: 68ms | Tot: 24s989ms | Loss: 11.841 | Acc: 67.954% (33977/5000 391/391 ep: 69ms | Tot: 1s96ms | Loss: 11.686 | Acc: 71.398% (1645/230 18/391 ..]  Step: 64ms | Tot: 1s160ms | Loss: 11.693 | Acc: 71.135% (1730/243 19/391 ......]  Step: 66ms | Tot: 1s227ms | Loss: 11.701 | Acc: 71.094% (1820/256 20/391 34/391  35/391 43/39 44/391 ..............]  Step: 69ms | Tot: 3s24ms | Loss: 11.786 | Acc: 68.620% (4216/614 48/391 54/39 55/39 58/391 60/39 62/39 66/391  68/39 70/391 ......]  Step: 65ms | Tot: 6s345ms | Loss: 11.825 | Acc: 67.858% (8599/1267 99/391 108/39 110/391 112/39 116/39 118/39 119/39 121/391 126/391 134/39 135/391 136/391 .............]  Step: 70ms | Tot: 8s838ms | Loss: 11.834 | Acc: 67.706% (11873/1753 137/391 =>................]  Step: 65ms | Tot: 8s969ms | Loss: 11.835 | Acc: 67.671% (12040/1779 139/391 =======>...............]  Step: 71ms | Tot: 9s543ms | Loss: 11.841 | Acc: 67.605% (12807/1894 148/391 ...........]  Step: 69ms | Tot: 9s804ms | Loss: 11.841 | Acc: 67.527% (13138/1945 152/391 =>..............]  Step: 65ms | Tot: 10s582ms | Loss: 11.842 | Acc: 67.592% (14189/2099 164/391 170/391 ]  Step: 66ms | Tot: 11s562ms | Loss: 11.842 | Acc: 67.593% (15487/2291 179/39 180/391 204/39 214/391 216/391 275/39 283/391 =====>......]  Step: 67ms | Tot: 18s610ms | Loss: 11.853 | Acc: 67.567% (25427/3763 294/391 ==============>.....]  Step: 61ms | Tot: 18s957ms | Loss: 11.853 | Acc: 67.564% (25858/3827 299/39 314/391 ..]  Step: 67ms | Tot: 20s873ms | Loss: 11.846 | Acc: 67.736% (28525/4211 329/39 339/391 >...]  Step: 63ms | Tot: 21s580ms | Loss: 11.846 | Acc: 67.744% (29482/4352 340/39 344/391 ============>...]  Step: 67ms | Tot: 21s910ms | Loss: 11.846 | Acc: 67.808% (29944/4416 345/391 372/391 ===================>.]  Step: 67ms | Tot: 23s766ms | Loss: 11.841 | Acc: 67.958% (32446/4774 373/391 375/39 382/391 =========>]  Step: 68ms | Tot: 24s857ms | Loss: 11.842 | Acc: 67.923% (33820/4979 389/391 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s906ms | Loss: 14.250 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7526, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7978, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6454, device='cuda:0'), tensor(1.3423, device='cuda:0')]\n",
      "\n",
      "Epoch: 40\n",
      " [========================>]  Step: 48ms | Tot: 23s240ms | Loss: 11.847 | Acc: 67.824% (33912/5000 391/391 1 60/391 ...........]  Step: 68ms | Tot: 9s154ms | Loss: 11.857 | Acc: 67.589% (12977/1920 150/39 152/39 158/39 198/391 204/391 ====>..........]  Step: 69ms | Tot: 13s988ms | Loss: 11.865 | Acc: 67.351% (19742/2931 229/39 241/391 \n",
      " [========================>]  Step: 43ms | Tot: 3s611ms | Loss: 14.363 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7526, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7978, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6453, device='cuda:0'), tensor(1.3423, device='cuda:0')]\n",
      "\n",
      "Epoch: 41\n",
      " [========================>]  Step: 64ms | Tot: 23s747ms | Loss: 11.836 | Acc: 68.066% (34033/5000 391/391 391   Step: 68ms | Tot: 6s294ms | Loss: 11.835 | Acc: 68.073% (9759/1433 112/39 141/391 219/39 321/391 ====>....]  Step: 66ms | Tot: 19s557ms | Loss: 11.843 | Acc: 67.928% (28258/4160 325/39 329/391 ======>..]  Step: 70ms | Tot: 20s932ms | Loss: 11.839 | Acc: 68.054% (30227/4441 347/391 359/39 375/391 \n",
      " [========================>]  Step: 46ms | Tot: 3s677ms | Loss: 14.309 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8083, device='cuda:0'), tensor(0.7526, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7978, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6453, device='cuda:0'), tensor(1.3423, device='cuda:0')]\n",
      "\n",
      "Epoch: 42\n",
      " [========================>]  Step: 65ms | Tot: 24s722ms | Loss: 11.835 | Acc: 68.052% (34026/5000 391/391 91 ..................]  Step: 63ms | Tot: 2s341ms | Loss: 11.758 | Acc: 69.857% (3219/460 36/391 ............]  Step: 68ms | Tot: 3s897ms | Loss: 11.806 | Acc: 68.763% (5281/768 60/391 62/39 71/391 79/391 89/391 ..............]  Step: 67ms | Tot: 6s97ms | Loss: 11.814 | Acc: 68.542% (8247/1203 94/39 96/39 97/391 ...........]  Step: 62ms | Tot: 6s429ms | Loss: 11.820 | Acc: 68.411% (8669/1267 99/391 103/391 ]  Step: 69ms | Tot: 7s97ms | Loss: 11.821 | Acc: 68.320% (9532/1395 109/391 ==>..................]  Step: 68ms | Tot: 7s165ms | Loss: 11.822 | Acc: 68.324% (9620/1408 110/391 =======>.................]  Step: 65ms | Tot: 7s231ms | Loss: 11.821 | Acc: 68.349% (9711/1420 111/3 112/391 ...........]  Step: 65ms | Tot: 7s499ms | Loss: 11.825 | Acc: 68.186% (10037/1472 115/391 ..]  Step: 70ms | Tot: 8s194ms | Loss: 11.832 | Acc: 67.863% (10945/1612 126/391 ..............]  Step: 62ms | Tot: 8s257ms | Loss: 11.831 | Acc: 67.883% (11035/1625 127/391 128/391 ..........]  Step: 66ms | Tot: 10s4ms | Loss: 11.839 | Acc: 67.801% (13365/1971 154/39 158/391 160/39 280/391 =================>.......]  Step: 67ms | Tot: 17s470ms | Loss: 11.848 | Acc: 67.655% (24334/3596 281/391 285/39 286/391  288/391 ==============>......]  Step: 70ms | Tot: 17s994ms | Loss: 11.848 | Acc: 67.693% (25041/3699 289/39 291/391 292/391 ==================>......]  Step: 64ms | Tot: 18s329ms | Loss: 11.848 | Acc: 67.700% (25477/37 294/391 ===========>.....]  Step: 67ms | Tot: 18s942ms | Loss: 11.846 | Acc: 67.708% (26260/3878 303/391 304/391 .]  Step: 67ms | Tot: 19s330ms | Loss: 11.847 | Acc: 67.708% (26780/3955 309/391 =>.....]  Step: 67ms | Tot: 19s398ms | Loss: 11.846 | Acc: 67.722% (26872/3968 310/391 =============>....]  Step: 66ms | Tot: 19s783ms | Loss: 11.846 | Acc: 67.704% (27385/4044 316/391 =======>....]  Step: 69ms | Tot: 20s44ms | Loss: 11.845 | Acc: 67.732% (27743/4096 320/391 ....]  Step: 68ms | Tot: 20s176ms | Loss: 11.844 | Acc: 67.767% (27931/4121 322/391 ====================>....]  Step: 69ms | Tot: 20s245ms | Loss: 11.844 | Acc: 67.783% (28024/4134 323/391 ..]  Step: 63ms | Tot: 20s308ms | Loss: 11.844 | Acc: 67.781% (28110/4147 324/391 ====>....]  Step: 70ms | Tot: 20s510ms | Loss: 11.843 | Acc: 67.821% (28387/4185 327/391 ============>..]  Step: 62ms | Tot: 22s66ms | Loss: 11.837 | Acc: 68.042% (30570/4492 351/391 ====>.]  Step: 60ms | Tot: 22s792ms | Loss: 11.837 | Acc: 68.029% (31522/4633 362/39 388/39 390/391 \n",
      " [========================>]  Step: 44ms | Tot: 3s653ms | Loss: 14.313 | Acc: 1.000% (100/1000 79/79 /79 \n",
      "Saving..\n",
      "Sparsity:  [1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "SNRS:  [tensor(0.8082, device='cuda:0'), tensor(0.7526, device='cuda:0'), tensor(0.7864, device='cuda:0'), tensor(0.7978, device='cuda:0'), tensor(0.7472, device='cuda:0'), tensor(1.6453, device='cuda:0'), tensor(1.3422, device='cuda:0')]\n",
      "\n",
      "Epoch: 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 64ms | Tot: 21s35ms | Loss: 11.852 | Acc: 67.640% (33820/5000 391/391  41/391 171/39 367/39 368/391 ==========>.]  Step: 53ms | Tot: 19s673ms | Loss: 11.856 | Acc: 67.554% (31907/4723 369/391 389/391 \n",
      " [==============>..........]  Step: 45ms | Tot: 2s72ms | Loss: 14.415 | Acc: 0.866% (51/588 46/79  \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-bee6f6abe7f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mSBP_net_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msbp_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr_adjust\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mSBP_net_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msbp_net\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-e32198c661a4>\u001b[0m in \u001b[0;36mSBP_net_test\u001b[0;34m(epoch, net, criterion)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/net-compression/working_code/alexnet/SBP_alexnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsbp2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrel3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/net-compression/working_code/alexnet/SBP_utils_gpu.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0mmultiplicator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_truncated_log_normal_reduced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0msnr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnr_truncated_log_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_log\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msnr\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/net-compression/working_code/alexnet/SBP_utils_gpu.py\u001b[0m in \u001b[0;36msnr_truncated_log_normal\u001b[0;34m(mu, sigma, a, b)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratio\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0merfcx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merfcx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenominator\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0merfcx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mdenominator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenominator\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-8\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/net-compression/working_code/alexnet/SBP_utils_gpu.py\u001b[0m in \u001b[0;36merfcx\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.4590054580646477331e-02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1177578934567401754080e+01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2.0\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_sbp_acc = best_base_acc = 0 #reset best accuracy to save after running SBP\n",
    "\n",
    "equal_weights = [1,1,1,1,1,1,1]\n",
    "lr_x = [] #learning rate decay\n",
    "\n",
    "def learning_rate_calc(optimizer, epoch):\n",
    "    if epoch < 350:\n",
    "        return 1e-5\n",
    "    else: \n",
    "        return 1e-5 * (400-epoch)/(400-350)\n",
    "\n",
    "\n",
    "sbp_learningrate = 1e-5\n",
    "finetune_epoch = 300 ## that seems excessive\n",
    "warmup_optimizer = optim.Adam(sbp_net.parameters(),lr=sbp_learningrate, betas=[0.95,0.999])\n",
    "#equal_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_x)\n",
    "warmup_scheduler = optim.lr_scheduler.MultiStepLR(warmup_optimizer,milestones=[10,20,50],gamma=0.1)\n",
    "\n",
    "for epoch in range(0,100):\n",
    "    SBP_net_train(epoch,sbp_net,optimizer=warmup_optimizer,criterion=nn.CrossEntropyLoss(),lr_adjust=None,scheduler=warmup_scheduler)\n",
    "    SBP_net_test(epoch,sbp_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(300,400):\n",
    "    SBP_net_train(epoch,sbp_equal_net,optimizer=equal_optimizer,criterion=nn.CrossEntropyLoss(),lr_adjust=learning_rate_calc)\n",
    "    SBP_net_test(epoch,sbp_equal_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sbp_acc = best_base_acc = 0 #reset best accuracy to save after running SBP\n",
    "equal_weights = [1,1,1,1,1,1,1]\n",
    "sbp_equal_net = SBPConv_AlexNet(cfg,kl_weights=equal_weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SBPConv_AlexNet:\n\tMissing key(s) in state_dict: \"block1.conv1.log_sigma\", \"block1.conv1.mu\", \"block1.conv1.weight\", \"block1.bn1.weight\", \"block1.bn1.bias\", \"block1.bn1.running_mean\", \"block1.bn1.running_var\", \"block2.conv1.log_sigma\", \"block2.conv1.mu\", \"block2.conv1.weight\", \"block2.bn1.weight\", \"block2.bn1.bias\", \"block2.bn1.running_mean\", \"block2.bn1.running_var\", \"block3.conv1.log_sigma\", \"block3.conv1.mu\", \"block3.conv1.weight\", \"block3.bn1.weight\", \"block3.bn1.bias\", \"block3.bn1.running_mean\", \"block3.bn1.running_var\", \"block4.conv1.log_sigma\", \"block4.conv1.mu\", \"block4.conv1.weight\", \"block4.bn1.weight\", \"block4.bn1.bias\", \"block4.bn1.running_mean\", \"block4.bn1.running_var\", \"block5.conv1.log_sigma\", \"block5.conv1.mu\", \"block5.conv1.weight\", \"block5.bn1.weight\", \"block5.bn1.bias\", \"block5.bn1.running_mean\", \"block5.bn1.running_var\", \"lsbp1.weight\", \"lsbp1.bias\", \"lsbp1.log_sigma\", \"lsbp1.mu\", \"lsbp2.weight\", \"lsbp2.bias\", \"lsbp2.log_sigma\", \"lsbp2.mu\", \"last.weight\", \"last.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.2.weight\", \"features.2.bias\", \"features.2.running_mean\", \"features.2.running_var\", \"features.2.num_batches_tracked\", \"features.4.weight\", \"features.4.bias\", \"features.6.weight\", \"features.6.bias\", \"features.6.running_mean\", \"features.6.running_var\", \"features.6.num_batches_tracked\", \"features.8.weight\", \"features.8.bias\", \"features.10.weight\", \"features.10.bias\", \"features.10.running_mean\", \"features.10.running_var\", \"features.10.num_batches_tracked\", \"features.11.weight\", \"features.11.bias\", \"features.13.weight\", \"features.13.bias\", \"features.13.running_mean\", \"features.13.running_var\", \"features.13.num_batches_tracked\", \"features.14.weight\", \"features.14.bias\", \"features.16.weight\", \"features.16.bias\", \"features.16.running_mean\", \"features.16.running_var\", \"features.16.num_batches_tracked\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.4.weight\", \"classifier.4.bias\", \"classifier.6.weight\", \"classifier.6.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5d103a6e66c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./checkpoint/ckpt.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msbp_equal_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'net'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'best_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 830\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    831\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SBPConv_AlexNet:\n\tMissing key(s) in state_dict: \"block1.conv1.log_sigma\", \"block1.conv1.mu\", \"block1.conv1.weight\", \"block1.bn1.weight\", \"block1.bn1.bias\", \"block1.bn1.running_mean\", \"block1.bn1.running_var\", \"block2.conv1.log_sigma\", \"block2.conv1.mu\", \"block2.conv1.weight\", \"block2.bn1.weight\", \"block2.bn1.bias\", \"block2.bn1.running_mean\", \"block2.bn1.running_var\", \"block3.conv1.log_sigma\", \"block3.conv1.mu\", \"block3.conv1.weight\", \"block3.bn1.weight\", \"block3.bn1.bias\", \"block3.bn1.running_mean\", \"block3.bn1.running_var\", \"block4.conv1.log_sigma\", \"block4.conv1.mu\", \"block4.conv1.weight\", \"block4.bn1.weight\", \"block4.bn1.bias\", \"block4.bn1.running_mean\", \"block4.bn1.running_var\", \"block5.conv1.log_sigma\", \"block5.conv1.mu\", \"block5.conv1.weight\", \"block5.bn1.weight\", \"block5.bn1.bias\", \"block5.bn1.running_mean\", \"block5.bn1.running_var\", \"lsbp1.weight\", \"lsbp1.bias\", \"lsbp1.log_sigma\", \"lsbp1.mu\", \"lsbp2.weight\", \"lsbp2.bias\", \"lsbp2.log_sigma\", \"lsbp2.mu\", \"last.weight\", \"last.bias\". \n\tUnexpected key(s) in state_dict: \"features.0.weight\", \"features.0.bias\", \"features.2.weight\", \"features.2.bias\", \"features.2.running_mean\", \"features.2.running_var\", \"features.2.num_batches_tracked\", \"features.4.weight\", \"features.4.bias\", \"features.6.weight\", \"features.6.bias\", \"features.6.running_mean\", \"features.6.running_var\", \"features.6.num_batches_tracked\", \"features.8.weight\", \"features.8.bias\", \"features.10.weight\", \"features.10.bias\", \"features.10.running_mean\", \"features.10.running_var\", \"features.10.num_batches_tracked\", \"features.11.weight\", \"features.11.bias\", \"features.13.weight\", \"features.13.bias\", \"features.13.running_mean\", \"features.13.running_var\", \"features.13.num_batches_tracked\", \"features.14.weight\", \"features.14.bias\", \"features.16.weight\", \"features.16.bias\", \"features.16.running_mean\", \"features.16.running_var\", \"features.16.num_batches_tracked\", \"classifier.1.weight\", \"classifier.1.bias\", \"classifier.4.weight\", \"classifier.4.bias\", \"classifier.6.weight\", \"classifier.6.bias\". "
     ]
    }
   ],
   "source": [
    "net_dict = torch.load('./checkpoint/sbp_ckpt.pth')\n",
    "sbp_equal_net.load_state_dict(net_dict['net'])\n",
    "best_acc = net_dict['best_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features.0.weight', 'features.0.bias', 'features.2.weight', 'features.2.bias', 'features.2.running_mean', 'features.2.running_var', 'features.2.num_batches_tracked', 'features.4.weight', 'features.4.bias', 'features.6.weight', 'features.6.bias', 'features.6.running_mean', 'features.6.running_var', 'features.6.num_batches_tracked', 'features.8.weight', 'features.8.bias', 'features.10.weight', 'features.10.bias', 'features.10.running_mean', 'features.10.running_var', 'features.10.num_batches_tracked', 'features.11.weight', 'features.11.bias', 'features.13.weight', 'features.13.bias', 'features.13.running_mean', 'features.13.running_var', 'features.13.num_batches_tracked', 'features.14.weight', 'features.14.bias', 'features.16.weight', 'features.16.bias', 'features.16.running_mean', 'features.16.running_var', 'features.16.num_batches_tracked', 'classifier.1.weight', 'classifier.1.bias', 'classifier.4.weight', 'classifier.4.bias', 'classifier.6.weight', 'classifier.6.bias'])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_dict['net'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([-5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.1025, -0.4885,  0.4237],\n",
       "           [-0.0737,  0.5720,  0.1400],\n",
       "           [ 0.4433,  0.4696,  0.2519]],\n",
       " \n",
       "          [[ 0.5657, -0.2519,  0.2215],\n",
       "           [-0.1572,  0.0922, -0.2797],\n",
       "           [ 0.2231, -0.0048, -0.2302]],\n",
       " \n",
       "          [[-0.1521,  0.2063, -0.3188],\n",
       "           [ 0.3253,  0.4383, -0.0304],\n",
       "           [-0.3237,  0.5112, -0.1433]]],\n",
       " \n",
       " \n",
       "         [[[-0.3762, -0.5478,  0.2220],\n",
       "           [ 0.2012,  0.0775, -0.5726],\n",
       "           [ 0.3423,  0.3010, -0.1742]],\n",
       " \n",
       "          [[-0.5326,  0.4959,  0.4547],\n",
       "           [ 0.0683,  0.1451, -0.5664],\n",
       "           [-0.5657,  0.0697,  0.1253]],\n",
       " \n",
       "          [[-0.0933, -0.4746,  0.4522],\n",
       "           [ 0.4998, -0.0978, -0.0628],\n",
       "           [-0.1558,  0.1552,  0.2409]]],\n",
       " \n",
       " \n",
       "         [[[-0.2256,  0.4493, -0.2036],\n",
       "           [ 0.1747,  0.0690, -0.1340],\n",
       "           [ 0.3390,  0.1257, -0.0069]],\n",
       " \n",
       "          [[-0.2670,  0.3247, -0.3979],\n",
       "           [-0.2171, -0.5125, -0.1343],\n",
       "           [ 0.0111,  0.3041, -0.5469]],\n",
       " \n",
       "          [[-0.0685,  0.2584, -0.0734],\n",
       "           [ 0.3025,  0.4150, -0.4507],\n",
       "           [ 0.2428,  0.1656, -0.2418]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0789,  0.4050,  0.1113],\n",
       "           [-0.5391,  0.3940,  0.3914],\n",
       "           [-0.1252, -0.1933, -0.0902]],\n",
       " \n",
       "          [[-0.0937,  0.5211,  0.5668],\n",
       "           [-0.0642,  0.1740,  0.3185],\n",
       "           [-0.0331,  0.5178, -0.3498]],\n",
       " \n",
       "          [[ 0.4703,  0.5514,  0.5167],\n",
       "           [-0.3452,  0.1837,  0.1992],\n",
       "           [-0.5401, -0.3217,  0.1985]]],\n",
       " \n",
       " \n",
       "         [[[-0.0876, -0.3386,  0.0565],\n",
       "           [ 0.2276,  0.0181, -0.3731],\n",
       "           [-0.0998,  0.2300, -0.2481]],\n",
       " \n",
       "          [[-0.0934,  0.1666, -0.0257],\n",
       "           [ 0.0540, -0.3005, -0.3278],\n",
       "           [ 0.1075,  0.5543, -0.3111]],\n",
       " \n",
       "          [[ 0.5460,  0.3730, -0.4012],\n",
       "           [-0.1722,  0.4141,  0.4856],\n",
       "           [ 0.0395,  0.0911,  0.3899]]],\n",
       " \n",
       " \n",
       "         [[[ 0.4631, -0.2848, -0.0728],\n",
       "           [-0.5697, -0.3658,  0.3965],\n",
       "           [ 0.4536,  0.4712,  0.1110]],\n",
       " \n",
       "          [[ 0.0698, -0.2170, -0.5627],\n",
       "           [ 0.1120,  0.0824,  0.3520],\n",
       "           [-0.2852, -0.5182, -0.2340]],\n",
       " \n",
       "          [[-0.4826,  0.2907,  0.5320],\n",
       "           [-0.4600, -0.5680,  0.3710],\n",
       "           [-0.2666, -0.2204, -0.0163]]]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0645,  0.0371, -0.0411],\n",
       "           [ 0.0896,  0.0574,  0.0541],\n",
       "           [-0.1175, -0.0810, -0.0536]],\n",
       " \n",
       "          [[ 0.0883,  0.0252,  0.0614],\n",
       "           [-0.0727,  0.0399,  0.0007],\n",
       "           [ 0.1218,  0.0196, -0.0103]],\n",
       " \n",
       "          [[-0.0714,  0.0299, -0.0796],\n",
       "           [-0.0300, -0.0981, -0.0663],\n",
       "           [-0.0423,  0.0486, -0.0335]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0547, -0.1208, -0.0500],\n",
       "           [-0.0625, -0.0358,  0.1095],\n",
       "           [ 0.0402,  0.0817, -0.0253]],\n",
       " \n",
       "          [[ 0.0556, -0.0288,  0.0222],\n",
       "           [-0.0846, -0.0992,  0.1214],\n",
       "           [ 0.0803,  0.1160, -0.0387]],\n",
       " \n",
       "          [[-0.0111,  0.0777,  0.0597],\n",
       "           [-0.0511, -0.0593,  0.0219],\n",
       "           [-0.0398,  0.0447,  0.0419]]],\n",
       " \n",
       " \n",
       "         [[[ 0.1093,  0.0247, -0.0166],\n",
       "           [ 0.0564, -0.0190, -0.1153],\n",
       "           [-0.0937,  0.0785,  0.1062]],\n",
       " \n",
       "          [[-0.0871, -0.1168,  0.1159],\n",
       "           [ 0.0285,  0.0202, -0.1092],\n",
       "           [ 0.1144,  0.1212,  0.1214]],\n",
       " \n",
       "          [[ 0.0854, -0.0225,  0.0156],\n",
       "           [-0.0070,  0.1035, -0.0521],\n",
       "           [ 0.0261, -0.0639,  0.0858]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0384, -0.0601,  0.0074],\n",
       "           [-0.0469, -0.0038, -0.0202],\n",
       "           [ 0.0063,  0.1070,  0.0200]],\n",
       " \n",
       "          [[ 0.0182, -0.0465,  0.0829],\n",
       "           [-0.0048,  0.1158,  0.0151],\n",
       "           [-0.0582,  0.1023,  0.0669]],\n",
       " \n",
       "          [[-0.0882, -0.0044, -0.1158],\n",
       "           [-0.0295,  0.0270,  0.0718],\n",
       "           [ 0.0158, -0.0668,  0.0851]]],\n",
       " \n",
       " \n",
       "         [[[-0.0005, -0.0122, -0.0952],\n",
       "           [-0.0296, -0.0727,  0.0949],\n",
       "           [ 0.0679, -0.0144,  0.0870]],\n",
       " \n",
       "          [[-0.1245, -0.0175, -0.1000],\n",
       "           [-0.0027,  0.0275,  0.0720],\n",
       "           [-0.0519, -0.0025, -0.0244]],\n",
       " \n",
       "          [[-0.0914, -0.0344,  0.0513],\n",
       "           [ 0.0337, -0.0168,  0.0454],\n",
       "           [ 0.0992, -0.0875, -0.0545]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1052,  0.0765, -0.0523],\n",
       "           [ 0.0016,  0.0212, -0.0456],\n",
       "           [-0.0023,  0.0478, -0.0349]],\n",
       " \n",
       "          [[-0.0585,  0.0257,  0.0758],\n",
       "           [-0.0113, -0.1073, -0.0114],\n",
       "           [ 0.0989,  0.0433, -0.0470]],\n",
       " \n",
       "          [[ 0.0485, -0.0588,  0.0100],\n",
       "           [-0.0397, -0.0767,  0.0626],\n",
       "           [-0.0312, -0.0069,  0.0245]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[-0.0420, -0.0930,  0.0941],\n",
       "           [-0.0168, -0.1010,  0.0326],\n",
       "           [-0.0786,  0.1197,  0.0589]],\n",
       " \n",
       "          [[ 0.0854, -0.0165, -0.0538],\n",
       "           [ 0.0856, -0.0694,  0.0195],\n",
       "           [-0.1203, -0.0022,  0.0949]],\n",
       " \n",
       "          [[ 0.0080, -0.1156,  0.0189],\n",
       "           [-0.0699,  0.0697,  0.0510],\n",
       "           [-0.0845,  0.0946, -0.0565]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0384, -0.0960, -0.0147],\n",
       "           [ 0.0253,  0.0216, -0.0386],\n",
       "           [ 0.0815,  0.0680,  0.0584]],\n",
       " \n",
       "          [[-0.0435,  0.0678,  0.0071],\n",
       "           [ 0.0550,  0.0486, -0.0044],\n",
       "           [ 0.0129, -0.1155,  0.0289]],\n",
       " \n",
       "          [[ 0.0750, -0.0956, -0.1064],\n",
       "           [ 0.0791,  0.0917, -0.0924],\n",
       "           [-0.1005,  0.0976, -0.1018]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0820, -0.0244,  0.0585],\n",
       "           [ 0.0720, -0.1210, -0.0784],\n",
       "           [ 0.0794,  0.0357, -0.0679]],\n",
       " \n",
       "          [[ 0.0930,  0.0246, -0.0549],\n",
       "           [ 0.0367,  0.0894, -0.0638],\n",
       "           [ 0.0809,  0.0075,  0.1169]],\n",
       " \n",
       "          [[-0.0180,  0.0041, -0.1101],\n",
       "           [ 0.1032,  0.0615, -0.1165],\n",
       "           [ 0.0744, -0.1046,  0.0656]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.1117,  0.0122, -0.0701],\n",
       "           [ 0.0772,  0.0124,  0.1120],\n",
       "           [ 0.0829, -0.0375,  0.0064]],\n",
       " \n",
       "          [[-0.1235,  0.1181,  0.0834],\n",
       "           [-0.0724, -0.0158,  0.0506],\n",
       "           [ 0.0067,  0.0075, -0.0461]],\n",
       " \n",
       "          [[ 0.1238,  0.0973,  0.0693],\n",
       "           [-0.1149, -0.0433,  0.0923],\n",
       "           [-0.0251,  0.0719,  0.1191]]],\n",
       " \n",
       " \n",
       "         [[[-0.0812, -0.0279,  0.0042],\n",
       "           [ 0.0425,  0.0907,  0.1110],\n",
       "           [ 0.1116,  0.1118,  0.0397]],\n",
       " \n",
       "          [[ 0.0498, -0.0758, -0.1198],\n",
       "           [ 0.0155,  0.0068, -0.0776],\n",
       "           [ 0.0910, -0.1248, -0.0999]],\n",
       " \n",
       "          [[-0.0450,  0.0609,  0.0451],\n",
       "           [-0.0451, -0.0326,  0.1072],\n",
       "           [ 0.0845, -0.0749, -0.0817]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0128, -0.0580, -0.0237],\n",
       "           [ 0.0508, -0.0137, -0.0980],\n",
       "           [ 0.1127, -0.0855, -0.1081]],\n",
       " \n",
       "          [[-0.1111, -0.0080,  0.1060],\n",
       "           [ 0.0914, -0.1101,  0.0823],\n",
       "           [ 0.0526, -0.0255,  0.0999]],\n",
       " \n",
       "          [[ 0.0245, -0.0145, -0.0607],\n",
       "           [ 0.0378,  0.0370, -0.0260],\n",
       "           [ 0.0708,  0.0336,  0.1212]]]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-0.0256,  0.0499,  0.0495],\n",
       "           [-0.0430, -0.0425,  0.0279],\n",
       "           [-0.0287, -0.0598,  0.0029]],\n",
       " \n",
       "          [[-0.0559, -0.0153, -0.0010],\n",
       "           [ 0.0151,  0.0704, -0.0055],\n",
       "           [-0.0663,  0.0195,  0.0273]],\n",
       " \n",
       "          [[ 0.0186,  0.0151,  0.0073],\n",
       "           [-0.0523,  0.0556,  0.0272],\n",
       "           [-0.0397,  0.0237,  0.0015]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0474, -0.0229,  0.0575],\n",
       "           [-0.0008,  0.0006,  0.0628],\n",
       "           [-0.0474, -0.0669, -0.0676]],\n",
       " \n",
       "          [[ 0.0172,  0.0637,  0.0122],\n",
       "           [ 0.0108, -0.0386,  0.0071],\n",
       "           [ 0.0576,  0.0171,  0.0559]],\n",
       " \n",
       "          [[-0.0320,  0.0295, -0.0639],\n",
       "           [-0.0038,  0.0477,  0.0274],\n",
       "           [-0.0435,  0.0587, -0.0207]]],\n",
       " \n",
       " \n",
       "         [[[-0.0373, -0.0022,  0.0451],\n",
       "           [-0.0486, -0.0306,  0.0679],\n",
       "           [-0.0484, -0.0063, -0.0557]],\n",
       " \n",
       "          [[-0.0653,  0.0187, -0.0276],\n",
       "           [-0.0525,  0.0672, -0.0229],\n",
       "           [-0.0598, -0.0443, -0.0261]],\n",
       " \n",
       "          [[-0.0712,  0.0350,  0.0162],\n",
       "           [ 0.0274,  0.0358,  0.0270],\n",
       "           [-0.0616,  0.0378,  0.0349]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0712,  0.0192, -0.0129],\n",
       "           [ 0.0060,  0.0603,  0.0237],\n",
       "           [ 0.0457,  0.0650,  0.0130]],\n",
       " \n",
       "          [[-0.0077, -0.0527,  0.0292],\n",
       "           [ 0.0367, -0.0384,  0.0566],\n",
       "           [ 0.0141, -0.0277, -0.0105]],\n",
       " \n",
       "          [[-0.0525, -0.0351, -0.0304],\n",
       "           [-0.0324, -0.0121,  0.0200],\n",
       "           [-0.0631,  0.0195, -0.0326]]],\n",
       " \n",
       " \n",
       "         [[[-0.0578,  0.0387, -0.0621],\n",
       "           [-0.0592,  0.0065,  0.0188],\n",
       "           [ 0.0277,  0.0625,  0.0331]],\n",
       " \n",
       "          [[ 0.0599, -0.0607,  0.0450],\n",
       "           [-0.0399,  0.0111,  0.0065],\n",
       "           [ 0.0639, -0.0297, -0.0642]],\n",
       " \n",
       "          [[-0.0657, -0.0108, -0.0716],\n",
       "           [-0.0466,  0.0042, -0.0470],\n",
       "           [-0.0403, -0.0289,  0.0577]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0125, -0.0571, -0.0224],\n",
       "           [ 0.0533,  0.0061, -0.0611],\n",
       "           [-0.0095, -0.0424,  0.0543]],\n",
       " \n",
       "          [[ 0.0066,  0.0559,  0.0461],\n",
       "           [ 0.0701, -0.0440,  0.0182],\n",
       "           [-0.0143, -0.0292,  0.0525]],\n",
       " \n",
       "          [[-0.0002, -0.0704,  0.0679],\n",
       "           [ 0.0673,  0.0185,  0.0564],\n",
       "           [ 0.0068,  0.0261,  0.0002]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0256,  0.0029,  0.0011],\n",
       "           [-0.0505, -0.0595, -0.0586],\n",
       "           [ 0.0122,  0.0465, -0.0282]],\n",
       " \n",
       "          [[-0.0086,  0.0370, -0.0500],\n",
       "           [-0.0397,  0.0175,  0.0202],\n",
       "           [ 0.0530, -0.0461,  0.0201]],\n",
       " \n",
       "          [[-0.0129, -0.0119,  0.0526],\n",
       "           [ 0.0417, -0.0432,  0.0172],\n",
       "           [ 0.0627, -0.0362,  0.0658]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0193, -0.0251,  0.0698],\n",
       "           [-0.0653, -0.0625,  0.0333],\n",
       "           [-0.0419,  0.0016, -0.0504]],\n",
       " \n",
       "          [[-0.0543, -0.0162,  0.0604],\n",
       "           [-0.0351, -0.0282, -0.0121],\n",
       "           [-0.0083, -0.0698, -0.0133]],\n",
       " \n",
       "          [[ 0.0236, -0.0139,  0.0628],\n",
       "           [-0.0368,  0.0473, -0.0557],\n",
       "           [-0.0359, -0.0438, -0.0604]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0140, -0.0117,  0.0214],\n",
       "           [ 0.0243, -0.0162,  0.0096],\n",
       "           [ 0.0072,  0.0259,  0.0276]],\n",
       " \n",
       "          [[-0.0374,  0.0573,  0.0531],\n",
       "           [ 0.0528,  0.0118,  0.0010],\n",
       "           [ 0.0252,  0.0358, -0.0375]],\n",
       " \n",
       "          [[-0.0082,  0.0460,  0.0416],\n",
       "           [ 0.0306,  0.0352, -0.0552],\n",
       "           [ 0.0684,  0.0100, -0.0339]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0258,  0.0364,  0.0492],\n",
       "           [ 0.0155,  0.0185,  0.0179],\n",
       "           [-0.0524,  0.0134,  0.0416]],\n",
       " \n",
       "          [[ 0.0157,  0.0257,  0.0702],\n",
       "           [-0.0479,  0.0350, -0.0344],\n",
       "           [ 0.0246,  0.0694,  0.0233]],\n",
       " \n",
       "          [[ 0.0534,  0.0706, -0.0270],\n",
       "           [ 0.0328, -0.0404,  0.0190],\n",
       "           [-0.0312, -0.0166,  0.0008]]],\n",
       " \n",
       " \n",
       "         [[[-0.0720, -0.0113, -0.0704],\n",
       "           [-0.0626,  0.0393,  0.0541],\n",
       "           [ 0.0449, -0.0450,  0.0254]],\n",
       " \n",
       "          [[ 0.0050, -0.0244,  0.0720],\n",
       "           [ 0.0721, -0.0579,  0.0702],\n",
       "           [ 0.0506,  0.0403, -0.0298]],\n",
       " \n",
       "          [[-0.0383,  0.0561,  0.0478],\n",
       "           [ 0.0659,  0.0001,  0.0648],\n",
       "           [-0.0694,  0.0274, -0.0249]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0627, -0.0083,  0.0231],\n",
       "           [ 0.0373, -0.0292,  0.0718],\n",
       "           [-0.0290,  0.0443,  0.0683]],\n",
       " \n",
       "          [[-0.0051, -0.0014,  0.0169],\n",
       "           [-0.0587, -0.0581,  0.0713],\n",
       "           [ 0.0692,  0.0446,  0.0153]],\n",
       " \n",
       "          [[-0.0691,  0.0584, -0.0298],\n",
       "           [-0.0425,  0.0008, -0.0183],\n",
       "           [-0.0159, -0.0120, -0.0698]]]], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[-4.2188e-02,  4.3409e-02,  1.3226e-02],\n",
       "           [ 3.8381e-02,  4.2388e-02, -8.9968e-03],\n",
       "           [-1.8900e-02,  3.9935e-02, -3.0373e-02]],\n",
       " \n",
       "          [[-5.0855e-02, -2.6949e-02, -1.1269e-02],\n",
       "           [-3.1180e-02,  3.7270e-02,  4.0516e-02],\n",
       "           [ 5.0920e-02,  7.4389e-03, -4.2375e-02]],\n",
       " \n",
       "          [[ 1.3063e-02, -4.2355e-02,  2.6646e-02],\n",
       "           [-1.1001e-02,  3.7120e-03,  3.3193e-02],\n",
       "           [ 5.0751e-02, -1.0405e-02,  7.4256e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.4341e-02,  3.3156e-02, -2.5963e-02],\n",
       "           [ 3.0856e-03, -3.2388e-03,  2.2616e-02],\n",
       "           [ 1.0273e-02, -4.9528e-02,  9.4644e-04]],\n",
       " \n",
       "          [[ 4.0924e-02,  1.9326e-03, -4.0014e-02],\n",
       "           [-4.4263e-02, -2.6155e-03, -5.8187e-03],\n",
       "           [-4.5544e-02,  5.2484e-03,  3.2573e-02]],\n",
       " \n",
       "          [[ 2.8635e-02,  2.4681e-02, -6.6171e-03],\n",
       "           [-4.5938e-02, -2.4265e-02, -2.6664e-02],\n",
       "           [ 1.4067e-02, -1.0357e-02,  4.8202e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.4990e-02, -3.7334e-02,  2.6080e-02],\n",
       "           [-8.2783e-03, -1.9912e-02, -1.9327e-02],\n",
       "           [ 2.1543e-02,  1.8105e-02,  2.1231e-02]],\n",
       " \n",
       "          [[ 1.9222e-02, -4.1912e-02,  1.0798e-02],\n",
       "           [-4.0032e-02, -1.2424e-03,  1.3936e-02],\n",
       "           [-5.0503e-02, -3.7057e-02,  4.6447e-02]],\n",
       " \n",
       "          [[-3.0285e-02,  4.5232e-02,  4.0555e-02],\n",
       "           [-1.8525e-02,  2.0410e-03,  5.2331e-03],\n",
       "           [-4.1635e-02, -1.8486e-02,  6.4382e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.9333e-03,  1.7235e-02,  3.2105e-02],\n",
       "           [ 4.7775e-02, -2.8998e-02, -3.5451e-02],\n",
       "           [ 4.3396e-02,  2.8501e-02, -8.0405e-03]],\n",
       " \n",
       "          [[ 4.7612e-02, -4.0895e-02,  4.1400e-02],\n",
       "           [ 3.4673e-02, -3.4668e-03,  1.4677e-02],\n",
       "           [ 2.9303e-02, -5.0152e-02,  1.4418e-02]],\n",
       " \n",
       "          [[-2.8927e-02, -5.0633e-02, -9.9117e-03],\n",
       "           [ 4.3192e-02,  2.2469e-02,  3.0335e-02],\n",
       "           [-4.1608e-02,  1.1259e-02,  3.8668e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 2.4745e-02, -4.9586e-02,  4.2050e-02],\n",
       "           [ 1.2452e-02,  3.6529e-02, -2.5490e-02],\n",
       "           [-4.8483e-02,  1.3773e-02, -9.8651e-03]],\n",
       " \n",
       "          [[ 1.3379e-02,  4.0992e-02, -3.9012e-02],\n",
       "           [ 4.8114e-02,  3.7672e-03, -3.1099e-02],\n",
       "           [ 3.1058e-02, -1.2396e-02, -2.4827e-02]],\n",
       " \n",
       "          [[ 3.6890e-02,  3.7544e-02,  2.1366e-02],\n",
       "           [-3.2039e-02,  3.3190e-02,  1.6524e-02],\n",
       "           [-8.0211e-03, -4.3694e-02,  5.3500e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 1.9829e-03,  3.5592e-02, -2.6573e-02],\n",
       "           [-2.9176e-02,  1.1510e-02, -1.9671e-02],\n",
       "           [ 4.1933e-02,  4.2826e-02,  7.8304e-03]],\n",
       " \n",
       "          [[-1.3526e-02, -1.0736e-02, -4.7116e-02],\n",
       "           [ 4.4045e-02, -7.4383e-03, -9.6576e-03],\n",
       "           [-5.6905e-03, -4.7337e-02,  1.7519e-02]],\n",
       " \n",
       "          [[ 8.0613e-03,  1.4836e-02, -1.5087e-02],\n",
       "           [-4.8221e-02, -3.8855e-03, -4.7581e-02],\n",
       "           [ 1.3943e-03,  3.2245e-02,  4.5598e-03]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 1.4481e-02, -3.3905e-02, -2.3274e-02],\n",
       "           [ 1.1626e-02,  1.5818e-02, -2.0465e-02],\n",
       "           [ 1.2521e-02,  4.4067e-02,  3.0149e-02]],\n",
       " \n",
       "          [[-2.1980e-02, -2.6392e-02,  3.2768e-02],\n",
       "           [ 1.0068e-02,  3.0424e-02,  3.0462e-02],\n",
       "           [-2.7053e-02, -2.3602e-02,  4.5200e-02]],\n",
       " \n",
       "          [[-9.2950e-05,  3.6427e-02, -2.1007e-02],\n",
       "           [-2.0479e-02, -4.7645e-02,  1.7497e-02],\n",
       "           [-1.1938e-02,  4.0704e-02, -5.0011e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.6390e-02,  5.9949e-03, -1.7075e-02],\n",
       "           [ 3.6725e-02,  4.6252e-03,  2.2736e-02],\n",
       "           [-2.6382e-02,  1.1397e-02, -3.9219e-03]],\n",
       " \n",
       "          [[ 5.4481e-03, -2.0864e-02, -3.4253e-03],\n",
       "           [-3.5106e-02,  4.9517e-02,  2.6475e-02],\n",
       "           [-8.8594e-03,  4.6236e-02, -1.2333e-02]],\n",
       " \n",
       "          [[ 1.0803e-02,  4.5187e-02, -4.5811e-02],\n",
       "           [-1.2581e-02,  3.8304e-02, -2.0133e-02],\n",
       "           [ 1.8250e-02,  2.8469e-02,  3.0118e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.1040e-02,  7.3316e-03,  5.0862e-02],\n",
       "           [ 3.7740e-02, -1.3414e-02,  4.2391e-02],\n",
       "           [-3.6487e-02, -2.4032e-02, -2.9691e-02]],\n",
       " \n",
       "          [[-2.2456e-02,  5.7579e-03,  3.4749e-02],\n",
       "           [-2.6429e-02, -1.1182e-02,  4.8092e-02],\n",
       "           [ 4.7760e-02, -3.2391e-02, -5.0507e-02]],\n",
       " \n",
       "          [[ 3.8016e-02,  3.1015e-02,  3.3396e-02],\n",
       "           [-4.7756e-02,  2.1951e-02,  4.5444e-03],\n",
       "           [ 4.8461e-03, -2.4621e-02,  3.3396e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.2620e-03,  6.0439e-03, -1.7046e-02],\n",
       "           [-1.6229e-02,  6.4211e-03, -6.0902e-03],\n",
       "           [-1.7244e-02, -3.6671e-02, -2.3596e-02]],\n",
       " \n",
       "          [[-2.7578e-02, -4.4743e-02,  2.2225e-02],\n",
       "           [-3.3727e-02,  5.7319e-03, -5.1387e-03],\n",
       "           [-2.8532e-02,  4.9350e-02, -6.6957e-03]],\n",
       " \n",
       "          [[ 4.4947e-02, -1.8946e-02,  1.2268e-02],\n",
       "           [-1.0848e-02,  3.1657e-02, -1.8624e-02],\n",
       "           [-1.9841e-02, -2.2895e-03, -6.5897e-03]]],\n",
       " \n",
       " \n",
       "         [[[-5.4222e-03,  4.4720e-02,  3.4098e-03],\n",
       "           [-9.0163e-03, -4.7056e-02,  1.4406e-02],\n",
       "           [-9.1551e-03, -3.3008e-04,  4.5112e-03]],\n",
       " \n",
       "          [[-1.4614e-03,  1.2077e-02,  4.4367e-02],\n",
       "           [-1.0161e-02, -2.9698e-02, -2.1010e-02],\n",
       "           [-2.9001e-02,  3.4456e-02,  3.0640e-02]],\n",
       " \n",
       "          [[ 1.4068e-02, -4.3468e-02,  1.2735e-02],\n",
       "           [-3.1830e-02,  3.7469e-02, -4.3126e-02],\n",
       "           [ 8.9290e-03, -1.4456e-02, -3.7578e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.6913e-02, -3.7187e-02, -3.5358e-02],\n",
       "           [-2.7221e-02, -1.2837e-02, -4.3611e-02],\n",
       "           [ 1.3605e-02, -3.7549e-02, -3.8725e-02]],\n",
       " \n",
       "          [[-3.0504e-02, -3.4094e-02, -3.3873e-02],\n",
       "           [ 5.5854e-03, -4.6962e-02, -5.2381e-03],\n",
       "           [-3.9771e-02,  4.0264e-02,  4.8680e-04]],\n",
       " \n",
       "          [[-3.0449e-02, -4.2524e-02, -1.1708e-02],\n",
       "           [ 3.3936e-02,  2.9715e-02, -4.5533e-02],\n",
       "           [-2.4269e-02, -1.0228e-02,  3.1776e-02]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5., -5.,\n",
       "         -5., -5., -5., -5.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 2.2920e-02, -2.2772e-02, -4.3125e-02],\n",
       "           [ 4.3538e-02,  5.4736e-03, -4.8272e-02],\n",
       "           [ 1.3063e-02, -4.0091e-02,  5.8149e-02]],\n",
       " \n",
       "          [[ 3.1396e-02,  5.1297e-02, -2.3879e-02],\n",
       "           [ 1.8584e-02, -1.9663e-02,  4.7659e-02],\n",
       "           [ 1.9992e-02,  1.9955e-02, -3.3214e-02]],\n",
       " \n",
       "          [[ 2.1643e-02, -5.5296e-03,  2.6792e-02],\n",
       "           [ 5.2098e-02, -3.0587e-02, -5.9749e-02],\n",
       "           [-3.9393e-02,  1.5577e-02,  5.1918e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 2.3424e-02,  2.4952e-02, -1.6265e-02],\n",
       "           [ 7.2059e-03,  3.7271e-02, -6.2216e-02],\n",
       "           [ 5.0727e-03, -4.1328e-02, -2.9708e-02]],\n",
       " \n",
       "          [[-3.3212e-02,  2.5290e-02,  2.7462e-02],\n",
       "           [-4.3588e-03,  4.2405e-02, -1.6814e-02],\n",
       "           [-5.1252e-02, -5.4002e-03, -2.4056e-02]],\n",
       " \n",
       "          [[-5.2689e-02, -1.6579e-02,  2.3283e-02],\n",
       "           [ 6.7425e-03, -2.7856e-02,  3.5414e-02],\n",
       "           [-4.4941e-02,  4.0544e-02, -1.1683e-02]]],\n",
       " \n",
       " \n",
       "         [[[-3.3684e-03, -2.4315e-02, -6.2253e-03],\n",
       "           [-5.1147e-02, -4.6238e-02, -3.3956e-02],\n",
       "           [ 1.3567e-02, -5.8805e-02, -3.1280e-02]],\n",
       " \n",
       "          [[ 2.7629e-02,  3.8497e-03, -3.2769e-02],\n",
       "           [ 4.4075e-02,  3.2859e-02,  3.4839e-02],\n",
       "           [ 6.0038e-02, -4.7079e-02,  5.7161e-02]],\n",
       " \n",
       "          [[-4.9297e-02, -9.2385e-03, -6.2286e-02],\n",
       "           [ 2.1591e-02,  6.0141e-02, -1.6865e-02],\n",
       "           [ 1.2415e-02,  1.9529e-02,  6.0859e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-1.4108e-02, -8.9181e-03, -5.7306e-02],\n",
       "           [ 3.1416e-02, -9.3212e-03,  2.4391e-02],\n",
       "           [-5.3992e-03, -6.2134e-02, -4.5678e-02]],\n",
       " \n",
       "          [[ 4.2717e-02, -3.2169e-02,  1.9052e-02],\n",
       "           [-4.1077e-02,  3.1704e-02, -2.3766e-02],\n",
       "           [-2.2263e-02,  3.9733e-02,  4.2090e-02]],\n",
       " \n",
       "          [[ 1.4330e-02, -5.7316e-02, -4.5305e-02],\n",
       "           [ 1.9675e-02,  4.6847e-02, -5.9965e-02],\n",
       "           [ 5.3735e-02,  3.5729e-02,  1.1310e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 8.0166e-03, -2.8951e-02, -1.2175e-02],\n",
       "           [ 4.1684e-02, -8.7514e-03,  4.1506e-02],\n",
       "           [ 9.2141e-05, -4.7327e-02, -5.7018e-02]],\n",
       " \n",
       "          [[ 4.8181e-02, -4.9230e-03, -3.3094e-02],\n",
       "           [-2.4874e-03, -1.9459e-02, -4.8538e-02],\n",
       "           [-2.8739e-03,  4.0668e-02,  2.6402e-02]],\n",
       " \n",
       "          [[-2.5322e-02, -1.4641e-02, -1.1138e-02],\n",
       "           [-5.1037e-02,  5.5628e-02,  1.5228e-02],\n",
       "           [-4.8821e-03, -6.1897e-02, -2.1123e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-4.2358e-02,  2.0898e-02,  2.1209e-02],\n",
       "           [ 2.5316e-02,  1.5586e-02, -3.5890e-02],\n",
       "           [ 2.5109e-02, -6.1844e-02, -5.2684e-02]],\n",
       " \n",
       "          [[-1.3917e-02, -7.7363e-03, -1.4923e-02],\n",
       "           [ 1.0364e-02,  4.2481e-03, -2.6755e-02],\n",
       "           [ 3.7906e-02,  4.3807e-02, -4.6062e-02]],\n",
       " \n",
       "          [[ 5.7373e-02,  3.3474e-03, -7.1953e-03],\n",
       "           [ 1.8868e-02,  7.3436e-03,  2.8304e-02],\n",
       "           [-1.9616e-03,  2.3949e-03, -3.7990e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 5.1002e-02,  2.6010e-02,  5.6628e-02],\n",
       "           [-4.4383e-02, -5.3249e-02, -4.3322e-02],\n",
       "           [-4.6846e-03, -1.7089e-02,  5.7992e-02]],\n",
       " \n",
       "          [[-3.6328e-02,  2.0751e-02,  7.8389e-03],\n",
       "           [-5.3507e-02, -5.0355e-03, -4.1411e-02],\n",
       "           [ 3.9161e-02, -2.7765e-02, -6.0883e-02]],\n",
       " \n",
       "          [[-1.0034e-02,  4.6194e-02, -3.2347e-02],\n",
       "           [ 1.2693e-02, -1.5344e-02,  4.8356e-02],\n",
       "           [ 4.8119e-02, -1.3135e-02,  2.3757e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 3.4130e-02,  6.1933e-02,  2.4764e-02],\n",
       "           [ 3.8097e-02,  1.7625e-02, -4.0908e-02],\n",
       "           [-6.0301e-02,  4.9806e-02, -1.2028e-02]],\n",
       " \n",
       "          [[-8.7230e-03,  3.3520e-02, -1.2422e-03],\n",
       "           [ 4.5939e-02, -6.0008e-03,  2.6767e-02],\n",
       "           [-4.0553e-02,  1.0443e-02, -1.6939e-02]],\n",
       " \n",
       "          [[-6.2469e-02,  4.4691e-02, -1.4924e-02],\n",
       "           [-5.7633e-02,  5.8026e-02,  5.6702e-02],\n",
       "           [ 2.8514e-03,  5.8136e-02, -7.5252e-04]]],\n",
       " \n",
       " \n",
       "         [[[-4.8250e-02, -1.3878e-02, -1.0754e-02],\n",
       "           [-4.8118e-02,  3.0064e-02, -3.5929e-02],\n",
       "           [ 2.2368e-02,  2.3384e-02, -5.0657e-02]],\n",
       " \n",
       "          [[-2.9174e-03, -1.5407e-02,  5.9229e-02],\n",
       "           [-1.8776e-02,  6.1352e-02,  1.5630e-02],\n",
       "           [-3.3915e-02,  3.5498e-02, -6.0605e-02]],\n",
       " \n",
       "          [[ 1.8675e-02, -3.4609e-02, -1.9468e-02],\n",
       "           [-2.2630e-02,  6.1343e-02,  5.3943e-02],\n",
       "           [ 3.7753e-02, -1.0209e-03, -2.3227e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 4.6279e-02, -4.3858e-02,  4.2037e-02],\n",
       "           [ 5.9960e-02, -3.0416e-02,  2.9538e-02],\n",
       "           [ 4.6737e-02,  2.3498e-02, -1.8387e-02]],\n",
       " \n",
       "          [[ 2.9648e-03,  3.3856e-02,  9.9323e-03],\n",
       "           [ 5.9547e-02, -1.3046e-02,  1.3348e-02],\n",
       "           [ 2.5352e-02,  1.9871e-02, -6.2026e-02]],\n",
       " \n",
       "          [[-5.9994e-02, -3.4473e-02, -4.7975e-02],\n",
       "           [-4.3202e-02, -2.3958e-02, -2.9462e-02],\n",
       "           [-2.1039e-02, -1.7554e-02, -4.4197e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 1.2837e-02, -2.5049e-02, -4.7526e-02],\n",
       "           [ 3.0004e-02, -5.6646e-02,  4.0680e-02],\n",
       "           [-2.2294e-02, -5.6298e-02,  5.6268e-03]],\n",
       " \n",
       "          [[-1.1261e-02, -4.7386e-02, -1.1437e-02],\n",
       "           [ 9.2987e-03,  3.3024e-02,  3.5142e-02],\n",
       "           [ 3.5233e-02,  6.2456e-02,  4.9028e-02]],\n",
       " \n",
       "          [[ 3.3466e-02, -1.5054e-02, -5.3042e-02],\n",
       "           [-4.4036e-02,  4.8022e-02, -1.8007e-02],\n",
       "           [-1.2232e-02,  4.3087e-02, -4.2360e-03]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-2.3499e-02,  5.5262e-02, -3.8804e-02],\n",
       "           [-4.8905e-02,  2.0838e-02, -4.1396e-02],\n",
       "           [-4.6786e-02,  6.2303e-02,  4.5586e-03]],\n",
       " \n",
       "          [[-6.0805e-02,  2.1212e-02, -4.3289e-02],\n",
       "           [-4.4541e-02, -5.9655e-03, -7.4787e-03],\n",
       "           [ 3.8452e-02,  6.0614e-02,  4.5635e-02]],\n",
       " \n",
       "          [[ 8.8266e-03, -4.1709e-02, -5.3267e-02],\n",
       "           [ 1.4041e-02, -3.4390e-02, -5.3623e-02],\n",
       "           [ 4.8851e-03, -2.5013e-02,  1.0709e-02]]]], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0535, -0.0283, -0.0372,  ..., -0.0363, -0.0521, -0.0369],\n",
       "         [-0.0082, -0.0502,  0.0313,  ...,  0.0205,  0.0154,  0.0425],\n",
       "         [ 0.0211,  0.0027, -0.0156,  ..., -0.0282,  0.0216,  0.0172],\n",
       "         ...,\n",
       "         [-0.0070,  0.0158, -0.0139,  ...,  0.0464, -0.0228, -0.0256],\n",
       "         [-0.0542,  0.0524,  0.0459,  ...,  0.0267,  0.0253, -0.0043],\n",
       "         [ 0.0376, -0.0290, -0.0164,  ..., -0.0255,  0.0102, -0.0204]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0093,  0.0201, -0.0449,  ..., -0.0002,  0.0349,  0.0066],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-5., -5., -5.,  ..., -5., -5., -5.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0018, -0.0038,  0.0059,  ...,  0.0062, -0.0041,  0.0046],\n",
       "         [ 0.0137,  0.0052, -0.0039,  ...,  0.0039,  0.0107,  0.0153],\n",
       "         [-0.0068, -0.0107, -0.0024,  ..., -0.0107, -0.0002,  0.0035],\n",
       "         ...,\n",
       "         [ 0.0074, -0.0127, -0.0134,  ..., -0.0105,  0.0032,  0.0031],\n",
       "         [ 0.0026, -0.0107, -0.0138,  ..., -0.0089,  0.0132,  0.0014],\n",
       "         [ 0.0117,  0.0083, -0.0109,  ...,  0.0037,  0.0058,  0.0078]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0137, -0.0081, -0.0149,  ...,  0.0025,  0.0044, -0.0113],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-5., -5., -5.,  ..., -5., -5., -5.], device='cuda:0',\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0051, -0.0132, -0.0094,  ..., -0.0028, -0.0044,  0.0048],\n",
       "         [-0.0077,  0.0012, -0.0109,  ..., -0.0088,  0.0092,  0.0002],\n",
       "         [-0.0151,  0.0071,  0.0120,  ..., -0.0122, -0.0012,  0.0012],\n",
       "         ...,\n",
       "         [-0.0142, -0.0103,  0.0001,  ...,  0.0092, -0.0152,  0.0037],\n",
       "         [-0.0096,  0.0020, -0.0055,  ...,  0.0040,  0.0015, -0.0020],\n",
       "         [-0.0107,  0.0074, -0.0046,  ..., -0.0115,  0.0109,  0.0149]],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0087,  0.0108,  0.0124,  0.0056,  0.0028, -0.0032, -0.0024,  0.0138,\n",
       "          0.0028,  0.0072,  0.0154, -0.0059,  0.0127, -0.0093,  0.0070,  0.0038,\n",
       "         -0.0143,  0.0110, -0.0080, -0.0112, -0.0104,  0.0051,  0.0094, -0.0082,\n",
       "         -0.0142, -0.0134,  0.0090,  0.0068,  0.0104,  0.0074, -0.0021,  0.0132,\n",
       "          0.0022,  0.0053, -0.0112, -0.0062, -0.0152,  0.0032, -0.0130, -0.0068,\n",
       "          0.0113,  0.0049, -0.0049, -0.0132, -0.0073, -0.0090,  0.0046,  0.0107,\n",
       "          0.0001, -0.0140, -0.0100,  0.0028,  0.0092, -0.0109, -0.0079, -0.0058,\n",
       "          0.0064,  0.0032, -0.0119,  0.0101, -0.0094, -0.0077, -0.0155,  0.0050,\n",
       "          0.0088, -0.0014,  0.0028, -0.0055, -0.0126, -0.0072, -0.0126,  0.0019,\n",
       "         -0.0138, -0.0113,  0.0057,  0.0103,  0.0023, -0.0041,  0.0143,  0.0052,\n",
       "         -0.0145,  0.0097,  0.0134,  0.0105, -0.0055,  0.0063, -0.0080,  0.0134,\n",
       "          0.0020, -0.0032, -0.0086, -0.0027, -0.0053,  0.0132, -0.0044,  0.0005,\n",
       "          0.0118,  0.0153, -0.0048,  0.0026], device='cuda:0',\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sbp_equal_net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(0,300):\n",
    "    SBP_net_train(epoch,sbp_equal_net,optimizer=equal_optimizer,criterion=nn.CrossEntropyLoss())\n",
    "    SBP_net_test(epoch,sbp_equal_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1.0,\n",
       " 0.98,\n",
       " 0.96,\n",
       " 0.94,\n",
       " 0.92,\n",
       " 0.9,\n",
       " 0.88,\n",
       " 0.86,\n",
       " 0.84,\n",
       " 0.82,\n",
       " 0.8,\n",
       " 0.78,\n",
       " 0.76,\n",
       " 0.74,\n",
       " 0.72,\n",
       " 0.7,\n",
       " 0.68,\n",
       " 0.66,\n",
       " 0.64,\n",
       " 0.62,\n",
       " 0.6,\n",
       " 0.58,\n",
       " 0.56,\n",
       " 0.54,\n",
       " 0.52,\n",
       " 0.5,\n",
       " 0.48,\n",
       " 0.46,\n",
       " 0.44,\n",
       " 0.42,\n",
       " 0.4,\n",
       " 0.38,\n",
       " 0.36,\n",
       " 0.34,\n",
       " 0.32,\n",
       " 0.3,\n",
       " 0.28,\n",
       " 0.26,\n",
       " 0.24,\n",
       " 0.22,\n",
       " 0.2,\n",
       " 0.18,\n",
       " 0.16,\n",
       " 0.14,\n",
       " 0.12,\n",
       " 0.1,\n",
       " 0.08,\n",
       " 0.06,\n",
       " 0.04,\n",
       " 0.02]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 30\n",
      " [========================>]  Step: 64ms | Tot: 21s394ms | Loss: 6190.482 | Acc: 41.866% (20933/5000 391/391 ................]  Step: 49ms | Tot: 631ms | Loss: 6212.230 | Acc: 42.132% (755/179 14/391 =>.......................]  Step: 50ms | Tot: 1s244ms | Loss: 6211.542 | Acc: 41.046% (1366/332 26/39 28/39 31/391 34/39 42/391 ..............]  Step: 51ms | Tot: 2s580ms | Loss: 6210.072 | Acc: 40.850% (2719/665 52/391 ................]  Step: 50ms | Tot: 2s630ms | Loss: 6210.016 | Acc: 40.846% (2771/678 53/391 ....................]  Step: 57ms | Tot: 2s831ms | Loss: 6209.781 | Acc: 40.954% (2988/729 57/391 104/391 ======>.............]  Step: 50ms | Tot: 9s7ms | Loss: 6203.003 | Acc: 41.680% (9283/2227 174/39 224/391 ==============>..........]  Step: 50ms | Tot: 11s632ms | Loss: 6200.061 | Acc: 41.736% (12020/2880 225/391 ........]  Step: 50ms | Tot: 11s683ms | Loss: 6200.003 | Acc: 41.738% (12074/2892 226/391 =====>...]  Step: 48ms | Tot: 18s549ms | Loss: 6193.312 | Acc: 41.797% (18297/4377 342/391 ========>..]  Step: 46ms | Tot: 18s750ms | Loss: 6193.082 | Acc: 41.801% (18513/4428 346/391 \n",
      " [========================>]  Step: 32ms | Tot: 2s703ms | Loss: 2.308 | Acc: 40.770% (4077/1000 79/79 /79 70/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(43.5962, device='cuda:0'), tensor(43.5865, device='cuda:0'), tensor(43.5885, device='cuda:0'), tensor(43.5875, device='cuda:0'), tensor(43.5872, device='cuda:0')]\n",
      "\n",
      "Epoch: 31\n",
      " [========================>]  Step: 60ms | Tot: 23s354ms | Loss: 6145.347 | Acc: 42.462% (21231/5000 391/391 ................]  Step: 48ms | Tot: 927ms | Loss: 6166.830 | Acc: 41.817% (1017/243 19/391 \n",
      " [========================>]  Step: 32ms | Tot: 2s556ms | Loss: 2.301 | Acc: 41.020% (4102/1000 79/79 \n",
      "Saving..\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(41.9232, device='cuda:0'), tensor(41.9329, device='cuda:0'), tensor(41.9390, device='cuda:0'), tensor(41.9393, device='cuda:0'), tensor(41.9408, device='cuda:0')]\n",
      "\n",
      "Epoch: 32\n",
      " [========================>]  Step: 51ms | Tot: 20s850ms | Loss: 6100.211 | Acc: 43.144% (21572/5000 391/391 .....]  Step: 49ms | Tot: 1s438ms | Loss: 6121.242 | Acc: 42.014% (1452/345 27/391 ===>.............]  Step: 45ms | Tot: 9s678ms | Loss: 6112.208 | Acc: 42.982% (10068/2342 183/391 .]  Step: 52ms | Tot: 9s730ms | Loss: 6112.150 | Acc: 42.960% (10118/2355 184/39 226/391 227/39 229/39 230/391 =======================>.]  Step: 49ms | Tot: 19s826ms | Loss: 6101.365 | Acc: 43.148% (20490/4748 371/39 377/391 =======>]  Step: 53ms | Tot: 20s177ms | Loss: 6100.960 | Acc: 43.213% (20908/4838 378/391 ========>]  Step: 49ms | Tot: 20s279ms | Loss: 6100.845 | Acc: 43.199% (21012/4864 380/391 ===================>]  Step: 49ms | Tot: 20s378ms | Loss: 6100.730 | Acc: 43.177% (21112/4889 382/391 383/39 385/391 \n",
      " [========================>]  Step: 32ms | Tot: 2s753ms | Loss: 2.300 | Acc: 41.420% (4142/100008/79 ====>............]  Step: 33ms | Tot: 1s411ms | Loss: 2.297 | Acc: 41.741% (2244/537 42/79 =====>..........]  Step: 34ms | Tot: 1s579ms | Loss: 2.295 | Acc: 41.739% (2511/601 47/79 ==============>..........]  Step: 33ms | Tot: 1s613ms | Loss: 2.297 | Acc: 41.732% (2564/614 48/79 =>.........]  Step: 33ms | Tot: 1s713ms | Loss: 2.303 | Acc: 41.805% (2729/652 51/79 ================>........]  Step: 33ms | Tot: 1s814ms | Loss: 2.301 | Acc: 41.898% (2896/691 54/7 61/79 63/79 79/79 \n",
      "Saving..\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(40.3647, device='cuda:0'), tensor(40.3841, device='cuda:0'), tensor(40.3931, device='cuda:0'), tensor(40.3912, device='cuda:0'), tensor(40.3956, device='cuda:0')]\n",
      "\n",
      "Epoch: 33\n",
      " [========================>]  Step: 63ms | Tot: 20s639ms | Loss: 6055.143 | Acc: 43.326% (21663/5000 391/391 ............]  Step: 51ms | Tot: 801ms | Loss: 6076.713 | Acc: 42.463% (924/217 17/391 22/391 23/391 .......................]  Step: 48ms | Tot: 1s444ms | Loss: 6075.944 | Acc: 42.292% (1624/384 30/39 38/391 ====>....................]  Step: 46ms | Tot: 3s221ms | Loss: 6073.970 | Acc: 42.981% (3521/819 64/391 ..................]  Step: 54ms | Tot: 3s275ms | Loss: 6073.911 | Acc: 43.005% (3578/832 65/39 77/391 ................]  Step: 52ms | Tot: 3s941ms | Loss: 6073.159 | Acc: 43.029% (4296/998 78/391 ]  Step: 50ms | Tot: 3s991ms | Loss: 6073.102 | Acc: 43.078% (4356/1011 79/391 ...........]  Step: 50ms | Tot: 4s295ms | Loss: 6072.753 | Acc: 43.272% (4708/1088 85/391 ===>...................]  Step: 49ms | Tot: 4s445ms | Loss: 6072.578 | Acc: 43.342% (4882/1126 88/39 93/391 ........]  Step: 47ms | Tot: 5s151ms | Loss: 6071.774 | Acc: 43.375% (5663/1305 102/391 =>.............]  Step: 50ms | Tot: 9s893ms | Loss: 6067.060 | Acc: 43.419% (10226/2355 184/391 ..........]  Step: 49ms | Tot: 9s943ms | Loss: 6067.003 | Acc: 43.408% (10279/2368 185/39 194/391 ===>............]  Step: 50ms | Tot: 10s699ms | Loss: 6066.141 | Acc: 43.398% (11110/2560 200/391 ============>............]  Step: 50ms | Tot: 10s850ms | Loss: 6065.968 | Acc: 43.392% (11275/2598 203/391 =>............]  Step: 50ms | Tot: 10s901ms | Loss: 6065.911 | Acc: 43.371% (11325/2611 204/39 208/391 ===========>...........]  Step: 48ms | Tot: 11s455ms | Loss: 6065.276 | Acc: 43.452% (11958/2752 215/391 ...]  Step: 48ms | Tot: 11s555ms | Loss: 6065.160 | Acc: 43.462% (12072/2777 217/391 271/391 ......]  Step: 47ms | Tot: 15s267ms | Loss: 6060.902 | Acc: 43.374% (16156/3724 291/391 299/39 315/391 ===========>....]  Step: 51ms | Tot: 16s773ms | Loss: 6059.176 | Acc: 43.246% (17769/4108 321/391 375/391 =====================>]  Step: 54ms | Tot: 19s803ms | Loss: 6055.948 | Acc: 43.350% (20919/4825 377/391 \n",
      " [========================>]  Step: 33ms | Tot: 2s598ms | Loss: 2.306 | Acc: 42.047% (4198/998 78/79 ============>.........]  Step: 33ms | Tot: 1s621ms | Loss: 2.295 | Acc: 42.267% (2651/627 49/79 ==================>......]  Step: 33ms | Tot: 1s991ms | Loss: 2.308 | Acc: 41.966% (3223/768 60/79 ==================>.....]  Step: 34ms | Tot: 2s93ms | Loss: 2.315 | Acc: 41.865% (3376/806 63/79 ======================>]  Step: 32ms | Tot: 2s631ms | Loss: 2.299 | Acc: 42.080% (4208/1000 79/79 \n",
      "Saving..\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(38.8237, device='cuda:0'), tensor(38.8300, device='cuda:0'), tensor(38.8299, device='cuda:0'), tensor(38.8293, device='cuda:0'), tensor(38.8302, device='cuda:0')]\n",
      "\n",
      "Epoch: 34\n",
      " [========================>]  Step: 47ms | Tot: 21s478ms | Loss: 6010.123 | Acc: 44.076% (22038/5000 391/391 ..........]  Step: 49ms | Tot: 2s627ms | Loss: 6030.003 | Acc: 43.716% (2574/588 46/391 ...........]  Step: 46ms | Tot: 5s46ms | Loss: 6027.499 | Acc: 44.145% (5029/1139 89/391 109/391 113/39 115/391 >.................]  Step: 51ms | Tot: 6s574ms | Loss: 6025.772 | Acc: 44.275% (6744/1523 119/391 ...........]  Step: 54ms | Tot: 7s170ms | Loss: 6025.085 | Acc: 44.108% (7396/1676 131/39 143/391 ..]  Step: 49ms | Tot: 8s944ms | Loss: 6023.127 | Acc: 44.219% (9339/2112 165/39 169/39 187/39 193/39 216/391 384/391 ==================>]  Step: 50ms | Tot: 21s176ms | Loss: 6010.470 | Acc: 44.052% (21709/4928 385/391 ========================>]  Step: 49ms | Tot: 21s226ms | Loss: 6010.412 | Acc: 44.056% (21767/4940 386/391 \n",
      " [========================>]  Step: 32ms | Tot: 2s504ms | Loss: 2.300 | Acc: 41.560% (4156/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(37.3455, device='cuda:0'), tensor(37.3460, device='cuda:0'), tensor(37.3422, device='cuda:0'), tensor(37.3429, device='cuda:0'), tensor(37.3422, device='cuda:0')]\n",
      "\n",
      "Epoch: 35\n",
      " [========================>]  Step: 60ms | Tot: 22s613ms | Loss: 5965.099 | Acc: 44.378% (22189/5000 391/391 ===========>.............]  Step: 45ms | Tot: 10s531ms | Loss: 5977.303 | Acc: 44.348% (10161/2291 179/391 ]  Step: 54ms | Tot: 10s636ms | Loss: 5977.189 | Acc: 44.302% (10264/2316 181/39 186/391 ..]  Step: 51ms | Tot: 11s80ms | Loss: 5976.673 | Acc: 44.280% (10769/2432 190/391 ...]  Step: 44ms | Tot: 11s124ms | Loss: 5976.617 | Acc: 44.257% (10820/2444 191/391 =========>............]  Step: 48ms | Tot: 11s280ms | Loss: 5976.445 | Acc: 44.241% (10986/2483 194/391 ==>............]  Step: 56ms | Tot: 11s675ms | Loss: 5975.983 | Acc: 44.249% (11441/2585 202/391 ======>............]  Step: 48ms | Tot: 11s724ms | Loss: 5975.925 | Acc: 44.250% (11498/2598 203/391 =====>...........]  Step: 45ms | Tot: 11s820ms | Loss: 5975.809 | Acc: 44.242% (11609/2624 205/39 240/391 .......]  Step: 49ms | Tot: 14s115ms | Loss: 5973.447 | Acc: 44.293% (13947/3148 246/39 249/39 254/391 255/391 ======>........]  Step: 46ms | Tot: 14s670ms | Loss: 5972.811 | Acc: 44.361% (14593/3289 257/391 \n",
      " [========================>]  Step: 31ms | Tot: 2s741ms | Loss: 2.306 | Acc: 41.750% (4175/1000 79/79 0/7 71/79 72/79 >..]  Step: 34ms | Tot: 2s543ms | Loss: 2.320 | Acc: 41.695% (3896/934 73/79 =>.]  Step: 33ms | Tot: 2s610ms | Loss: 2.319 | Acc: 41.677% (4001/960 75/7 76/79 ==============>]  Step: 34ms | Tot: 2s677ms | Loss: 2.314 | Acc: 41.741% (4114/985 77/79 =>]  Step: 32ms | Tot: 2s709ms | Loss: 2.312 | Acc: 41.737% (4167/998 78/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(35.8746, device='cuda:0'), tensor(35.8929, device='cuda:0'), tensor(35.9001, device='cuda:0'), tensor(35.9007, device='cuda:0'), tensor(35.9013, device='cuda:0')]\n",
      "\n",
      "Epoch: 36\n",
      " [========================>]  Step: 43ms | Tot: 18s469ms | Loss: 5920.076 | Acc: 44.646% (22323/5000 391/391 ep: 48ms | Tot: 784ms | Loss: 5941.622 | Acc: 43.980% (957/217 17/39 19/391 ..]  Step: 52ms | Tot: 2s275ms | Loss: 5939.832 | Acc: 44.124% (2711/614 48/391 ..]  Step: 48ms | Tot: 3s358ms | Loss: 5938.437 | Acc: 44.282% (4081/921 72/391 90/391 208/391 300/391 ==>.....]  Step: 48ms | Tot: 14s2ms | Loss: 5925.201 | Acc: 44.436% (17177/3865 302/391 ============>.....]  Step: 49ms | Tot: 14s510ms | Loss: 5924.626 | Acc: 44.436% (17746/3993 312/ 316/391 ....]  Step: 47ms | Tot: 14s910ms | Loss: 5924.167 | Acc: 44.426% (18197/4096 320/391 332/39 334/39 370/391 374/39 380/391 382/391 \n",
      " [========================>]  Step: 32ms | Tot: 2s719ms | Loss: 2.293 | Acc: 41.660% (4166/1000 79/79 7 61/79 ..]  Step: 49ms | Tot: 2s200ms | Loss: 2.315 | Acc: 41.479% (3398/819 64/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(34.4876, device='cuda:0'), tensor(34.4872, device='cuda:0'), tensor(34.4853, device='cuda:0'), tensor(34.4890, device='cuda:0'), tensor(34.4887, device='cuda:0')]\n",
      "\n",
      "Epoch: 37\n",
      " [========================>]  Step: 62ms | Tot: 21s657ms | Loss: 5875.062 | Acc: 45.302% (22651/5000 391/391 1 ...............]  Step: 50ms | Tot: 2s249ms | Loss: 5895.247 | Acc: 43.026% (2258/524 41/391 =>.................]  Step: 50ms | Tot: 6s384ms | Loss: 5890.840 | Acc: 44.464% (6659/1497 117/391 ...........]  Step: 49ms | Tot: 7s806ms | Loss: 5889.225 | Acc: 44.752% (8306/1856 145/39 206/391 295/391 ===========>......]  Step: 52ms | Tot: 16s369ms | Loss: 5880.527 | Acc: 45.323% (17172/3788 296/39 297/39 300/391 =====================>...]  Step: 50ms | Tot: 18s479ms | Loss: 5878.228 | Acc: 45.275% (19472/4300 336/391 \n",
      " [========================>]  Step: 33ms | Tot: 2s674ms | Loss: 2.304 | Acc: 41.220% (4122/1000 79/79 .]  Step: 33ms | Tot: 404ms | Loss: 2.328 | Acc: 41.046% (683/166 13/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(33.2028, device='cuda:0'), tensor(33.2042, device='cuda:0'), tensor(33.1985, device='cuda:0'), tensor(33.1956, device='cuda:0'), tensor(33.1935, device='cuda:0')]\n",
      "\n",
      "Epoch: 38\n",
      " [========================>]  Step: 55ms | Tot: 20s257ms | Loss: 5830.027 | Acc: 45.780% (22890/5000 391/391 91 ..............]  Step: 47ms | Tot: 5s468ms | Loss: 5847.055 | Acc: 45.312% (5510/1216 95/391 ==>..................]  Step: 49ms | Tot: 5s568ms | Loss: 5846.940 | Acc: 45.272% (5621/1241 97/39 284/39 308/391 320/391 ====================>....]  Step: 38ms | Tot: 17s589ms | Loss: 5833.714 | Acc: 45.559% (19069/4185 327/39 356/391 >..]  Step: 40ms | Tot: 18s873ms | Loss: 5831.929 | Acc: 45.681% (20933/4582 358/391 ===================>.]  Step: 40ms | Tot: 19s35ms | Loss: 5831.699 | Acc: 45.673% (21163/4633 362/391 364/39 378/391 \n",
      " [========================>]  Step: 32ms | Tot: 2s732ms | Loss: 2.323 | Acc: 41.540% (4154/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(31.8560, device='cuda:0'), tensor(31.8547, device='cuda:0'), tensor(31.8511, device='cuda:0'), tensor(31.8518, device='cuda:0'), tensor(31.8504, device='cuda:0')]\n",
      "\n",
      "Epoch: 39\n",
      " [========================>]  Step: 46ms | Tot: 20s624ms | Loss: 5785.018 | Acc: 46.284% (23142/5000 391/391 .................]  Step: 59ms | Tot: 3s797ms | Loss: 5803.683 | Acc: 45.802% (3928/857 67/391 ====>..............]  Step: 49ms | Tot: 9s25ms | Loss: 5798.028 | Acc: 45.933% (9701/2112 165/39 283/391 ========>......]  Step: 50ms | Tot: 15s382ms | Loss: 5791.008 | Acc: 46.056% (16919/3673 287/391 ===================>.....]  Step: 48ms | Tot: 15s984ms | Loss: 5790.316 | Acc: 46.159% (17666/3827 299/391 \n",
      " [========================>]  Step: 32ms | Tot: 2s645ms | Loss: 2.320 | Acc: 41.840% (4184/100008/79 =>...]  Step: 33ms | Tot: 2s313ms | Loss: 2.332 | Acc: 41.735% (3686/883 69/79 ====================>..]  Step: 33ms | Tot: 2s447ms | Loss: 2.334 | Acc: 41.802% (3906/934 73/79 74/79 =================>.]  Step: 33ms | Tot: 2s514ms | Loss: 2.336 | Acc: 41.698% (4003/960 75/79 =====>.]  Step: 33ms | Tot: 2s547ms | Loss: 2.331 | Acc: 41.745% (4061/972 76/79 77/79 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(30.6601, device='cuda:0'), tensor(30.6626, device='cuda:0'), tensor(30.6618, device='cuda:0'), tensor(30.6548, device='cuda:0'), tensor(30.6591, device='cuda:0')]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0,300):\n",
    "    SBP_net_train(epoch,sbp_net,optimizer=optimizer,criterion=nn.CrossEntropyLoss())\n",
    "    SBP_net_test(epoch,sbp_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Resuming from checkpoint..\n"
     ]
    }
   ],
   "source": [
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "sbp_net.load_state_dict(checkpoint['net'])\n",
    "best_acc = checkpoint['best_acc']\n",
    "start_epoch = 20 # set manually from previous training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  tensor(7289.9297)\n",
      "MASK:  tensor(64.)\n",
      "SNR:  tensor(21809.4375)\n",
      "MASK:  tensor(192.)\n",
      "SNR:  tensor(43668.1445)\n",
      "MASK:  tensor(384.)\n",
      "SNR:  tensor(29090.8965)\n",
      "MASK:  tensor(256.)\n",
      "SNR:  tensor(29085.9785)\n",
      "MASK:  tensor(256.)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        [[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        [[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        [[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        [[0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         ...,\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,32,32)\n",
    "sbp_net.eval()\n",
    "sbp_net(x)\n",
    "print(sbp_net.features[0].sbp.mask)\n",
    "print(sbp_net.features[0].sbp.multiplicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.39\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20\n",
      " [========================>]  Step: 293ms | Tot: 1m36s | Loss: 7.817 | Acc: 60.584% (30292/5000 391/391 1  \n",
      " [========================>]  Step: 93ms | Tot: 7s527ms | Loss: 2.006 | Acc: 50.180% (5018/1000 79/79 1/79 \n",
      "\n",
      "Epoch: 21\n",
      " [========================>]  Step: 274ms | Tot: 1m37s | Loss: 7.805 | Acc: 60.658% (30329/5000 391/391 1  \n",
      " [========================>]  Step: 104ms | Tot: 7s87ms | Loss: 2.002 | Acc: 50.010% (5001/1000 79/79 .....................]  Step: 97ms | Tot: 864ms | Loss: 2.126 | Acc: 48.698% (561/115 9/79 \n",
      "\n",
      "Epoch: 22\n",
      " [========================>]  Step: 250ms | Tot: 1m37s | Loss: 7.783 | Acc: 61.118% (30559/5000 391/391 1  \n",
      " [========================>]  Step: 104ms | Tot: 7s258ms | Loss: 1.998 | Acc: 50.380% (5038/1000 79/79 \n",
      "\n",
      "Epoch: 23\n",
      " [========================>]  Step: 257ms | Tot: 1m37s | Loss: 7.768 | Acc: 61.090% (30545/5000 391/391 1  \n",
      " [========================>]  Step: 106ms | Tot: 6s860ms | Loss: 2.003 | Acc: 50.380% (5038/1000 79/79 \n",
      "\n",
      "Epoch: 24\n",
      " [========================>]  Step: 273ms | Tot: 1m37s | Loss: 7.757 | Acc: 61.350% (30675/5000 391/391 1  \n",
      " [========================>]  Step: 101ms | Tot: 6s932ms | Loss: 1.994 | Acc: 50.580% (5058/1000 79/79 \n",
      "Saving..\n",
      "\n",
      "Epoch: 25\n",
      " [========================>]  Step: 267ms | Tot: 1m37s | Loss: 7.725 | Acc: 61.688% (30844/5000 391/391 1  \n",
      " [========================>]  Step: 95ms | Tot: 7s106ms | Loss: 2.002 | Acc: 50.360% (5036/1000 79/79 \n",
      "\n",
      "Epoch: 26\n",
      " [========================>]  Step: 277ms | Tot: 1m38s | Loss: 7.722 | Acc: 61.614% (30807/5000 391/391 1  \n",
      " [========================>]  Step: 108ms | Tot: 7s192ms | Loss: 2.001 | Acc: 50.530% (5053/1000 79/79 .]  Step: 89ms | Tot: 3s172ms | Loss: 1.998 | Acc: 50.069% (2179/435 34/7 35/79 \n",
      "\n",
      "Epoch: 27\n",
      " [========================>]  Step: 250ms | Tot: 1m38s | Loss: 7.709 | Acc: 61.924% (30962/5000 391/391 1  \n",
      " [========================>]  Step: 90ms | Tot: 7s40ms | Loss: 1.996 | Acc: 50.400% (5040/1000 79/79  \n",
      "\n",
      "Epoch: 28\n",
      " [========================>]  Step: 269ms | Tot: 1m38s | Loss: 7.683 | Acc: 62.152% (31076/5000 391/391 1  \n",
      " [========================>]  Step: 104ms | Tot: 7s187ms | Loss: 2.002 | Acc: 50.160% (5016/1000 79/79 \n",
      "\n",
      "Epoch: 29\n",
      " [========================>]  Step: 278ms | Tot: 1m37s | Loss: 7.674 | Acc: 62.222% (31111/5000 391/391 1  \n",
      " [========================>]  Step: 104ms | Tot: 7s14ms | Loss: 2.007 | Acc: 50.170% (5017/1000 79/79 \n",
      "\n",
      "Epoch: 30\n",
      " [========================>]  Step: 295ms | Tot: 1m38s | Loss: 7.655 | Acc: 62.596% (31298/5000 391/391 1  \n",
      " [========================>]  Step: 113ms | Tot: 7s100ms | Loss: 2.029 | Acc: 50.420% (5042/1000 79/79  Step: 106ms | Tot: 537ms | Loss: 2.179 | Acc: 48.828% (375/76 6/79 ===>.....................]  Step: 98ms | Tot: 1s56ms | Loss: 2.111 | Acc: 49.716% (700/140 11/79 \n",
      "\n",
      "Epoch: 31\n",
      " [========================>]  Step: 255ms | Tot: 1m37s | Loss: 7.644 | Acc: 62.594% (31297/5000 391/391 1  \n",
      " [========================>]  Step: 106ms | Tot: 7s245ms | Loss: 2.020 | Acc: 50.360% (5036/10008/79 79/79 \n",
      "\n",
      "Epoch: 32\n",
      " [========================>]  Step: 275ms | Tot: 1m37s | Loss: 7.618 | Acc: 62.864% (31432/5000 391/391 1  \n",
      " [========================>]  Step: 100ms | Tot: 7s476ms | Loss: 2.040 | Acc: 50.520% (5052/1000 79/79 \n",
      "\n",
      "Epoch: 33\n",
      " [========================>]  Step: 253ms | Tot: 1m38s | Loss: 7.609 | Acc: 63.036% (31518/5000 391/391 1  \n",
      " [========================>]  Step: 103ms | Tot: 7s244ms | Loss: 2.023 | Acc: 50.730% (5073/1000 79/79 4/7 67/79 \n",
      "Saving..\n",
      "\n",
      "Epoch: 34\n",
      " [========================>]  Step: 266ms | Tot: 1m38s | Loss: 7.594 | Acc: 63.230% (31615/5000 391/391 1  \n",
      " [========================>]  Step: 105ms | Tot: 7s132ms | Loss: 2.033 | Acc: 50.400% (5040/1000 79/79 \n",
      "\n",
      "Epoch: 35\n",
      " [========================>]  Step: 273ms | Tot: 1m39s | Loss: 7.580 | Acc: 63.348% (31674/5000 391/391 1  \n",
      " [========================>]  Step: 98ms | Tot: 7s827ms | Loss: 2.039 | Acc: 50.160% (5016/1000 79/79 \n",
      "\n",
      "Epoch: 36\n",
      " [========================>]  Step: 268ms | Tot: 1m39s | Loss: 7.566 | Acc: 63.420% (31710/5000 391/391 1  \n",
      " [========================>]  Step: 99ms | Tot: 7s300ms | Loss: 2.031 | Acc: 50.320% (5032/1000 79/79 9/79 ..]  Step: 101ms | Tot: 6s489ms | Loss: 2.031 | Acc: 50.357% (4512/896 70/79 \n",
      "\n",
      "Epoch: 37\n",
      " [========================>]  Step: 258ms | Tot: 1m38s | Loss: 7.551 | Acc: 63.708% (31854/5000 391/391 1  \n",
      " [========================>]  Step: 95ms | Tot: 7s377ms | Loss: 2.041 | Acc: 50.530% (5053/1000 79/79 \n",
      "\n",
      "Epoch: 38\n",
      " [=>.......................]  Step: 261ms | Tot: 5s400ms | Loss: 7.590 | Acc: 63.594% (1628/256 20/391 \r"
     ]
    }
   ],
   "source": [
    "for epoch in range(20,45):\n",
    "    SBP_net_train(epoch,sbp_net)\n",
    "    SBP_net_test(epoch,sbp_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Mask & Prune Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SBP_Block(\n",
       "   (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " SBP_Block(\n",
       "   (conv1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " SBP_Block(\n",
       "   (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " SBP_Block(\n",
       "   (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " SBP_Block(\n",
       "   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_importance_0(net, l_id, num_stop=100):\n",
    "    layer_weights = net.features[0].sbp.weight.data\n",
    "    imp_corr_bn = layer_weights.abs().sum(dim=(1,2,3))        \n",
    "    neuron_order = [np.linspace(0, imp_corr_bn.shape[0]-1, imp_corr_bn.shape[0]), imp_corr_bn]\n",
    "    return neuron_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_truncated_log_normal(mu, sigma, a, b):\n",
    "    alpha = (a - mu)/sigma\n",
    "    beta = (b - mu)/sigma\n",
    "    z = phi(beta) - phi(alpha)\n",
    "    ratio = erfcx((sigma-beta)/(2 ** 0.5))*torch.exp((b-mu)-beta**2/2.0)\n",
    "    ratio = ratio - erfcx((sigma-alpha)/2 ** 0.5)*torch.exp((a-mu)-alpha**2/2.0)\n",
    "    denominator = 2*z*erfcx((2.0*sigma-beta)/2 ** 0.5)*torch.exp(2.0*(b-mu)-beta**2/2.0)\n",
    "    denominator = denominator - 2*z*erfcx((2.0*sigma-alpha)/(2 ** 0.5))*torch.exp(2.0*(a-mu)-alpha**2/2.0)\n",
    "    denominator = denominator - ratio**2\n",
    "    ratio = ratio/torch.sqrt(1e-8 + denominator)\n",
    "    print(denominator)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the sbp layer mask\n",
    "def get_mask(mu,sigma,min_log=-20, max_log=0):\n",
    "    multiplicator = SBP_utils.mean_truncated_log_normal_reduced(mu, sigma, min_log, max_log)\n",
    "    print(\"multiplicator: \",multiplicator)\n",
    "    snr = snr_truncated_log_normal(mu, sigma, min_log, max_log)\n",
    "    print(\"snr: \", snr)\n",
    "    mask = snr\n",
    "    \n",
    "    mask[snr <= 1.0] = 0.0\n",
    "    mask[snr > 1.0] = 1.\n",
    "    \n",
    "    print(\"mask: \",mask)\n",
    "    multiplicator = multiplicator * mask\n",
    "    \n",
    "    return mask, multiplicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_net.features[0].sbp.log_sigma.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sbp_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cfa3d98638c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmask_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmultiplicator_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msbp_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sbp_net' is not defined"
     ]
    }
   ],
   "source": [
    "mask_list = []\n",
    "multiplicator_list = []\n",
    "for i in sbp_net.features:\n",
    "    if not (isinstance(i,nn.MaxPool2d)):\n",
    "        #print(i)\n",
    "        mu = i.sbp.mu.detach()\n",
    "        sigma = i.sbp.log_sigma.detach()\n",
    "        mask,multiplicator = get_mask(mu,sigma)\n",
    "        mask_list.append(mask)\n",
    "        multiplicator_list.append(multiplicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -6.5035,  -8.3538,  -6.6634, -10.2934, -17.9784,  -5.0302, -11.5280,\n",
      "         -10.6385,  -1.8071,  -4.3939,   4.3780, -12.2435, -13.1021, -10.5908,\n",
      "          -7.5355, -12.7850,   2.3540, -12.5417,  -9.5258, -16.9257,  -8.0328,\n",
      "         -16.6011,   4.9747,  -3.3861, -12.9907,  -4.4500,  -5.9589, -14.0933,\n",
      "          -4.2610, -14.5732, -16.0110, -13.5321,  -3.9859,  -2.0124, -13.0010,\n",
      "          -9.6966,  -9.1011,  -3.9229, -16.7927,   8.4844,  -8.6888, -13.6158,\n",
      "          -8.8288,  -9.8294, -15.8931,  -3.8235, -12.4232,  -6.1532, -10.6135,\n",
      "         -11.1450,  -8.6385,  -7.6694, -15.9593,  -3.3235,  -4.4470, -18.4937,\n",
      "         -20.6754,  -0.6448, -18.1565,  -9.3899, -13.1982,   7.3392,  -3.7231,\n",
      "          -9.8469, -13.8983,  -7.2742, -11.2102, -11.6250, -19.0181, -17.3108,\n",
      "           3.8214, -17.8009, -10.2750, -17.4043, -15.8597, -20.3146, -11.4058,\n",
      "         -14.2033,   1.2470,  -9.8833, -10.9950,  -7.2665,  -4.5578,  -1.9062,\n",
      "          -7.2311, -17.2258,  -2.7540,  -8.5210,  -3.8104, -17.1154, -17.3639,\n",
      "         -15.8900,   0.2752, -12.9152,  -2.4497, -19.5410,  -4.8236, -15.2546,\n",
      "         -12.3533,  -0.7627],\n",
      "        [ -5.5915,  -9.1841,  -7.7051,  -9.7543, -19.4744,  -5.8066,  -8.4483,\n",
      "         -10.7928,  -2.1940,  -2.1287,   2.3543, -12.3746, -14.9163, -11.5979,\n",
      "          -5.4929, -12.7419,   1.7019, -11.0425,  -8.8909, -15.8277,  -9.7929,\n",
      "         -18.9493,   2.6915,  -3.9755, -13.4060,  -5.5475,  -7.7619, -15.9256,\n",
      "          -6.1361, -14.8914, -20.1665, -12.8649,  -6.1795,  -0.7316, -11.5431,\n",
      "          -9.2830,  -8.3521,  -4.5545, -16.0758,   6.1910,  -8.9242, -13.4092,\n",
      "          -8.8071,  -8.8093, -15.8464,  -3.8303, -13.3426,  -4.9743, -12.4512,\n",
      "         -12.6957,  -9.1950,  -6.7219, -17.0006,  -0.3365,  -2.8278, -20.2181,\n",
      "         -21.1222,   1.2568, -21.4667,  -9.5398, -12.5775,   5.0351,  -2.1755,\n",
      "         -11.7800, -14.2985,  -7.9930, -13.3791, -13.8296, -20.3413, -17.0050,\n",
      "           3.4482, -19.5875, -12.5436, -20.7362, -17.9641, -22.3547, -11.5132,\n",
      "         -14.3976,   0.9487,  -7.6800, -10.9545,  -8.0611,  -1.0108,  -0.9441,\n",
      "          -6.4214, -20.0051,  -5.1951, -11.1930,  -2.7661, -15.8085, -18.8767,\n",
      "         -19.6317,   2.1807, -15.8462,  -1.2437, -25.5990,  -3.3167, -16.4760,\n",
      "         -12.2014,  -2.3929]], grad_fn=<AddmmBackward>) torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,32,32)\n",
    "sbp_net.eval()\n",
    "y = sbp_net.forward(x)\n",
    "print(y,y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 16, 16])\n",
      "Parameter containing:\n",
      "tensor([-0.0501, -0.0499, -0.0500, -0.0501, -0.0501, -0.0500, -0.0497, -0.0501,\n",
      "        -0.0500, -0.0500, -0.0502, -0.0500, -0.0501, -0.0500, -0.0498, -0.0500,\n",
      "        -0.0501, -0.0509, -0.0499, -0.0500, -0.0500, -0.0500, -0.0501, -0.0500,\n",
      "        -0.0501, -0.0500, -0.0498, -0.0500, -0.0500, -0.0500, -0.0500, -0.0500,\n",
      "        -0.0500, -0.0499, -0.0501, -0.0500, -0.0501, -0.0500, -0.0501, -0.0499,\n",
      "        -0.0500, -0.0500, -0.0497, -0.0501, -0.0500, -0.0501, -0.0495, -0.0500,\n",
      "        -0.0501, -0.0499, -0.0500, -0.0500, -0.0500, -0.0501, -0.0500, -0.0505,\n",
      "        -0.0500, -0.0500, -0.0500, -0.0498, -0.0502, -0.0500, -0.0499, -0.0513],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441],\n",
      "       requires_grad=True)\n",
      "multiplicator:  tensor([-0.1782,  0.3021,  0.1472, -0.0077, -0.0077, -0.4570,  0.5035,  1.0302,\n",
      "        -0.4570,  0.2246,  0.1704,  0.7514,  0.7746, -0.0310,  0.2789,  0.5732,\n",
      "         0.1549,  0.5964,  0.2944, -0.2014,  0.2246, -0.0232, -0.0155,  0.0620,\n",
      "         0.1704,  0.4958, -0.2401,  0.2246, -0.6352,  0.3176,  0.8288,  0.5810,\n",
      "        -0.5500, -0.3951,  0.4105,  0.1472, -0.0077, -0.6352,  0.7746,  0.5500,\n",
      "         0.9295, -0.2014,  0.6120, -0.0930,  0.8366,  0.3408,  0.3099,  0.2246,\n",
      "         0.5887,  0.2091,  0.6584,  0.4880, -0.0232,  0.4260,  0.2324,  1.0301,\n",
      "        -0.0310, -0.2169, -0.1937,  0.1704,  0.0077,  0.5810,  0.2944,  0.4337])\n",
      "snr:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "mask:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "(tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]))\n"
     ]
    }
   ],
   "source": [
    "sbp_net.eval()\n",
    "out_1 = sbp_net.features[0].conv1(x)\n",
    "print(out.shape)\n",
    "out_2 = sbp_net.features[0].sbp(out_1)\n",
    "mu = sbp_net.features[0].sbp.mu.detach()\n",
    "sigma = sbp_net.features[0].sbp.log_sigma.detach()\n",
    "print(sbp_net.features[0].sbp.mu)\n",
    "print(sbp_net.features[0].sbp.log_sigma)\n",
    "print(get_mask(mu,sigma))\n",
    "#print(out_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4.3465e-01, -4.3465e-01, -1.7600e-01,  ..., -4.3465e-01,\n",
       "            1.7735e+00, -4.3465e-01],\n",
       "          [ 1.3551e+00,  5.0437e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -3.1233e-01,  1.1398e+00],\n",
       "          [-4.3465e-01, -4.3465e-01, -4.3465e-01,  ...,  5.5210e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          ...,\n",
       "          [ 2.9487e+00, -4.3465e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "            5.1174e-01, -4.3465e-01],\n",
       "          [-4.3465e-01, -3.3155e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          [-4.3465e-01,  1.4996e+00,  3.1659e+00,  ..., -4.3465e-01,\n",
       "            9.4603e-01,  3.1426e+00]],\n",
       "\n",
       "         [[-5.0862e-01,  1.2093e+00, -5.0862e-01,  ...,  9.4067e-02,\n",
       "           -5.0862e-01, -5.0862e-01],\n",
       "          [-5.0862e-01,  3.7695e-01,  4.3916e-01,  ..., -5.0862e-01,\n",
       "            3.3940e+00,  4.3031e-01],\n",
       "          [ 2.3318e+00,  1.4081e+00,  4.7294e+00,  ..., -5.0862e-01,\n",
       "           -5.0862e-01, -5.0862e-01],\n",
       "          ...,\n",
       "          [-5.0862e-01, -3.8492e-01, -5.0862e-01,  ..., -5.0862e-01,\n",
       "           -5.0862e-01,  4.2691e+00],\n",
       "          [ 2.9053e+00,  5.8004e-01, -1.1890e-01,  ...,  7.7107e+00,\n",
       "           -1.5871e-01,  6.8816e-01],\n",
       "          [-5.0862e-01,  2.8869e+00, -5.0862e-01,  ..., -5.0862e-01,\n",
       "           -5.0862e-01, -5.0862e-01]],\n",
       "\n",
       "         [[ 2.0997e-02, -6.2678e-01, -2.1714e-01,  ...,  1.2464e+00,\n",
       "           -4.8382e-01, -6.2678e-01],\n",
       "          [-6.2678e-01, -6.2678e-01, -6.2678e-01,  ..., -6.2678e-01,\n",
       "            7.7742e-01, -6.2678e-01],\n",
       "          [-6.2678e-01, -6.2678e-01, -1.5465e-01,  ..., -2.0036e-01,\n",
       "           -1.6880e-01,  1.9561e+00],\n",
       "          ...,\n",
       "          [-6.2678e-01, -1.3335e-01, -1.1206e-01,  ...,  2.0777e+00,\n",
       "            7.5063e-01, -6.2678e-01],\n",
       "          [ 1.0796e+00,  2.2099e-01,  1.5710e+00,  ..., -6.2678e-01,\n",
       "           -6.2678e-01,  8.3510e-01],\n",
       "          [-6.2678e-01, -6.2678e-01, -6.2678e-01,  ...,  5.1011e-01,\n",
       "            1.6262e-01,  4.3153e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.2287e-01, -7.2919e-01, -6.8307e-01,  ..., -7.2919e-01,\n",
       "            1.4937e-01, -2.7064e-01],\n",
       "          [-5.0224e-01, -7.2919e-01, -3.8661e-01,  ..., -4.5314e-02,\n",
       "            7.0651e-02,  4.6142e-01],\n",
       "          [ 7.0200e-01, -7.2919e-01, -7.2919e-01,  ..., -5.1552e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          ...,\n",
       "          [-7.2919e-01,  2.1859e-01, -6.8067e-01,  ...,  1.5953e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          [-7.2919e-01, -7.2919e-01, -4.7214e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          [-7.2919e-01, -7.2919e-01, -7.2919e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -7.2919e-01]],\n",
       "\n",
       "         [[-5.6570e-01,  1.0460e+00, -5.6570e-01,  ..., -5.6570e-01,\n",
       "            4.9174e-01,  3.9126e-01],\n",
       "          [-5.6570e-01,  2.6591e-01, -1.2089e-01,  ..., -5.6570e-01,\n",
       "           -3.2473e-01, -5.6570e-01],\n",
       "          [ 1.3682e+00, -5.6570e-01,  1.3096e+00,  ..., -3.0707e-01,\n",
       "           -1.3151e-01,  3.4683e-01],\n",
       "          ...,\n",
       "          [-5.6570e-01, -5.6570e-01,  2.0471e-01,  ...,  1.9936e+00,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          [-5.6570e-01, -5.6570e-01,  2.1770e+00,  ..., -5.6570e-01,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          [-5.6570e-01,  1.2844e+00, -5.6570e-01,  ..., -5.6570e-01,\n",
       "            4.5362e+00, -5.6570e-01]],\n",
       "\n",
       "         [[-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          ...,\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01,  6.1376e-01, -1.7195e-01,  ...,  6.3056e-01,\n",
       "           -1.7195e-01,  1.0886e+00]]],\n",
       "\n",
       "\n",
       "        [[[-4.3465e-01,  1.3661e+00, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          [ 2.0482e+00, -4.3465e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "            2.1568e+00, -4.3465e-01],\n",
       "          [ 1.0606e+00,  8.3775e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          ...,\n",
       "          [-4.3465e-01,  5.8554e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -2.4039e-01, -4.3465e-01],\n",
       "          [ 1.0879e-01, -4.3465e-01, -4.3465e-01,  ...,  9.0902e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          [-4.3465e-01, -3.8163e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "            2.4868e+00,  2.3758e-01]],\n",
       "\n",
       "         [[-5.0862e-01, -5.0862e-01,  1.7032e+00,  ...,  4.6044e-01,\n",
       "           -5.0862e-01, -5.0862e-01],\n",
       "          [ 4.0207e-01, -5.0862e-01,  7.9302e-01,  ..., -5.0862e-01,\n",
       "           -5.0862e-01,  4.1737e+00],\n",
       "          [-5.0862e-01,  1.7934e-01, -5.0862e-01,  ...,  3.0002e+00,\n",
       "           -5.0862e-01, -5.0862e-01],\n",
       "          ...,\n",
       "          [-5.0862e-01, -5.0862e-01,  3.1067e+00,  ..., -5.0862e-01,\n",
       "           -5.0862e-01,  8.1345e+00],\n",
       "          [ 1.5770e+00, -5.0862e-01, -5.0862e-01,  ...,  6.5456e+00,\n",
       "            2.1325e+00, -5.0862e-01],\n",
       "          [-5.0862e-01,  2.6705e+00,  4.2465e+00,  ...,  3.0863e+00,\n",
       "           -5.0862e-01, -5.0862e-01]],\n",
       "\n",
       "         [[ 3.0393e-01, -4.4843e-02, -6.2678e-01,  ..., -6.2678e-01,\n",
       "            5.9379e-01, -4.2223e-01],\n",
       "          [-6.2678e-01, -6.2678e-01,  9.4275e-01,  ..., -3.5613e-01,\n",
       "           -4.5225e-01, -5.0315e-01],\n",
       "          [ 8.0327e-02, -3.8676e-01, -6.2678e-01,  ...,  3.2790e-01,\n",
       "            1.8275e+00, -1.5110e-01],\n",
       "          ...,\n",
       "          [-6.2678e-01, -6.2678e-01, -6.2678e-01,  ..., -7.2902e-02,\n",
       "            1.1736e+00, -6.2678e-01],\n",
       "          [ 3.0201e-02, -6.2678e-01,  7.6819e-01,  ..., -6.2678e-01,\n",
       "           -4.9704e-01,  1.0082e+00],\n",
       "          [ 2.8679e-01,  1.1269e+00, -6.2532e-01,  ..., -3.4910e-01,\n",
       "           -6.2678e-01, -6.2678e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.6985e-02, -1.6527e-01, -7.2919e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -6.9186e-01],\n",
       "          [-4.7667e-01,  1.5352e-01, -7.2919e-01,  ...,  4.5625e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          [-7.2919e-01, -7.2919e-01, -7.2919e-01,  ..., -2.6281e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          ...,\n",
       "          [-4.5974e-01, -7.2919e-01, -4.9821e-01,  ..., -3.9266e-03,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          [-5.1480e-01, -5.0311e-01, -2.1999e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -4.7041e-01],\n",
       "          [-7.2919e-01, -1.3880e-01, -7.2919e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -7.2919e-01]],\n",
       "\n",
       "         [[-5.6570e-01, -4.9504e-01, -5.6570e-01,  ..., -2.1850e-01,\n",
       "           -5.6570e-01,  1.1194e+00],\n",
       "          [-5.6570e-01,  4.1219e+00, -5.6570e-01,  ...,  7.1772e-01,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          [-5.6570e-01, -5.6570e-01, -3.0889e-01,  ..., -5.6570e-01,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          ...,\n",
       "          [-5.6570e-01, -5.6570e-01, -4.4840e-02,  ...,  1.7051e+00,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          [-5.6570e-01, -5.6570e-01,  4.7130e+00,  ..., -5.6570e-01,\n",
       "           -5.6570e-01, -6.0467e-02],\n",
       "          [-5.6570e-01, -5.6570e-01, -5.6570e-01,  ...,  3.1991e+00,\n",
       "           -5.6570e-01, -5.6570e-01]],\n",
       "\n",
       "         [[-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          ...,\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01]]]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SBP_layer' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-37bfd47aeb11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcal_importance_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msbp_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-7f38cf2f1e0e>\u001b[0m in \u001b[0;36mcal_importance_0\u001b[0;34m(net, l_id, num_stop)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcal_importance_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlayer_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimp_corr_bn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mneuron_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_corr_bn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_corr_bn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_corr_bn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mneuron_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SBP_layer' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "cal_importance_0(sbp_net,l_id=1,num_stop=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBPConv_AlexNet(\n",
      "  20.516 M, 100.000% Params, 0.001 GMac, 100.000% MACs, \n",
      "  (block1): SBP_ConvBlock(\n",
      "    0.002 M, 0.010% Params, 0.0 GMac, 8.978% MACs, \n",
      "    (conv1): Conv2d_SBP(0.002 M, 0.009% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 5.986% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 2.993% MACs, inplace=True)\n",
      "  )\n",
      "  (mp1): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 2.993% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (block2): SBP_ConvBlock(\n",
      "    0.112 M, 0.544% Params, 0.0 GMac, 5.155% MACs, \n",
      "    (conv1): Conv2d_SBP(0.111 M, 0.542% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 3.437% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 1.718% MACs, inplace=True)\n",
      "  )\n",
      "  (mp2): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 1.718% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (block3): SBP_ConvBlock(\n",
      "    0.665 M, 3.244% Params, 0.0 GMac, 1.894% MACs, \n",
      "    (conv1): Conv2d_SBP(0.665 M, 3.240% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 1.263% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.631% MACs, inplace=True)\n",
      "  )\n",
      "  (block4): SBP_ConvBlock(\n",
      "    0.886 M, 4.319% Params, 0.0 GMac, 1.263% MACs, \n",
      "    (conv1): Conv2d_SBP(0.886 M, 4.316% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.842% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.421% MACs, inplace=True)\n",
      "  )\n",
      "  (block5): SBP_ConvBlock(\n",
      "    0.591 M, 2.881% Params, 0.0 GMac, 1.263% MACs, \n",
      "    (conv1): Conv2d_SBP(0.591 M, 2.879% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.842% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.421% MACs, inplace=True)\n",
      "  )\n",
      "  (mp3): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.421% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dr1): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "  (lsbp1): Linear_SBP(1.061 M, 5.171% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  (rel2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.748% MACs, inplace=True)\n",
      "  (dr2): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "  (lsbp2): Linear_SBP(16.79 M, 81.835% Params, 0.0 GMac, 0.000% MACs, )\n",
      "  (rel3): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.748% MACs, inplace=True)\n",
      "  (last): Linear(0.41 M, 1.997% Params, 0.0 GMac, 74.819% MACs, in_features=4096, out_features=100, bias=True)\n",
      ")\n",
      "Computational complexity:       0.0 GMac\n"
     ]
    }
   ],
   "source": [
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "with torch.cuda.device(-1):\n",
    "    flops, params = get_model_complexity_info(sbp_net, (3, 32, 32), as_strings=True, print_per_layer_stat=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  20.498 M, 100.000% Params, 0.044 GMac, 100.000% MACs, \n",
      "  (features): Sequential(\n",
      "    2.254 M, 10.996% Params, 0.025 GMac, 58.072% MACs, \n",
      "    (0): Conv2d(0.002 M, 0.009% Params, 0.0 GMac, 1.054% MACs, 3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.038% MACs, inplace=True)\n",
      "    (2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.075% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.038% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(0.111 M, 0.540% Params, 0.005 GMac, 12.476% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.022% MACs, inplace=True)\n",
      "    (6): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.043% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.022% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(0.664 M, 3.239% Params, 0.006 GMac, 13.733% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.008% MACs, inplace=True)\n",
      "    (10): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.016% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(0.885 M, 4.318% Params, 0.008 GMac, 18.305% MACs, 384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, inplace=True)\n",
      "    (13): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.011% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Conv2d(0.59 M, 2.879% Params, 0.005 GMac, 12.205% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, inplace=True)\n",
      "    (16): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.011% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    18.244 M, 89.004% Params, 0.018 GMac, 41.928% MACs, \n",
      "    (0): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (1): Linear(1.053 M, 5.136% Params, 0.001 GMac, 2.410% MACs, in_features=256, out_features=4096, bias=True)\n",
      "    (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "    (3): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (4): Linear(16.781 M, 81.870% Params, 0.017 GMac, 38.558% MACs, in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "    (6): Linear(0.41 M, 1.999% Params, 0.0 GMac, 0.941% MACs, in_features=4096, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(-1):\n",
    "    #flops, params = get_model_complexity_info(sbp_net, (3, 32, 32), as_strings=True, print_per_layer_stat=True)\n",
    "    flops, params = get_model_complexity_info(best_net, (3, 32, 32), as_strings=True, print_per_layer_stat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flop weighted importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importance for SBP Net\n",
    "\n",
    "l_imp = {}\n",
    "\n",
    "for conv_ind in [0, 2, 4, 5, 6]:\n",
    "    l_imp.update({conv_ind: net.features[conv_ind].bn1.bias.shape[0]})\n",
    "## do not need to update the classifer indices b/c no blocks \n",
    "for lin_ind in [1, 4]:\n",
    "    l_imp.update({lin_ind: net.classifier[lin_ind].bias.shape[0]})\n",
    "    \n",
    "normalizer = 0\n",
    "for key, val in l_imp.items():\n",
    "    normalizer += val\n",
    "for key, val in l_imp.items():\n",
    "    l_imp[key] = val / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=5e-4, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SBP_AlexNet(cfg)\n",
    "net_ortho = SBP_AlexNet(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 261ms | Tot: 1m35s | Loss: 11.952 | Acc: 1.048% (524/5000 391/391 1  \n",
      " [========================>]  Step: 89ms | Tot: 6s501ms | Loss: 4.621 | Acc: 1.310% (131/1000 79/79 \n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      " [========================>]  Step: 266ms | Tot: 1m36s | Loss: 11.952 | Acc: 0.992% (496/5000 391/391 1  \n",
      " [========================>]  Step: 97ms | Tot: 6s579ms | Loss: 4.621 | Acc: 1.310% (131/1000 79/79 \n",
      "\n",
      "Epoch: 2\n",
      " [========================>]  Step: 262ms | Tot: 1m37s | Loss: 11.952 | Acc: 1.076% (538/5000 391/391 1  \n",
      " [========================>]  Step: 101ms | Tot: 6s502ms | Loss: 4.621 | Acc: 1.370% (137/1000 79/79 \n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      " [========================>]  Step: 325ms | Tot: 1m47s | Loss: 11.952 | Acc: 1.102% (551/5000 391/391 1  \n",
      " [========================>]  Step: 88ms | Tot: 6s200ms | Loss: 4.621 | Acc: 1.320% (132/1000 79/79 \n",
      "\n",
      "Epoch: 4\n",
      " [=>.......................]  Step: 279ms | Tot: 4s887ms | Loss: 11.956 | Acc: 0.873% (19/217 17/391 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0a7b0bc7a1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mSBP_net_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mSBP_net_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4b5a8edcee52>\u001b[0m in \u001b[0;36mSBP_net_train\u001b[0;34m(epoch, net)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    SBP_net_train(epoch,net)\n",
    "    SBP_net_test(epoch,net)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 154ms | Tot: 1m4s | Loss: 11.956 | Acc: 1.018% (509/5000 391/391 91  \n",
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 714ms | Tot: 4m20s | Loss: 3634.107 | Acc: 0.970% (485/5000 391/391 1 \n",
      "angle_cost:  283.252374375\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "net_test() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2429cfba53f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mSBP_net_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mSBP_net_train_ortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_ortho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnet_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnet_test_ortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_ortho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mw_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_ortho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: net_test() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    SBP_net_train_ortho(epoch,net_ortho)\n",
    "    w_diag(net_ortho)\n",
    "    SBP_net_test_ortho(epoch,net_ortho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner product training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "alex_net = AlexNet(cfg)\n",
    "print(alex_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_net.features[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ortho = AlexNet(cfg).to(device)\n",
    "net_dict = torch.load('./ortho_checkpoint/ckpt.pth')\n",
    "net_ortho.load_state_dict(net_dict['net'])\n",
    "best_acc_ortho = net_dict['best_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importance for SBP Net\n",
    "\n",
    "l_imp = {}\n",
    "\n",
    "for conv_ind in [0, 2, 4, 5, 6]:\n",
    "    l_imp.update({conv_ind: net.features[conv_ind].bn1.bias.shape[0]})\n",
    "## do not need to update the classifer indices b/c no blocks \n",
    "for lin_ind in [1, 4]:\n",
    "    l_imp.update({lin_ind: net.classifier[lin_ind].bias.shape[0]})\n",
    "    \n",
    "normalizer = 0\n",
    "for key, val in l_imp.items():\n",
    "    normalizer += val\n",
    "for key, val in l_imp.items():\n",
    "    l_imp[key] = val / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normal AlexNet\n",
    "l_imp = {}\n",
    "\n",
    "for conv_ind in [2, 6, 10, 13, 16]:\n",
    "    l_imp.update({conv_ind: net.features[conv_ind].bias.shape[0]})\n",
    "    \n",
    "for lin_ind in [1, 4]:\n",
    "    l_imp.update({lin_ind: net.classifier[lin_ind].bias.shape[0]})\n",
    "    \n",
    "normalizer = 0\n",
    "for key, val in l_imp.items():\n",
    "    normalizer += val\n",
    "for key, val in l_imp.items():\n",
    "    l_imp[key] = val / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_test_ortho(epoch):\n",
    "    global best_acc_ortho\n",
    "    net_ortho.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net_ortho(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    print(acc)\n",
    "    if acc > best_acc_ortho:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net_ortho.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('ortho_checkpoint'):\n",
    "            os.mkdir('ortho_checkpoint')\n",
    "        torch.save(state, './ortho_checkpoint/ckpt.pth')\n",
    "        best_acc_ortho = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for conv_ind in [6, 10, 13, 16]:\n",
    "    print(alex_net.features[conv_ind-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBP_net_train_ortho(epoch,net_ortho):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net_ortho.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    angle_cost = 0.0\n",
    "            \n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, kl = net_ortho(inputs)\n",
    "        L_angle = 0\n",
    "        \n",
    "        ### Conv_ind == 0 ###\n",
    "        w_mat = net_ortho.features[0].conv1.weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.features[0].conv1.bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[2])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "\n",
    "        ### Conv_ind != 0 ###\n",
    "        for conv_ind in [2, 4, 5, 6]:\n",
    "            w_mat = net_ortho.features[conv_ind].conv1.weight\n",
    "            w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "            b_mat = net_ortho.features[conv_ind].conv1.bias\n",
    "            b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "            params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "            angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(w_mat.shape[0]).to(device)            \n",
    "            L_angle += (l_imp[conv_ind])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "    \n",
    "        ### lin_ind = 1 ###        \n",
    "        w_mat = net_ortho.classifier[1].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[1].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[1])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "        \n",
    "        ### lin_ind = 4 ###        \n",
    "        w_mat = net_ortho.classifier[4].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[4].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(params.shape[0]).to(device)\n",
    "        L_angle += (l_imp[4])*(angle_mat).norm(1) #.norm().pow(2))        \n",
    "        \n",
    "        Lc = criterion(outputs, labels)\n",
    "        loss = (1e-1)*(L_angle) + Lc + kl #from the sparsity inducer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        angle_cost += (L_angle).item()\n",
    "    \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (running_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    print(\"angle_cost: \", angle_cost/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_train_ortho(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net_ortho.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    angle_cost = 0.0\n",
    "            \n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_ortho(inputs)\n",
    "        L_angle = 0\n",
    "        \n",
    "        ### Conv_ind == 0 ###\n",
    "        w_mat = net_ortho.features[0].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.features[0].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[2])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "\n",
    "        ### Conv_ind != 0 ###\n",
    "        for conv_ind in [6, 10, 13, 16]:\n",
    "            w_mat = net_ortho.features[conv_ind-2].weight\n",
    "            w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "            b_mat = net_ortho.features[conv_ind-2].bias\n",
    "            b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "            params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "            angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(w_mat.shape[0]).to(device)            \n",
    "            L_angle += (l_imp[conv_ind])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "    \n",
    "        ### lin_ind = 1 ###        \n",
    "        w_mat = net_ortho.classifier[1].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[1].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[1])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "        \n",
    "        ### lin_ind = 4 ###        \n",
    "        w_mat = net_ortho.classifier[4].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[4].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(params.shape[0]).to(device)\n",
    "        L_angle += (l_imp[4])*(angle_mat).norm(1) #.norm().pow(2))        \n",
    "        \n",
    "        Lc = criterion(outputs, labels)\n",
    "        loss = (1e-1)*(L_angle) + Lc\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        angle_cost += (L_angle).item()\n",
    "    \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (running_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    print(\"angle_cost: \", angle_cost/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBP_net_ortho = SBP_AlexNet(cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(SBP_net_ortho.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBP_AlexNet(\n",
       "  (block1): SBP_Block(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block2): SBP_Block(\n",
       "    (conv1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block3): SBP_Block(\n",
       "    (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block4): SBP_Block(\n",
       "    (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block5): SBP_Block(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_net_ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SBP_net_ortho' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3ea1007e84db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#SBP_net_train(epoch,SBP_net_ortho)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mSBP_net_train_ortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSBP_net_ortho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#net_test_ortho(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#w_diag(net_ortho)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SBP_net_ortho' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    #SBP_net_train(epoch,SBP_net_ortho)\n",
    "    SBP_net_train_ortho(epoch,SBP_net_ortho)\n",
    "    #net_test_ortho(epoch)\n",
    "    #w_diag(net_ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './w_decorr/base_params/wnet_base_2.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBP_AlexNet(\n",
       "  (block1): SBP_Block(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block2): SBP_Block(\n",
       "    (conv1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block3): SBP_Block(\n",
       "    (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block4): SBP_Block(\n",
       "    (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block5): SBP_Block(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_net_ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_index = 4\n",
    "layer_id = 'bn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AlexNet(cfg).to(device)\n",
    "net_dict = torch.load('./checkpoint/ckpt.pth')\n",
    "net.load_state_dict(net_dict['net'])\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changed for SBP_Aexnet\n",
    "weight_base = net.features[l_index].bn1.weight.data.clone().detach()\n",
    "bias_base = net.features[l_index].bn1.bias.data.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_base_corr = 0\n",
    "num_stop = 0\n",
    "for epoch in range(1):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs, kl = net(inputs)\n",
    "        loss = criterion(outputs, labels) + kl\n",
    "        loss_base_corr += loss.item()\n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "loss_base_corr = loss_base_corr**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n"
     ]
    }
   ],
   "source": [
    "## changed for SBP_Alexnet\n",
    "\n",
    "loss_mat_corr = torch.zeros(weight_base.shape[0])\n",
    "\n",
    "for n_index in tqdm(range(weight_base.shape[0])): \n",
    "    num_stop = 0\n",
    "    print(n_index)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    net.features[l_index].bn1.weight.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    net.features[l_index].bn1.bias.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    \n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs, kl = net(inputs)\n",
    "\n",
    "        loss = (criterion(outputs, labels)) + kl\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "            \n",
    "    loss_mat_corr[n_index] = running_loss**2\n",
    "    \n",
    "    net.features[l_index].bn1.weight.data = weight_base.clone().detach()\n",
    "    net.features[l_index].bn1.bias.data = bias_base.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal alex net w/ no KL loss\n",
    "loss_base_corr = 0\n",
    "num_stop = 0\n",
    "for epoch in range(1):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_base_corr += loss.item()\n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "loss_base_corr = loss_base_corr**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SBP_Alexnet\n",
    "### Change bn1 to access other layers in the block.\n",
    "loss_mat_corr = torch.zeros(weight_base.shape[0])\n",
    "\n",
    "for n_index in tqdm(range(weight_base.shape[0])): \n",
    "    num_stop = 0\n",
    "    print(n_index)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    net.features[l_index].bn1.weight.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    net.features[l_index].bn1.bias.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    \n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs, kl = net(inputs)\n",
    "\n",
    "        loss = (criterion(outputs, labels)) + kl\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "            \n",
    "    loss_mat_corr[n_index] = running_loss**2\n",
    "    \n",
    "    net.features[l_index].bn1.weight.data = weight_base.clone().detach()\n",
    "    net.features[l_index].bn1.bias.data = bias_base.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normal AlexNet\n",
    "\n",
    "loss_mat_corr = torch.zeros(weight_base.shape[0])\n",
    "\n",
    "for n_index in range(weight_base.shape[0]): \n",
    "    num_stop = 0\n",
    "    print(n_index)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    net.features[l_index].weight.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    net.features[l_index].bias.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    \n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = (criterion(outputs, labels))\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "            \n",
    "    loss_mat_corr[n_index] = running_loss**2\n",
    "    \n",
    "    net.features[l_index].weight.data = weight_base.clone().detach()\n",
    "    net.features[l_index].bias.data = bias_base.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(loss_mat_corr, './w_decorr/loss_mats/corr/'+str(l_index)+'/loss_corr_bn_train_'+str(l_index)+'.pt')\n",
    "loss_mat_corr = torch.load('./w_decorr/loss_mats/corr/'+str(l_index)+'/loss_corr_bn_train_'+str(l_index)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### SBP AlexNet\n",
    "optimizer = optim.SGD(net.parameters(), lr=0, weight_decay=0)\n",
    "av_corrval = 0\n",
    "n_epochs = 1\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    num_stop = 0\n",
    "    running_loss = 0.0\n",
    "    imp_corr_conv = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    imp_corr_bn = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, kl = net(inputs) + kl\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        imp_corr_bn += (((net.features[l_index].bn1.weight.grad)*(net.features[l_index].bn1.weight.data)) + ((net.features[l_index].bn1.bias.grad)*(net.features[l_index].bn1.bias.data))).abs().pow(2)\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "         \n",
    "    corrval = (np.corrcoef(imp_corr_bn.cpu().detach().numpy(), (loss_mat_corr - loss_base_corr).abs().cpu().detach().numpy()))\n",
    "    print(\"Correlation at epoch \"+str(epoch)+\": \"+str(corrval[0,1]))\n",
    "    av_corrval += corrval[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Normal AlexNet\n",
    "optimizer = optim.SGD(net.parameters(), lr=0, weight_decay=0)\n",
    "av_corrval = 0\n",
    "n_epochs = 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    num_stop = 0\n",
    "    running_loss = 0.0\n",
    "    imp_corr_conv = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    imp_corr_bn = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        imp_corr_bn += (((net.features[l_index].weight.grad)*(net.features[l_index].weight.data)) + ((net.features[l_index].bias.grad)*(net.features[l_index].bias.data))).abs().pow(2)\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "         \n",
    "    corrval = (np.corrcoef(imp_corr_bn.cpu().detach().numpy(), (loss_mat_corr - loss_base_corr).abs().cpu().detach().numpy()))\n",
    "    print(\"Correlation at epoch \"+str(epoch)+\": \"+str(corrval[0,1]))\n",
    "    av_corrval += corrval[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorrelated net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_decorr = AlexNet(cfg).to(device)\n",
    "net_dict = torch.load('./ortho_checkpoint/ckpt.pth')\n",
    "net_decorr.load_state_dict(net_dict['net'])\n",
    "net_decorr = net_decorr.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_base = net_decorr.features[l_index].weight.data.clone().detach()\n",
    "bias_base = net_decorr.features[l_index].bias.data.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_decorr.parameters(), lr=0, weight_decay=0)\n",
    "num_stop = 0\n",
    "loss_base_decorr = 0\n",
    "for epoch in range(1):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net_decorr(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_base_decorr += loss.item()\n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "loss_base_decorr = loss_base_decorr**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_decorr.parameters(), lr=0, weight_decay=0)\n",
    "\n",
    "loss_mat_decorr = torch.zeros(weight_base.shape[0])\n",
    "\n",
    "for n_index in range(weight_base.shape[0]): \n",
    "    print(n_index)\n",
    "    num_stop = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        net_decorr.features[l_index].weight.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "        net_decorr.features[l_index].bias.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "        outputs = net_decorr(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "            \n",
    "    loss_mat_decorr[n_index] = running_loss**2\n",
    "    \n",
    "    net_decorr.features[l_index].weight.data = weight_base.clone().detach()\n",
    "    net_decorr.features[l_index].bias.data = bias_base.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(loss_mat_decorr, './w_decorr/loss_mats/decorr/'+str(l_index)+'/loss_decorr_bn_train_'+str(l_index)+'.pt')\n",
    "loss_mat_decorr = torch.load('./w_decorr/loss_mats/decorr/'+str(l_index)+'/loss_decorr_bn_train_'+str(l_index)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_decorr.parameters(), lr=0, weight_decay=0)\n",
    "av_corrval = 0\n",
    "n_epochs = 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    num_stop = 0\n",
    "    imp_decorr_conv = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    imp_decorr_bn = torch.zeros(bias_base.shape[0]).to(device)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_decorr(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "        \n",
    "        imp_decorr_bn += (((net_decorr.features[l_index].weight.grad)*(net_decorr.features[l_index].weight.data)) + ((net_decorr.features[l_index].bias.grad)*(net_decorr.features[l_index].bias.data))).abs().pow(2)\n",
    "    \n",
    "    corrval = (np.corrcoef(imp_decorr_bn.cpu().detach().numpy(), (loss_mat_decorr - loss_base_decorr).abs().cpu().detach().numpy()))\n",
    "    print(\"Correlation at epoch \"+str(epoch)+\": \"+str(corrval[0,1]))\n",
    "    av_corrval += corrval[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "s = imp_corr_bn.cpu().sort()[0].cpu().numpy()\n",
    "order = imp_corr_bn.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max(), label=\"Estimated importance\")\n",
    "plt.title(\"Correlated (Taylor FO) for \"+str(l_index))\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "plt.xlabel(\"Neuron index\")\n",
    "plt.ylabel(\"Normalized importance\")\n",
    "plt.plot(loss_diff[order]/loss_diff.max(), label=\"Actual importance\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./w_decorr/loss_mats/corr/graphs/\"+str(l_index)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "s = imp_decorr_bn.cpu().sort()[0].cpu().numpy()\n",
    "order = imp_decorr_bn.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max(), label=\"Estimated importance\")\n",
    "plt.title(\"Decorrelated (Taylor FO) for \"+str(l_index))\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "plt.xlabel(\"Neuron index\")\n",
    "plt.ylabel(\"Normalized importance\")\n",
    "plt.plot(loss_diff[order]/loss_diff.max(), label=\"Actual importance\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./w_decorr/loss_mats/decorr/graphs/\"+str(l_index)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = imp_decorr_bn.cpu().sort()[0].cpu().numpy()\n",
    "s = s/s.max()\n",
    "order = imp_decorr_bn.sort()[1].cpu().numpy()\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "loss_diff = (loss_diff[order]/loss_diff.max())\n",
    "ortho_rms = ((loss_diff - s)**2).sum()\n",
    "\n",
    "s = imp_corr_bn.cpu().sort()[0].cpu().numpy()\n",
    "s = s/s.max()\n",
    "order = imp_corr_bn.sort()[1].cpu().numpy()\n",
    "loss_diff = (loss_mat_corr - loss_base_corr).abs()\n",
    "loss_diff = (loss_diff[order]/loss_diff.max())\n",
    "\n",
    "base_rms = ((loss_diff - s)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ortho_rms, base_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms_ortho = np.sqrt(np.array(rms_ortho) / np.array([64, 64, 128, 128, 256, 256, 512, 512, 512, 512]))\n",
    "# rms_base = np.sqrt(np.array(rms_base) / np.array([64, 64, 128, 128, 256, 256, 512, 512, 512, 512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(np.linspace(0,30,10)-0.5, rms_ortho, label=\"Decorrelated network\")\n",
    "plt.bar(np.linspace(0,30,10)+0.5, rms_base, label=\"Correlated network\")\n",
    "plt.xlabel(\"Layer ID\")\n",
    "plt.ylabel(\"RMS\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./w_decorr/loss_mats/rms.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "s = imp_decorr_bn.cpu().sort()[0].cpu().numpy()\n",
    "order = imp_decorr_bn.sort()[1].cpu().numpy()\n",
    "axes[0].plot(s/s.max(), label=\"Estimated importance\")\n",
    "axes[0].set_title(\"Decorrelated Network (layer \"+str(l_index)+\")\")\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "axes[0].set_xlabel(\"Neuron index\")\n",
    "axes[0].set_ylabel(\"Normalized importance\")\n",
    "axes[0].plot(loss_diff[order]/loss_diff.max(), label=\"Actual importance\")\n",
    "axes[0].legend()\n",
    "\n",
    "s = imp_corr_bn.cpu().sort()[0].cpu().numpy()\n",
    "order = imp_corr_bn.sort()[1].cpu().numpy()\n",
    "axes[1].plot(s/s.max(), label=\"Estimated importance\")\n",
    "axes[1].set_title(\"Correlated Network (layer \"+str(l_index)+\")\")\n",
    "loss_diff = (loss_mat_corr - loss_base_corr).abs()\n",
    "axes[1].set_xlabel(\"Neuron index\")\n",
    "axes[1].set_ylabel(\"Normalized importance\")\n",
    "axes[1].plot(loss_diff[order]/loss_diff.max(), label=\"Actual importance\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.savefig(\"./w_decorr/loss_mats/subplots/\"+str(l_index)+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net-Slim Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_corr = net.features[l_index].weight.data.clone()\n",
    "np.corrcoef(scale_corr.cpu().numpy(), (loss_mat_corr - loss_base_corr).abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_decorr = net_decorr.features[l_index].weight.data.clone().abs()\n",
    "np.corrcoef((scale_decorr).cpu().numpy(), (loss_mat_decorr - loss_base_decorr).abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 based pruning Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_corr = net.features[l_index - 2].weight.data.clone()\n",
    "w_imp_corr = w_corr.pow(2).sum(dim=(1,2,3)).cpu()\n",
    "np.corrcoef(w_imp_corr.numpy(), (loss_mat_corr - loss_base_corr).abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_decorr = net_decorr.features[l_index - 2].weight.data.clone()\n",
    "w_imp_decorr = w_decorr.pow(2).sum(dim=(1,2,3)).cpu()\n",
    "w_imp_decorr = (w_imp_decorr - w_imp_decorr.min())\n",
    "w_imp_decorr = w_imp_decorr/w_imp_decorr.max()\n",
    "np.corrcoef(w_imp_decorr.numpy(), (loss_mat_decorr - loss_base_decorr).abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance plots Netslim Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "\n",
    "s = scale_corr.cpu().sort()[0].cpu().numpy()\n",
    "order = scale_corr.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max())\n",
    "plt.title(\"Correlated (Net-Slim)\")\n",
    "loss_diff = (loss_mat_corr - loss_base_corr).abs()\n",
    "plt.plot(loss_diff[order]/loss_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "\n",
    "s = scale_decorr.cpu().sort()[0].cpu().numpy()\n",
    "order = scale_decorr.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max())\n",
    "plt.title(\"Decorrelated (Net-Slim)\")\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "plt.plot(loss_diff[order]/loss_diff.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance plots L2 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "s = w_imp_corr.sort()[0].cpu().numpy()\n",
    "order = w_imp_corr.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max())\n",
    "plt.title(\"Correlated (L2)\")\n",
    "loss_diff = (loss_mat_corr - loss_base_corr).abs()\n",
    "plt.plot(loss_diff[order]/loss_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "s = w_imp_decorr.sort()[0].cpu().numpy()\n",
    "order = w_imp_decorr.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max())\n",
    "plt.title(\"Decorrelated (L2)\")\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "plt.plot(loss_diff[order]/loss_diff.max())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
