{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Get-Pretrained-Params\" data-toc-modified-id=\"Get-Pretrained-Params-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Get Pretrained Params</a></span></li><li><span><a href=\"#Transfer-Weights\" data-toc-modified-id=\"Transfer-Weights-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>Transfer Weights</a></span></li><li><span><a href=\"#Prune-w/-SBP\" data-toc-modified-id=\"Prune-w/-SBP-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Prune w/ SBP</a></span></li><li><span><a href=\"#Resume-Training\" data-toc-modified-id=\"Resume-Training-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Resume Training</a></span></li><li><span><a href=\"#Get-Mask-&amp;-Prune-Network\" data-toc-modified-id=\"Get-Mask-&amp;-Prune-Network-0.5\"><span class=\"toc-item-num\">0.5&nbsp;&nbsp;</span>Get Mask &amp; Prune Network</a></span></li><li><span><a href=\"#PTFLOPS\" data-toc-modified-id=\"PTFLOPS-0.6\"><span class=\"toc-item-num\">0.6&nbsp;&nbsp;</span>PTFLOPS</a></span></li><li><span><a href=\"#Flop-weighted-importance\" data-toc-modified-id=\"Flop-weighted-importance-0.7\"><span class=\"toc-item-num\">0.7&nbsp;&nbsp;</span>Flop weighted importance</a></span></li><li><span><a href=\"#Layer-index\" data-toc-modified-id=\"Layer-index-0.8\"><span class=\"toc-item-num\">0.8&nbsp;&nbsp;</span>Layer index</a></span></li><li><span><a href=\"#Correlated-Net\" data-toc-modified-id=\"Correlated-Net-0.9\"><span class=\"toc-item-num\">0.9&nbsp;&nbsp;</span>Correlated Net</a></span></li><li><span><a href=\"#Decorrelated-net\" data-toc-modified-id=\"Decorrelated-net-0.10\"><span class=\"toc-item-num\">0.10&nbsp;&nbsp;</span>Decorrelated net</a></span></li></ul></li><li><span><a href=\"#Subplots\" data-toc-modified-id=\"Subplots-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Subplots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Net-Slim-Train\" data-toc-modified-id=\"Net-Slim-Train-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Net-Slim Train</a></span></li><li><span><a href=\"#L2-based-pruning-Train\" data-toc-modified-id=\"L2-based-pruning-Train-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>L2 based pruning Train</a></span><ul class=\"toc-item\"><li><span><a href=\"#Importance-plots-Netslim-Train\" data-toc-modified-id=\"Importance-plots-Netslim-Train-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Importance plots Netslim Train</a></span></li><li><span><a href=\"#Importance-plots-L2-train\" data-toc-modified-id=\"Importance-plots-L2-train-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Importance plots L2 train</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SBP_alexnet import SBP_AlexNet\n",
    "import SBP_utils\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomRotation(45),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "     ])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./../data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, cfg, classes=100):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, cfg[0], kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[0]),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(cfg[0], cfg[1], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[1]),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(cfg[1], cfg[2], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[2]),\n",
    "            \n",
    "            nn.Conv2d(cfg[2], cfg[3], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[3]),\n",
    "            \n",
    "            nn.Conv2d(cfg[3], cfg[4], kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(cfg[4]),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(cfg[4] * 1 * 1, cfg[5]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(cfg[5], cfg[6]),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(cfg[6], classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBP_w_diag(net):\n",
    "    ### Conv_ind == 0 ###\n",
    "    w_mat = net.features[0].conv1.weight\n",
    "    w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "    b_mat = net.features[0].conv1.bias\n",
    "    b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "    params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "    angle_mat = torch.matmul(torch.t(params), params)\n",
    "    L_diag = (angle_mat.diag().norm(1))\n",
    "    L_angle = (angle_mat.norm(1))\n",
    "    print(L_diag.cpu()/L_angle.cpu())\n",
    "    \n",
    "    for conv_ind in [2, 4, 5, 6]:\n",
    "        w_mat = net.features[conv_ind].conv1.weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net.features[conv_ind].conv1.bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(params, torch.t(params)) \n",
    "        L_diag = (angle_mat.diag().norm(1))\n",
    "        L_angle = (angle_mat.norm(1))\n",
    "        print(L_diag.cpu()/L_angle.cpu())\n",
    "\n",
    "        \n",
    "    '''\n",
    "    IMPT! Untested with the linear SBP Layers in the classifier.\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    ### lin_ind = 1 ###        \n",
    "    w_mat = net.classifier[1].weight\n",
    "    w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "    b_mat = net.classifier[1].bias\n",
    "    b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "    params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "    angle_mat = torch.matmul(torch.t(params), params)\n",
    "    L_diag = (angle_mat.diag().norm(1))\n",
    "    L_angle = (angle_mat.norm(1))\n",
    "    print(L_diag.cpu()/L_angle.cpu())\n",
    "\n",
    "    ### lin_ind = 4 ###        \n",
    "    w_mat = net.classifier[4].weight\n",
    "    w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "    b_mat = net.classifier[4].bias\n",
    "    b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "    params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "    angle_mat = torch.matmul(params, torch.t(params))\n",
    "    L_diag = (angle_mat.diag().norm(1))\n",
    "    L_angle = (angle_mat.norm(1))\n",
    "    print(L_diag.cpu()/L_angle.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_test(epoch,net):\n",
    "    global best_acc_net\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc_net:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc_net = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def SBP_net_train(epoch,net):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs,kl = net(inputs)\n",
    "        loss = criterion(outputs, targets) + kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "        \n",
    "def SBP_net_test(epoch,net):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item() \n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc\n",
    "         \n",
    "    net.get_sparsity()\n",
    "    return acc\n",
    "\n",
    "def SBP_net_train_ortho(epoch,net_ortho):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net_ortho.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    angle_cost = 0.0\n",
    "            \n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, kl = net_ortho(inputs)\n",
    "        L_angle = 0\n",
    "        \n",
    "        ### Conv_ind == 0 ###\n",
    "        w_mat = net_ortho.features[0].conv1.weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.features[0].conv1.bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[2])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "\n",
    "        ### Conv_ind != 0 ###\n",
    "        for conv_ind in [2, 4, 5, 6]:\n",
    "            w_mat = net_ortho.features[conv_ind].conv1.weight\n",
    "            w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "            b_mat = net_ortho.features[conv_ind].conv1.bias\n",
    "            b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "            params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "            angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(w_mat.shape[0]).to(device)            \n",
    "            L_angle += (l_imp[conv_ind])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "    \n",
    "        ### lin_ind = 1 ###        \n",
    "        w_mat = net_ortho.classifier[1].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[1].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[1])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "        \n",
    "        ### lin_ind = 4 ###        \n",
    "        w_mat = net_ortho.classifier[4].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[4].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(params.shape[0]).to(device)\n",
    "        L_angle += (l_imp[4])*(angle_mat).norm(1) #.norm().pow(2))        \n",
    "        \n",
    "        Lc = criterion(outputs, labels)\n",
    "        loss = (1e-1)*(L_angle) + Lc + kl #from the sparsity inducer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        angle_cost += (L_angle).item()\n",
    "    \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (running_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    print(\"angle_cost: \", angle_cost/total)\n",
    "    \n",
    "def SBP_net_test_ortho(epoch,net_ortho):\n",
    "    global best_acc_ortho\n",
    "    net_ortho.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net_ortho(inputs)\n",
    "            loss = criterion(outputs, targets) \n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    print(acc)\n",
    "    if acc > best_acc_ortho:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net_ortho.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('ortho_checkpoint'):\n",
    "            os.mkdir('ortho_checkpoint')\n",
    "        torch.save(state, './ortho_checkpoint/ckpt.pth')\n",
    "        best_acc_ortho = acc\n",
    "    return acc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, absolute_import\n",
    "\n",
    "__all__ = ['accuracy']\n",
    "\n",
    "def kaccuracy(output, target, topk=(5,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "def top5cal(net):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    top1 = 0\n",
    "    top5 = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            acc1, acc5 = kaccuracy(outputs, targets, topk=(1, 5))\n",
    "            top1 += (acc1.item()*inputs.shape[0])\n",
    "            top5 += (acc5.item()*inputs.shape[0])\n",
    "    top1 /= 10000\n",
    "    top5 /= 10000\n",
    "    \n",
    "    print(\"top5\", top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Pretrained Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = [64, 192, 384, 256, 256, 4096, 4096]\n",
    "best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net = AlexNet(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dict = torch.load('./pretrained_alex.pth', map_location=torch.device('cpu'))\n",
    "best_net.load_state_dict(net_dict['net'])\n",
    "best_acc = net_dict['best_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now we must manually load in the weights from the best layer\n",
    "best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global best_acc_net\n",
    "best_acc_net = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 59ms | Tot: 5s821ms | Loss: 1.950 | Acc: 50.960% (5096/1000 79/79 \n",
      "Saving..\n"
     ]
    }
   ],
   "source": [
    "## check pretrained accuracy 51%\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "net_test(1,best_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_net acc:  0\n"
     ]
    }
   ],
   "source": [
    "print('best_net acc: ',best_acc_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0 #reset best accuracy to save after running SBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_net = SBP_AlexNet(cfg,conv=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "for i in best_net.modules():\n",
    "    if(isinstance(i,nn.Conv2d)):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBP_AlexNet(\n",
       "  (block1): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block2): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block3): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block4): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block5): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_net.block1.conv1.weight = best_net.features[0].weight\n",
    "sbp_net.block1.conv1.bias = best_net.features[0].bias\n",
    "\n",
    "sbp_net.block1.bn1.weight = best_net.features[2].weight\n",
    "sbp_net.block1.bn1.bias = best_net.features[2].bias\n",
    "\n",
    "\n",
    "sbp_net.block2.conv1.weight = best_net.features[4].weight\n",
    "sbp_net.block2.conv1.bias = best_net.features[4].bias\n",
    "\n",
    "sbp_net.block2.bn1.weight = best_net.features[6].weight\n",
    "sbp_net.block2.bn1.bias = best_net.features[6].bias\n",
    "\n",
    "sbp_net.block3.conv1.weight = best_net.features[8].weight\n",
    "sbp_net.block3.conv1.bias = best_net.features[8].bias\n",
    "\n",
    "sbp_net.block3.bn1.weight = best_net.features[10].weight\n",
    "sbp_net.block3.bn1.bias = best_net.features[10].bias\n",
    "\n",
    "sbp_net.block4.conv1.weight = best_net.features[11].weight\n",
    "sbp_net.block4.conv1.bias = best_net.features[11].bias\n",
    "\n",
    "sbp_net.block4.bn1.weight = best_net.features[13].weight\n",
    "sbp_net.block4.bn1.bias = best_net.features[13].bias\n",
    "\n",
    "sbp_net.block5.conv1.weight = best_net.features[14].weight\n",
    "sbp_net.block5.conv1.bias = best_net.features[14].bias\n",
    "\n",
    "sbp_net.block5.bn1.weight = best_net.features[16].weight\n",
    "sbp_net.block5.bn1.bias = best_net.features[16].bias\n",
    "\n",
    "sbp_net.classifier = best_net.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [========================>]  Step: 77ms | Tot: 6s710ms | Loss: 6.626 | Acc: 1.000% (100/1000 79/79 \n",
      "Saving..\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(246.9508), tensor(246.9508), tensor(246.9507), tensor(246.9508), tensor(246.9508)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#its not that terrifying that the accuracy is trash \n",
    "# because the sbp layers need to be trained... \n",
    "# hopefully it works lol\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "SBP_net_test(1,sbp_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prune w/ SBP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_learningrate = 1e-4\n",
    "finetune_epoch = 300 ## that seems excessive\n",
    "optimizer = optim.Adam(sbp_net.parameters(), lr=sbp_learningrate, betas=[0.95,0.999])\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size= 250,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBP_AlexNet(\n",
       "  (block1): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block2): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block3): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block4): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block5): SBP_ConvBlock(\n",
       "    (conv1): Conv2d_SBP()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 259ms | Tot: 1m33s | Loss: 33770.029 | Acc: 59.868% (29934/5000 391/391 1  \n",
      " [========================>]  Step: 94ms | Tot: 6s481ms | Loss: 1.991 | Acc: 49.760% (4976/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(133.4652), tensor(133.6114), tensor(133.7856), tensor(133.9306), tensor(133.4543)]\n",
      "\n",
      "Epoch: 1\n",
      " [========================>]  Step: 283ms | Tot: 1m34s | Loss: 33562.822 | Acc: 60.298% (30149/5000 391/391 1  \n",
      " [========================>]  Step: 108ms | Tot: 6s367ms | Loss: 1.998 | Acc: 49.710% (4971/1000 79/79 79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(134.8893), tensor(133.6431), tensor(134.6861), tensor(135.4410), tensor(133.3140)]\n",
      "\n",
      "Epoch: 2\n",
      " [========================>]  Step: 354ms | Tot: 1m36s | Loss: 33359.603 | Acc: 60.664% (30332/5000 391/391 1  \n",
      " [========================>]  Step: 101ms | Tot: 7s253ms | Loss: 2.001 | Acc: 50.270% (5027/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(127.7240), tensor(127.5423), tensor(127.6600), tensor(127.5935), tensor(127.6219)]\n",
      "\n",
      "Epoch: 3\n",
      " [========================>]  Step: 345ms | Tot: 1m50s | Loss: 33156.562 | Acc: 61.000% (30500/5000 391/391 1  \n",
      " [========================>]  Step: 143ms | Tot: 9s583ms | Loss: 2.010 | Acc: 50.040% (5004/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(119.3935), tensor(119.1167), tensor(119.5392), tensor(119.6653), tensor(118.9387)]\n",
      "\n",
      "Epoch: 4\n",
      " [========================>]  Step: 296ms | Tot: 1m58s | Loss: 32953.545 | Acc: 61.376% (30688/5000 391/391 1  \n",
      " [========================>]  Step: 103ms | Tot: 6s492ms | Loss: 2.018 | Acc: 49.890% (4989/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(118.8847), tensor(118.5076), tensor(118.9281), tensor(118.8893), tensor(118.3586)]\n",
      "\n",
      "Epoch: 5\n",
      " [========================>]  Step: 344ms | Tot: 2m3s | Loss: 32750.540 | Acc: 61.618% (30809/5000 391/391 91  \n",
      " [========================>]  Step: 105ms | Tot: 8s180ms | Loss: 2.028 | Acc: 50.310% (5031/1000 79/79 30/79 56/79 63/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(113.3901), tensor(113.6175), tensor(113.2370), tensor(113.0592), tensor(113.9350)]\n",
      "\n",
      "Epoch: 6\n",
      " [========================>]  Step: 276ms | Tot: 1m59s | Loss: 32547.533 | Acc: 62.040% (31020/5000 391/391 1  \n",
      " [========================>]  Step: 100ms | Tot: 7s35ms | Loss: 2.030 | Acc: 50.090% (5009/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(108.7222), tensor(109.0070), tensor(108.3961), tensor(108.4231), tensor(109.5331)]\n",
      "\n",
      "Epoch: 7\n",
      " [========================>]  Step: 276ms | Tot: 1m35s | Loss: 32344.534 | Acc: 62.570% (31285/5000 391/391 1  \n",
      " [========================>]  Step: 80ms | Tot: 6s639ms | Loss: 2.043 | Acc: 49.980% (4998/1000 79/79 ]  Step: 102ms | Tot: 202ms | Loss: 2.075 | Acc: 52.083% (200/38 3/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(102.3439), tensor(102.1550), tensor(102.3085), tensor(102.4023), tensor(102.0240)]\n",
      "\n",
      "Epoch: 8\n",
      " [========================>]  Step: 266ms | Tot: 1m35s | Loss: 32141.526 | Acc: 63.178% (31589/5000 391/391 1  \n",
      " [========================>]  Step: 97ms | Tot: 6s740ms | Loss: 2.053 | Acc: 50.070% (5007/1000 79/79 9/79 60/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(100.6416), tensor(100.6406), tensor(100.8360), tensor(100.8330), tensor(100.8029)]\n",
      "\n",
      "Epoch: 9\n",
      " [========================>]  Step: 270ms | Tot: 1m34s | Loss: 31938.521 | Acc: 63.496% (31748/5000 391/391 1  \n",
      " [========================>]  Step: 86ms | Tot: 6s277ms | Loss: 2.052 | Acc: 50.160% (5016/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(96.9478), tensor(97.1043), tensor(97.1139), tensor(97.2673), tensor(97.2615)]\n",
      "\n",
      "Epoch: 10\n",
      " [========================>]  Step: 257ms | Tot: 1m34s | Loss: 31735.523 | Acc: 64.070% (32035/5000 391/391 1  \n",
      " [========================>]  Step: 97ms | Tot: 6s457ms | Loss: 2.070 | Acc: 49.970% (4997/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(92.7240), tensor(92.6676), tensor(92.6495), tensor(92.6213), tensor(92.6531)]\n",
      "\n",
      "Epoch: 11\n",
      " [========================>]  Step: 268ms | Tot: 1m35s | Loss: 31532.520 | Acc: 64.720% (32360/5000 391/391 1  \n",
      " [========================>]  Step: 102ms | Tot: 6s757ms | Loss: 2.082 | Acc: 49.780% (4978/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(89.5721), tensor(89.4353), tensor(89.6042), tensor(89.6144), tensor(89.4885)]\n",
      "\n",
      "Epoch: 12\n",
      " [========================>]  Step: 260ms | Tot: 1m34s | Loss: 31329.519 | Acc: 64.916% (32458/5000 391/391 1  \n",
      " [========================>]  Step: 101ms | Tot: 6s902ms | Loss: 2.085 | Acc: 50.110% (5011/1000 79/79 0/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(85.4458), tensor(85.4659), tensor(85.4975), tensor(85.3813), tensor(85.3531)]\n",
      "\n",
      "Epoch: 13\n",
      " [========================>]  Step: 327ms | Tot: 1m40s | Loss: 31126.525 | Acc: 65.520% (32760/5000 391/391 1  \n",
      " [========================>]  Step: 127ms | Tot: 9s337ms | Loss: 2.098 | Acc: 50.180% (5018/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(82.0362), tensor(81.9546), tensor(82.0584), tensor(82.1161), tensor(81.7471)]\n",
      "\n",
      "Epoch: 14\n",
      " [========================>]  Step: 324ms | Tot: 2m2s | Loss: 30923.518 | Acc: 66.102% (33051/5000 391/391 91  \n",
      " [========================>]  Step: 123ms | Tot: 9s883ms | Loss: 2.123 | Acc: 50.190% (5019/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(78.5753), tensor(78.6686), tensor(78.5156), tensor(78.4497), tensor(78.6683)]\n",
      "\n",
      "Epoch: 15\n",
      " [========================>]  Step: 307ms | Tot: 2m1s | Loss: 30720.520 | Acc: 66.532% (33266/5000 391/391 91  \n",
      " [========================>]  Step: 117ms | Tot: 9s717ms | Loss: 2.138 | Acc: 49.840% (4984/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(75.8691), tensor(75.8423), tensor(75.9007), tensor(75.9418), tensor(75.8197)]\n",
      "\n",
      "Epoch: 16\n",
      " [========================>]  Step: 307ms | Tot: 2m1s | Loss: 30517.517 | Acc: 67.092% (33546/5000 391/391 91  \n",
      " [========================>]  Step: 131ms | Tot: 9s257ms | Loss: 2.151 | Acc: 49.680% (4968/1000 79/79 \n",
      "[0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[tensor(73.4814), tensor(73.5437), tensor(73.5450), tensor(73.5282), tensor(73.4779)]\n",
      "\n",
      "Epoch: 17\n",
      " [=====>...................]  Step: 302ms | Tot: 29s233ms | Loss: 30392.399 | Acc: 67.385% (7849/1164 91/391 \r"
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    SBP_net_train(epoch,sbp_net)\n",
    "    SBP_net_test(epoch,sbp_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Resuming from checkpoint..\n"
     ]
    }
   ],
   "source": [
    "print('==> Resuming from checkpoint..')\n",
    "assert os.path.isdir('checkpoint'), 'Error: no checkpoint directory found!'\n",
    "checkpoint = torch.load('./checkpoint/ckpt.pth')\n",
    "sbp_net.load_state_dict(checkpoint['net'])\n",
    "best_acc = checkpoint['best_acc']\n",
    "start_epoch = 20 # set manually from previous training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR:  tensor(7289.9297)\n",
      "MASK:  tensor(64.)\n",
      "SNR:  tensor(21809.4375)\n",
      "MASK:  tensor(192.)\n",
      "SNR:  tensor(43668.1445)\n",
      "MASK:  tensor(384.)\n",
      "SNR:  tensor(29090.8965)\n",
      "MASK:  tensor(256.)\n",
      "SNR:  tensor(29085.9785)\n",
      "MASK:  tensor(256.)\n",
      "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
      "tensor([[[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        [[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        [[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        [[0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         ...,\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588],\n",
      "         [0.9588, 0.9588, 0.9588,  ..., 0.9588, 0.9588, 0.9588]],\n",
      "\n",
      "        [[0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         ...,\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584],\n",
      "         [0.9584, 0.9584, 0.9584,  ..., 0.9584, 0.9584, 0.9584]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,32,32)\n",
    "sbp_net.eval()\n",
    "sbp_net(x)\n",
    "print(sbp_net.features[0].sbp.mask)\n",
    "print(sbp_net.features[0].sbp.multiplicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.39\n"
     ]
    }
   ],
   "source": [
    "print(best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 20\n",
      " [========================>]  Step: 293ms | Tot: 1m36s | Loss: 7.817 | Acc: 60.584% (30292/5000 391/391 1  \n",
      " [========================>]  Step: 93ms | Tot: 7s527ms | Loss: 2.006 | Acc: 50.180% (5018/1000 79/79 1/79 \n",
      "\n",
      "Epoch: 21\n",
      " [========================>]  Step: 274ms | Tot: 1m37s | Loss: 7.805 | Acc: 60.658% (30329/5000 391/391 1  \n",
      " [========================>]  Step: 104ms | Tot: 7s87ms | Loss: 2.002 | Acc: 50.010% (5001/1000 79/79 .....................]  Step: 97ms | Tot: 864ms | Loss: 2.126 | Acc: 48.698% (561/115 9/79 \n",
      "\n",
      "Epoch: 22\n",
      " [========================>]  Step: 250ms | Tot: 1m37s | Loss: 7.783 | Acc: 61.118% (30559/5000 391/391 1  \n",
      " [========================>]  Step: 104ms | Tot: 7s258ms | Loss: 1.998 | Acc: 50.380% (5038/1000 79/79 \n",
      "\n",
      "Epoch: 23\n",
      " [========================>]  Step: 257ms | Tot: 1m37s | Loss: 7.768 | Acc: 61.090% (30545/5000 391/391 1  \n",
      " [========================>]  Step: 106ms | Tot: 6s860ms | Loss: 2.003 | Acc: 50.380% (5038/1000 79/79 \n",
      "\n",
      "Epoch: 24\n",
      " [========================>]  Step: 273ms | Tot: 1m37s | Loss: 7.757 | Acc: 61.350% (30675/5000 391/391 1  \n",
      " [========================>]  Step: 101ms | Tot: 6s932ms | Loss: 1.994 | Acc: 50.580% (5058/1000 79/79 \n",
      "Saving..\n",
      "\n",
      "Epoch: 25\n",
      " [========================>]  Step: 267ms | Tot: 1m37s | Loss: 7.725 | Acc: 61.688% (30844/5000 391/391 1  \n",
      " [========================>]  Step: 95ms | Tot: 7s106ms | Loss: 2.002 | Acc: 50.360% (5036/1000 79/79 \n",
      "\n",
      "Epoch: 26\n",
      " [========================>]  Step: 277ms | Tot: 1m38s | Loss: 7.722 | Acc: 61.614% (30807/5000 391/391 1  \n",
      " [========================>]  Step: 108ms | Tot: 7s192ms | Loss: 2.001 | Acc: 50.530% (5053/1000 79/79 .]  Step: 89ms | Tot: 3s172ms | Loss: 1.998 | Acc: 50.069% (2179/435 34/7 35/79 \n",
      "\n",
      "Epoch: 27\n",
      " [========================>]  Step: 250ms | Tot: 1m38s | Loss: 7.709 | Acc: 61.924% (30962/5000 391/391 1  \n",
      " [========================>]  Step: 90ms | Tot: 7s40ms | Loss: 1.996 | Acc: 50.400% (5040/1000 79/79  \n",
      "\n",
      "Epoch: 28\n",
      " [========================>]  Step: 269ms | Tot: 1m38s | Loss: 7.683 | Acc: 62.152% (31076/5000 391/391 1  \n",
      " [========================>]  Step: 104ms | Tot: 7s187ms | Loss: 2.002 | Acc: 50.160% (5016/1000 79/79 \n",
      "\n",
      "Epoch: 29\n",
      " [========================>]  Step: 278ms | Tot: 1m37s | Loss: 7.674 | Acc: 62.222% (31111/5000 391/391 1  \n",
      " [========================>]  Step: 104ms | Tot: 7s14ms | Loss: 2.007 | Acc: 50.170% (5017/1000 79/79 \n",
      "\n",
      "Epoch: 30\n",
      " [========================>]  Step: 295ms | Tot: 1m38s | Loss: 7.655 | Acc: 62.596% (31298/5000 391/391 1  \n",
      " [========================>]  Step: 113ms | Tot: 7s100ms | Loss: 2.029 | Acc: 50.420% (5042/1000 79/79  Step: 106ms | Tot: 537ms | Loss: 2.179 | Acc: 48.828% (375/76 6/79 ===>.....................]  Step: 98ms | Tot: 1s56ms | Loss: 2.111 | Acc: 49.716% (700/140 11/79 \n",
      "\n",
      "Epoch: 31\n",
      " [========================>]  Step: 255ms | Tot: 1m37s | Loss: 7.644 | Acc: 62.594% (31297/5000 391/391 1  \n",
      " [========================>]  Step: 106ms | Tot: 7s245ms | Loss: 2.020 | Acc: 50.360% (5036/10008/79 79/79 \n",
      "\n",
      "Epoch: 32\n",
      " [========================>]  Step: 275ms | Tot: 1m37s | Loss: 7.618 | Acc: 62.864% (31432/5000 391/391 1  \n",
      " [========================>]  Step: 100ms | Tot: 7s476ms | Loss: 2.040 | Acc: 50.520% (5052/1000 79/79 \n",
      "\n",
      "Epoch: 33\n",
      " [========================>]  Step: 253ms | Tot: 1m38s | Loss: 7.609 | Acc: 63.036% (31518/5000 391/391 1  \n",
      " [========================>]  Step: 103ms | Tot: 7s244ms | Loss: 2.023 | Acc: 50.730% (5073/1000 79/79 4/7 67/79 \n",
      "Saving..\n",
      "\n",
      "Epoch: 34\n",
      " [========================>]  Step: 266ms | Tot: 1m38s | Loss: 7.594 | Acc: 63.230% (31615/5000 391/391 1  \n",
      " [========================>]  Step: 105ms | Tot: 7s132ms | Loss: 2.033 | Acc: 50.400% (5040/1000 79/79 \n",
      "\n",
      "Epoch: 35\n",
      " [========================>]  Step: 273ms | Tot: 1m39s | Loss: 7.580 | Acc: 63.348% (31674/5000 391/391 1  \n",
      " [========================>]  Step: 98ms | Tot: 7s827ms | Loss: 2.039 | Acc: 50.160% (5016/1000 79/79 \n",
      "\n",
      "Epoch: 36\n",
      " [========================>]  Step: 268ms | Tot: 1m39s | Loss: 7.566 | Acc: 63.420% (31710/5000 391/391 1  \n",
      " [========================>]  Step: 99ms | Tot: 7s300ms | Loss: 2.031 | Acc: 50.320% (5032/1000 79/79 9/79 ..]  Step: 101ms | Tot: 6s489ms | Loss: 2.031 | Acc: 50.357% (4512/896 70/79 \n",
      "\n",
      "Epoch: 37\n",
      " [========================>]  Step: 258ms | Tot: 1m38s | Loss: 7.551 | Acc: 63.708% (31854/5000 391/391 1  \n",
      " [========================>]  Step: 95ms | Tot: 7s377ms | Loss: 2.041 | Acc: 50.530% (5053/1000 79/79 \n",
      "\n",
      "Epoch: 38\n",
      " [=>.......................]  Step: 261ms | Tot: 5s400ms | Loss: 7.590 | Acc: 63.594% (1628/256 20/391 \r"
     ]
    }
   ],
   "source": [
    "for epoch in range(20,45):\n",
    "    SBP_net_train(epoch,sbp_net)\n",
    "    SBP_net_test(epoch,sbp_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Mask & Prune Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SBP_Block(\n",
       "   (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " SBP_Block(\n",
       "   (conv1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
       " SBP_Block(\n",
       "   (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " SBP_Block(\n",
       "   (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " SBP_Block(\n",
       "   (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (sbp): SBP_layer()\n",
       "   (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (rel): ReLU(inplace=True)\n",
       " ),\n",
       " MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_importance_0(net, l_id, num_stop=100):\n",
    "    layer_weights = net.features[0].sbp.weight.data\n",
    "    imp_corr_bn = layer_weights.abs().sum(dim=(1,2,3))        \n",
    "    neuron_order = [np.linspace(0, imp_corr_bn.shape[0]-1, imp_corr_bn.shape[0]), imp_corr_bn]\n",
    "    return neuron_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_truncated_log_normal(mu, sigma, a, b):\n",
    "    alpha = (a - mu)/sigma\n",
    "    beta = (b - mu)/sigma\n",
    "    z = phi(beta) - phi(alpha)\n",
    "    ratio = erfcx((sigma-beta)/(2 ** 0.5))*torch.exp((b-mu)-beta**2/2.0)\n",
    "    ratio = ratio - erfcx((sigma-alpha)/2 ** 0.5)*torch.exp((a-mu)-alpha**2/2.0)\n",
    "    denominator = 2*z*erfcx((2.0*sigma-beta)/2 ** 0.5)*torch.exp(2.0*(b-mu)-beta**2/2.0)\n",
    "    denominator = denominator - 2*z*erfcx((2.0*sigma-alpha)/(2 ** 0.5))*torch.exp(2.0*(a-mu)-alpha**2/2.0)\n",
    "    denominator = denominator - ratio**2\n",
    "    ratio = ratio/torch.sqrt(1e-8 + denominator)\n",
    "    print(denominator)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get the sbp layer mask\n",
    "def get_mask(mu,sigma,min_log=-20, max_log=0):\n",
    "    multiplicator = SBP_utils.mean_truncated_log_normal_reduced(mu, sigma, min_log, max_log)\n",
    "    print(\"multiplicator: \",multiplicator)\n",
    "    snr = snr_truncated_log_normal(mu, sigma, min_log, max_log)\n",
    "    print(\"snr: \", snr)\n",
    "    mask = snr\n",
    "    \n",
    "    mask[snr <= 1.0] = 0.0\n",
    "    mask[snr > 1.0] = 1.\n",
    "    \n",
    "    print(\"mask: \",mask)\n",
    "    multiplicator = multiplicator * mask\n",
    "    \n",
    "    return mask, multiplicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
       "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbp_net.features[0].sbp.log_sigma.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sbp_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-cfa3d98638c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmask_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmultiplicator_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msbp_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPool2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#print(i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sbp_net' is not defined"
     ]
    }
   ],
   "source": [
    "mask_list = []\n",
    "multiplicator_list = []\n",
    "for i in sbp_net.features:\n",
    "    if not (isinstance(i,nn.MaxPool2d)):\n",
    "        #print(i)\n",
    "        mu = i.sbp.mu.detach()\n",
    "        sigma = i.sbp.log_sigma.detach()\n",
    "        mask,multiplicator = get_mask(mu,sigma)\n",
    "        mask_list.append(mask)\n",
    "        multiplicator_list.append(multiplicator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -6.5035,  -8.3538,  -6.6634, -10.2934, -17.9784,  -5.0302, -11.5280,\n",
      "         -10.6385,  -1.8071,  -4.3939,   4.3780, -12.2435, -13.1021, -10.5908,\n",
      "          -7.5355, -12.7850,   2.3540, -12.5417,  -9.5258, -16.9257,  -8.0328,\n",
      "         -16.6011,   4.9747,  -3.3861, -12.9907,  -4.4500,  -5.9589, -14.0933,\n",
      "          -4.2610, -14.5732, -16.0110, -13.5321,  -3.9859,  -2.0124, -13.0010,\n",
      "          -9.6966,  -9.1011,  -3.9229, -16.7927,   8.4844,  -8.6888, -13.6158,\n",
      "          -8.8288,  -9.8294, -15.8931,  -3.8235, -12.4232,  -6.1532, -10.6135,\n",
      "         -11.1450,  -8.6385,  -7.6694, -15.9593,  -3.3235,  -4.4470, -18.4937,\n",
      "         -20.6754,  -0.6448, -18.1565,  -9.3899, -13.1982,   7.3392,  -3.7231,\n",
      "          -9.8469, -13.8983,  -7.2742, -11.2102, -11.6250, -19.0181, -17.3108,\n",
      "           3.8214, -17.8009, -10.2750, -17.4043, -15.8597, -20.3146, -11.4058,\n",
      "         -14.2033,   1.2470,  -9.8833, -10.9950,  -7.2665,  -4.5578,  -1.9062,\n",
      "          -7.2311, -17.2258,  -2.7540,  -8.5210,  -3.8104, -17.1154, -17.3639,\n",
      "         -15.8900,   0.2752, -12.9152,  -2.4497, -19.5410,  -4.8236, -15.2546,\n",
      "         -12.3533,  -0.7627],\n",
      "        [ -5.5915,  -9.1841,  -7.7051,  -9.7543, -19.4744,  -5.8066,  -8.4483,\n",
      "         -10.7928,  -2.1940,  -2.1287,   2.3543, -12.3746, -14.9163, -11.5979,\n",
      "          -5.4929, -12.7419,   1.7019, -11.0425,  -8.8909, -15.8277,  -9.7929,\n",
      "         -18.9493,   2.6915,  -3.9755, -13.4060,  -5.5475,  -7.7619, -15.9256,\n",
      "          -6.1361, -14.8914, -20.1665, -12.8649,  -6.1795,  -0.7316, -11.5431,\n",
      "          -9.2830,  -8.3521,  -4.5545, -16.0758,   6.1910,  -8.9242, -13.4092,\n",
      "          -8.8071,  -8.8093, -15.8464,  -3.8303, -13.3426,  -4.9743, -12.4512,\n",
      "         -12.6957,  -9.1950,  -6.7219, -17.0006,  -0.3365,  -2.8278, -20.2181,\n",
      "         -21.1222,   1.2568, -21.4667,  -9.5398, -12.5775,   5.0351,  -2.1755,\n",
      "         -11.7800, -14.2985,  -7.9930, -13.3791, -13.8296, -20.3413, -17.0050,\n",
      "           3.4482, -19.5875, -12.5436, -20.7362, -17.9641, -22.3547, -11.5132,\n",
      "         -14.3976,   0.9487,  -7.6800, -10.9545,  -8.0611,  -1.0108,  -0.9441,\n",
      "          -6.4214, -20.0051,  -5.1951, -11.1930,  -2.7661, -15.8085, -18.8767,\n",
      "         -19.6317,   2.1807, -15.8462,  -1.2437, -25.5990,  -3.3167, -16.4760,\n",
      "         -12.2014,  -2.3929]], grad_fn=<AddmmBackward>) torch.Size([2, 100])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2,3,32,32)\n",
    "sbp_net.eval()\n",
    "y = sbp_net.forward(x)\n",
    "print(y,y.size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 64, 16, 16])\n",
      "Parameter containing:\n",
      "tensor([-0.0501, -0.0499, -0.0500, -0.0501, -0.0501, -0.0500, -0.0497, -0.0501,\n",
      "        -0.0500, -0.0500, -0.0502, -0.0500, -0.0501, -0.0500, -0.0498, -0.0500,\n",
      "        -0.0501, -0.0509, -0.0499, -0.0500, -0.0500, -0.0500, -0.0501, -0.0500,\n",
      "        -0.0501, -0.0500, -0.0498, -0.0500, -0.0500, -0.0500, -0.0500, -0.0500,\n",
      "        -0.0500, -0.0499, -0.0501, -0.0500, -0.0501, -0.0500, -0.0501, -0.0499,\n",
      "        -0.0500, -0.0500, -0.0497, -0.0501, -0.0500, -0.0501, -0.0495, -0.0500,\n",
      "        -0.0501, -0.0499, -0.0500, -0.0500, -0.0500, -0.0501, -0.0500, -0.0505,\n",
      "        -0.0500, -0.0500, -0.0500, -0.0498, -0.0502, -0.0500, -0.0499, -0.0513],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441,\n",
      "        -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441, -4.6441],\n",
      "       requires_grad=True)\n",
      "multiplicator:  tensor([-0.1782,  0.3021,  0.1472, -0.0077, -0.0077, -0.4570,  0.5035,  1.0302,\n",
      "        -0.4570,  0.2246,  0.1704,  0.7514,  0.7746, -0.0310,  0.2789,  0.5732,\n",
      "         0.1549,  0.5964,  0.2944, -0.2014,  0.2246, -0.0232, -0.0155,  0.0620,\n",
      "         0.1704,  0.4958, -0.2401,  0.2246, -0.6352,  0.3176,  0.8288,  0.5810,\n",
      "        -0.5500, -0.3951,  0.4105,  0.1472, -0.0077, -0.6352,  0.7746,  0.5500,\n",
      "         0.9295, -0.2014,  0.6120, -0.0930,  0.8366,  0.3408,  0.3099,  0.2246,\n",
      "         0.5887,  0.2091,  0.6584,  0.4880, -0.0232,  0.4260,  0.2324,  1.0301,\n",
      "        -0.0310, -0.2169, -0.1937,  0.1704,  0.0077,  0.5810,  0.2944,  0.4337])\n",
      "snr:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "mask:  tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan])\n",
      "(tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]), tensor([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
      "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]))\n"
     ]
    }
   ],
   "source": [
    "sbp_net.eval()\n",
    "out_1 = sbp_net.features[0].conv1(x)\n",
    "print(out.shape)\n",
    "out_2 = sbp_net.features[0].sbp(out_1)\n",
    "mu = sbp_net.features[0].sbp.mu.detach()\n",
    "sigma = sbp_net.features[0].sbp.log_sigma.detach()\n",
    "print(sbp_net.features[0].sbp.mu)\n",
    "print(sbp_net.features[0].sbp.log_sigma)\n",
    "print(get_mask(mu,sigma))\n",
    "#print(out_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-4.3465e-01, -4.3465e-01, -1.7600e-01,  ..., -4.3465e-01,\n",
       "            1.7735e+00, -4.3465e-01],\n",
       "          [ 1.3551e+00,  5.0437e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -3.1233e-01,  1.1398e+00],\n",
       "          [-4.3465e-01, -4.3465e-01, -4.3465e-01,  ...,  5.5210e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          ...,\n",
       "          [ 2.9487e+00, -4.3465e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "            5.1174e-01, -4.3465e-01],\n",
       "          [-4.3465e-01, -3.3155e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          [-4.3465e-01,  1.4996e+00,  3.1659e+00,  ..., -4.3465e-01,\n",
       "            9.4603e-01,  3.1426e+00]],\n",
       "\n",
       "         [[-5.0862e-01,  1.2093e+00, -5.0862e-01,  ...,  9.4067e-02,\n",
       "           -5.0862e-01, -5.0862e-01],\n",
       "          [-5.0862e-01,  3.7695e-01,  4.3916e-01,  ..., -5.0862e-01,\n",
       "            3.3940e+00,  4.3031e-01],\n",
       "          [ 2.3318e+00,  1.4081e+00,  4.7294e+00,  ..., -5.0862e-01,\n",
       "           -5.0862e-01, -5.0862e-01],\n",
       "          ...,\n",
       "          [-5.0862e-01, -3.8492e-01, -5.0862e-01,  ..., -5.0862e-01,\n",
       "           -5.0862e-01,  4.2691e+00],\n",
       "          [ 2.9053e+00,  5.8004e-01, -1.1890e-01,  ...,  7.7107e+00,\n",
       "           -1.5871e-01,  6.8816e-01],\n",
       "          [-5.0862e-01,  2.8869e+00, -5.0862e-01,  ..., -5.0862e-01,\n",
       "           -5.0862e-01, -5.0862e-01]],\n",
       "\n",
       "         [[ 2.0997e-02, -6.2678e-01, -2.1714e-01,  ...,  1.2464e+00,\n",
       "           -4.8382e-01, -6.2678e-01],\n",
       "          [-6.2678e-01, -6.2678e-01, -6.2678e-01,  ..., -6.2678e-01,\n",
       "            7.7742e-01, -6.2678e-01],\n",
       "          [-6.2678e-01, -6.2678e-01, -1.5465e-01,  ..., -2.0036e-01,\n",
       "           -1.6880e-01,  1.9561e+00],\n",
       "          ...,\n",
       "          [-6.2678e-01, -1.3335e-01, -1.1206e-01,  ...,  2.0777e+00,\n",
       "            7.5063e-01, -6.2678e-01],\n",
       "          [ 1.0796e+00,  2.2099e-01,  1.5710e+00,  ..., -6.2678e-01,\n",
       "           -6.2678e-01,  8.3510e-01],\n",
       "          [-6.2678e-01, -6.2678e-01, -6.2678e-01,  ...,  5.1011e-01,\n",
       "            1.6262e-01,  4.3153e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-7.2287e-01, -7.2919e-01, -6.8307e-01,  ..., -7.2919e-01,\n",
       "            1.4937e-01, -2.7064e-01],\n",
       "          [-5.0224e-01, -7.2919e-01, -3.8661e-01,  ..., -4.5314e-02,\n",
       "            7.0651e-02,  4.6142e-01],\n",
       "          [ 7.0200e-01, -7.2919e-01, -7.2919e-01,  ..., -5.1552e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          ...,\n",
       "          [-7.2919e-01,  2.1859e-01, -6.8067e-01,  ...,  1.5953e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          [-7.2919e-01, -7.2919e-01, -4.7214e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          [-7.2919e-01, -7.2919e-01, -7.2919e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -7.2919e-01]],\n",
       "\n",
       "         [[-5.6570e-01,  1.0460e+00, -5.6570e-01,  ..., -5.6570e-01,\n",
       "            4.9174e-01,  3.9126e-01],\n",
       "          [-5.6570e-01,  2.6591e-01, -1.2089e-01,  ..., -5.6570e-01,\n",
       "           -3.2473e-01, -5.6570e-01],\n",
       "          [ 1.3682e+00, -5.6570e-01,  1.3096e+00,  ..., -3.0707e-01,\n",
       "           -1.3151e-01,  3.4683e-01],\n",
       "          ...,\n",
       "          [-5.6570e-01, -5.6570e-01,  2.0471e-01,  ...,  1.9936e+00,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          [-5.6570e-01, -5.6570e-01,  2.1770e+00,  ..., -5.6570e-01,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          [-5.6570e-01,  1.2844e+00, -5.6570e-01,  ..., -5.6570e-01,\n",
       "            4.5362e+00, -5.6570e-01]],\n",
       "\n",
       "         [[-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          ...,\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01,  6.1376e-01, -1.7195e-01,  ...,  6.3056e-01,\n",
       "           -1.7195e-01,  1.0886e+00]]],\n",
       "\n",
       "\n",
       "        [[[-4.3465e-01,  1.3661e+00, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          [ 2.0482e+00, -4.3465e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "            2.1568e+00, -4.3465e-01],\n",
       "          [ 1.0606e+00,  8.3775e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          ...,\n",
       "          [-4.3465e-01,  5.8554e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "           -2.4039e-01, -4.3465e-01],\n",
       "          [ 1.0879e-01, -4.3465e-01, -4.3465e-01,  ...,  9.0902e-01,\n",
       "           -4.3465e-01, -4.3465e-01],\n",
       "          [-4.3465e-01, -3.8163e-01, -4.3465e-01,  ..., -4.3465e-01,\n",
       "            2.4868e+00,  2.3758e-01]],\n",
       "\n",
       "         [[-5.0862e-01, -5.0862e-01,  1.7032e+00,  ...,  4.6044e-01,\n",
       "           -5.0862e-01, -5.0862e-01],\n",
       "          [ 4.0207e-01, -5.0862e-01,  7.9302e-01,  ..., -5.0862e-01,\n",
       "           -5.0862e-01,  4.1737e+00],\n",
       "          [-5.0862e-01,  1.7934e-01, -5.0862e-01,  ...,  3.0002e+00,\n",
       "           -5.0862e-01, -5.0862e-01],\n",
       "          ...,\n",
       "          [-5.0862e-01, -5.0862e-01,  3.1067e+00,  ..., -5.0862e-01,\n",
       "           -5.0862e-01,  8.1345e+00],\n",
       "          [ 1.5770e+00, -5.0862e-01, -5.0862e-01,  ...,  6.5456e+00,\n",
       "            2.1325e+00, -5.0862e-01],\n",
       "          [-5.0862e-01,  2.6705e+00,  4.2465e+00,  ...,  3.0863e+00,\n",
       "           -5.0862e-01, -5.0862e-01]],\n",
       "\n",
       "         [[ 3.0393e-01, -4.4843e-02, -6.2678e-01,  ..., -6.2678e-01,\n",
       "            5.9379e-01, -4.2223e-01],\n",
       "          [-6.2678e-01, -6.2678e-01,  9.4275e-01,  ..., -3.5613e-01,\n",
       "           -4.5225e-01, -5.0315e-01],\n",
       "          [ 8.0327e-02, -3.8676e-01, -6.2678e-01,  ...,  3.2790e-01,\n",
       "            1.8275e+00, -1.5110e-01],\n",
       "          ...,\n",
       "          [-6.2678e-01, -6.2678e-01, -6.2678e-01,  ..., -7.2902e-02,\n",
       "            1.1736e+00, -6.2678e-01],\n",
       "          [ 3.0201e-02, -6.2678e-01,  7.6819e-01,  ..., -6.2678e-01,\n",
       "           -4.9704e-01,  1.0082e+00],\n",
       "          [ 2.8679e-01,  1.1269e+00, -6.2532e-01,  ..., -3.4910e-01,\n",
       "           -6.2678e-01, -6.2678e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.6985e-02, -1.6527e-01, -7.2919e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -6.9186e-01],\n",
       "          [-4.7667e-01,  1.5352e-01, -7.2919e-01,  ...,  4.5625e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          [-7.2919e-01, -7.2919e-01, -7.2919e-01,  ..., -2.6281e-01,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          ...,\n",
       "          [-4.5974e-01, -7.2919e-01, -4.9821e-01,  ..., -3.9266e-03,\n",
       "           -7.2919e-01, -7.2919e-01],\n",
       "          [-5.1480e-01, -5.0311e-01, -2.1999e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -4.7041e-01],\n",
       "          [-7.2919e-01, -1.3880e-01, -7.2919e-01,  ..., -7.2919e-01,\n",
       "           -7.2919e-01, -7.2919e-01]],\n",
       "\n",
       "         [[-5.6570e-01, -4.9504e-01, -5.6570e-01,  ..., -2.1850e-01,\n",
       "           -5.6570e-01,  1.1194e+00],\n",
       "          [-5.6570e-01,  4.1219e+00, -5.6570e-01,  ...,  7.1772e-01,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          [-5.6570e-01, -5.6570e-01, -3.0889e-01,  ..., -5.6570e-01,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          ...,\n",
       "          [-5.6570e-01, -5.6570e-01, -4.4840e-02,  ...,  1.7051e+00,\n",
       "           -5.6570e-01, -5.6570e-01],\n",
       "          [-5.6570e-01, -5.6570e-01,  4.7130e+00,  ..., -5.6570e-01,\n",
       "           -5.6570e-01, -6.0467e-02],\n",
       "          [-5.6570e-01, -5.6570e-01, -5.6570e-01,  ...,  3.1991e+00,\n",
       "           -5.6570e-01, -5.6570e-01]],\n",
       "\n",
       "         [[-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          ...,\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01],\n",
       "          [-1.7195e-01, -1.7195e-01, -1.7195e-01,  ..., -1.7195e-01,\n",
       "           -1.7195e-01, -1.7195e-01]]]], grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SBP_layer' object has no attribute 'weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-37bfd47aeb11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcal_importance_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msbp_net\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-7f38cf2f1e0e>\u001b[0m in \u001b[0;36mcal_importance_0\u001b[0;34m(net, l_id, num_stop)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcal_importance_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_stop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlayer_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msbp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mimp_corr_bn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_weights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mneuron_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_corr_bn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_corr_bn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimp_corr_bn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mneuron_order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SBP_layer' object has no attribute 'weight'"
     ]
    }
   ],
   "source": [
    "cal_importance_0(sbp_net,l_id=1,num_stop=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PTFLOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBP_AlexNet(\n",
      "  20.5 M, 100.000% Params, 0.044 GMac, 100.000% MACs, \n",
      "  (block1): SBP_Block(\n",
      "    0.002 M, 0.010% Params, 0.001 GMac, 1.167% MACs, \n",
      "    (conv1): Conv2d(0.002 M, 0.009% Params, 0.0 GMac, 1.054% MACs, 3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (sbp): SBP_layer(0.0 M, 0.001% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.075% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.038% MACs, inplace=True)\n",
      "  )\n",
      "  (mp1): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.038% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (block2): SBP_Block(\n",
      "    0.112 M, 0.544% Params, 0.005 GMac, 12.541% MACs, \n",
      "    (conv1): Conv2d(0.111 M, 0.540% Params, 0.005 GMac, 12.476% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sbp): SBP_layer(0.0 M, 0.002% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.043% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.022% MACs, inplace=True)\n",
      "  )\n",
      "  (mp2): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.022% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (block3): SBP_Block(\n",
      "    0.665 M, 3.246% Params, 0.006 GMac, 13.757% MACs, \n",
      "    (conv1): Conv2d(0.664 M, 3.239% Params, 0.006 GMac, 13.733% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sbp): SBP_layer(0.001 M, 0.004% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.016% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.008% MACs, inplace=True)\n",
      "  )\n",
      "  (block4): SBP_Block(\n",
      "    0.886 M, 4.322% Params, 0.008 GMac, 18.321% MACs, \n",
      "    (conv1): Conv2d(0.885 M, 4.317% Params, 0.008 GMac, 18.305% MACs, 384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sbp): SBP_layer(0.001 M, 0.002% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.011% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (block5): SBP_Block(\n",
      "    0.591 M, 2.883% Params, 0.005 GMac, 12.221% MACs, \n",
      "    (conv1): Conv2d(0.59 M, 2.878% Params, 0.005 GMac, 12.205% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (sbp): SBP_layer(0.001 M, 0.002% Params, 0.0 GMac, 0.000% MACs, )\n",
      "    (bn1): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.011% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (rel): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, inplace=True)\n",
      "  )\n",
      "  (mp3): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (classifier): Sequential(\n",
      "    18.244 M, 88.994% Params, 0.018 GMac, 41.928% MACs, \n",
      "    (0): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (1): Linear(1.053 M, 5.135% Params, 0.001 GMac, 2.410% MACs, in_features=256, out_features=4096, bias=True)\n",
      "    (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "    (3): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (4): Linear(16.781 M, 81.861% Params, 0.017 GMac, 38.558% MACs, in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "    (6): Linear(0.41 M, 1.999% Params, 0.0 GMac, 0.941% MACs, in_features=4096, out_features=100, bias=True)\n",
      "  )\n",
      ")\n",
      "Computational complexity:       0.04 GMac\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(-1):\n",
    "    flops, params = get_model_complexity_info(sbp_net, (3, 32, 32), as_strings=True, print_per_layer_stat=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  20.498 M, 100.000% Params, 0.044 GMac, 100.000% MACs, \n",
      "  (features): Sequential(\n",
      "    2.254 M, 10.996% Params, 0.025 GMac, 58.072% MACs, \n",
      "    (0): Conv2d(0.002 M, 0.009% Params, 0.0 GMac, 1.054% MACs, 3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.038% MACs, inplace=True)\n",
      "    (2): BatchNorm2d(0.0 M, 0.001% Params, 0.0 GMac, 0.075% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.038% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(0.111 M, 0.540% Params, 0.005 GMac, 12.476% MACs, 64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.022% MACs, inplace=True)\n",
      "    (6): BatchNorm2d(0.0 M, 0.002% Params, 0.0 GMac, 0.043% MACs, 192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.022% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(0.664 M, 3.239% Params, 0.006 GMac, 13.733% MACs, 192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.008% MACs, inplace=True)\n",
      "    (10): BatchNorm2d(0.001 M, 0.004% Params, 0.0 GMac, 0.016% MACs, 384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(0.885 M, 4.318% Params, 0.008 GMac, 18.305% MACs, 384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, inplace=True)\n",
      "    (13): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.011% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Conv2d(0.59 M, 2.879% Params, 0.005 GMac, 12.205% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, inplace=True)\n",
      "    (16): BatchNorm2d(0.001 M, 0.002% Params, 0.0 GMac, 0.011% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): MaxPool2d(0.0 M, 0.000% Params, 0.0 GMac, 0.005% MACs, kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    18.244 M, 89.004% Params, 0.018 GMac, 41.928% MACs, \n",
      "    (0): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (1): Linear(1.053 M, 5.136% Params, 0.001 GMac, 2.410% MACs, in_features=256, out_features=4096, bias=True)\n",
      "    (2): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "    (3): Dropout(0.0 M, 0.000% Params, 0.0 GMac, 0.000% MACs, p=0.5, inplace=False)\n",
      "    (4): Linear(16.781 M, 81.870% Params, 0.017 GMac, 38.558% MACs, in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(0.0 M, 0.000% Params, 0.0 GMac, 0.009% MACs, inplace=True)\n",
      "    (6): Linear(0.41 M, 1.999% Params, 0.0 GMac, 0.941% MACs, in_features=4096, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with torch.cuda.device(-1):\n",
    "    #flops, params = get_model_complexity_info(sbp_net, (3, 32, 32), as_strings=True, print_per_layer_stat=True)\n",
    "    flops, params = get_model_complexity_info(best_net, (3, 32, 32), as_strings=True, print_per_layer_stat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbp_net."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flop weighted importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importance for SBP Net\n",
    "\n",
    "l_imp = {}\n",
    "\n",
    "for conv_ind in [0, 2, 4, 5, 6]:\n",
    "    l_imp.update({conv_ind: net.features[conv_ind].bn1.bias.shape[0]})\n",
    "## do not need to update the classifer indices b/c no blocks \n",
    "for lin_ind in [1, 4]:\n",
    "    l_imp.update({lin_ind: net.classifier[lin_ind].bias.shape[0]})\n",
    "    \n",
    "normalizer = 0\n",
    "for key, val in l_imp.items():\n",
    "    normalizer += val\n",
    "for key, val in l_imp.items():\n",
    "    l_imp[key] = val / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=1e-3, betas=(0.9, 0.999), eps=1e-08, weight_decay=5e-4, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SBP_AlexNet(cfg)\n",
    "net_ortho = SBP_AlexNet(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 261ms | Tot: 1m35s | Loss: 11.952 | Acc: 1.048% (524/5000 391/391 1  \n",
      " [========================>]  Step: 89ms | Tot: 6s501ms | Loss: 4.621 | Acc: 1.310% (131/1000 79/79 \n",
      "Saving..\n",
      "\n",
      "Epoch: 1\n",
      " [========================>]  Step: 266ms | Tot: 1m36s | Loss: 11.952 | Acc: 0.992% (496/5000 391/391 1  \n",
      " [========================>]  Step: 97ms | Tot: 6s579ms | Loss: 4.621 | Acc: 1.310% (131/1000 79/79 \n",
      "\n",
      "Epoch: 2\n",
      " [========================>]  Step: 262ms | Tot: 1m37s | Loss: 11.952 | Acc: 1.076% (538/5000 391/391 1  \n",
      " [========================>]  Step: 101ms | Tot: 6s502ms | Loss: 4.621 | Acc: 1.370% (137/1000 79/79 \n",
      "Saving..\n",
      "\n",
      "Epoch: 3\n",
      " [========================>]  Step: 325ms | Tot: 1m47s | Loss: 11.952 | Acc: 1.102% (551/5000 391/391 1  \n",
      " [========================>]  Step: 88ms | Tot: 6s200ms | Loss: 4.621 | Acc: 1.320% (132/1000 79/79 \n",
      "\n",
      "Epoch: 4\n",
      " [=>.......................]  Step: 279ms | Tot: 4s887ms | Loss: 11.956 | Acc: 0.873% (19/217 17/391 \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-0a7b0bc7a1fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mSBP_net_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mSBP_net_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-24-4b5a8edcee52>\u001b[0m in \u001b[0;36mSBP_net_train\u001b[0;34m(epoch, net)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gnn/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                     \u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    SBP_net_train(epoch,net)\n",
    "    SBP_net_test(epoch,net)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 154ms | Tot: 1m4s | Loss: 11.956 | Acc: 1.018% (509/5000 391/391 91  \n",
      "\n",
      "Epoch: 0\n",
      " [========================>]  Step: 714ms | Tot: 4m20s | Loss: 3634.107 | Acc: 0.970% (485/5000 391/391 1 \n",
      "angle_cost:  283.252374375\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "net_test() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-2429cfba53f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mSBP_net_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mSBP_net_train_ortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_ortho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mnet_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mnet_test_ortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet_ortho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mw_diag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_ortho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: net_test() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    SBP_net_train_ortho(epoch,net_ortho)\n",
    "    w_diag(net_ortho)\n",
    "    SBP_net_test_ortho(epoch,net_ortho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner product training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "alex_net = AlexNet(cfg)\n",
    "print(alex_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_net.features[2].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ortho = AlexNet(cfg).to(device)\n",
    "net_dict = torch.load('./ortho_checkpoint/ckpt.pth')\n",
    "net_ortho.load_state_dict(net_dict['net'])\n",
    "best_acc_ortho = net_dict['best_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importance for SBP Net\n",
    "\n",
    "l_imp = {}\n",
    "\n",
    "for conv_ind in [0, 2, 4, 5, 6]:\n",
    "    l_imp.update({conv_ind: net.features[conv_ind].bn1.bias.shape[0]})\n",
    "## do not need to update the classifer indices b/c no blocks \n",
    "for lin_ind in [1, 4]:\n",
    "    l_imp.update({lin_ind: net.classifier[lin_ind].bias.shape[0]})\n",
    "    \n",
    "normalizer = 0\n",
    "for key, val in l_imp.items():\n",
    "    normalizer += val\n",
    "for key, val in l_imp.items():\n",
    "    l_imp[key] = val / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normal AlexNet\n",
    "l_imp = {}\n",
    "\n",
    "for conv_ind in [2, 6, 10, 13, 16]:\n",
    "    l_imp.update({conv_ind: net.features[conv_ind].bias.shape[0]})\n",
    "    \n",
    "for lin_ind in [1, 4]:\n",
    "    l_imp.update({lin_ind: net.classifier[lin_ind].bias.shape[0]})\n",
    "    \n",
    "normalizer = 0\n",
    "for key, val in l_imp.items():\n",
    "    normalizer += val\n",
    "for key, val in l_imp.items():\n",
    "    l_imp[key] = val / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_test_ortho(epoch):\n",
    "    global best_acc_ortho\n",
    "    net_ortho.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net_ortho(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    print(acc)\n",
    "    if acc > best_acc_ortho:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net_ortho.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('ortho_checkpoint'):\n",
    "            os.mkdir('ortho_checkpoint')\n",
    "        torch.save(state, './ortho_checkpoint/ckpt.pth')\n",
    "        best_acc_ortho = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for conv_ind in [6, 10, 13, 16]:\n",
    "    print(alex_net.features[conv_ind-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBP_net_train_ortho(epoch,net_ortho):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net_ortho.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    angle_cost = 0.0\n",
    "            \n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, kl = net_ortho(inputs)\n",
    "        L_angle = 0\n",
    "        \n",
    "        ### Conv_ind == 0 ###\n",
    "        w_mat = net_ortho.features[0].conv1.weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.features[0].conv1.bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[2])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "\n",
    "        ### Conv_ind != 0 ###\n",
    "        for conv_ind in [2, 4, 5, 6]:\n",
    "            w_mat = net_ortho.features[conv_ind].conv1.weight\n",
    "            w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "            b_mat = net_ortho.features[conv_ind].conv1.bias\n",
    "            b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "            params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "            angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(w_mat.shape[0]).to(device)            \n",
    "            L_angle += (l_imp[conv_ind])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "    \n",
    "        ### lin_ind = 1 ###        \n",
    "        w_mat = net_ortho.classifier[1].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[1].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[1])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "        \n",
    "        ### lin_ind = 4 ###        \n",
    "        w_mat = net_ortho.classifier[4].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[4].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(params.shape[0]).to(device)\n",
    "        L_angle += (l_imp[4])*(angle_mat).norm(1) #.norm().pow(2))        \n",
    "        \n",
    "        Lc = criterion(outputs, labels)\n",
    "        loss = (1e-1)*(L_angle) + Lc + kl #from the sparsity inducer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        angle_cost += (L_angle).item()\n",
    "    \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (running_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    print(\"angle_cost: \", angle_cost/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_train_ortho(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net_ortho.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    angle_cost = 0.0\n",
    "            \n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_ortho(inputs)\n",
    "        L_angle = 0\n",
    "        \n",
    "        ### Conv_ind == 0 ###\n",
    "        w_mat = net_ortho.features[0].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.features[0].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[2])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "\n",
    "        ### Conv_ind != 0 ###\n",
    "        for conv_ind in [6, 10, 13, 16]:\n",
    "            w_mat = net_ortho.features[conv_ind-2].weight\n",
    "            w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "            b_mat = net_ortho.features[conv_ind-2].bias\n",
    "            b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "            params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "            angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(w_mat.shape[0]).to(device)            \n",
    "            L_angle += (l_imp[conv_ind])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "    \n",
    "        ### lin_ind = 1 ###        \n",
    "        w_mat = net_ortho.classifier[1].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[1].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[1])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "        \n",
    "        ### lin_ind = 4 ###        \n",
    "        w_mat = net_ortho.classifier[4].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.classifier[4].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))            \n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(params.shape[0]).to(device)\n",
    "        L_angle += (l_imp[4])*(angle_mat).norm(1) #.norm().pow(2))        \n",
    "        \n",
    "        Lc = criterion(outputs, labels)\n",
    "        loss = (1e-1)*(L_angle) + Lc\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        angle_cost += (L_angle).item()\n",
    "    \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (running_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    print(\"angle_cost: \", angle_cost/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SBP_net_ortho = SBP_AlexNet(cfg).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(SBP_net_ortho.parameters(), lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBP_AlexNet(\n",
       "  (block1): SBP_Block(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block2): SBP_Block(\n",
       "    (conv1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block3): SBP_Block(\n",
       "    (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block4): SBP_Block(\n",
       "    (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block5): SBP_Block(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_net_ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SBP_net_ortho' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3ea1007e84db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#SBP_net_train(epoch,SBP_net_ortho)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mSBP_net_train_ortho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSBP_net_ortho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#net_test_ortho(epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#w_diag(net_ortho)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SBP_net_ortho' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    #SBP_net_train(epoch,SBP_net_ortho)\n",
    "    SBP_net_train_ortho(epoch,SBP_net_ortho)\n",
    "    #net_test_ortho(epoch)\n",
    "    #w_diag(net_ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = './w_decorr/base_params/wnet_base_2.pth'\n",
    "# torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layer index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (11): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (12): ReLU(inplace=True)\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alex_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SBP_AlexNet(\n",
       "  (block1): SBP_Block(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block2): SBP_Block(\n",
       "    (conv1): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (block3): SBP_Block(\n",
       "    (conv1): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block4): SBP_Block(\n",
       "    (conv1): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (block5): SBP_Block(\n",
       "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (sbp): SBP_layer()\n",
       "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (rel): ReLU(inplace=True)\n",
       "  )\n",
       "  (mp3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=256, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=100, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SBP_net_ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_index = 4\n",
    "layer_id = 'bn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlated Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AlexNet(cfg).to(device)\n",
    "net_dict = torch.load('./checkpoint/ckpt.pth')\n",
    "net.load_state_dict(net_dict['net'])\n",
    "net = net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changed for SBP_Aexnet\n",
    "weight_base = net.features[l_index].bn1.weight.data.clone().detach()\n",
    "bias_base = net.features[l_index].bn1.bias.data.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_base_corr = 0\n",
    "num_stop = 0\n",
    "for epoch in range(1):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs, kl = net(inputs)\n",
    "        loss = criterion(outputs, labels) + kl\n",
    "        loss_base_corr += loss.item()\n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "loss_base_corr = loss_base_corr**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n"
     ]
    }
   ],
   "source": [
    "## changed for SBP_Alexnet\n",
    "\n",
    "loss_mat_corr = torch.zeros(weight_base.shape[0])\n",
    "\n",
    "for n_index in tqdm(range(weight_base.shape[0])): \n",
    "    num_stop = 0\n",
    "    print(n_index)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    net.features[l_index].bn1.weight.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    net.features[l_index].bn1.bias.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    \n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs, kl = net(inputs)\n",
    "\n",
    "        loss = (criterion(outputs, labels)) + kl\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "            \n",
    "    loss_mat_corr[n_index] = running_loss**2\n",
    "    \n",
    "    net.features[l_index].bn1.weight.data = weight_base.clone().detach()\n",
    "    net.features[l_index].bn1.bias.data = bias_base.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal alex net w/ no KL loss\n",
    "loss_base_corr = 0\n",
    "num_stop = 0\n",
    "for epoch in range(1):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_base_corr += loss.item()\n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "loss_base_corr = loss_base_corr**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SBP_Alexnet\n",
    "### Change bn1 to access other layers in the block.\n",
    "loss_mat_corr = torch.zeros(weight_base.shape[0])\n",
    "\n",
    "for n_index in tqdm(range(weight_base.shape[0])): \n",
    "    num_stop = 0\n",
    "    print(n_index)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    net.features[l_index].bn1.weight.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    net.features[l_index].bn1.bias.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    \n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs, kl = net(inputs)\n",
    "\n",
    "        loss = (criterion(outputs, labels)) + kl\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "            \n",
    "    loss_mat_corr[n_index] = running_loss**2\n",
    "    \n",
    "    net.features[l_index].bn1.weight.data = weight_base.clone().detach()\n",
    "    net.features[l_index].bn1.bias.data = bias_base.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### normal AlexNet\n",
    "\n",
    "loss_mat_corr = torch.zeros(weight_base.shape[0])\n",
    "\n",
    "for n_index in range(weight_base.shape[0]): \n",
    "    num_stop = 0\n",
    "    print(n_index)\n",
    "    running_loss = 0.0\n",
    "\n",
    "    net.features[l_index].weight.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    net.features[l_index].bias.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "    \n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        loss = (criterion(outputs, labels))\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "            \n",
    "    loss_mat_corr[n_index] = running_loss**2\n",
    "    \n",
    "    net.features[l_index].weight.data = weight_base.clone().detach()\n",
    "    net.features[l_index].bias.data = bias_base.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(loss_mat_corr, './w_decorr/loss_mats/corr/'+str(l_index)+'/loss_corr_bn_train_'+str(l_index)+'.pt')\n",
    "loss_mat_corr = torch.load('./w_decorr/loss_mats/corr/'+str(l_index)+'/loss_corr_bn_train_'+str(l_index)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### SBP AlexNet\n",
    "optimizer = optim.SGD(net.parameters(), lr=0, weight_decay=0)\n",
    "av_corrval = 0\n",
    "n_epochs = 1\n",
    "\n",
    "for epoch in tqdm(range(n_epochs)):\n",
    "    num_stop = 0\n",
    "    running_loss = 0.0\n",
    "    imp_corr_conv = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    imp_corr_bn = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, kl = net(inputs) + kl\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        imp_corr_bn += (((net.features[l_index].bn1.weight.grad)*(net.features[l_index].bn1.weight.data)) + ((net.features[l_index].bn1.bias.grad)*(net.features[l_index].bn1.bias.data))).abs().pow(2)\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "         \n",
    "    corrval = (np.corrcoef(imp_corr_bn.cpu().detach().numpy(), (loss_mat_corr - loss_base_corr).abs().cpu().detach().numpy()))\n",
    "    print(\"Correlation at epoch \"+str(epoch)+\": \"+str(corrval[0,1]))\n",
    "    av_corrval += corrval[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Normal AlexNet\n",
    "optimizer = optim.SGD(net.parameters(), lr=0, weight_decay=0)\n",
    "av_corrval = 0\n",
    "n_epochs = 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    num_stop = 0\n",
    "    running_loss = 0.0\n",
    "    imp_corr_conv = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    imp_corr_bn = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    \n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        imp_corr_bn += (((net.features[l_index].weight.grad)*(net.features[l_index].weight.data)) + ((net.features[l_index].bias.grad)*(net.features[l_index].bias.data))).abs().pow(2)\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "         \n",
    "    corrval = (np.corrcoef(imp_corr_bn.cpu().detach().numpy(), (loss_mat_corr - loss_base_corr).abs().cpu().detach().numpy()))\n",
    "    print(\"Correlation at epoch \"+str(epoch)+\": \"+str(corrval[0,1]))\n",
    "    av_corrval += corrval[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decorrelated net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_decorr = AlexNet(cfg).to(device)\n",
    "net_dict = torch.load('./ortho_checkpoint/ckpt.pth')\n",
    "net_decorr.load_state_dict(net_dict['net'])\n",
    "net_decorr = net_decorr.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_base = net_decorr.features[l_index].weight.data.clone().detach()\n",
    "bias_base = net_decorr.features[l_index].bias.data.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_decorr.parameters(), lr=0, weight_decay=0)\n",
    "num_stop = 0\n",
    "loss_base_decorr = 0\n",
    "for epoch in range(1):\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):        \n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net_decorr(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_base_decorr += loss.item()\n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "loss_base_decorr = loss_base_decorr**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_decorr.parameters(), lr=0, weight_decay=0)\n",
    "\n",
    "loss_mat_decorr = torch.zeros(weight_base.shape[0])\n",
    "\n",
    "for n_index in range(weight_base.shape[0]): \n",
    "    print(n_index)\n",
    "    num_stop = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        net_decorr.features[l_index].weight.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "        net_decorr.features[l_index].bias.data[n_index] = 0 #torch.zeros((weight_base.shape[1],weight_base.shape[2],weight_base.shape[3]))\n",
    "        outputs = net_decorr(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "            \n",
    "    loss_mat_decorr[n_index] = running_loss**2\n",
    "    \n",
    "    net_decorr.features[l_index].weight.data = weight_base.clone().detach()\n",
    "    net_decorr.features[l_index].bias.data = bias_base.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(loss_mat_decorr, './w_decorr/loss_mats/decorr/'+str(l_index)+'/loss_decorr_bn_train_'+str(l_index)+'.pt')\n",
    "loss_mat_decorr = torch.load('./w_decorr/loss_mats/decorr/'+str(l_index)+'/loss_decorr_bn_train_'+str(l_index)+'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net_decorr.parameters(), lr=0, weight_decay=0)\n",
    "av_corrval = 0\n",
    "n_epochs = 1\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    num_stop = 0\n",
    "    imp_decorr_conv = torch.zeros(bias_base.shape[0]).to(device)\n",
    "    imp_decorr_bn = torch.zeros(bias_base.shape[0]).to(device)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "#     for i, data in enumerate(testloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_decorr(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        num_stop += labels.shape[0]\n",
    "        if(num_stop > 5000):\n",
    "            break\n",
    "        \n",
    "        imp_decorr_bn += (((net_decorr.features[l_index].weight.grad)*(net_decorr.features[l_index].weight.data)) + ((net_decorr.features[l_index].bias.grad)*(net_decorr.features[l_index].bias.data))).abs().pow(2)\n",
    "    \n",
    "    corrval = (np.corrcoef(imp_decorr_bn.cpu().detach().numpy(), (loss_mat_decorr - loss_base_decorr).abs().cpu().detach().numpy()))\n",
    "    print(\"Correlation at epoch \"+str(epoch)+\": \"+str(corrval[0,1]))\n",
    "    av_corrval += corrval[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "s = imp_corr_bn.cpu().sort()[0].cpu().numpy()\n",
    "order = imp_corr_bn.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max(), label=\"Estimated importance\")\n",
    "plt.title(\"Correlated (Taylor FO) for \"+str(l_index))\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "plt.xlabel(\"Neuron index\")\n",
    "plt.ylabel(\"Normalized importance\")\n",
    "plt.plot(loss_diff[order]/loss_diff.max(), label=\"Actual importance\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./w_decorr/loss_mats/corr/graphs/\"+str(l_index)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "s = imp_decorr_bn.cpu().sort()[0].cpu().numpy()\n",
    "order = imp_decorr_bn.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max(), label=\"Estimated importance\")\n",
    "plt.title(\"Decorrelated (Taylor FO) for \"+str(l_index))\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "plt.xlabel(\"Neuron index\")\n",
    "plt.ylabel(\"Normalized importance\")\n",
    "plt.plot(loss_diff[order]/loss_diff.max(), label=\"Actual importance\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./w_decorr/loss_mats/decorr/graphs/\"+str(l_index)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = imp_decorr_bn.cpu().sort()[0].cpu().numpy()\n",
    "s = s/s.max()\n",
    "order = imp_decorr_bn.sort()[1].cpu().numpy()\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "loss_diff = (loss_diff[order]/loss_diff.max())\n",
    "ortho_rms = ((loss_diff - s)**2).sum()\n",
    "\n",
    "s = imp_corr_bn.cpu().sort()[0].cpu().numpy()\n",
    "s = s/s.max()\n",
    "order = imp_corr_bn.sort()[1].cpu().numpy()\n",
    "loss_diff = (loss_mat_corr - loss_base_corr).abs()\n",
    "loss_diff = (loss_diff[order]/loss_diff.max())\n",
    "\n",
    "base_rms = ((loss_diff - s)**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ortho_rms, base_rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rms_ortho = np.sqrt(np.array(rms_ortho) / np.array([64, 64, 128, 128, 256, 256, 512, 512, 512, 512]))\n",
    "# rms_base = np.sqrt(np.array(rms_base) / np.array([64, 64, 128, 128, 256, 256, 512, 512, 512, 512]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(np.linspace(0,30,10)-0.5, rms_ortho, label=\"Decorrelated network\")\n",
    "plt.bar(np.linspace(0,30,10)+0.5, rms_base, label=\"Correlated network\")\n",
    "plt.xlabel(\"Layer ID\")\n",
    "plt.ylabel(\"RMS\")\n",
    "plt.legend()\n",
    "plt.savefig(\"./w_decorr/loss_mats/rms.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20,5))\n",
    "\n",
    "s = imp_decorr_bn.cpu().sort()[0].cpu().numpy()\n",
    "order = imp_decorr_bn.sort()[1].cpu().numpy()\n",
    "axes[0].plot(s/s.max(), label=\"Estimated importance\")\n",
    "axes[0].set_title(\"Decorrelated Network (layer \"+str(l_index)+\")\")\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "axes[0].set_xlabel(\"Neuron index\")\n",
    "axes[0].set_ylabel(\"Normalized importance\")\n",
    "axes[0].plot(loss_diff[order]/loss_diff.max(), label=\"Actual importance\")\n",
    "axes[0].legend()\n",
    "\n",
    "s = imp_corr_bn.cpu().sort()[0].cpu().numpy()\n",
    "order = imp_corr_bn.sort()[1].cpu().numpy()\n",
    "axes[1].plot(s/s.max(), label=\"Estimated importance\")\n",
    "axes[1].set_title(\"Correlated Network (layer \"+str(l_index)+\")\")\n",
    "loss_diff = (loss_mat_corr - loss_base_corr).abs()\n",
    "axes[1].set_xlabel(\"Neuron index\")\n",
    "axes[1].set_ylabel(\"Normalized importance\")\n",
    "axes[1].plot(loss_diff[order]/loss_diff.max(), label=\"Actual importance\")\n",
    "axes[1].legend()\n",
    "\n",
    "plt.savefig(\"./w_decorr/loss_mats/subplots/\"+str(l_index)+\".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net-Slim Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_corr = net.features[l_index].weight.data.clone()\n",
    "np.corrcoef(scale_corr.cpu().numpy(), (loss_mat_corr - loss_base_corr).abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_decorr = net_decorr.features[l_index].weight.data.clone().abs()\n",
    "np.corrcoef((scale_decorr).cpu().numpy(), (loss_mat_decorr - loss_base_decorr).abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 based pruning Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_corr = net.features[l_index - 2].weight.data.clone()\n",
    "w_imp_corr = w_corr.pow(2).sum(dim=(1,2,3)).cpu()\n",
    "np.corrcoef(w_imp_corr.numpy(), (loss_mat_corr - loss_base_corr).abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_decorr = net_decorr.features[l_index - 2].weight.data.clone()\n",
    "w_imp_decorr = w_decorr.pow(2).sum(dim=(1,2,3)).cpu()\n",
    "w_imp_decorr = (w_imp_decorr - w_imp_decorr.min())\n",
    "w_imp_decorr = w_imp_decorr/w_imp_decorr.max()\n",
    "np.corrcoef(w_imp_decorr.numpy(), (loss_mat_decorr - loss_base_decorr).abs().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance plots Netslim Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "\n",
    "s = scale_corr.cpu().sort()[0].cpu().numpy()\n",
    "order = scale_corr.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max())\n",
    "plt.title(\"Correlated (Net-Slim)\")\n",
    "loss_diff = (loss_mat_corr - loss_base_corr).abs()\n",
    "plt.plot(loss_diff[order]/loss_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "\n",
    "s = scale_decorr.cpu().sort()[0].cpu().numpy()\n",
    "order = scale_decorr.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max())\n",
    "plt.title(\"Decorrelated (Net-Slim)\")\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "plt.plot(loss_diff[order]/loss_diff.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importance plots L2 train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "s = w_imp_corr.sort()[0].cpu().numpy()\n",
    "order = w_imp_corr.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max())\n",
    "plt.title(\"Correlated (L2)\")\n",
    "loss_diff = (loss_mat_corr - loss_base_corr).abs()\n",
    "plt.plot(loss_diff[order]/loss_diff.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20,5))\n",
    "s = w_imp_decorr.sort()[0].cpu().numpy()\n",
    "order = w_imp_decorr.sort()[1].cpu().numpy()\n",
    "plt.plot(s/s.max())\n",
    "plt.title(\"Decorrelated (L2)\")\n",
    "loss_diff = (loss_mat_decorr - loss_base_decorr).abs()\n",
    "plt.plot(loss_diff[order]/loss_diff.max())"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
