{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "import os\n",
    "from utils import progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomRotation(45),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "     ])\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "     ])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR100(root='./../data', train=True,\n",
    "                                        download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128,\n",
    "                                          shuffle=False, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./../data', train=False,\n",
    "                                       download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''VGG11/13/16/19 in Pytorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "cfg = {\n",
    "    'VGG11': [32, 32, 'M', 64, 64, 'M', 128, 128, 'M'],\n",
    "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, vgg_name):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg[vgg_name])\n",
    "        self.classifier = nn.Linear(512, 100)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.ReLU(inplace=True),\n",
    "                           nn.BatchNorm2d(x)]\n",
    "                in_channels = x\n",
    "        #layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def test():\n",
    "    net = VGG('VGG11')\n",
    "    x = torch.randn(2,3,32,32)\n",
    "    y = net(x)\n",
    "    print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w_diag():\n",
    "    \n",
    "    ### conv_ind == 0 ###\n",
    "    w_mat = net_ortho.features[0].weight\n",
    "    w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "    b_mat = net.features[0].bias\n",
    "    b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "    params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "    angle_mat = torch.matmul(torch.t(params), params)\n",
    "    L_diag = (angle_mat.diag().norm(1))\n",
    "    L_angle = (angle_mat.norm(1))\n",
    "    print(L_diag.cpu()/L_angle.cpu())\n",
    "\n",
    "    ### conv_ind != 0 ###\n",
    "    for conv_ind in [3, 7, 10, 14, 17, 21, 24, 28, 31]:\n",
    "        w_mat = net_ortho.features[conv_ind].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net.features[conv_ind].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(params, torch.t(params))\n",
    "        L_diag = (angle_mat.diag().norm(1))\n",
    "        L_angle = (angle_mat.norm(1))\n",
    "        print(L_diag.cpu()/L_angle.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = VGG('VGG13').to(device)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def net_train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "        \n",
    "def net_test(epoch):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    if acc > best_acc:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint')\n",
    "        torch.save(state, './checkpoint/ckpt.pth')\n",
    "        best_acc = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=5e-4, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    net_train(epoch)\n",
    "    net_test(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dict = torch.load('./checkpoint/ckpt.pth')\n",
    "net.load_state_dict(net_dict['net'])\n",
    "best_acc = net_dict['best_acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inner product training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_ortho = AlexNet(cfg).to(device)\n",
    "net_dict = torch.load('./checkpoint/ckpt.pth')\n",
    "net_ortho.load_state_dict(net_dict['net'])\n",
    "best_acc_ortho = net_dict['best_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_imp = {}\n",
    "\n",
    "for conv_ind in [0, 3, 7, 10, 14, 17, 21, 24, 28, 31]:\n",
    "    l_imp.update({conv_ind: net_ortho.features[conv_ind].bias.shape[0]})\n",
    "    \n",
    "normalizer = 0\n",
    "for key, val in l_imp.items():\n",
    "    normalizer += val\n",
    "for key, val in l_imp.items():\n",
    "    l_imp[key] = val / normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_test_ortho(epoch):\n",
    "    global best_acc_ortho\n",
    "    net_ortho.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net_ortho(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Save checkpoint.\n",
    "    acc = 100.*correct/total\n",
    "    print(acc)\n",
    "    if acc > best_acc_ortho:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net_ortho.state_dict(),\n",
    "            'best_acc': acc\n",
    "        }\n",
    "        if not os.path.isdir('ortho_checkpoint'):\n",
    "            os.mkdir('ortho_checkpoint')\n",
    "        torch.save(state, './ortho_checkpoint/ckpt.pth')\n",
    "        best_acc_ortho = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_train_ortho(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    net_ortho.train()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    angle_cost = 0.0\n",
    "            \n",
    "    for batch_idx, (inputs, labels) in enumerate(trainloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net_ortho(inputs)\n",
    "        L_angle = 0\n",
    "        \n",
    "        ### Conv_ind == 0 ###\n",
    "        w_mat = net_ortho.features[0].weight\n",
    "        w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "        b_mat = net_ortho.features[0].bias\n",
    "        b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "        params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "        angle_mat = torch.matmul(torch.t(params), params) - torch.eye(params.shape[1]).to(device)\n",
    "        L_angle += (l_imp[0])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "        \n",
    "        ### Conv_ind != 0 ###\n",
    "        for conv_ind in [3, 7, 10, 14, 17, 21, 24, 28, 31]:\n",
    "            w_mat = net_ortho.features[conv_ind].weight\n",
    "            w_mat1 = (w_mat.reshape(w_mat.shape[0],-1))\n",
    "            b_mat = net_ortho.features[conv_ind].bias\n",
    "            b_mat1 = (b_mat.reshape(b_mat.shape[0],-1))\n",
    "            params = torch.cat((w_mat1, b_mat1), dim=1)\n",
    "            angle_mat = torch.matmul(params, torch.t(params)) - torch.eye(w_mat.shape[0]).to(device)\n",
    "            L_angle += (l_imp[conv_ind])*(angle_mat).norm(1) #.norm().pow(2))\n",
    "    \n",
    "        Lc = criterion(outputs, labels)\n",
    "        loss = (1e-1)*(L_angle) + Lc\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        angle_cost += (L_angle).item()\n",
    "    \n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "            % (running_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    \n",
    "    print(\"angle_cost: \", angle_cost/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net_ortho.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):\n",
    "    net_train_ortho(epoch)\n",
    "    net_test_ortho(epoch)\n",
    "    w_diag(net_ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_dict = torch.load('./ortho_checkpoint/ckpt.pth')\n",
    "net_ortho.load_state_dict(net_dict['net'])\n",
    "best_acc_ortho = net_dict['best_acc']"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
